{"meta":{"title":"在线分享网","subtitle":"分享，成为你我之间的快乐！","description":"在线分享网是一个专门给程序员服务的博客，不像其它分享视频、图片、音乐的网站，这里主要分享一些技术博客与学习视频，为大家提供便利。","author":"HuiProgramer","url":"https://me.obey.fun"},"pages":[{"title":"分类","date":"2018-12-09T12:58:13.000Z","updated":"2018-12-10T09:38:43.328Z","comments":false,"path":"categories/index.html","permalink":"https://me.obey.fun/categories/index.html","excerpt":"","text":""},{"title":"标签","date":"2018-12-09T12:59:59.000Z","updated":"2018-12-10T09:38:43.448Z","comments":false,"path":"tags/index.html","permalink":"https://me.obey.fun/tags/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-01-05T06:30:13.000Z","updated":"2019-05-09T04:13:53.023Z","comments":false,"path":"links/index.html","permalink":"https://me.obey.fun/links/index.html","excerpt":"","text":"以下链接排名不分先后，感谢您的到来，友链申请 请移步此页面头像名称网站橙色的一亩三分地http://blog.talei.me/周宇峰的博客https://542869246.github.io/爱生活爱技术http://www.xioaxin12.xyz/QuanYi.Chenhttp://blog.chenquanyi.siteYomihttps://xczhello.gitee.io低调小熊猫https://aodeng.cc天堂芝士的个人博客https://www.godcheese.comRyan0up’S Bloghttps://ryanc.cc琅涯阁https://memento.net.cn/Inickhttp://inick.top/博采众长https://lruihao.cndocument.onreadystatechange=function(){\"complete\"==document.readyState&&wenkmTips.show(\"进入友情链接\")}"},{"title":"留言板","date":"2019-04-12T10:49:07.000Z","updated":"2019-05-18T08:06:25.513Z","comments":true,"path":"message/index.html","permalink":"https://me.obey.fun/message/index.html","excerpt":"","text":"功能介绍留言区是本站密切联系用户的重要桥梁，是公众向我站反映问题，提出意见、建议的一个重要渠道，是公众为我站不断升级完善的一个信息交流平台。网友可以通过在线分享网首页左上角的“留言板”专栏实时在线给我留言，本站定会在一个工作日内给您答复。 留言须知不得发表违反中华人民共和国宪法和法律、违反改革开放和四项基本原则的言论；不得发表造谣、诽谤他人的言论；不得发表未经证实的消息，亲身经历请注明；请勿发表任何形式的广告，企业推广产品或服务；本网站拥有发布、编辑、删除网上留言的权利，凡不符合本须知规定的留言将予以删除；留言者承担一切因留言行为而直接或间接引起的法律责任；如在本栏留言，即表明已阅读并接受了上述各项条款。document.onreadystatechange=function(){\"complete\"==document.readyState&&wenkmTips.show(\"进入留言板\")}"},{"title":"友链申请","date":"2019-01-05T06:42:16.000Z","updated":"2019-05-18T08:06:09.313Z","comments":true,"path":"apply/index.html","permalink":"https://me.obey.fun/apply/index.html","excerpt":"","text":"友链申请原则贵站不涉及黄，赌，毒，暴力等一切违法违背道德内容。贵站保持更新状态。本站有权删除长时间打不开的站点。友链提交之后，等待博主审核。审核通过后，本站会以邮件的方式回复您。本站友链信息名称：在线分享网网站：https://www.52share.online介绍：技术分享与学习交流头像：https://ws3.sinaimg.cn/large/006MOU0zgy1g19n0u9anzj30jg0kbabt.jpg申请友链格式名称：xxx网站：xxx.xxx头像：图片地址邮箱：xxx@xx.xx友情申请方式直接下方留言即可 通过右下角的聊天工具联系我 联系邮箱：HuiProgramer@outlook.com document.onreadystatechange=function(){\"complete\"==document.readyState&&wenkmTips.show(\"进入友链申请页面\")}"},{"title":"关于","date":"2018-12-09T13:00:09.000Z","updated":"2019-05-04T13:41:37.723Z","comments":false,"path":"about/index.html","permalink":"https://me.obey.fun/about/index.html","excerpt":"","text":"基础信息QQ：2101348712 E-Mail：huiprogramer@outlook.comGithub：https://github.com/HuiProgramer坐标：湘潭职业：大学生热衷方向JavaPythonHTML5/CSSJavaScriptC/C++Golang兴趣爱好玩游戏写代码听歌以及各种能让我分泌多巴胺的事情免责声明在线分享网提供的所有内容仅供学习、分享与交流，我们不保证内容的正确性，当您通过使用本站内容随之而来的风险与本站无关，当您使用本站时，代表你已接受本站的免费声明和隐私原则等条款。博客简介在线分享网是一个专门给程序员服务的博客，不像其它分享视频、图片、音乐的网站，这里主要分享一些技术博客与学习视频，为大家提供便利。本站公众号更新日志 [2019/4/12] 更新新增公众号网站部分加载优化取消音乐自动播放新增返回顶部卡通新增留言板 [2019/3/07] 更新新增评分系统修改来必力评论为畅言 [2019/3/04] 更新增加归档，标签，分类统计修改标题和有序、无序列表样式 [2019/3/02] 更新修改列表和标题样式网站正式改名为在线分享网 [2019/2/27] 更新更改友情链接样式手机端不显示粒子效果 [2019/2/25] 更新修改热度排序样式底部增加网站运行时间移除needmoreshare2分享样式修改标签云样式增加动态标题 [2019/1/15] 更新新增页面热度排序 [2019/1/13] 更新新增hexo-neat插件实现静态资源压缩 [2019/1/9] 更新修改404页面新增底部❤跳动动画 [2019/1/8] 更新修改时间轴为彩色修改底部心型为粉色 [2019/1/5] 更新写about页面调整友情链接为推荐阅读新增友情链接页面（解决手机端无法看见友情链接问题）在Coding上备份此博客 [2018/12/29] 更新新增sitemap.xml [2018/12/27] 更新新增一些小部件移除hexo底部显示新增网站访问量和站内字数统计 [2018/12/25] 更新移除学校官网选项（测试自己写的一个网页放在博客里）播放器更换 [2018/12/23] 更新新增友情链接面板（现已改为推荐阅读）新增鼠标放在头像上旋转新增加载文章显示进度条 [2018/12/22] 更新新增网易云播放器插件给每篇文章增加边框 [2018/12/21] 更新移除小播放器部件新增DaoVoice实现博客内部聊天修改点击特效为爆炸效果 [2018/12/20] 更新新增文章分享按钮新增全文结束语句新增小播放器部件新增头像为圆形 [2018/12/19] 更新新增热度显示新增字数统计和阅读时长修改评论系统为来必力 [2018/12/18] 更新新增学校官网页面（大一的一个期末考核）新增RSS订阅新增阅读全文按钮新增动态背景修改看板娘新增本地搜索 [2018/12/17] 更新修改主题为next添加右上角Github猫。 [2018/12/15] 更新新增看板娘新增网站统计和不蒜子访客统计新增代码高亮 [2018/12/11] 更新新增评论功能（valine）新增分类设置新增友链页面 [2018/12/05] 更新新增爱心点击特效添加打赏功能 [2018/11/27] 更新修改主题为snippet. [2018/11/25] 更新搭建博客document.onreadystatechange=function(){\"complete\"==document.readyState&&wenkmTips.show(\"进入关于页面\")}"},{"title":"文章热度排序","date":"2019-01-15T06:54:12.000Z","updated":"2019-10-28T05:28:50.429Z","comments":false,"path":"topx/index.html","permalink":"https://me.obey.fun/topx/index.html","excerpt":"","text":"document.onreadystatechange=function(){\"complete\"==document.readyState&&wenkmTips.show(\"进入文章热度排序页面\")}AV.initialize(\"TCcAB5wC7Rjx4Xe9aFUYiMUU-gzGzoHsz\",\"pC764tcMRXbraCg5anMgT3QF\")var num=30,time=0,title=\"\",url=\"\",query=new AV.Query(\"Counter\");query.notEqualTo(\"id\",0),query.descending(\"time\"),query.limit(num),query.find().then(function(r){for(var e=0;e"}],"posts":[{"title":"Activiti7工作流详解","slug":"Activiti7工作流详解","date":"2021-03-17T09:16:26.000Z","updated":"2021-03-17T11:34:30.322Z","comments":true,"path":"Activiti7工作流详解.html","link":"","permalink":"https://me.obey.fun/Activiti7工作流详解.html","excerpt":"","text":"工作流介绍概念工作流(Workflow)，就是通过计算机对业务流程自动化执行管理。它主要解决的是“使在多个参与者之间按照某种预定义的规则自动进行传递文档、信息或任务的过程，从而实现某个预期的业务目标，或者促使此目标的实现”。工作流系统一个软件系统中具有工作流的功能，我们把它称为工作流系统，一个系统中工作流的功能是什么？就是对系统的业务流程进行自动化管理，所以工作流是建立在业务流程的基础上，所以一个软件的系统核心根本上还是系统的业务流程，工作流只是协助进行业务流程管理。即使没有工作流业务系统也可以开发运行，只不过有了工作流可以更好的管理业务流程，提高系统的可扩展性。适用行业消费品行业，制造业，电信服务业，银证险等金融服务业，物流服务业，物业服务业，物业管理，大中型进出口贸易公司，政府事业机构，研究院所及教育服务业等，特别是大的跨国企业和集团公司。具体应用1、关键业务流程：订单、报价处理、合同审核、客户电话处理、供应链管理等2、行政管理类:出差申请、加班申请、请假申请、用车申请、各种办公用品申请、购买申请、日报周报等凡是原来手工流转处理的行政表单。3、人事管理类：员工培训安排、绩效考评、职位变动处理、员工档案信息管理等。4、财务相关类：付款请求、应收款处理、日常报销处理、出差报销、预算和计划申请等。5、客户服务类：客户信息管理、客户投诉、请求处理、售后服务管理等。6、特殊服务类：ISO系列对应流程、质量管理对应流程、产品数据信息管理、贸易公司报关处理、物流公司货物跟踪处理等各种通过表单逐步手工流转完成的任务均可应用工作流软件自动规范地实施。实现方式在没有专门的工作流引擎之前，我们之前为了实现流程控制，通常的做法就是采用状态字段的值来跟踪流程的变化情况。这样不用角色的用户，通过状态字段的取值来决定记录是否显示。针对有权限可以查看的记录，当前用户根据自己的角色来决定审批是否合格的操作。如果合格将状态字段设置一个值，来代表合格；当然如果不合格也需要设置一个值来代表不合格的情况。这是一种最为原始的方式。通过状态字段虽然做到了流程控制，但是当我们的流程发生变更的时候，这种方式所编写的代码也要进行调整。那么有没有专业的方式来实现工作流的管理呢？并且可以做到业务流程变化之后，我们的程序可以不用改变，如果可以实现这样的效果，那么我们的业务系统的适应能力就得到了极大提升。Activiti7概述介绍Alfresco软件在2010年5月17日宣布Activiti业务流程管理（BPM）开源项目的正式启动，其首席架构师由业务流程管理BPM的专家 Tom Baeyens担任，Tom Baeyens就是原来jbpm的架构师，而jbpm是一个非常有名的工作流引擎，当然activiti也是一个工作流引擎。Activiti是一个工作流引擎， activiti可以将业务系统中复杂的业务流程抽取出来，使用专门的建模语言BPMN2.0进行定义，业务流程按照预先定义的流程进行执行，实现了系统的流程由activiti进行管理，减少业务系统由于流程变更进行系统升级改造的工作量，从而提高系统的健壮性，同时也减少了系统开发维护成本。官方网站：https://www.activiti.org目前最新版本：Activiti7.1.0-M11BPMBPM（Business Process Management），即业务流程管理，是一种规范化的构造端到端的业务流程，以持续的提高组织业务效率。常见商业管理教育如EMBA、MBA等均将BPM包含在内。BPM软件BPM软件就是根据企业中业务环境的变化，推进人与人之间、人与系统之间以及系统与系统之间的整合及调整的经营方法与解决方案的IT工具。通过BPM软件对企业内部及外部的业务流程的整个生命周期进行建模、自动化、管理监控和优化，使企业成本降低，利润得以大幅提升。BPM软件在企业中应用领域广泛，凡是有业务流程的地方都可以BPM软件进行管理，比如企业人事办公管理、采购流程管理、公文审批流程管理、财务管理等。BPMNBPMN（Business Process Model AndNotation）- 业务流程模型和符号 是由BPMI（BusinessProcess Management Initiative）开发的一套标准的业务流程建模符号，使用BPMN提供的符号可以创建业务流程。2004年5月发布了BPMN1.0规范.BPMI于2005年9月并入OMG（The Object Management Group对象管理组织)组织。OMG于2011年1月发布BPMN2.0的最终版本。具体发展历史如下:BPMN 是目前被各 BPM 厂商广泛接受的 BPM 标准。Activiti 就是使用 BPMN 2.0 进行流程建模、流程执行管理，它包括很多的建模符号，比如：Event用一个圆圈表示，它是流程中运行过程中发生的事情。活动用圆角矩形表示，一个流程由一个活动或多个活动组成Bpmn图形其实是通过xml表示业务流程，上边的.bpmn文件使用文本编辑器打开：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;definitions xmlns=\"http://www.omg.org/spec/BPMN/20100524/MODEL\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:activiti=\"http://activiti.org/bpmn\" xmlns:bpmndi=\"http://www.omg.org/spec/BPMN/20100524/DI\" xmlns:omgdc=\"http://www.omg.org/spec/DD/20100524/DC\" xmlns:omgdi=\"http://www.omg.org/spec/DD/20100524/DI\" typeLanguage=\"http://www.w3.org/2001/XMLSchema\" expressionLanguage=\"http://www.w3.org/1999/XPath\" targetNamespace=\"http://www.activiti.org/test\"&gt; &lt;process id=\"myProcess\" name=\"My process\" isExecutable=\"true\"&gt; &lt;startEvent id=\"startevent1\" name=\"Start\"&gt;&lt;/startEvent&gt; &lt;userTask id=\"usertask1\" name=\"创建请假单\"&gt;&lt;/userTask&gt; &lt;sequenceFlow id=\"flow1\" sourceRef=\"startevent1\" targetRef=\"usertask1\"&gt;&lt;/sequenceFlow&gt; &lt;userTask id=\"usertask2\" name=\"部门经理审核\"&gt;&lt;/userTask&gt; &lt;sequenceFlow id=\"flow2\" sourceRef=\"usertask1\" targetRef=\"usertask2\"&gt;&lt;/sequenceFlow&gt; &lt;userTask id=\"usertask3\" name=\"人事复核\"&gt;&lt;/userTask&gt; &lt;sequenceFlow id=\"flow3\" sourceRef=\"usertask2\" targetRef=\"usertask3\"&gt;&lt;/sequenceFlow&gt; &lt;endEvent id=\"endevent1\" name=\"End\"&gt;&lt;/endEvent&gt; &lt;sequenceFlow id=\"flow4\" sourceRef=\"usertask3\" targetRef=\"endevent1\"&gt;&lt;/sequenceFlow&gt; &lt;/process&gt; &lt;bpmndi:BPMNDiagram id=\"BPMNDiagram_myProcess\"&gt; &lt;bpmndi:BPMNPlane bpmnElement=\"myProcess\" id=\"BPMNPlane_myProcess\"&gt; &lt;bpmndi:BPMNShape bpmnElement=\"startevent1\" id=\"BPMNShape_startevent1\"&gt; &lt;omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"130.0\" y=\"160.0\"&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=\"usertask1\" id=\"BPMNShape_usertask1\"&gt; &lt;omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"210.0\" y=\"150.0\"&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=\"usertask2\" id=\"BPMNShape_usertask2\"&gt; &lt;omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"360.0\" y=\"150.0\"&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=\"usertask3\" id=\"BPMNShape_usertask3\"&gt; &lt;omgdc:Bounds height=\"55.0\" width=\"105.0\" x=\"510.0\" y=\"150.0\"&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNShape bpmnElement=\"endevent1\" id=\"BPMNShape_endevent1\"&gt; &lt;omgdc:Bounds height=\"35.0\" width=\"35.0\" x=\"660.0\" y=\"160.0\"&gt;&lt;/omgdc:Bounds&gt; &lt;/bpmndi:BPMNShape&gt; &lt;bpmndi:BPMNEdge bpmnElement=\"flow1\" id=\"BPMNEdge_flow1\"&gt; &lt;omgdi:waypoint x=\"165.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=\"210.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=\"flow2\" id=\"BPMNEdge_flow2\"&gt; &lt;omgdi:waypoint x=\"315.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=\"360.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=\"flow3\" id=\"BPMNEdge_flow3\"&gt; &lt;omgdi:waypoint x=\"465.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=\"510.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;bpmndi:BPMNEdge bpmnElement=\"flow4\" id=\"BPMNEdge_flow4\"&gt; &lt;omgdi:waypoint x=\"615.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;omgdi:waypoint x=\"660.0\" y=\"177.0\"&gt;&lt;/omgdi:waypoint&gt; &lt;/bpmndi:BPMNEdge&gt; &lt;/bpmndi:BPMNPlane&gt; &lt;/bpmndi:BPMNDiagram&gt;&lt;/definitions&gt;使用步骤部署activitiActiviti是一个工作流引擎（其实就是一堆jar包API），业务系统访问(操作)activiti的接口，就可以方便的操作流程相关数据，这样就可以把工作流环境与业务系统的环境集成在一起。流程定义使用activiti流程建模工具(activity-designer)定义业务流程(.bpmn文件) 。.bpmn文件就是业务流程定义文件，通过xml定义业务流程。流程定义部署activiti部署业务流程定义（.bpmn文件）。使用activiti提供的api把流程定义内容存储起来，在Activiti执行过程中可以查询定义的内容Activiti执行把流程定义内容存储在数据库中启动一个流程实例流程实例也叫：ProcessInstance启动一个流程实例表示开始一次业务流程的运行。在员工请假流程定义部署完成后，如果张三要请假就可以启动一个流程实例，如果李四要请假也启动一个流程实例，两个流程的执行互相不影响。用户查询待办任务(Task)因为现在系统的业务流程已经交给activiti管理，通过activiti就可以查询当前流程执行到哪了，当前用户需要办理什么任务了，这些activiti帮我们管理了，而不需要开发人员自己编写在sql语句查询。用户办理任务用户查询待办任务后，就可以办理某个任务，如果这个任务办理完成还需要其它用户办理，比如采购单创建后由部门经理审核，这个过程也是由activiti帮我们完成了。流程结束当任务办理完成没有下一个任务结点了，这个流程实例就完成了。Activiti环境开发环境Jdk1.8或以上版本Mysql 5及以上的版本Tomcat8.5IDEA注意：activiti的流程定义工具插件可以安装在IDEA下，也可以安装在Eclipse工具下Activiti环境我们使用：Activiti7.0.0.Beta1 默认支持spring5下载activiti7Activiti下载地址：http://activiti.org/download.html ，Maven的依赖如下：1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-dependencies&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;Database：activiti运行需要有数据库的支持，支持的数据库有：h2, mysql, oracle, postgres, mssql, db2。流程设计器IDEA下安装在IDEA的File菜单中找到子菜单”Settings”,后面我们再选择左侧的“plugins”菜单，如下图所示：此时我们就可以搜索到actiBPM插件，它就是Activiti Designer的IDEA版本，我们点击Install安装。安装好后，页面如下：提示需要重启idea，点击重启。重启完成后，再次打开Settings 下的 Plugins（插件列表），点击右侧的Installed（已安装的插件），在列表中看到actiBPM，就说明已经安装成功了，如下图所示：Activiti的数据库支持Activiti 在运行时需要数据库的支持，使用25张表，把流程定义节点内容读取到数据库表中，以供后续使用。Activiti 支持的数据库activiti 支持的数据库和版本如下：数据库类型版本JDBC连接示例说明h21.3.168jdbc:h2:tcp://localhost/activiti默认配置的数据库mysql5.1.21jdbc:mysql://localhost:3306/activiti?autoReconnect=true使用 mysql-connector-java 驱动测试oracle11.2.0.1.0jdbc:oracle:thin:@localhost:1521:xepostgres8.1jdbc:postgresql://localhost:5432/activitidb2DB2 10.1 using db2jcc4jdbc:db2://localhost:50000/activitimssql2008 using sqljdbc4jdbc:sqlserver://localhost:1433/activiti在MySQL生成表创建数据库创建 mysql 数据库 activiti （名字任意）：CREATE DATABASE activiti DEFAULT CHARACTER SET utf8;使用java代码生成表创建 java 工程使用idea 创建 java 的maven工程，取名：activiti01。加入 maven 依赖的坐标（jar 包）首先需要在 java 工程中加入 ProcessEngine 所需要的 jar 包，包括：1) activiti-engine-7.0.0.beta1.jar2) activiti 依赖的 jar 包： mybatis、 alf4j、 log4j 等3) activiti 依赖的 spring 包4) mysql数据库驱动5) 第三方数据连接池 dbcp6) 单元测试 Junit-4.12.jar我们使用 maven 来实现项目的构建，所以应当导入这些 jar 所对应的坐标到 pom.xml 文件中。完整的依赖内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586&lt;properties&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt; &lt;activiti.version&gt;7.0.0.Beta1&lt;/activiti.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-engine&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 模型处理 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-model&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 转换 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-converter&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn json数据转换 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-json-converter&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- bpmn 布局 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-layout&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- activiti 云支持 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti.cloud&lt;/groupId&gt; &lt;artifactId&gt;activiti-cloud-services-api&lt;/artifactId&gt; &lt;version&gt;$&#123;activiti.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mysql驱动 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.40&lt;/version&gt; &lt;/dependency&gt; &lt;!-- mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 链接池 --&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;添加log4j日志配置我们使用log4j日志包，可以对日志进行配置在resources 下创建log4j.properties123456789101112131415# Set root category priority to INFO and its only appender to CONSOLE.#log4j.rootCategory=INFO, CONSOLE debug info warn error fatallog4j.rootCategory=debug, CONSOLE, LOGFILE# Set the enterprise logger category to FATAL and its only appender to CONSOLE.log4j.logger.org.apache.axis.enterprise=FATAL, CONSOLE# CONSOLE is set to be a ConsoleAppender using a PatternLayout.log4j.appender.CONSOLE=org.apache.log4j.ConsoleAppenderlog4j.appender.CONSOLE.layout=org.apache.log4j.PatternLayoutlog4j.appender.CONSOLE.layout.ConversionPattern=%d&#123;ISO8601&#125; %-6r[%15.15t] %-5p %30.30c %x - %m\\n# LOGFILE is set to be a File appender using a PatternLayout.log4j.appender.LOGFILE=org.apache.log4j.FileAppenderlog4j.appender.LOGFILE.File=f:\\act\\activiti.loglog4j.appender.LOGFILE.Append=truelog4j.appender.LOGFILE.layout=org.apache.log4j.PatternLayoutlog4j.appender.LOGFILE.layout.ConversionPattern=%d&#123;ISO8601&#125; %-6r[%15.15t] %-5p %30.30c %x - %m\\n添加activiti配置文件我们使用activiti提供的默认方式来创建mysql的表。默认方式的要求是在 resources 下创建 activiti.cfg.xml 文件，注意：默认方式目录和文件名不能修改，因为activiti的源码中已经设置，到固定的目录读取固定文件名的文件。123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\"xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"xmlns:context=\"http://www.springframework.org/schema/context\"xmlns:tx=\"http://www.springframework.org/schema/tx\"xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd\"&gt;&lt;/beans&gt;在 activiti.cfg.xml 中进行配置默认方式要在在activiti.cfg.xml中bean的名字叫processEngineConfiguration，名字不可修改在这里有2中配置方式：一种是单独配置数据源，一种是不单独配置数据源直接配置processEngineConfigurationprocessEngineConfiguration 用来创建 ProcessEngine，在创建 ProcessEngine 时会执行数据库的操作。1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!-- 默认id对应的值 为processEngineConfiguration --&gt; &lt;!-- processEngine Activiti的流程引擎 --&gt; &lt;bean id=\"processEngineConfiguration\" class=\"org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\"&gt; &lt;property name=\"jdbcDriver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///activiti\"/&gt; &lt;property name=\"jdbcUsername\" value=\"root\"/&gt; &lt;property name=\"jdbcPassword\" value=\"123456\"/&gt; &lt;!-- activiti数据库表处理策略 --&gt; &lt;property name=\"databaseSchemaUpdate\" value=\"true\"/&gt; &lt;/bean&gt;&lt;/beans&gt;配置数据源后，在processEngineConfiguration 引用首先配置数据源123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;!-- 这里可以使用 链接池 dbcp--&gt; &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///activiti\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"123456\" /&gt; &lt;property name=\"maxActive\" value=\"3\" /&gt; &lt;property name=\"maxIdle\" value=\"1\" /&gt; &lt;/bean&gt; &lt;bean id=\"processEngineConfiguration\" class=\"org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\"&gt; &lt;!-- 引用数据源 上面已经设置好了--&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;!-- activiti数据库表处理策略 --&gt; &lt;property name=\"databaseSchemaUpdate\" value=\"true\"/&gt; &lt;/bean&gt;&lt;/beans&gt;java类编写程序生成表创建一个测试类，调用activiti的工具类，生成acitivti需要的数据库表。直接使用activiti提供的工具类ProcessEngines，会默认读取classpath下的activiti.cfg.xml文件，读取其中的数据库配置，创建 ProcessEngine，在创建ProcessEngine 时会自动创建表。代码如下：1234567891011121314151617package fun.obey.activiti01.test;import org.activiti.engine.ProcessEngine;import org.activiti.engine.ProcessEngineConfiguration;import org.junit.Test;public class TestDemo &#123; /** * 生成 activiti的数据库表 */ @Test public void testCreateDbTable() &#123; //使用classpath下的activiti.cfg.xml中的配置创建processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); System.out.println(processEngine); &#125;&#125;说明：1、运行以上程序段即可完成 activiti 表创建，通过改变 activiti.cfg.xml 中databaseSchemaUpdate 参数的值执行不同的数据表处理策略。2 、 上 边 的 方法 getDefaultProcessEngine方法在执行时，从activiti.cfg.xml 中找固定的名称 processEngineConfiguration 。在测试程序执行过程中，idea的控制台会输出日志，说明程序正在创建数据表，类似如下,注意红线内容：执行完成后我们查看数据库， 创建了 25 张表，结果如下：到这，我们就完成activiti运行需要的数据库和表的创建。表结构介绍表的命名规则和作用看到刚才创建的表，我们发现Activiti 的表都以 ACT_ 开头。第二部分是表示表的用途的两个字母标识。 用途也和服务的 API 对应。ACT_RE ：’RE’表示 repository。 这个前缀的表包含了流程定义和流程静态资源 （图片，规则，等等）。ACT_RU：’RU’表示 runtime。 这些运行时的表，包含流程实例，任务，变量，异步任务，等运行中的数据。 Activiti 只在流程实例执行过程中保存这些数据， 在流程结束时就会删除这些记录。 这样运行时表可以一直很小速度很快。ACT_HI：’HI’表示 history。 这些表包含历史数据，比如历史流程实例， 变量，任务等等。ACT_GE ： GE 表示 general。 通用数据， 用于不同场景下Activiti数据表介绍表分类表名解释一般数据[ACT_GE_BYTEARRAY]通用的流程定义和流程资源[ACT_GE_PROPERTY]系统相关属性流程历史记录[ACT_HI_ACTINST]历史的流程实例[ACT_HI_ATTACHMENT]历史的流程附件[ACT_HI_COMMENT]历史的说明性信息[ACT_HI_DETAIL]历史的流程运行中的细节信息[ACT_HI_IDENTITYLINK]历史的流程运行过程中用户关系[ACT_HI_PROCINST]历史的流程实例[ACT_HI_TASKINST]历史的任务实例[ACT_HI_VARINST]历史的流程运行中的变量信息流程定义表[ACT_RE_DEPLOYMENT]部署单元信息[ACT_RE_MODEL]模型信息[ACT_RE_PROCDEF]已部署的流程定义运行实例表[ACT_RU_EVENT_SUBSCR]运行时事件[ACT_RU_EXECUTION]运行时流程执行实例[ACT_RU_IDENTITYLINK]运行时用户关系信息，存储任务节点与参与者的相关信息[ACT_RU_JOB]运行时作业[ACT_RU_TASK]运行时任务[ACT_RU_VARIABLE]运行时变量表Activiti类关系图上面我们完成了Activiti数据库表的生成，java代码中我们调用Activiti的工具类，下面来了解Activiti的类关系类关系图在新版本中，我们通过实验可以发现IdentityService，FormService两个Serivce都已经删除了。所以后面我们对于这两个Service也不讲解了，但老版本中还是有这两个Service，同学们需要了解一下activiti.cfg.xmlactiviti的引擎配置文件，包括：ProcessEngineConfiguration的定义、数据源定义、事务管理器等，此文件其实就是一个spring配置文件。流程引擎配置类流程引擎的配置类（ProcessEngineConfiguration），通过ProcessEngineConfiguration可以创建工作流引擎ProceccEngine，常用的两种方法如下：StandaloneProcessEngineConfiguration使用StandaloneProcessEngineConfigurationActiviti可以单独运行，来创建ProcessEngine，Activiti会自己处理事务。配置文件方式：通常在activiti.cfg.xml配置文件中定义一个id为 processEngineConfiguration 的bean.方法如下：1234567891011121314&lt;bean id=\"processEngineConfiguration\" class=\"org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\"&gt; &lt;!--配置数据库相关的信息--&gt; &lt;!--数据库驱动--&gt; &lt;property name=\"jdbcDriver\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;!--数据库链接--&gt; &lt;property name=\"jdbcUrl\" value=\"jdbc:mysql:///activiti\"/&gt; &lt;!--数据库用户名--&gt; &lt;property name=\"jdbcUsername\" value=\"root\"/&gt; &lt;!--数据库密码--&gt; &lt;property name=\"jdbcPassword\" value=\"123456\"/&gt; &lt;!--actviti数据库表在生成时的策略 true - 如果数据库中已经存在相应的表，那么直接使用，如果不存在，那么会创建--&gt; &lt;property name=\"databaseSchemaUpdate\" value=\"true\"/&gt; &lt;/bean&gt;还可以加入连接池:12345678910111213141516171819202122232425262728&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsdhttp://www.springframework.org/schema/contexhttp://www.springframework.org/schema/context/spring-context.xsdhttp://www.springframework.org/schema/txhttp://www.springframework.org/schema/tx/spring-tx.xsd\"&gt; &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql:///activiti\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;property name=\"maxActive\" value=\"3\"/&gt; &lt;property name=\"maxIdle\" value=\"1\"/&gt; &lt;/bean&gt; &lt;!--在默认方式下 bean的id 固定为 processEngineConfiguration--&gt; &lt;bean id=\"processEngineConfiguration\" class=\"org.activiti.engine.impl.cfg.StandaloneProcessEngineConfiguration\"&gt; &lt;!--引入上面配置好的 链接池--&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!--actviti数据库表在生成时的策略 true - 如果数据库中已经存在相应的表，那么直接使用，如果不存在，那么会创建--&gt; &lt;property name=\"databaseSchemaUpdate\" value=\"true\"/&gt; &lt;/bean&gt;&lt;/beans&gt;SpringProcessEngineConfiguration通过org.activiti.spring.SpringProcessEngineConfiguration 与Spring整合。创建spring与activiti的整合配置文件：activity-spring.cfg.xml（名称可修改）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.1.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-3.1.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.1.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.1.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-3.1.xsd \"&gt; &lt;!-- 工作流引擎配置bean --&gt; &lt;bean id=\"processEngineConfiguration\" class=\"org.activiti.spring.SpringProcessEngineConfiguration\"&gt; &lt;!-- 数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;!-- 使用spring事务管理器 --&gt; &lt;property name=\"transactionManager\" ref=\"transactionManager\" /&gt; &lt;!-- 数据库策略 --&gt; &lt;property name=\"databaseSchemaUpdate\" value=\"drop-create\" /&gt; &lt;!-- activiti的定时任务关闭 --&gt; &lt;property name=\"jobExecutorActivate\" value=\"false\" /&gt; &lt;/bean&gt; &lt;!-- 流程引擎 --&gt; &lt;bean id=\"processEngine\" class=\"org.activiti.spring.ProcessEngineFactoryBean\"&gt; &lt;property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\" /&gt; &lt;/bean&gt; &lt;!-- 资源服务service --&gt; &lt;bean id=\"repositoryService\" factory-bean=\"processEngine\" factory-method=\"getRepositoryService\" /&gt; &lt;!-- 流程运行service --&gt; &lt;bean id=\"runtimeService\" factory-bean=\"processEngine\" factory-method=\"getRuntimeService\" /&gt; &lt;!-- 任务管理service --&gt; &lt;bean id=\"taskService\" factory-bean=\"processEngine\" factory-method=\"getTaskService\" /&gt; &lt;!-- 历史管理service --&gt; &lt;bean id=\"historyService\" factory-bean=\"processEngine\" factory-method=\"getHistoryService\" /&gt; &lt;!-- 用户管理service --&gt; &lt;bean id=\"identityService\" factory-bean=\"processEngine\" factory-method=\"getIdentityService\" /&gt; &lt;!-- 引擎管理service --&gt; &lt;bean id=\"managementService\" factory-bean=\"processEngine\" factory-method=\"getManagementService\" /&gt; &lt;!-- 数据源 --&gt; &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/activiti\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"mysql\" /&gt; &lt;property name=\"maxActive\" value=\"3\" /&gt; &lt;property name=\"maxIdle\" value=\"1\" /&gt; &lt;/bean&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt;&lt;/tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"insert*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"find*\" propagation=\"SUPPORTS\" read-only=\"true\" /&gt; &lt;tx:method name=\"get*\" propagation=\"SUPPORTS\" read-only=\"true\" /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 切面，根据具体项目修改切点配置 --&gt; &lt;aop:config proxy-target-class=\"true\"&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut=\"execution(* com.itheima.ihrm.service.impl.*.(..))\"* /&gt; &lt;/aop:config&gt;&lt;/beans&gt;创建processEngineConfiguration1ProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(\"activiti.cfg.xml\")​ 上边的代码要求activiti.cfg.xml中必须有一个processEngineConfiguration的bean也可以使用下边的方法，更改bean 的名字：1ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(String resource, String beanName);工作流引擎创建工作流引擎（ProcessEngine），相当于一个门面接口，通过ProcessEngineConfiguration创建processEngine，通过ProcessEngine创建各个service接口。默认创建方式将activiti.cfg.xml文件名及路径固定，且activiti.cfg.xml文件中有 processEngineConfiguration的配置， 可以使用如下代码创建processEngine:123//直接使用工具类 ProcessEngines，使用classpath下的activiti.cfg.xml中的配置创建processEngineProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();System.out.println(processEngine);一般创建方式1234//先构建ProcessEngineConfigurationProcessEngineConfiguration configuration = ProcessEngineConfiguration.createProcessEngineConfigurationFromResource(\"activiti.cfg.xml\");//通过ProcessEngineConfiguration创建ProcessEngine，此时会创建数据库ProcessEngine processEngine = configuration.buildProcessEngine();Servcie服务接口Service是工作流引擎提供用于进行工作流部署、执行、管理的服务接口，我们使用这些接口可以就是操作服务对应的数据表Service创建方式通过ProcessEngine创建Service方式如下：123RuntimeService runtimeService = processEngine.getRuntimeService();RepositoryService repositoryService = processEngine.getRepositoryService();TaskService taskService = processEngine.getTaskService();4.5.2 Service总览service名称service作用RepositoryServiceactiviti的资源管理类RuntimeServiceactiviti的流程运行管理类TaskServiceactiviti的任务管理类HistoryServiceactiviti的历史管理类ManagerServiceactiviti的引擎管理类简单介绍：RepositoryService是activiti的资源管理类，提供了管理和控制流程发布包和流程定义的操作。使用工作流建模工具设计的业务流程图需要使用此service将流程定义文件的内容部署到计算机。除了部署流程定义以外还可以：查询引擎中的发布包和流程定义。暂停或激活发布包，对应全部和特定流程定义。 暂停意味着它们不能再执行任何操作了，激活是对应的反向操作。获得多种资源，像是包含在发布包里的文件， 或引擎自动生成的流程图。获得流程定义的pojo版本， 可以用来通过java解析流程，而不必通过xml。RuntimeServiceActiviti的流程运行管理类。可以从这个服务类中获取很多关于流程执行相关的信息TaskServiceActiviti的任务管理类。可以从这个类中获取任务的信息。HistoryServiceActiviti的历史管理类，可以查询历史信息，执行流程时，引擎会保存很多数据（根据配置），比如流程实例启动时间，任务的参与者， 完成任务的时间，每个流程实例的执行路径，等等。 这个服务主要通过查询功能来获得这些数据。ManagementServiceActiviti的引擎管理类，提供了对 Activiti 流程引擎的管理和维护功能，这些功能不在工作流驱动的应用程序中使用，主要用于 Activiti 系统的日常维护。Activiti入门在本章内容中，我们来创建一个Activiti工作流，并启动这个流程。创建Activiti工作流主要包含以下几步：1、定义流程，按照BPMN的规范，使用流程定义工具，用流程符号把整个流程描述出来2、部署流程，把画好的流程定义文件，加载到数据库中，生成表的数据3、启动流程，使用java代码来操作数据库表中的内容流程符号BPMN 2.0是业务流程建模符号2.0的缩写。它由Business Process Management Initiative这个非营利协会创建并不断发展。作为一种标识，BPMN 2.0是使用一些符号来明确业务流程设计流程图的一整套符号规范，它能增进业务建模时的沟通效率。目前BPMN2.0是最新的版本，它用于在BPM上下文中进行布局和可视化的沟通。接下来我们先来了解在流程设计中常见的 符号。BPMN2.0的基本符合主要包含：事件 Event活动 Activity活动是工作或任务的一个通用术语。一个活动可以是一个任务，还可以是一个当前流程的子处理流程； 其次，你还可以为活动指定不同的类型。常见活动如下：网关 GateWay网关用来处理决策，有几种常用网关需要了解：排他网关 (x)——只有一条路径会被选择。流程执行到该网关时，按照输出流的顺序逐个计算，当条件的计算结果为true时，继续执行当前网关的输出流；​ 如果多条线路计算结果都是 true，则会执行第一个值为 true 的线路。如果所有网关计算结果没有true，则引擎会抛出异常。​ 排他网关需要和条件顺序流结合使用，default 属性指定默认顺序流，当所有的条件不满足时会执行默认顺序流。并行网关 (+)——所有路径会被同时选择​ 拆分 —— 并行执行所有输出顺序流，为每一条顺序流创建一个并行执行线路。​ 合并 —— 所有从并行网关拆分并执行完成的线路均在此等候，直到所有的线路都执行完成才继续向下执行。包容网关 (+)—— 可以同时执行多条线路，也可以在网关上设置条件​ 拆分 —— 计算每条线路上的表达式，当表达式计算结果为true时，创建一个并行线路并继续执行​ 合并 —— 所有从并行网关拆分并执行完成的线路均在此等候，直到所有的线路都执行完成才继续向下执行。事件网关 (+)—— 专门为中间捕获事件设置的，允许设置多个输出流指向多个不同的中间捕获事件。当流程执行到事件网关后，流程处于等待状态，需要等待抛出事件才能将等待状态转换为活动状态。流向 Flow流是连接两个流程节点的连线。常见的流向包含以下几种：流程设计器使用Activiti-Designer使用Palette（画板）在idea中安装插件即可使用，画板中包括以下结点：Connection—连接Event—事件Task—任务Gateway—网关Container—容器Boundary event—边界事件Intermediate event- -中间事件流程图设计完毕保存生成.bpmn文件新建流程(IDEA工具)首先选中存放图形的目录(选择resources下的bpmn目录)，点击菜单：New -&gt; BpmnFile，如图：弹出如下图所示框，输入evection 表示 出差审批流程：起完名字evection后（默认扩展名为bpmn），就可以看到流程设计页面，如图所示：左侧区域是绘图区，右侧区域是palette画板区域鼠标先点击画板的元素即可在左侧绘图绘制流程使用滑板来绘制流程，通过从右侧把图标拖拽到左侧的画板，最终效果如下：指定流程定义Key流程定义key即流程定义的标识，通过properties视图查看流程的key指定任务负责人在properties视图指定每个任务结点的负责人，如：填写出差申请的负责人为 zhangsan经理审批负责人为 jerry总经理审批负责人为 jack财务审批负责人为 rose流程操作流程定义概述流程定义是线下按照bpmn2.0标准去描述 业务流程，通常使用idea中的插件对业务流程进行建模。使用idea下的designer设计器绘制流程，并会生成两个文件：.bpmn和.png.bpmn文件使用activiti-desinger设计业务流程，会生成.bpmn文件，上面我们已经创建好了bpmn文件BPMN 2.0根节点是definitions节点。 这个元素中，可以定义多个流程定义（不过我们建议每个文件只包含一个流程定义， 可以简化开发过程中的维护难度）。 注意，definitions元素 最少也要包含xmlns 和 targetNamespace的声明。 targetNamespace可以是任意值，它用来对流程实例进行分类。流程定义部分：定义了流程每个结点的描述及结点之间的流程流转。流程布局定义：定义流程每个结点在流程图上的位置坐标等信息。生成.png图片文件IDEA工具中的操作方式修改文件后缀为xml首先将evection.bpmn文件改名为evection.xml，如下图：evection.xml修改前的bpmn文件，效果如下：使用designer设计器打开.xml文件在evection.xml文件上面，点右键并选择Diagrams菜单，再选择Show BPMN2.0 Designer…查看打开的文件打开后，却出现乱码，如图：解决中文乱码1、打开Settings，找到File Encodings，把encoding的选项都选择UTF-82、打开IDEA安装路径，找到如下的安装目录根据自己所安装的版本来决定，我使用的是64位的idea，所以在idea64.exe.vmoptions文件的最后一行追加一条命令： -Dfile.encoding=UTF-8如下所示：一定注意，不要有空格，否则重启IDEA时会打不开，然后 重启IDEA。如果以上方法已经做完，还出现乱码，就再修改一个文件，并在文件的末尾添加： -Dfile.encoding=UTF-8，然后重启idea，如图：最后重新在evection.xml文件上面，点右键并选择Diagrams菜单，再选择Show BPMN2.0 Designer…，看到生成图片，如图：到此，解决乱码问题导出为图片文件点击Export To File的小图标，打开如下窗口，注意填写文件名及扩展名，选择好保存图片的位置：然后，我们把png文件拷贝到resources下的bpmn目录，并且把evection.xml改名为evection.bpmn。流程定义部署概述将上面在设计器中定义的流程部署到activiti数据库中，就是流程定义部署。通过调用activiti的api将流程定义的bpmn和png两个文件一个一个添加部署到activiti中，也可以将两个文件打成zip包进行部署。单个文件部署方式分别将bpmn文件和png图片文件部署。1234567891011121314151617181920212223242526272829package com.itheima.test;import org.activiti.engine.ProcessEngine;import org.activiti.engine.ProcessEngines;import org.activiti.engine.RepositoryService;import org.activiti.engine.repository.Deployment;import org.junit.Test;public class ActivitiDemo &#123; /** * 部署流程定义 */ @Test public void testDeployment()&#123;// 1、创建ProcessEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、得到RepositoryService实例 RepositoryService repositoryService = processEngine.getRepositoryService();// 3、使用RepositoryService进行部署 Deployment deployment = repositoryService.createDeployment() .addClasspathResource(\"bpmn/evection.bpmn\") // 添加bpmn资源 .addClasspathResource(\"bpmn/evection.png\") // 添加png资源 .name(\"出差申请流程\") .deploy();// 4、输出部署信息 System.out.println(\"流程部署id：\" + deployment.getId()); System.out.println(\"流程部署名称：\" + deployment.getName()); &#125;&#125;执行此操作后activiti会将上边代码中指定的bpm文件和图片文件保存在activiti数据库。压缩包部署方式将evection.bpmn和evection.png压缩成zip包。12345678910111213141516171819@Test public void deployProcessByZip() &#123; // 定义zip输入流 InputStream inputStream = this .getClass() .getClassLoader() .getResourceAsStream( \"bpmn/evection.zip\"); ZipInputStream zipInputStream = new ZipInputStream(inputStream); // 获取repositoryService RepositoryService repositoryService = processEngine .getRepositoryService(); // 流程部署 Deployment deployment = repositoryService.createDeployment() .addZipInputStream(zipInputStream) .deploy(); System.out.println(\"流程部署id：\" + deployment.getId()); System.out.println(\"流程部署名称：\" + deployment.getName()); &#125;执行此操作后activiti会将上边代码中指定的bpm文件和图片文件保存在activiti数据库。操作数据表流程定义部署后操作activiti的3张表如下：act_re_deployment 流程定义部署表，每部署一次增加一条记录act_re_procdef 流程定义表，部署每个新的流程定义都会在这张表中增加一条记录act_ge_bytearray 流程资源表接下来我们来看看，写入了什么数据：1SELECT * FROM act_re_deployment #流程定义部署表，记录流程部署信息结果：1SELECT * FROM act_re_procdef #流程定义表，记录流程定义信息结果：注意，KEY 这个字段是用来唯一识别不同流程的关键字1SELECT * FROM act_ge_bytearray #资源表结果：注意：act_re_deployment和act_re_procdef一对多关系，一次部署在流程部署表生成一条记录，但一次部署可以部署多个流程定义，每个流程定义在流程定义表生成一条记录。每一个流程定义在act_ge_bytearray会存在两个资源记录，bpmn和png。建议：一次部署一个流程，这样部署表和流程定义表是一对一有关系，方便读取流程部署及流程定义信息。启动流程实例流程定义部署在activiti后就可以通过工作流管理业务流程了，也就是说上边部署的出差申请流程可以使用了。针对该流程，启动一个流程表示发起一个新的出差申请单，这就相当于java类与java对象的关系，类定义好后需要new创建一个对象使用，当然可以new多个对象。对于请出差申请流程，张三发起一个出差申请单需要启动一个流程实例，出差申请单发起一个出差单也需要启动一个流程实例。代码如下：1234567891011121314151617 /** * 启动流程实例 */ @Test public void testStartProcess()&#123;// 1、创建ProcessEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、获取RunTimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 3、根据流程定义Id启动流程 ProcessInstance processInstance = runtimeService .startProcessInstanceByKey(\"myEvection\");// 输出内容 System.out.println(\"流程定义id：\" + processInstance.getProcessDefinitionId()); System.out.println(\"流程实例id：\" + processInstance.getId()); System.out.println(\"当前活动Id：\" + processInstance.getActivityId()); &#125;输出内容如下：操作数据表act_hi_actinst 流程实例执行历史act_hi_identitylink 流程的参与用户历史信息act_hi_procinst 流程实例历史信息act_hi_taskinst 流程任务历史信息act_ru_execution 流程执行信息act_ru_identitylink 流程的参与用户信息act_ru_task 任务信息任务查询流程启动后，任务的负责人就可以查询自己当前需要处理的任务，查询出来的任务都是该用户的待办任务。12345678910111213141516171819202122232425/** * 查询当前个人待执行的任务 */ @Test public void testFindPersonalTaskList() &#123;// 任务负责人 String assignee = \"zhangsan\"; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 创建TaskService TaskService taskService = processEngine.getTaskService();// 根据流程key 和 任务负责人 查询任务 List&lt;Task&gt; list = taskService.createTaskQuery() .processDefinitionKey(\"myEvection\") //流程Key .taskAssignee(assignee)//只查询该任务负责人的任务 .list(); for (Task task : list) &#123; System.out.println(\"流程实例id：\" + task.getProcessInstanceId()); System.out.println(\"任务id：\" + task.getId()); System.out.println(\"任务负责人：\" + task.getAssignee()); System.out.println(\"任务名称：\" + task.getName()); &#125; &#125;输出结果如下：1234流程实例id：2501任务id：2505任务负责人：zhangsan任务名称：创建出差申请流程任务处理任务负责人查询待办任务，选择任务进行处理，完成任务。123456789101112131415161718// 完成任务 @Test public void completTask()&#123;// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取taskService TaskService taskService = processEngine.getTaskService();// 根据流程key 和 任务的负责人 查询任务// 返回一个任务对象 Task task = taskService.createTaskQuery() .processDefinitionKey(\"myEvection\") //流程Key .taskAssignee(\"zhangsan\") //要查询的负责人 .singleResult();// 完成任务,参数：任务id taskService.complete(task.getId()); &#125;流程定义信息查询查询流程相关信息，包含流程定义，流程部署，流程定义版本123456789101112131415161718192021222324252627282930 /** * 查询流程定义 */ @Test public void queryProcessDefinition()&#123; // 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 得到ProcessDefinitionQuery 对象 ProcessDefinitionQuery processDefinitionQuery = repositoryService.createProcessDefinitionQuery();// 查询出当前所有的流程定义// 条件：processDefinitionKey =evection// orderByProcessDefinitionVersion 按照版本排序// desc倒叙// list 返回集合 List&lt;ProcessDefinition&gt; definitionList = processDefinitionQuery.processDefinitionKey(\"myEvection\") .orderByProcessDefinitionVersion() .desc() .list();// 输出流程定义信息 for (ProcessDefinition processDefinition : definitionList) &#123; System.out.println(\"流程定义 id=\"+processDefinition.getId()); System.out.println(\"流程定义 name=\"+processDefinition.getName()); System.out.println(\"流程定义 key=\"+processDefinition.getKey()); System.out.println(\"流程定义 Version=\"+processDefinition.getVersion()); System.out.println(\"流程部署ID =\"+processDefinition.getDeploymentId()); &#125; &#125;输出结果：1234流程定义id：myEvection:1:4流程定义名称：出差申请单流程定义key：myEvection流程定义版本：1流程删除12345678910111213public void deleteDeployment() &#123; // 流程部署id String deploymentId = \"1\"; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 通过流程引擎获取repositoryService RepositoryService repositoryService = processEngine .getRepositoryService(); //删除流程定义，如果该流程定义已有流程实例启动则删除时出错 repositoryService.deleteDeployment(deploymentId); //设置true 级联删除流程定义，即使该流程有流程实例启动也可以删除，设置为false非级别删除方式，如果流程 //repositoryService.deleteDeployment(deploymentId, true); &#125;说明：1) 使用repositoryService删除流程定义，历史表信息不会被删除2) 如果该流程定义下没有正在运行的流程，则可以用普通删除。如果该流程定义下存在已经运行的流程，使用普通删除报错，可用级联删除方法将流程及相关记录全部删除。先删除没有完成流程节点，最后就可以完全删除流程定义信息项目开发中级联删除操作一般只开放给超级管理员使用.流程资源下载现在我们的流程资源文件已经上传到数据库了，如果其他用户想要查看这些资源文件，可以从数据库中把资源文件下载到本地。解决方案有：1、jdbc对blob类型，clob类型数据读取出来，保存到文件目录2、使用activiti的api来实现使用commons-io.jar 解决IO的操作引入commons-io依赖包12345&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt;通过流程定义对象获取流程定义资源，获取bpmn和png123456789101112131415161718192021222324252627282930313233343536373839404142import org.apache.commons.io.IOUtils;@Test public void deleteDeployment()&#123;// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 根据部署id 删除部署信息,如果想要级联删除，可以添加第二个参数，true repositoryService.deleteDeployment(\"1\"); &#125; public void queryBpmnFile() throws IOException &#123;// 1、得到引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、获取repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 3、得到查询器：ProcessDefinitionQuery，设置查询条件,得到想要的流程定义 ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery() .processDefinitionKey(\"myEvection\") .singleResult();// 4、通过流程定义信息，得到部署ID String deploymentId = processDefinition.getDeploymentId();// 5、通过repositoryService的方法，实现读取图片信息和bpmn信息// png图片的流 InputStream pngInput = repositoryService.getResourceAsStream(deploymentId, processDefinition.getDiagramResourceName());// bpmn文件的流 InputStream bpmnInput = repositoryService.getResourceAsStream(deploymentId, processDefinition.getResourceName());// 6、构造OutputStream流 File file_png = new File(\"d:/evectionflow01.png\"); File file_bpmn = new File(\"d:/evectionflow01.bpmn\"); FileOutputStream bpmnOut = new FileOutputStream(file_bpmn); FileOutputStream pngOut = new FileOutputStream(file_png);// 7、输入流，输出流的转换 IOUtils.copy(pngInput,pngOut); IOUtils.copy(bpmnInput,bpmnOut);// 8、关闭流 pngOut.close(); bpmnOut.close(); pngInput.close(); bpmnInput.close(); &#125;说明：1) deploymentId为流程部署ID2) resource_name为act_ge_bytearray表中NAME_列的值3) 使用repositoryService的getDeploymentResourceNames方法可以获取指定部署下得所有文件的名称4) 使用repositoryService的getResourceAsStream方法传入部署ID和资源图片名称可以获取部署下指定名称文件的输入流最后的将输入流中的图片资源进行输出。流程历史信息的查看即使流程定义已经删除了，流程执行的历史信息通过前面的分析，依然保存在activiti的act_hi_*相关的表中。所以我们还是可以查询流程执行的历史信息，可以通过HistoryService来查看相关的历史记录。12345678910111213141516171819202122232425262728 /** * 查看历史信息 */ @Test public void findHistoryInfo()&#123;// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取HistoryService HistoryService historyService = processEngine.getHistoryService();// 获取 actinst表的查询对象 HistoricActivityInstanceQuery instanceQuery = historyService.createHistoricActivityInstanceQuery();// 查询 actinst表，条件：根据 InstanceId 查询// instanceQuery.processInstanceId(\"2501\");// 查询 actinst表，条件：根据 DefinitionId 查询 instanceQuery.processDefinitionId(\"myEvection:1:4\");// 增加排序操作,orderByHistoricActivityInstanceStartTime 根据开始时间排序 asc 升序 instanceQuery.orderByHistoricActivityInstanceStartTime().asc();// 查询所有内容 List&lt;HistoricActivityInstance&gt; activityInstanceList = instanceQuery.list();// 输出 for (HistoricActivityInstance hi : activityInstanceList) &#123; System.out.println(hi.getActivityId()); System.out.println(hi.getActivityName()); System.out.println(hi.getProcessDefinitionId()); System.out.println(hi.getProcessInstanceId()); System.out.println(\"&lt;==========================&gt;\"); &#125; &#125;Activiti进阶流程实例什么是流程实例流程实例（ProcessInstance）代表流程定义的执行实例。一个流程实例包括了所有的运行节点。我们可以利用这个对象来了解当前流程实例的进度等信息。例如：用户或程序按照流程定义内容发起一个流程，这就是一个流程实例。流程定义和流程实例的图解：启动流程实例 并添加Businesskey（业务标识）流程定义部署在activiti后，就可以在系统中通过activiti去管理该流程的执行，执行流程表示流程的一次执行。比如部署系统出差流程后，如果某用户要申请出差这时就需要执行这个流程，如果另外一个用户也要申请出差则也需要执行该流程，每个执行互不影响，每个执行是单独的流程实例。启动流程实例时，指定的businesskey，就会在act_ru_execution #流程实例的执行表中存储businesskey。Businesskey：业务标识，通常为业务表的主键，业务标识和流程实例一一对应。业务标识来源于业务系统。存储业务标识就是根据业务标识来关联查询业务系统的数据。比如：出差流程启动一个流程实例，就可以将出差单的id作为业务标识存储到activiti中，将来查询activiti的流程实例信息就可以获取出差单的id从而关联查询业务系统数据库得到出差单信息。12345678910111213141516 /** * 启动流程实例，添加businessKey */ @Test public void addBusinessKey()&#123;// 1、得到ProcessEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 2、得到RunTimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 3、启动流程实例，同时还要指定业务标识businessKey，也就是出差申请单id，这里是1001 ProcessInstance processInstance = runtimeService. startProcessInstanceByKey(\"myEvection\",\"1001\");// 4、输出processInstance相关属性 System.out.println(\"业务id==\"+processInstance.getBusinessKey()); &#125;Activiti的act_ru_execution中存储业务标识：操作数据库表启动流程实例，操作如下数据库表：SELECT * FROM act_ru_execution #流程实例执行表，记录当前流程实例的执行情况说明：流程实例执行，如果当前只有一个分支时，一个流程实例只有一条记录且执行表的主键id和流程实例id相同，如果当前有多个分支正在运行则该执行表中有多条记录，存在执行表的主键和流程实例id不相同的记录。不论当前有几个分支总会有一条记录的执行表的主键和流程实例id相同一个流程实例运行完成，此表中与流程实例相关的记录删除。SELECT * FROM act_ru_task #任务执行表，记录当前执行的任务说明：启动流程实例，流程当前执行到第一个任务结点，此表会插入一条记录表示当前任务的执行情况，如果任务完成则记录删除。SELECT * FROM act_ru_identitylink #任务参与者，记录当前参与任务的用户或组SELECT * FROM act_hi_procinst #流程实例历史表流程实例启动，会在此表插入一条记录，流程实例运行完成记录也不会删除。SELECT * FROM act_hi_taskinst #任务历史表，记录所有任务开始一个任务，不仅在act_ru_task表插入记录，也会在历史任务表插入一条记录，任务历史表的主键就是任务id，任务完成此表记录不删除。SELECT * FROM act_hi_actinst #活动历史表，记录所有活动活动包括任务，所以此表中不仅记录了任务，还记录了流程执行过程的其它活动，比如开始事件、结束事件。查询流程实例流程在运行过程中可以查询流程实例的状态，当前运行结点等信息。1234567891011121314151617181920212223@Test public void queryProcessInstance() &#123; // 流程定义key String processDefinitionKey = \"evection\"; ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 获取RunTimeService RuntimeService runtimeService = processEngine.getRuntimeService(); List&lt;ProcessInstance&gt; list = runtimeService .createProcessInstanceQuery() .processDefinitionKey(processDefinitionKey)// .list(); for (ProcessInstance processInstance : list) &#123; System.out.println(\"----------------------------\"); System.out.println(\"流程实例id：\" + processInstance.getProcessInstanceId()); System.out.println(\"所属流程定义id：\" + processInstance.getProcessDefinitionId()); System.out.println(\"是否执行完成：\" + processInstance.isEnded()); System.out.println(\"是否暂停：\" + processInstance.isSuspended()); System.out.println(\"当前活动标识：\" + processInstance.getActivityId()); &#125; &#125;关联BusinessKey需求：在activiti实际应用时，查询流程实例列表时可能要显示出业务系统的一些相关信息，比如：查询当前运行的出差流程列表需要将出差单名称、出差天数等信息显示出来，出差天数等信息在业务系统中存在，而并没有在activiti数据库中存在，所以是无法通过activiti的api查询到出差天数等信息。实现：在查询流程实例时，通过businessKey（业务标识 ）关联查询业务系统的出差单表，查询出出差天数等信息。通过下面的代码就可以获取activiti中所对应实例保存的业务Key。而这个业务Key一般都会保存相关联的业务操作表的主键，再通过主键ID去查询业务信息，比如通过出差单的ID，去查询更多的请假信息（出差人，出差时间，出差天数，出差目的地等）String businessKey = processInstance.getBusinessKey();在activiti的act_ru_execution表，字段BUSINESS_KEY就是存放业务KEY的。挂起、激活流程实例某些情况可能由于流程变更需要将当前运行的流程暂停而不是直接删除，流程暂停后将不会继续执行。全部流程实例挂起操作流程定义为挂起状态，该流程定义下边所有的流程实例全部暂停：流程定义为挂起状态该流程定义将不允许启动新的流程实例，同时该流程定义下所有的流程实例将全部挂起暂停执行。12345678910111213141516171819202122232425262728293031323334/** * 全部流程实例挂起与激活 */ @Test public void SuspendAllProcessInstance()&#123;// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取repositoryService RepositoryService repositoryService = processEngine.getRepositoryService();// 查询流程定义的对象 ProcessDefinition processDefinition = repositoryService.createProcessDefinitionQuery(). processDefinitionKey(\"myEvection\"). singleResult();// 得到当前流程定义的实例是否都为暂停状态 boolean suspended = processDefinition.isSuspended();// 流程定义id String processDefinitionId = processDefinition.getId();// 判断是否为暂停 if(suspended)&#123;// 如果是暂停，可以执行激活操作 ,参数1 ：流程定义id ，参数2：是否激活，参数3：激活时间 repositoryService.activateProcessDefinitionById(processDefinitionId, true, null ); System.out.println(\"流程定义：\"+processDefinitionId+\",已激活\"); &#125;else&#123;// 如果是激活状态，可以暂停，参数1 ：流程定义id ，参数2：是否暂停，参数3：暂停时间 repositoryService.suspendProcessDefinitionById(processDefinitionId, true, null); System.out.println(\"流程定义：\"+processDefinitionId+\",已挂起\"); &#125; &#125;单个流程实例挂起操作流程实例对象，针对单个流程执行挂起操作，某个流程实例挂起则此流程不再继续执行，完成该流程实例的当前任务将报异常。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 单个流程实例挂起与激活 */ @Test public void SuspendSingleProcessInstance()&#123;// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// RuntimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 查询流程定义的对象 ProcessInstance processInstance = runtimeService. createProcessInstanceQuery(). processInstanceId(\"15001\"). singleResult();// 得到当前流程定义的实例是否都为暂停状态 boolean suspended = processInstance.isSuspended();// 流程定义id String processDefinitionId = processInstance.getId();// 判断是否为暂停 if(suspended)&#123;// 如果是暂停，可以执行激活操作 ,参数：流程定义id runtimeService.activateProcessInstanceById(processDefinitionId); System.out.println(\"流程定义：\"+processDefinitionId+\",已激活\"); &#125;else&#123;// 如果是激活状态，可以暂停，参数：流程定义id runtimeService.suspendProcessInstanceById( processDefinitionId); System.out.println(\"流程定义：\"+processDefinitionId+\",已挂起\"); &#125; &#125; /** * 测试完成个人任务 */ @Test public void completTask()&#123;// 获取引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取操作任务的服务 TaskService TaskService taskService = processEngine.getTaskService();// 完成任务,参数：流程实例id,完成zhangsan的任务 Task task = taskService.createTaskQuery() .processInstanceId(\"15001\") .taskAssignee(\"rose\") .singleResult(); System.out.println(\"流程实例id=\"+task.getProcessInstanceId()); System.out.println(\"任务Id=\"+task.getId()); System.out.println(\"任务负责人=\"+task.getAssignee()); System.out.println(\"任务名称=\"+task.getName()); taskService.complete(task.getId()); &#125;个人任务分配任务负责人固定分配在进行业务流程建模时指定固定的任务负责人， 如图：并在 properties 视图中，填写 Assignee 项为任务负责人。表达式分配由于固定分配方式，任务只管一步一步执行任务，执行到每一个任务将按照 bpmn 的配置去分配任务负责人。UEL 表达式Activiti 使用 UEL 表达式， UEL 是 java EE6 规范的一部分， UEL（Unified Expression Language）即 统一表达式语言， activiti 支持两个 UEL 表达式： UEL-value 和 UEL-method。UEL-value 定义如图：assignee 这个变量是 activiti 的一个流程变量，或者使用这种方式定义：如图：user 也是 activiti 的一个流程变量， user.assignee 表示通过调用 user 的 getter 方法获取值。UEL-method 方式如图：userBean 是 spring 容器中的一个 bean，表示调用该 bean 的 getUserId()方法。UEL-method 与 UEL-value 结合再比如：${ldapService.findManagerForEmployee(emp)}ldapService 是 spring 容器的一个 bean，findManagerForEmployee 是该 bean 的一个方法，emp 是 activiti流程变量， emp 作为参数传到 ldapService.findManagerForEmployee 方法中。其它表达式支持解析基础类型、 bean、 list、 array 和 map，也可作为条件判断。如下：${order.price &gt; 100 &amp;&amp; order.price &lt; 250}编写代码配置负责人定义任务分配流程变量如图：设置流程变量在启动流程实例时设置流程变量，如下：1234567891011121314151617181920 /** * 设置流程负责人 */ @Test public void assigneeUEL()&#123;// 获取流程引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取 RuntimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 设置assignee的取值，用户可以在界面上设置流程的执行 Map&lt;String,Object&gt; assigneeMap = new HashMap&lt;&gt;(); assigneeMap.put(\"assignee0\",\"张三\"); assigneeMap.put(\"assignee1\",\"李经理\"); assigneeMap.put(\"assignee2\",\"王总经理\"); assigneeMap.put(\"assignee3\",\"赵财务\");// 启动流程实例，同时还要设置流程定义的assignee的值 runtimeService.startProcessInstanceByKey(\"myEvection1\",assigneeMap);// 输出 System.out.println(processEngine.getName()); &#125;执行成功后，可以在act_ru_variable表中看到刚才map中的数据注意事项由于使用了表达式分配，必须保证在任务执行过程表达式执行成功，比如：某个任务使用了表达式${order.price &gt; 100 &amp;&amp; order.price &lt; 250}，当执行该任务时必须保证 order 在流程变量中存在，否则 activiti 异常。监听器分配可以使用监听器来完成很多Activiti流程的业务。在本章我们使用监听器的方式来指定负责人，那么在流程设计时就不需要指定assignee。任务监听器是发生对应的任务相关事件时执行自定义 java 逻辑 或表达式。任务相当事件包括：Event的选项包含：1234Create：任务创建后触发Assignment：任务分配后触发Delete：任务完成后触发All：所有事件发生都触发定义任务监听类，且类必须实现 org.activiti.engine.delegate.TaskListener 接口12345678910public class MyTaskListener implements TaskListener &#123; @Override public void notify(DelegateTask delegateTask) &#123; if(delegateTask.getName().equals(\"创建出差申请\")&amp;&amp; delegateTask.getEventName().equals(\"create\"))&#123; //这里指定任务负责人 delegateTask.setAssignee(\"张三\"); &#125; &#125;&#125;DelegateTask对象的内容如下：注意事项使用监听器分配方式，按照监听事件去执行监听类的 notify 方法，方法如果不能正常执行也会影响任务的执行。查询任务查询任务负责人的待办任务代码如下：12345678910111213141516171819202122// 查询当前个人待执行的任务@Testpublic void findPersonalTaskList() &#123; // 流程定义key String processDefinitionKey = \"myEvection1\"; // 任务负责人 String assignee = \"张三\"; // 获取TaskService TaskService taskService = processEngine.getTaskService(); List&lt;Task&gt; taskList = taskService.createTaskQuery() .processDefinitionKey(processDefinitionKey) .includeProcessVariables() .taskAssignee(assignee) .list(); for (Task task : taskList) &#123; System.out.println(\"----------------------------\"); System.out.println(\"流程实例id： \" + task.getProcessInstanceId()); System.out.println(\"任务id： \" + task.getId()); System.out.println(\"任务负责人： \" + task.getAssignee()); System.out.println(\"任务名称： \" + task.getName()); &#125;&#125;关联 businessKey需求：在 activiti 实际应用时，查询待办任务可能要显示出业务系统的一些相关信息。比如：查询待审批出差任务列表需要将出差单的日期、 出差天数等信息显示出来。出差天数等信息在业务系统中存在，而并没有在 activiti 数据库中存在，所以是无法通过 activiti 的 api 查询到出差天数等信息。实现：在查询待办任务时，通过 businessKey（业务标识 ）关联查询业务系统的出差单表，查询出出差天数等信息。12345678910111213141516171819202122232425@Test public void findProcessInstance()&#123;// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取TaskService TaskService taskService = processEngine.getTaskService();// 获取RuntimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 查询流程定义的对象 Task task = taskService.createTaskQuery() .processDefinitionKey(\"myEvection1\") .taskAssignee(\"张三\") .singleResult();// 使用task对象获取实例id String processInstanceId = task.getProcessInstanceId();// 使用实例id，获取流程实例对象 ProcessInstance processInstance = runtimeService.createProcessInstanceQuery() .processInstanceId(processInstanceId) .singleResult();// 使用processInstance，得到 businessKey String businessKey = processInstance.getBusinessKey(); System.out.println(\"businessKey==\"+businessKey); &#125;办理任务注意：在实际应用中，完成任务前需要校验任务的负责人是否具有该任务的办理权限 。12345678910111213141516171819202122232425/** * 完成任务，判断当前用户是否有权限 */ @Test public void completTask() &#123; //任务id String taskId = \"15005\";// 任务负责人 String assingee = \"张三\"; //获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 创建TaskService TaskService taskService = processEngine.getTaskService();// 完成任务前，需要校验该负责人可以完成当前任务// 校验方法：// 根据任务id和任务负责人查询当前任务，如果查到该用户有权限，就完成 Task task = taskService.createTaskQuery() .taskId(taskId) .taskAssignee(assingee) .singleResult(); if(task != null)&#123; taskService.complete(taskId); System.out.println(\"完成任务\"); &#125; &#125;流程变量什么是流程变量流程变量在 activiti 中是一个非常重要的角色，流程运转有时需要靠流程变量，业务系统和 activiti结合时少不了流程变量，流程变量就是 activiti 在管理工作流时根据管理需要而设置的变量。比如：在出差申请流程流转时如果出差天数大于 3 天则由总经理审核，否则由人事直接审核， 出差天数就可以设置为流程变量，在流程流转时使用。注意：虽然流程变量中可以存储业务数据可以通过activiti的api查询流程变量从而实现 查询业务数据，但是不建议这样使用，因为业务数据查询由业务系统负责，activiti设置流程变量是为了流程执行需要而创建。流程变量类型如果将 pojo 存储到流程变量中，必须实现序列化接口 serializable，为了防止由于新增字段无法反序列化，需要生成 serialVersionUID。流程变量作用域流程变量的作用域可以是一个流程实例(processInstance)，或一个任务(task)，或一个执行实例(execution)global变量流程变量的默认作用域是流程实例。当一个流程变量的作用域为流程实例时，可以称为 global 变量注意：如： Global变量：userId（变量名）、zhangsan（变量值）global 变量中变量名不允许重复，设置相同名称的变量，后设置的值会覆盖前设置的变量值。local变量任务和执行实例仅仅是针对一个任务和一个执行实例范围，范围没有流程实例大， 称为 local 变量。Local 变量由于在不同的任务或不同的执行实例中，作用域互不影响，变量名可以相同没有影响。Local 变量名也可以和 global 变量名相同，没有影响。流程变量的使用方法在属性上使用UEL表达式可以在 assignee 处设置 UEL 表达式，表达式的值为任务的负责人，比如： ${assignee}， assignee 就是一个流程变量名称。Activiti获取UEL表达式的值，即流程变量assignee的值 ，将assignee的值作为任务的负责人进行任务分配在连线上使用UEL表达式可以在连线上设置UEL表达式，决定流程走向。比如：${price&lt;10000} 。price就是一个流程变量名称，uel表达式结果类型为布尔类型。如果UEL表达式是true，要决定 流程执行走向。使用Global变量控制流程需求员工创建出差申请单，由部门经理审核，部门经理审核通过后出差3天及以下由人财务直接审批，3天以上先由总经理审核，总经理审核通过再由财务审批。流程定义1）、出差天数大于等于3连线条件也可以使用对象参数命名，如evection.num：2）、出差天数小于3连线条件也可以使用对象参数命名，如：设置global流程变量在部门经理审核前设置流程变量，变量值为出差单信息（包括出差天数），部门经理审核后可以根据流程变量的值决定流程走向。在设置流程变量时，可以在启动流程时设置，也可以在任务办理时设置创建POJO对象创建出差申请pojo对象12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394package fun.obey.pojo;import java.io.Serializable;import java.util.Date;/** * 出差申请 pojo */public class Evection implements Serializable &#123; /** * 主键id */ private Long id; /** * 出差申请单名称 */ private String evectionName; /** * 出差天数 */ private Double num; /** * 预计开始时间 */ private Date beginDate; /** * 预计结束时间 */ private Date endDate; /** * 目的地 */ private String destination; /** * 出差事由 */ private String reson; public Long getId() &#123; return id; &#125; public void setId(Long id) &#123; this.id = id; &#125; public String getEvectionName() &#123; return evectionName; &#125; public void setEvectionName(String evectionName) &#123; this.evectionName = evectionName; &#125; public Date getBeginDate() &#123; return beginDate; &#125; public void setBeginDate(Date beginDate) &#123; this.beginDate = beginDate; &#125; public Date getEndDate() &#123; return endDate; &#125; public void setEndDate(Date endDate) &#123; this.endDate = endDate; &#125; public String getDestination() &#123; return destination; &#125; public void setDestination(String destination) &#123; this.destination = destination; &#125; public String getReson() &#123; return reson; &#125; public void setReson(String reson) &#123; this.reson = reson; &#125; public Double getNum() &#123; return num; &#125; public void setNum(Double num) &#123; this.num = num; &#125;&#125;启动流程时设置变量在启动流程时设置流程变量，变量的作用域是整个流程实例。通过Map&lt;key,value&gt;设置流程变量，map中可以设置多个变量，这个key就是流程变量的名字。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 /** * 启动流程实例,设置流程变量的值 */ @Test public void startProcess()&#123;// 获取流程引擎 ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取RunTimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 流程定义key String key = \"myEvection2\";// 创建变量集合 Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();// 创建出差pojo对象 Evection evection = new Evection();// 设置出差天数 evection.setNum(2d);// 定义流程变量，把出差pojo对象放入map map.put(\"evection\",evection);// 设置assignee的取值，用户可以在界面上设置流程的执行 map.put(\"assignee0\",\"张三\"); map.put(\"assignee1\",\"李经理\"); map.put(\"assignee2\",\"王总经理\"); map.put(\"assignee3\",\"赵财务\");// 启动流程实例，并设置流程变量的值（把map传入） ProcessInstance processInstance = runtimeService .startProcessInstanceByKey(key, map);// 输出 System.out.println(\"流程实例名称=\"+processInstance.getName()); System.out.println(\"流程定义id==\"+processInstance.getProcessDefinitionId()); &#125; /** * 完成任务，判断当前用户是否有权限 */ @Test public void completTask() &#123; //任务id String key = \"myEvection2\";// 任务负责人 String assingee = \"张三\"; //获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 创建TaskService TaskService taskService = processEngine.getTaskService();// 完成任务前，需要校验该负责人可以完成当前任务// 校验方法：// 根据任务id和任务负责人查询当前任务，如果查到该用户有权限，就完成 Task task = taskService.createTaskQuery() .processDefinitionKey(key) .taskAssignee(assingee) .singleResult(); if(task != null)&#123; taskService.complete(task.getId()); System.out.println(\"任务执行完成\"); &#125; &#125;说明：startProcessInstanceByKey(processDefinitionKey, variables)流程变量作用域是一个流程实例，流程变量使用Map存储，同一个流程实例设置变量map中key相同，后者覆盖前者。任务办理时设置变量在完成任务时设置流程变量，该流程变量只有在该任务完成后其它结点才可使用该变量，它的作用域是整个流程实例，如果设置的流程变量的key在流程实例中已存在相同的名字则后设置的变量替换前边设置的变量。这里需要在创建出差单任务完成时设置流程变量12345678910111213141516171819202122232425262728293031323334 /** * 完成任务，判断当前用户是否有权限 */ @Test public void completTask() &#123; //任务id String key = \"myEvection2\";// 任务负责人 String assingee = \"张三\";// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 创建TaskService TaskService taskService = processEngine.getTaskService();// 创建变量集合 Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();// 创建出差pojo对象 Evection evection = new Evection();// 设置出差天数 evection.setNum(2d);// 定义流程变量 map.put(\"evection\",evection);// 完成任务前，需要校验该负责人可以完成当前任务// 校验方法：// 根据任务id和任务负责人查询当前任务，如果查到该用户有权限，就完成 Task task = taskService.createTaskQuery() .processDefinitionKey(key) .taskAssignee(assingee) .singleResult(); if(task != null)&#123; //完成任务是，设置流程变量的值 taskService.complete(task.getId(),map); System.out.println(\"任务执行完成\"); &#125; &#125;说明：通过当前任务设置流程变量，需要指定当前任务id，如果当前执行的任务id不存在则抛出异常。任务办理时也是通过map&lt;key,value&gt;设置流程变量，一次可以设置多个变量。通过当前流程实例设置通过流程实例id设置全局变量，该流程实例必须未执行完成。1234567891011121314151617 @Test public void setGlobalVariableByExecutionId()&#123;// 当前流程实例执行 id，通常设置为当前执行的流程实例 String executionId=\"2601\";// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine();// 获取RuntimeService RuntimeService runtimeService = processEngine.getRuntimeService();// 创建出差pojo对象 Evection evection = new Evection();// 设置天数 evection.setNum(3d);// 通过流程实例 id设置流程变量 runtimeService.setVariable(executionId, \"evection\", evection);// 一次设置多个值// runtimeService.setVariables(executionId, variables) &#125;注意：executionId必须当前未结束 流程实例的执行id，通常此id设置流程实例 的id。也可以通runtimeService.getVariable()获取流程变量。通过当前任务设置123456789101112131415@Test public void setGlobalVariableByTaskId()&#123; //当前待办任务id String taskId=\"1404\";// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); TaskService taskService = processEngine.getTaskService(); Evection evection = new Evection(); evection.setNum(3); //通过任务设置流程变量 taskService.setVariable(taskId, \"evection\", evection); //一次设置多个值 //taskService.setVariables(taskId, variables) &#125;注意：任务id必须是当前待办任务id，act_ru_task中存在。如果该任务已结束，会报错也可以通过taskService.getVariable()获取流程变量。测试正常测试：​ 设置流程变量的值大于等于3天​ 设计流程变量的值小于3天异常测试：​ 流程变量不存在​ 流程变量的值为空NULL，price属性为空​ UEL表达式都不符合条件​ 不设置连线的条件注意事项1、 如果UEL表达式中流程变量名不存在则报错。2、 如果UEL表达式中流程变量值为空NULL，流程不按UEL表达式去执行，而流程结束 。3、 如果UEL表达式都不符合条件，流程结束4、 如果连线不设置条件，会走flow序号小的那条线操作数据库表设置流程变量会在当前执行流程变量表插入记录，同时也会在历史流程变量表也插入记录。12//当前流程变量表SELECT * FROM act_ru_variable记录当前运行流程实例可使用的流程变量，包括 global和local变量Id_：主键Type_：变量类型Name_：变量名称Execution_id_：所属流程实例执行id，global和local变量都存储Proc_inst_id_：所属流程实例id，global和local变量都存储Task_id_：所属任务id，local变量存储Bytearray_：serializable类型变量存储对应act_ge_bytearray表的idDouble_：double类型变量值Long_：long类型变量值Text_：text类型变量值12 #历史流程变量表SELECT * FROM act_hi_varinst记录所有已创建的流程变量，包括 global和local变量字段意义参考当前流程变量表。设置local流程变量任务办理时设置任务办理时设置local流程变量，当前运行的流程实例只能在该任务结束前使用，任务结束该变量无法在当前流程实例使用，可以通过查询历史任务查询。1234567891011121314151617181920212223/**处理任务时设置local流程变量*/@Testpublic void completTask() &#123; //任务id String taskId = \"1404\";// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); TaskService taskService = processEngine.getTaskService();// 定义流程变量 Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;(); Evection evection = new Evection (); evection.setNum(3d);// 定义流程变量 Map&lt;String, Object&gt; variables = new HashMap&lt;String, Object&gt;();// 变量名是holiday，变量值是holiday对象 variables.put(\"evection\", evection);// 设置local变量，作用域为该任务 taskService.setVariablesLocal(taskId, variables);// 完成任务 taskService.complete(taskId);&#125;​ 说明：设置作用域为任务的local变量，每个任务可以设置同名的变量，互不影响。通过当前任务设置1234567891011121314@Testpublic void setLocalVariableByTaskId()&#123;// 当前待办任务id String taskId=\"1404\";// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); TaskService taskService = processEngine.getTaskService(); Evection evection = new Evection (); evection.setNum(3d);// 通过任务设置流程变量 taskService.setVariableLocal(taskId, \"evection\", evection);// 一次设置多个值 //taskService.setVariablesLocal(taskId, variables)&#125;注意：任务id必须是当前待办任务id，act_ru_task中存在。Local变量测试1如果上边例子中设置global变量改为设置local变量是否可行？为什么？Local变量在任务结束后无法在当前流程实例执行中使用，如果后续的流程执行需要用到此变量则会报错。Local变量测试2在部门经理审核、总经理审核、财务审核时设置local变量，可通过historyService查询每个历史任务时将流程变量的值也查询出来。代码如下：123456789101112// 创建历史任务查询对象 HistoricTaskInstanceQuery historicTaskInstanceQuery = historyService.createHistoricTaskInstanceQuery(); // 查询结果包括 local变量 historicTaskInstanceQuery.includeTaskLocalVariables();for (HistoricTaskInstance historicTaskInstance : list) &#123; System.out.println(\"==============================\"); System.out.println(\"任务id：\" + historicTaskInstance.getId()); System.out.println(\"任务名称：\" + historicTaskInstance.getName()); System.out.println(\"任务负责人：\" + historicTaskInstance.getAssignee()); System.out.println(\"任务local变量：\"+ historicTaskInstance.getTaskLocalVariables());&#125;注意：查询历史流程变量，特别是查询pojo变量需要经过反序列化，不推荐使用。组任务需求在流程定义中在任务结点的 assignee 固定设置任务负责人，在流程定义时将参与者固定设置在.bpmn 文件中，如果临时任务负责人变更则需要修改流程定义，系统可扩展性差。针对这种情况可以给任务设置多个候选人，可以从候选人中选择参与者来完成任务。设置任务候选人在流程图中任务节点的配置中设置 candidate-users(候选人)，多个候选人之间用逗号分开。查看bpmn文件1&lt;userTask activiti:candidateUsers=\"lisi,wangwu\" activiti:exclusive=\"true\" id=\"_3\" name=\"经理审批\"/&gt;我们可以看到部门经理的审核人已经设置为 lisi,wangwu 这样的一组候选人，可以使用activiti:candiateUsers=”用户 1,用户 2,用户 3”的这种方式来实现设置一组候选人组任务组任务办理流程查询组任务指定候选人，查询该候选人当前的待办任务。候选人不能立即办理任务。b拾取(claim)任务该组任务的所有候选人都能拾取。将候选人的组任务，变成个人任务。原来候选人就变成了该任务的负责人。如果拾取后不想办理该任务？需要将已经拾取的个人任务归还到组里边，将个人任务变成了组任务。查询个人任务查询方式同个人任务部分，根据assignee查询用户负责的个人任务。办理个人任务查询组任务根据候选人查询组任务1234567891011121314151617181920212223@Test public void findGroupTaskList() &#123; // 流程定义key String processDefinitionKey = \"evection3\"; // 任务候选人 String candidateUser = \"lisi\"; // 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 创建TaskService TaskService taskService = processEngine.getTaskService(); //查询组任务 List&lt;Task&gt; list = taskService.createTaskQuery() .processDefinitionKey(processDefinitionKey) .taskCandidateUser(candidateUser)//根据候选人查询 .list(); for (Task task : list) &#123; System.out.println(\"----------------------------\"); System.out.println(\"流程实例id：\" + task.getProcessInstanceId()); System.out.println(\"任务id：\" + task.getId()); System.out.println(\"任务负责人：\" + task.getAssignee()); System.out.println(\"任务名称：\" + task.getName()); &#125; &#125;拾取组任务候选人员拾取组任务后该任务变为自己的个人任务。12345678910111213141516171819202122@Test public void claimTask()&#123; // 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); TaskService taskService = processEngine.getTaskService(); //要拾取的任务id String taskId = \"6302\"; //任务候选人id String userId = \"lisi\"; //拾取任务 //即使该用户不是候选人也能拾取(建议拾取时校验是否有资格) //校验该用户有没有拾取任务的资格 Task task = taskService.createTaskQuery() .taskId(taskId) .taskCandidateUser(userId)//根据候选人查询 .singleResult(); if(task!=null)&#123; //拾取任务 taskService.claim(taskId, userId); System.out.println(\"任务拾取成功\"); &#125; &#125;说明：即使该用户不是候选人也能拾取，建议拾取时校验是否有资格组任务拾取后，该任务已有负责人，通过候选人将查询不到该任务查询个人待办任务查询方式同个人任务查询12345678910111213141516171819202122@Testpublic void findPersonalTaskList() &#123; // 流程定义key String processDefinitionKey = \"evection1\"; // 任务负责人 String assignee = \"zhangsan\"; // 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 创建TaskService TaskService taskService = processEngine.getTaskService(); List&lt;Task&gt; list = taskService.createTaskQuery() .processDefinitionKey(processDefinitionKey) .taskAssignee(assignee) .list(); for (Task task : list) &#123; System.out.println(\"----------------------------\"); System.out.println(\"流程实例id：\" + task.getProcessInstanceId()); System.out.println(\"任务id：\" + task.getId()); System.out.println(\"任务负责人：\" + task.getAssignee()); System.out.println(\"任务名称：\" + task.getName()); &#125;&#125;办理个人任务同个人任务办理1234567891011 /*完成任务*/ @Test public void completeTask()&#123;// 任务ID String taskId = \"12304\";// 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); processEngine.getTaskService() .complete(taskId); System.out.println(\"完成任务：\"+taskId); &#125;说明：建议完成任务前校验该用户是否是该任务的负责人。归还组任务如果个人不想办理该组任务，可以归还组任务，归还后该用户不再是该任务的负责人123456789101112131415161718192021222324/**归还组任务，由个人任务变为组任务，还可以进行任务交接*/@Testpublic void setAssigneeToGroupTask() &#123; // 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 查询任务使用TaskService TaskService taskService = processEngine.getTaskService(); // 当前待办任务 String taskId = \"6004\"; // 任务负责人 String userId = \"zhangsan2\"; // 校验userId是否是taskId的负责人，如果是负责人才可以归还组任务 Task task = taskService .createTaskQuery() .taskId(taskId) .taskAssignee(userId) .singleResult(); if (task != null) &#123; // 如果设置为null，归还组任务,该 任务没有负责人 taskService.setAssignee(taskId, null); &#125;&#125;说明：建议归还任务前校验该用户是否是该任务的负责人也可以通过setAssignee方法将任务委托给其它用户负责，注意被委托的用户可以不是候选人（建议不要这样使用）任务交接任务交接,任务负责人将任务交给其它候选人办理该任务12345678910111213141516171819202122@Test public void setAssigneeToCandidateUser() &#123; // 获取processEngine ProcessEngine processEngine = ProcessEngines.getDefaultProcessEngine(); // 查询任务使用TaskService TaskService taskService = processEngine.getTaskService(); // 当前待办任务 String taskId = \"6004\"; // 任务负责人 String userId = \"zhangsan2\";// 将此任务交给其它候选人办理该 任务 String candidateuser = \"zhangsan\"; // 校验userId是否是taskId的负责人，如果是负责人才可以归还组任务 Task task = taskService .createTaskQuery() .taskId(taskId) .taskAssignee(userId) .singleResult(); if (task != null) &#123; taskService.setAssignee(taskId, candidateuser); &#125; &#125;数据库表操作查询当前任务执行表1SELECT * FROM act_ru_task任务执行表，记录当前执行的任务，由于该任务当前是组任务，所有assignee为空，当拾取任务后该字段就是拾取用户的id查询任务参与者1SELECT * FROM act_ru_identitylink任务参与者，记录当前参考任务用户或组，当前任务如果设置了候选人，会向该表插入候选人记录，有几个候选就插入几个与act_ru_identitylink对应的还有一张历史表act_hi_identitylink，向act_ru_identitylink插入记录的同时也会向历史表插入记录。任务完成网关网关用来控制流程的流向排他网关ExclusiveGateway什么是排他网关：排他网关，用来在流程中实现决策。 当流程执行到这个网关，所有分支都会判断条件是否为true，如果为true则执行该分支，注意：排他网关只会选择一个为true的分支执行。如果有两个分支条件都为true，排他网关会选择id值较小的一条分支去执行。为什么要用排他网关？不用排他网关也可以实现分支，如：在连线的condition条件上设置分支条件。在连线设置condition条件的缺点：如果条件都不满足，流程就结束了(是异常结束)。如果 使用排他网关决定分支的走向，如下：如果从网关出去的线所有条件都不满足则系统抛出异常。12org.activiti.engine.ActivitiException: No outgoing sequence flow of the exclusive gateway 'exclusivegateway1' could be selected for continuing the process at org.activiti.engine.impl.bpmn.behavior.ExclusiveGatewayActivityBehavior.leave(ExclusiveGatewayActivityBehavior.java:85)流程定义排他网关图标，红框内：测试在部门经理审核后，走排他网关，从排他网关出来的分支有两条，一条是判断出差天数是否大于3天，另一条是判断出差天数是否小于等于3天。设置分支条件时，如果所有分支条件都不是true，报错：123org.activiti.engine.ActivitiException: No outgoing sequence flow of the exclusive gateway 'exclusivegateway1' could be selected for continuing the process at org.activiti.engine.impl.bpmn.behavior.ExclusiveGatewayActivityBehavior.leave(ExclusiveGatewayActivityBehavior.java:85)并行网关ParallelGateway什么是并行网关并行网关允许将流程分成多条分支，也可以把多条分支汇聚到一起，并行网关的功能是基于进入和外出顺序流的：l fork分支：并行后的所有外出顺序流，为每个顺序流都创建一个并发分支。l join汇聚：所有到达并行网关，在此等待的进入分支， 直到所有进入顺序流的分支都到达以后， 流程就会通过汇聚网关。注意，如果同一个并行网关有多个进入和多个外出顺序流， 它就同时具有分支和汇聚功能。 这时，网关会先汇聚所有进入的顺序流，然后再切分成多个并行分支。与其他网关的主要区别是，并行网关不会解析条件。 即使顺序流中定义了条件，也会被忽略。例子：说明：技术经理和项目经理是两个execution分支，在act_ru_execution表有两条记录分别是技术经理和项目经理，act_ru_execution还有一条记录表示该流程实例。待技术经理和项目经理任务全部完成，在汇聚点汇聚，通过parallelGateway并行网关。并行网关在业务应用中常用于会签任务，会签任务即多个参与者共同办理的任务。流程定义并行网关图标，红框内：测试当执行到并行网关数据库跟踪如下：当前任务表：SELECT * FROM act_ru_task上图中：有两个任务当前执行。查询流程实例执行表：SELECT * FROM act_ru_execution上图中，说明当前流程实例有多个分支(两个)在运行。对并行任务的执行：并行任务执行不分前后，由任务的负责人去执行即可。执行技术经理任务后，查询当前任务表 SELECT * FROM act_ru_task已完成的技术经理任务在当前任务表act_ru_task_已被删除。在流程实例执行表：SELECT * FROM act_ru_execution有中多个分支存在且有并行网关的汇聚结点。有并行网关的汇聚结点：说明有一个分支已经到汇聚，等待其它的分支到达。当所有分支任务都完成，都到达汇聚结点后：流程实例执行表：SELECT * FROM act_ru_execution，执行流程实例已经变为总经理审批，说明流程执行已经通过并行网关总结：所有分支到达汇聚结点，并行网关执行完成。包含网关InclusiveGateway什么是包含网关包含网关可以看做是排他网关和并行网关的结合体。和排他网关一样，你可以在外出顺序流上定义条件，包含网关会解析它们。 但是主要的区别是包含网关可以选择多于一条顺序流，这和并行网关一样。包含网关的功能是基于进入和外出顺序流的：l 分支：所有外出顺序流的条件都会被解析，结果为true的顺序流会以并行方式继续执行， 会为每个顺序流创建一个分支。l 汇聚：所有并行分支到达包含网关，会进入等待状态， 直到每个包含流程token的进入顺序流的分支都到达。 这是与并行网关的最大不同。换句话说，包含网关只会等待被选中执行了的进入顺序流。 在汇聚之后，流程会穿过包含网关继续执行。流程定义：出差申请大于等于3天需要由项目经理审批，小于3天由技术经理审批，出差申请必须经过人事经理审批。包含网关图标，红框内：定义流程：注意：通过包含网关的每个分支的连线上设置condition条件。测试如果包含网关设置的条件中，流程变量不存在，报错;1org.activiti.engine.ActivitiException: Unknown property used in expression: $&#123;evection.num&gt;=3&#125;需要在流程启动时设置流程变量evection.num。1）、当流程执行到第一个包含网关后，会根据条件判断，当前要走哪几个分支：流程实例执行表：SELECT * FROM act_ru_execution第一条记录：包含网关分支。后两条记录代表两个要执行的分支：ACT_ID = “_13” 代表 项目经理神品ACT_ID = “_5” 代表 人事经理审批当前任务表：ACT_RU_TASK上图中，项目经理审批、人事经理审批 都是当前的任务，在并行执行。如果有一个分支执行先走到汇聚结点的分支，要等待其它执行分支走到汇聚。2）、先执行项目经理审批，然后查询当前任务表：ACT_RU_TASK当前任务还有人事经理审批需要处理。流程实例执行表：SELECT * FROM act_ru_execution发现人事经理的分支还存在，而项目经理分支已经走到ACT_ID = _18的节点。而ACT_ID=__18就是第二个包含网关这时，因为有2个分支要执行，包含网关会等所有分支走到汇聚才能执行完成。3）、执行人事经理审批然后查询当前任务表：ACT_RU_TASK当前任务表已经不是人事经理审批了，说明人事经理审批已经完成。流程实例执行表：SELECT * FROM act_ru_execution包含网关执行完成，分支和汇聚就从act_ru_execution删除。小结：在分支时，需要判断条件，符合条件的分支，将会执行，符合条件的分支最终才进行汇聚。事件网关EventGateway事件网关允许根据事件判断流向。网关的每个外出顺序流都要连接到一个中间捕获事件。 当流程到达一个基于事件网关，网关会进入等待状态：会暂停执行。与此同时，会为每个外出顺序流创建相对的事件订阅。事件网关的外出顺序流和普通顺序流不同，这些顺序流不会真的”执行”， 相反它们让流程引擎去决定执行到事件网关的流程需要订阅哪些事件。 要考虑以下条件：事件网关必须有两条或以上外出顺序流；事件网关后，只能使用intermediateCatchEvent类型（activiti不支持基于事件网关后连接ReceiveTask）连接到事件网关的中间捕获事件必须只有一个入口顺序流。流程定义事件网关图标，红框内intermediateCatchEvent：intermediateCatchEvent支持的事件类型：Message Event: 消息事件Singal Event： 信号事件Timer Event： 定时事件使用事件网关定义流程：Activiti与Spring整合开发Activiti与Spring整合的配置在pom.xml文件引入坐标如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103&lt;properties&gt; &lt;slf4j.version&gt;1.6.6&lt;/slf4j.version&gt; &lt;log4j.version&gt;1.2.12&lt;/log4j.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-engine&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-model&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-converter&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-json-converter&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-bpmn-layout&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti.cloud&lt;/groupId&gt; &lt;artifactId&gt;activiti-cloud-services-api&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.5.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.40&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;5.0.7.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log start --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-nop&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log end --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;commons-dbcp&lt;/groupId&gt; &lt;artifactId&gt;commons-dbcp&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;alfresco&lt;/id&gt; &lt;name&gt;Activiti Releases&lt;/name&gt; &lt;url&gt;https://artifacts.alfresco.com/nexus/content/repositories/activiti-releases/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;/repository&gt;&lt;/repositories&gt;在Activiti中核心类的是ProcessEngine流程引擎，与Spring整合就是让Spring来管理ProcessEngine通过org.activiti.spring.SpringProcessEngineConfiguration 与Spring整合方式来创建ProcessEngine对象。创建spring与activiti的整合配置文件：activiti-spring.xml（名称不固定）创建activiti-spring.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd\"&gt; &lt;!-- 数据源 --&gt; &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\"&gt; &lt;property name=\"driverClassName\" value=\"com.mysql.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/activiti\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;property name=\"maxActive\" value=\"3\"/&gt; &lt;property name=\"maxIdle\" value=\"1\"/&gt; &lt;/bean&gt; &lt;!-- 工作流引擎配置bean --&gt; &lt;bean id=\"processEngineConfiguration\" class=\"org.activiti.spring.SpringProcessEngineConfiguration\"&gt; &lt;!-- 数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;!-- 使用spring事务管理器 --&gt; &lt;property name=\"transactionManager\" ref=\"transactionManager\"/&gt; &lt;!-- 数据库策略 --&gt; &lt;property name=\"databaseSchemaUpdate\" value=\"drop-create\"/&gt; &lt;/bean&gt; &lt;!-- 流程引擎 --&gt; &lt;bean id=\"processEngine\" class=\"org.activiti.spring.ProcessEngineFactoryBean\"&gt; &lt;property name=\"processEngineConfiguration\" ref=\"processEngineConfiguration\"/&gt; &lt;/bean&gt; &lt;!-- 资源服务service --&gt; &lt;bean id=\"repositoryService\" factory-bean=\"processEngine\" factory-method=\"getRepositoryService\"/&gt; &lt;!-- 流程运行service --&gt; &lt;bean id=\"runtimeService\" factory-bean=\"processEngine\" factory-method=\"getRuntimeService\"/&gt; &lt;!-- 任务管理service --&gt; &lt;bean id=\"taskService\" factory-bean=\"processEngine\" factory-method=\"getTaskService\"/&gt; &lt;!-- 历史管理service --&gt; &lt;bean id=\"historyService\" factory-bean=\"processEngine\" factory-method=\"getHistoryService\"/&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\"/&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"insert*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\"/&gt; &lt;tx:method name=\"find*\" propagation=\"SUPPORTS\" read-only=\"true\"/&gt; &lt;tx:method name=\"get*\" propagation=\"SUPPORTS\" read-only=\"true\"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 切面，根据具体项目修改切点配置 &lt;aop:config proxy-target-class=\"true\"&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut=\"execution(*com.itheima.service.impl..(..))\"/&gt; &lt;/aop:config&gt;--&gt;&lt;/beans&gt;databaseSchemaUpdate的取值内容：flase： 默认值。activiti在启动时，会对比数据库表中保存的版本，如果没有表或者版本不匹配，将抛出异常。（生产环境常用）true： activiti会对数据库中所有表进行更新操作。如果表不存在，则自动创建。（开发时常用）create_drop： 在activiti启动时创建表，在关闭时删除表（必须手动关闭引擎，才能删除表）。（单元测试常用）drop-create： 在activiti启动时删除原来的旧表，然后在创建新表（不需要手动关闭引擎）。测试Activiti与Spring整合测试代码1234567891011121314/** 测试activiti与spring整合是否成功**/@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(locations = \"classpath:activiti-spring.xml\") public class ActivitiTest &#123; @Autowired private RepositoryService repositoryService; @Test public void test01()&#123; System.out.println(\"部署对象:\"+repositoryService); &#125; &#125;执行流程分析下面我们一起来分析Activiti与Spring整合加载的过程。1、加载activiti-spring.xml配置文件2、加载SpringProcessEngineConfiguration对象，这个对象它需要依赖注入dataSource对象和transactionManager对象。3、加载ProcessEngineFactoryBean工厂来创建ProcessEngine对象，而ProcessEngineFactoryBean工厂又需要依赖注入processEngineConfiguration对象。4、processEngine对象来负责创建我们的Service对象，从而简化Activiti的开发过程。Activiti7与SpringBoot整合开发Activiti7发布正式版之后，它与SpringBoot2.x已经完全支持整合开发。SpringBoot整合Activiti7的配置为了能够实现SpringBoot与Activiti7整合开发，首先我们要引入相关的依赖支持。在工程的pom.xml文件中引入相关的依赖，其中activiti的依赖是：activiti-spring-boot-starter。具体依赖如下所示：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.0.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;7.0.0.Beta2&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.29&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;通过该pom.xml文件所导入的坐标，我们就可以实现activiti7与Springboot整合。SpringBoot的application.yml文件配置为了能够实现Activiti7生成的表放到Mysql数据库中，需要在配置文件application.yml中添加相关的配置注意：activiti7默认没有开启数据库历史记录，需要手动配置开启12345678910111213141516171819202122spring: datasource: url: jdbc:mysql:///activiti?useUnicode=true&amp;characterEncoding=utf8&amp;serverTimezone=GMT username: root password: 123456 driver-class-name: com.mysql.jdbc.Driver activiti: #1.flase：默认值。activiti在启动时，对比数据库表中保存的版本，如果没有表或者版本不匹配，将抛出异常 #2.true： activiti会对数据库中所有表进行更新操作。如果表不存在，则自动创建 #3.create_drop： 在activiti启动时创建表，在关闭时删除表（必须手动关闭引擎，才能删除表） #4.drop-create： 在activiti启动时删除原来的旧表，然后在创建新表（不需要手动关闭引擎） database-schema-update: true #检测历史表是否存在 activiti7默认没有开启数据库历史记录 启动数据库历史记录 db-history-used: true #记录历史等级 可配置的历史级别有none, activity, audit, full #none：不保存任何的历史数据，因此，在流程执行过程中，这是最高效的。 #activity：级别高于none，保存流程实例与流程行为，其他数据不保存。 #audit：除activity级别会保存的数据外，还会保存全部的流程任务及其属性。audit为history的默认值。 #full：保存历史数据的最高级别，除了会保存audit级别的数据外，还会保存其他全部流程相关的细节数据，包括一些流程参数等。 history-level: full #校验流程文件，默认校验resources下的processes文件夹里的流程文件 check-process-definitions: false编写启动类1234567891011package com.itheima;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class ActApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ActApplication.class,args); &#125;&#125;添加SpringSecurity安全框架整合配置因为Activiti7与SpringBoot整合后，默认情况下，集成了SpringSecurity安全框架，这样我们就要去准备SpringSecurity整合进来的相关用户权限配置信息。SpringBoot的依赖包已经将SpringSecurity的依赖包也添加进项目中。添加SecurityUtil类为了能够快速实现SpringSecurity安全框架的配置，所添加的一个组件。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566package fun.obey.utils;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.security.core.Authentication;import org.springframework.security.core.GrantedAuthority;import org.springframework.security.core.context.SecurityContextHolder;import org.springframework.security.core.context.SecurityContextImpl;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.stereotype.Component;import java.util.Collection;@Componentpublic class SecurityUtil &#123; private Logger logger = LoggerFactory.getLogger(SecurityUtil.class); @Autowired @Qualifier(\"myUserDetailsService\") private UserDetailsService userDetailsService; public void logInAs(String username) &#123; UserDetails user = userDetailsService.loadUserByUsername(username); if (user == null) &#123; throw new IllegalStateException(\"User \" + username + \" doesn't exist, please provide a valid user\"); &#125; logger.info(\"&gt; Logged in as: \" + username); SecurityContextHolder.setContext( new SecurityContextImpl( new Authentication() &#123; @Override public Collection&lt;? extends GrantedAuthority&gt; getAuthorities() &#123; return user.getAuthorities(); &#125; @Override public Object getCredentials() &#123; return user.getPassword(); &#125; @Override public Object getDetails() &#123; return user; &#125; @Override public Object getPrincipal() &#123; return user; &#125; @Override public boolean isAuthenticated() &#123; return true; &#125; @Override public void setAuthenticated(boolean isAuthenticated) throws IllegalArgumentException &#123; &#125; @Override public String getName() &#123; return user.getUsername(); &#125; &#125;)); org.activiti.engine.impl.identity.Authentication.setAuthenticatedUserId(username); &#125; &#125;这个类可以从我们下载的Activiti7官方提供的Example中找到。添加DemoApplicationConfig类在Activiti7官方下载的Example中找到DemoApplicationConfig类，它的作用是为了实现SpringSecurity框架的用户权限的配置，这样我们就可以在系统中使用用户权限信息。本次项目中基本是在文件中定义出来的用户信息，当然也可以是数据库中查询的用户权限信息。后面处理流程时用到的任务负责人，需要添加在这里1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package fun.obey.config;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.security.core.authority.SimpleGrantedAuthority;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.crypto.password.PasswordEncoder;import org.springframework.security.provisioning.InMemoryUserDetailsManager;import java.util.Arrays;import java.util.List;import java.util.stream.Collectors;@Configurationpublic class DemoApplicationConfiguration &#123; private Logger logger = LoggerFactory.getLogger(DemoApplicationConfiguration.class); @Bean public UserDetailsService myUserDetailsService() &#123; InMemoryUserDetailsManager inMemoryUserDetailsManager = new InMemoryUserDetailsManager(); //这里添加用户，后面处理流程时用到的任务负责人，需要添加在这里 String[][] usersGroupsAndRoles = &#123; &#123;\"jack\", \"password\", \"ROLE_ACTIVITI_USER\", \"GROUP_activitiTeam\"&#125;, &#123;\"rose\", \"password\", \"ROLE_ACTIVITI_USER\", \"GROUP_activitiTeam\"&#125;, &#123;\"tom\", \"password\", \"ROLE_ACTIVITI_USER\", \"GROUP_activitiTeam\"&#125;, &#123;\"other\", \"password\", \"ROLE_ACTIVITI_USER\", \"GROUP_otherTeam\"&#125;, &#123;\"system\", \"password\", \"ROLE_ACTIVITI_USER\"&#125;, &#123;\"admin\", \"password\", \"ROLE_ACTIVITI_ADMIN\"&#125;, &#125;; for (String[] user : usersGroupsAndRoles) &#123; List&lt;String&gt; authoritiesStrings = Arrays.asList(Arrays.copyOfRange(user, 2, user.length)); logger.info(\"&gt; Registering new user: \" + user[0] + \" with the following Authorities[\" + authoritiesStrings + \"]\"); inMemoryUserDetailsManager.createUser(new User(user[0], passwordEncoder().encode(user[1]), authoritiesStrings.stream().map(s -&gt; new SimpleGrantedAuthority(s)).collect(Collectors.toList()))); &#125; return inMemoryUserDetailsManager; &#125; @Bean public PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder(); &#125;&#125;创建Bpmn文件Activiti7可以自动部署流程，前提是在resources目录下，创建一个新的目录processes，用来放置bpmn文件。创建一个简单的Bpmn流程文件，并设置任务的用户组Candidate Groups。Candidate Groups中的内容与上面DemoApplicationConfiguration类中出现的用户组名称要保持一致，可以填写：activitiTeam 或者 otherTeam。这样填写的好处：当不确定到底由谁来负责当前任务的时候，只要是Groups内的用户都可以拾取这个任务使用Junit方式测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package fun.obey.test;import fun.obey.utils.SecurityUtil;import org.activiti.api.process.model.ProcessInstance;import org.activiti.api.process.model.builders.ProcessPayloadBuilder;import org.activiti.api.process.runtime.ProcessRuntime;import org.activiti.api.runtime.shared.query.Page;import org.activiti.api.runtime.shared.query.Pageable;import org.activiti.api.task.model.Task;import org.activiti.api.task.model.builders.TaskPayloadBuilder;import org.activiti.api.task.runtime.TaskRuntime;import org.activiti.engine.repository.ProcessDefinition;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTest public class Actviti7DemoApplicationTests &#123; @Autowired private ProcessRuntime processRuntime; @Autowired private TaskRuntime taskRuntime; @Autowired private SecurityUtil securityUtil; @Test public void testActBoot()&#123; System.out.println(taskRuntime); &#125; /** * 查看流程定义 */ @Test public void contextLoads() &#123; securityUtil.logInAs(\"system\"); Page&lt;org.activiti.api.process.model.ProcessDefinition&gt; processDefinitionPage = processRuntime.processDefinitions(Pageable.of(0, 10)); System.out.println(\"可用的流程定义数量：\" + processDefinitionPage.getTotalItems()); for (org.activiti.api.process.model.ProcessDefinition pd : processDefinitionPage.getContent()) &#123; System.out.println(\"流程定义：\" + pd); &#125; &#125; /** * 启动流程实例 */ @Test public void testStartProcess() &#123; securityUtil.logInAs(\"system\"); ProcessInstance pi = processRuntime.start(ProcessPayloadBuilder. start(). withProcessDefinitionKey(\"myProcess\"). build()); System.out.println(\"流程实例ID：\" + pi.getId()); &#125; /** **查询任务，并完成自己的任务 **/ @Test public void testTask() &#123; securityUtil.logInAs(\"jack\"); Page&lt;Task&gt; taskPage=taskRuntime.tasks(Pageable.of(0,10)); if (taskPage.getTotalItems()&gt;0)&#123; for (Task task:taskPage.getContent())&#123; taskRuntime.claim(TaskPayloadBuilder. claim(). withTaskId(task.getId()).build()); System.out.println(\"任务：\"+task); taskRuntime.complete(TaskPayloadBuilder. complete(). withTaskId(task.getId()).build()); &#125; &#125; Page&lt;Task&gt; taskPage2=taskRuntime.tasks(Pageable.of*(0,10)); if (taskPage2.getTotalItems()&gt;0)&#123; System.out.println(\"任务：\"+taskPage2.getContent()); &#125; &#125;&#125;","categories":[{"name":"工作流框架","slug":"工作流框架","permalink":"https://me.obey.fun/categories/工作流框架/"},{"name":"Activiti7","slug":"工作流框架/Activiti7","permalink":"https://me.obey.fun/categories/工作流框架/Activiti7/"}],"tags":[{"name":"BPMN","slug":"BPMN","permalink":"https://me.obey.fun/tags/BPMN/"},{"name":"Activiti","slug":"Activiti","permalink":"https://me.obey.fun/tags/Activiti/"}],"keywords":[{"name":"工作流框架","slug":"工作流框架","permalink":"https://me.obey.fun/categories/工作流框架/"},{"name":"Activiti7","slug":"工作流框架/Activiti7","permalink":"https://me.obey.fun/categories/工作流框架/Activiti7/"}]},{"title":"持续集成及Jenkins详解","slug":"持续集成及Jenkins详解","date":"2021-03-05T14:19:10.000Z","updated":"2021-03-05T15:45:35.639Z","comments":false,"path":"持续集成及Jenkins详解.html","link":"","permalink":"https://me.obey.fun/持续集成及Jenkins详解.html","excerpt":"","text":"持续集成及Jenkins介绍软件开发生命周期软件开发生命周期又叫做SDLC（Software Development Life Cycle），它是集合了计划、开发、测试 和部署过程的集合。如下图所示 ：需求分析这是生命周期的第一阶段，根据项目需求，团队执行一个可行性计划的分析。项目需求可能是公司内部 或者客户提出的。这阶段主要是对信息的收集，也有可能是对现有项目的改善和重新做一个新的项目。 还要分析项目的预算多长，可以从哪方面受益及布局，这也是项目创建的目标。设计第二阶段就是设计阶段，系统架构和满意状态（就是要做成什么样子，有什么功能），和创建一个项目 计划。计划可以使用图表，布局设计或者文者的方式呈现。实现第三阶段就是实现阶段，项目经理创建和分配工作给开者，开发者根据任务和在设计阶段定义的目标进 行开发代码。依据项目的大小和复杂程度，可以需要数月或更长时间才能完成。测试测试人员进行代码测试 ，包括功能测试、代码测试、压力测试等。进化最后进阶段就是对产品不断的进化改进和维护阶段，根据用户的使用情况，可能需要对某功能进行修 改，bug修复，功能增加等。软件开发瀑布模型瀑布模型是最著名和最常使用的软件开发模型。瀑布模型就是一系列的软件开发过程。它是由制造业繁 衍出来的。一个高度化的结构流程在一个方向上流动，有点像生产线一样。在瀑布模型创建之初，没有 其它开发的模型，有很多东西全靠开发人员去猜测，去开发。这样的模型仅适用于那些简单的软件开 发， 但是已经不适合现在的开发了。下图对软件开发模型的一个阐述。优势劣势简单易用和理解各个阶段的划分完全固定，阶段之间产生大量的文档，极大地 增加了工作量。当前一阶段完成后，您只需要 去关注后续阶段。由于开发模型是线性的，用户只有等到整个过程的末期才能见 到开发成果，从而增加了开发风险。为项目提供了按阶段划分的检 查节点瀑布模型的突出缺点是不适应用户需求的变化。软件的敏捷开发什么是敏捷开发敏捷开发（Agile Development） 的核心是迭代开发（Iterative Development） 与 增量开发（Incremental Development） 。何为迭代开发？对于大型软件项目，传统的开发方式是采用一个大周期（比如一年）进行开发，整个过程就是一次”大开发”；迭代开发的方式则不一样，它将开发过程拆分成多个小周期，即一次”大开发”变成多次”小开发”，每次小开发都是同样的流程，所以看上去就好像重复在做同样的步骤。举例来说，SpaceX 公司想造一个大推力火箭，将人类送到火星。但是，它不是一开始就造大火箭，而是先造一个最简陋的小火箭 Falcon 1。结果，第一次发射就爆炸了，直到第四次发射，才成功进入轨道。然后，开发了中型火箭 Falcon 9，九年中发射了70次。最后，才开发 Falcon 重型火箭。如果SpaceX 不采用迭代开发，它可能直到现在还无法上天。何为增量开发？软件的每个版本，都会新增一个用户可以感知的完整功能。也就是说，按照新增功能来划分迭代。举例来说，房产公司开发一个10栋楼的小区。如果采用增量开发的模式，该公司第一个迭代就是交付一号楼，第二个迭代交付二号楼……每个迭代都是完成一栋完整的楼。而不是第一个迭代挖好10栋楼的地基，第二个迭代建好每栋楼的骨架，第三个迭代架设屋顶……敏捷开发如何迭代？虽然敏捷开发将软件开发分成多个迭代，但是也要求，每次迭代都是一个完整的软件开发周期，必须按照软件工程的方法论，进行正规的流程管理。敏捷开发有什么好处？早期交付敏捷开发的第一个好处，就是早期交付，从而大大降低成本。 还是以上一节的房产公司为例，如果按照传统的”瀑布开发模式”，先挖10栋楼的地基、再盖骨架、然后架设屋顶，每个阶段都等到前一个阶段完成后开始，可能需要两年才能一次性交付10栋楼。也就是说，如果不考虑预售，该项目必须等到两年后才能回款。 敏捷开发是六个月后交付一号楼，后面每两个月交付一栋楼。因此，半年就能回款10%，后面每个月都会有现金流，资金压力就大大减轻了。降低风险敏捷开发的第二个好处是，及时了解市场需求，降低产品不适用的风险。 请想一想，哪一种情况损失比较小：10栋楼都造好以后，才发现卖不出去，还是造好第一栋楼，就发现卖不出去，从而改进或停建后面9栋楼？什么是持续集成持续集成（ Continuous integration ， 简称 CI ）指的是，频繁地（一天多次）将代码集成到主干。持续集成的目的，就是让产品可以快速迭代，同时还能保持高质量。它的核心措施是，代码集成到主干之前，必须通过自动化测试。只要有一个测试用例失败，就不能集成。通过持续集成， 团队可以快速的从一个功能到另一个功能，简而言之，敏捷软件开发很大一部分都要归功于持续集成。持续集成的流程根据持续集成的设计，代码从提交到生产，整个过程有以下几步。提交流程的第一步，是开发者向代码仓库提交代码。所有后面的步骤都始于本地代码的一次提交（commit）。测试（第一轮）代码仓库对commit操作配置了钩子（hook），只要提交代码或者合并进主干，就会跑自动化测试。构建通过第一轮测试，代码就可以合并进主干，就算可以交付了。交付后，就先进行构建（build），再进入第二轮测试。所谓构建，指的是将源码转换为可以运行的实际代码，比如安装依赖，配置各种资源（样式表、JS脚本、图片）等等。测试（第二轮）构建完成，就要进行第二轮测试。如果第一轮已经涵盖了所有测试内容，第二轮可以省略，当然，这时构建步骤也要移到第一轮测试前面。部署过了第二轮测试，当前代码就是一个可以直接部署的版本（artifact）。将这个版本的所有文件打包（tar filename.tar * ）存档，发到生产服务器。回滚一旦当前版本发生问题，就要回滚到上一个版本的构建结果。最简单的做法就是修改一下符号链接，指向上一个版本的目录。持续集成的组成要素一个自动构建过程， 从检出代码、 编译构建、 运行测试、 结果记录、 测试统计等都是自动完成的， 无需人工干预。一个代码存储库，即需要版本控制软件来保障代码的可维护性，同时作为构建过程的素材库，一般使用SVN或Git。一个持续集成服务器， Jenkins 就是一个配置简单和使用方便的持续集成服务器。持续集成的好处降低风险，由于持续集成不断去构建，编译和测试，可以很早期发现问题，所以修复的代价就少；对系统健康持续检查，减少发布风险带来的问题；减少重复性工作；持续部署，提供可部署单元包；持续交付可供使用的版本；增强团队信心；Jenkins介绍Jenkins 是一款流行的开源持续集成（Continuous Integration）工具，广泛用于项目开发，具有自动化构建、测试和部署等功能。官网： http://jenkins-ci.org/。Jenkins的特征：开源的Java语言开发持续集成工具，支持持续集成，持续部署。易于安装部署配置：可通过yum安装,或下载war包以及通过docker容器等快速实现安装部署，可方便web界面配置管理。消息通知及测试报告：集成RSS/E-mail通过RSS发布构建结果或当构建完成时通过e-mail通知，生成JUnit/TestNG测试报告。分布式构建：支持Jenkins能够让多台计算机一起构建/测试。文件识别：Jenkins能够跟踪哪次构建生成哪些jar，哪次构建使用哪个版本的jar等。丰富的插件支持：支持扩展插件，你可以开发适合自己团队使用的工具，如git，svn，maven，docker等。Jenkins安装和持续集成环境配置持续集成流程说明首先，开发人员每天进行代码提交，提交到Git仓库然后，Jenkins作为持续集成工具，使用Git工具到Git仓库拉取代码到集成服务器，再配合JDK，Maven等软件完成代码编译，代码测试与审查，测试，打包等工作，在这个过程中每一步出错，都重新再执行一次整个流程。最后，Jenkins把生成的jar或war包分发到测试服务器或者生产服务器，测试人员或用户就可以访问应用。服务器列表名称IP地址安装的软件代码托管服务器192.168.66.100Gitlab-12.4.2持续集成服务器192.168.66.101Jenkins-2.190.3，JDK1.8，Maven3.6.2，Git， SonarQube应用测试服务器192.168.66.102JDK1.8，Tomcat8.5Gitlab代码托管服务器安装Gitlab简介官网： https://about.gitlab.com/GitLab 是一个用于仓库管理系统的开源项目，使用Git作为代码管理工具，并在此基础上搭建起来的web服务。GitLab和GitHub一样属于第三方基于Git开发的作品，免费且开源（基于MIT协议），与Github类似，可以注册用户，任意提交你的代码，添加SSHKey等等。不同的是，GitLab是可以部署到自己的服务器上，数据库等一切信息都掌握在自己手上，适合团队内部协作开发，你总不可能把团队内部的智慧总放在别人的服务器上吧？简单来说可把GitLab看作个人版的GitHub。Gitlab安装安装相关依赖yum -y install policycoreutils openssh-server openssh-clients postfix启动ssh服务&amp;设置为开机启动systemctl enable sshd &amp;&amp; sudo systemctl start sshd设置postfix开机自启，并启动，postfix支持gitlab发信功能systemctl enable postfix &amp;&amp; systemctl start postfix开放ssh以及http服务，然后重新加载防火墙列表firewall-cmd –add-service=ssh –permanentfirewall-cmd –add-service=http –permanentfirewall-cmd –reload如果关闭防火墙就不需要做以上配置下载gitlab包，并且安装在线下载安装包：wget https://mirrors.tuna.tsinghua.edu.cn/gitlab-ce/yum/el6/gitlab-ce-12.4.2-ce.0.el6.x86_64.rpm安装：rpm -i gitlab-ce-12.4.2-ce.0.el6.x86_64.rpm修改gitlab配置vi /etc/gitlab/gitlab.rb修改gitlab访问地址和端口，默认为80，我们改为82external_url ‘http://192.168.66.100:82nginx[‘listen_port’] = 82重载配置及启动gitlabgitlab-ctl reconfiguregitlab-ctl restart把端口添加到防火墙firewall-cmd –zone=public –add-port=82/tcp –permanentfirewall-cmd –reload启动成功后，看到以下修改管理员root密码的页面，修改密码后，然后登录即可Gitlab添加组、创建用户、创建项目1）创建组使用管理员 root 创建组，一个组里面可以有多个项目分支，可以将开发添加到组里面进行设置权限，不同的组就是公司不同的开发项目或者服务模块，不同的组添加不同的开发即可实现对开发设置权限的管理2）创建用户创建用户的时候，可以选择Regular或Admin类型。创建完用户后，立即修改密码3）将用户添加到组中选择某个用户组，进行Members管理组的成员Gitlab用户在组里面有5种不同权限：Guest：可以创建issue、发表评论，不能读写版本库Reporter：可以克隆代码，不能提交，QA、PM可以赋予这个权限Developer：可以克隆代码、开发、提交、push，普通开发可以赋予这个权限Maintainer：可以创建项目、添加tag、保护分支、添加项目成员、编辑项目，核心开发可以赋予这个权限Owner：可以设置项目访问权限 - Visibility Level、删除项目、迁移项目、管理组成员，开发组组长可以赋予这个权限4）在用户组中创建项目以刚才创建的新用户身份登录到Gitlab，然后在用户组中创建新的项目源码上传到Gitlab仓库下面来到IDEA开发工具，我们已经准备好一个简单的Web应用准备到集成部署。我们要把源码上传到Gitlab的项目仓库中。1）项目结构说明我们建立了一个非常简单的web应用，只有一个index.jsp页面，如果部署好，可以访问该页面就成功啦！2）开启版本控制3）提交代码到本地仓库先Add到缓存区再Commit到本地仓库4）推送到Gitlab项目仓库中这时都Gitlab的项目中拷贝url地址输入gitlab的用户名和密码，然后就可以把代码推送到远程仓库啦刷新gitlab项目持续集成环境(1)-Jenkins安装1）安装JDKJenkins需要依赖JDK，所以先安装JDK1.8yum install java-1.8.0-openjdk* -y安装目录为：/usr/lib/jvm2）获取jenkins安装包下载页面：https://jenkins.io/zh/download/安装文件：jenkins-2.190.3-1.1.noarch.rpm3）把安装包上传到192.168.66.101服务器，进行安装rpm -ivh jenkins-2.190.3-1.1.noarch.rpm4）修改Jenkins配置vi /etc/syscofig/jenkins修改内容如下：JENKINS_USER=”root”JENKINS_PORT=”8888”5）启动Jenkinssystemctl start jenkins6）打开浏览器访问http://192.168.66.101:8888注意：本服务器把防火墙关闭了，如果开启防火墙，需要在防火墙添加端口7）获取并输入admin账户密码cat /var/lib/jenkins/secrets/initialAdminPassword8）跳过插件安装因为Jenkins插件需要连接默认官网下载，速度非常慢，而且经过会失败，所以我们暂时先跳过插件安装9）添加一个管理员账户，并进入Jenkins后台保存并完成开始使用Jenkins持续集成环境(2)-Jenkins插件管理Jenkins本身不提供很多功能，我们可以通过使用插件来满足我们的使用。例如从Gitlab拉取代码，使用Maven构建项目等功能需要依靠插件完成。接下来演示如何下载插件。修改Jenkins插件下载地址Jenkins国外官方插件地址下载速度非常慢，所以可以修改为国内插件地址：Jenkins-&gt;Manage Jenkins-&gt;Manage Plugins，点击Available这样做是为了把Jenkins官方的插件列表下载到本地，接着修改地址文件，替换为国内插件地址cd /var/lib/jenkins/updatessed -i ‘s/http:\\/\\/updates.jenkinsci.org\\/download/https:\\/\\/mirrors.tuna.tsinghua.edu.cn\\/jenkins/g’ default.json &amp;&amp; sed -i‘s/http:\\/\\/www.google.com/https:\\/\\/www.baidu.com/g&#39; default.json最后，Manage Plugins点击Advanced，把Update Site改为国内插件下载地址https://mirrors.tuna.tsinghua.edu.cn/jenkins/updates/update-center.jsonSumbit后，在浏览器输入： http://192.168.66.101:8888/restart ，重启Jenkins。下载中文汉化插件Jenkins-&gt;Manage Jenkins-&gt;Manage Plugins，点击Available，搜索”Chinese”完成后如下图：重启Jenkins后，就看到Jenkins汉化了！（PS：但可能部分菜单汉化会失败）持续集成环境(3)-Jenkins用户权限管理我们可以利用Role-based Authorization Strategy 插件来管理Jenkins用户权限安装Role-based Authorization Strategy插件开启权限全局安全配置授权策略切换为”Role-Based Strategy”，保存创建角色在系统管理页面进入 Manage and Assign Roles点击”Manage Roles”Global roles（全局角色）：管理员等高级用户可以创建基于全局的角色 Project roles（项目角色）：针对某个或者某些项目的角色 Slave roles（奴隶角色）：节点相关的权限我们添加以下三个角色：baseRole：该角色为全局角色。这个角色需要绑定Overall下面的Read权限，是为了给所有用户绑定最基本的Jenkins访问权限。注意：如果不给后续用户绑定这个角色，会报错误：用户名 ismissing the Overall/Read permissionrole1：该角色为项目角色。使用正则表达式绑定”itcast.*”，意思是只能操作itcast开头的项目。role2：该角色也为项目角色。绑定”itheima.*”，意思是只能操作itheima开头的项目。保存。创建用户在系统管理页面进入 Manage Users分别创建两个用户：jack和eric给用户分配角色系统管理页面进入Manage and Assign Roles，点击Assign Roles绑定规则如下：eric用户分别绑定baseRole和role1角色jack用户分别绑定baseRole和role2角色保存。创建项目测试权限以itcast管理员账户创建两个项目，分别为itcast01和itheima01结果为：eric用户登录，只能看到itcast01项目jack用户登录，只能看到itheima01项目持续集成环境(4)-Jenkins凭证管理凭据可以用来存储需要密文保护的数据库密码、Gitlab密码信息、Docker私有仓库密码等，以便Jenkins可以和这些第三方的应用进行交互。安装Credentials Binding插件要在Jenkins使用凭证管理功能，需要安装Credentials Binding插件安装插件后，左边多了”凭证”菜单，在这里管理所有凭证可以添加的凭证有5种：Username with password：用户名和密码SSH Username with private key： 使用SSH用户和密钥Secret file：需要保密的文本文件，使用时Jenkins会将文件复制到一个临时目录中，再将文件路径设置到一个变量中，等构建结束后，所复制的Secret file就会被删除。Secret text：需要保存的一个加密的文本串，如钉钉机器人或Github的api tokenCertificate：通过上传证书文件的方式常用的凭证类型有：Username with password（用户密码）和SSH Username with private key（SSH密钥）接下来以使用Git工具到Gitlab拉取项目源码为例，演示Jenkins的如何管理Gitlab的凭证。安装Git插件和Git工具为了让Jenkins支持从Gitlab拉取源码，需要安装Git插件以及在CentOS7上安装Git工具。Git插件安装：CentOS7上安装Git工具：yum install git -y 安装git –version 安装后查看版本用户密码类型1）创建凭证Jenkins-&gt;凭证-&gt;系统-&gt;全局凭证-&gt;添加凭证选择”Username with password”，输入Gitlab的用户名和密码，点击”确定”。2）测试凭证是否可用创建一个FreeStyle项目：新建Item-&gt;FreeStyle Project-&gt;确定找到”源码管理”-&gt;”Git”，在Repository URL复制Gitlab中的项目URL这时会报错说无法连接仓库！在Credentials选择刚刚添加的凭证就不报错啦保存配置后，点击构建”Build Now“ 开始构建项目查看/var/lib/jenkins/workspace/目录，发现已经从Gitlab成功拉取了代码到Jenkins中。SSH密钥类型SSH免密登录示意图1）使用root用户生成公钥和私钥ssh-keygen -t rsa在/root/.ssh/目录保存了公钥和使用id_rsa：私钥文件id_rsa.pub：公钥文件2）把生成的公钥放在Gitlab中以root账户登录-&gt;点击头像-&gt;Settings-&gt;SSH Keys复制刚才id_rsa.pub文件的内容到这里，点击”Add Key”3）在Jenkins中添加凭证，配置私钥在Jenkins添加一个新的凭证，类型为”SSH Username with private key”，把刚才生成私有文件内容复制过来4）测试凭证是否可用新建”test02”项目-&gt;源码管理-&gt;Git，这次要使用Gitlab的SSH连接，并且选择SSH凭证同样尝试构建项目，如果代码可以正常拉取，代表凭证配置成功！持续集成环境(5)-Maven安装和配置在Jenkins集成服务器上，我们需要安装Maven来编译和打包项目。安装Maven先上传Maven软件到192.168.66.101tar -xzf apache-maven-3.6.2-bin.tar.gz 解压mkdir -p /opt/maven 创建目录mv apache-maven-3.6.2/* /opt/maven 移动文件配置环境变量vi /etc/profile123export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdkexport MAVEN_HOME=/opt/mavenexport PATH=$PATH:$JAVA_HOME/bin:$MAVEN_HOME/binsource /etc/profile 配置生效mvn -v 查找Maven版本全局工具配置关联JDK和MavenJenkins-&gt;Global Tool Configuration-&gt;JDK-&gt;新增JDK，配置如下：Jenkins-&gt;Global Tool Configuration-&gt;Maven-&gt;新增Maven，配置如下：添加Jenkins全局变量Manage Jenkins-&gt;Configure System-&gt;Global Properties ，添加三个全局变量JAVA_HOME、M2_HOME、PATH+EXTRA修改Maven的settings.xmlmkdir /root/repo 创建本地仓库目录vi /opt/maven/conf/settings.xml本地仓库改为：/root/repo/添加阿里云私服地址：alimaven aliyun maven http://maven.aliyun.com/nexus/content/groups/public/ central测试Maven是否配置成功使用之前的gitlab密码测试项目，修改配置构建-&gt;增加构建步骤-&gt;Execute Shell输入mvn clean package再次构建，如果可以把项目打成war包，代表maven环境配置成功啦！持续集成环境(6)-Tomcat安装和配置安装Tomcat8.5把Tomcat压缩包上传到192.168.66.102服务器yum install java-1.8.0-openjdk -y 安装JDK（已完成）tar -xzf apache-tomcat-8.5.47.tar.gz 解压mkdir -p /opt/tomcat 创建目录mv /root/apache-tomcat-8.5.47/ /opt/tomcat 移动文件/opt/tomcat/bin/startup.sh 启动tomcat注意：服务器已经关闭了防火墙，所以可以直接访问Tomcat啦地址为：http://192.168.66.102/8080配置Tomcat用户角色权限默认情况下Tomcat是没有配置用户角色权限的但是，后续Jenkins部署项目到Tomcat服务器，需要用到Tomcat的用户，所以修改tomcat以下配置，添加用户及权限vi /opt/tomcat/conf/tomcat-users.xml内容如下：12345678910&lt;tomcat-users&gt; &lt;role rolename=\"tomcat\"/&gt; &lt;role rolename=\"role1\"/&gt; &lt;role rolename=\"manager-script\"/&gt; &lt;role rolename=\"manager-gui\"/&gt; &lt;role rolename=\"manager-status\"/&gt; &lt;role rolename=\"admin-gui\"/&gt; &lt;role rolename=\"admin-script\"/&gt; &lt;user username=\"tomcat\" password=\"tomcat\" roles=\"manager-gui,managerscript,tomcat,admin-gui,admin-script\"/&gt;&lt;/tomcat-users&gt;用户和密码都是：tomcat注意：为了能够刚才配置的用户登录到Tomcat，还需要修改以下配置vi /opt/tomcat/webapps/manager/META-INF/context.xml1234&lt;!--&lt;Valve className=\"org.apache.catalina.valves.RemoteAddrValve\"allow=\"127\\.\\d+\\.\\d+\\.\\d+|::1|0:0:0:0:0:0:0:1\" /&gt;--&gt;把上面这行注释掉即可！重启Tomcat，访问测试/opt/tomcat/bin/shutdown.sh 停止/opt/tomcat/bin/startup.sh 启动访问： http://192.168.66.102:8080/manager/html ，输入tomcat和tomcat，看到以下页面代表成功啦Jenkins构建Maven项目Jenkins项目构建类型(1)-Jenkins构建的项目类型介绍Jenkins中自动构建项目的类型有很多，常用的有以下三种：自由风格软件项目（FreeStyle Project）Maven项目（Maven Project）流水线项目（Pipeline Project）每种类型的构建其实都可以完成一样的构建过程与结果，只是在操作方式、灵活度等方面有所区别，在实际开发中可以根据自己的需求和习惯来选择。（PS：个人推荐使用流水线类型，因为灵活度非常高）Jenkins项目构建类型(2)-自由风格项目构建下面演示创建一个自由风格项目来完成项目的集成过程：拉取代码-&gt;编译-&gt;打包-&gt;部署拉取代码1）创建项目2）配置源码管理，从gitlab拉取代码编译打包构建-&gt;添加构建步骤-&gt;Executor Shell123echo \"开始编译和打包\"mvn clean packageecho \"编译和打包结束\"部署把项目部署到远程的Tomcat里面1）安装 Deploy to container插件Jenkins本身无法实现远程部署到Tomcat的功能，需要安装Deploy to container插件实现2）添加Tomcat用户凭证3）添加构建后操作点击”Build Now”，开始构建过程4）部署成功后，访问项目http://192.168.66.102:8080/web_demo-1.0-SNAPSHOT/演示改动代码后的持续集成1）IDEA中源码修改并提交到gitlab2）在Jenkins中项目重新构建3）访问TomcatJenkins项目构建类型(3)-Maven项目构建1）安装Maven Integration插件2）创建Maven项目3）配置项目拉取代码和远程部署的过程和自由风格项目一样，只是”构建”部分不同Jenkins项目构建类型(4)-Pipeline流水线项目构建(*)Pipeline简介1）概念Pipeline，简单来说，就是一套运行在 Jenkins 上的工作流框架，将原来独立运行于单个或者多个节点的任务连接起来，实现单个任务难以完成的复杂流程编排和可视化的工作。2）使用Pipeline有以下好处（来自翻译自官方文档）：代码：Pipeline以代码的形式实现，通常被检入源代码控制，使团队能够编辑，审查和迭代其传送流程。 持久：无论是计划内的还是计划外的服务器重启，Pipeline都是可恢复的。 可停止：Pipeline可接收交互式输入，以确定是否继续执行Pipeline。 多功能：Pipeline支持现实世界中复杂的持续交付要求。它支持fork/join、循环执行，并行执行任务的功能。 可扩展：Pipeline插件支持其DSL的自定义扩展 ，以及与其他插件集成的多个选项。3）如何创建 Jenkins Pipeline呢？Pipeline 脚本是由 Groovy 语言实现的，但是我们没必要单独去学习 GroovyPipeline 支持两种语法：Declarative(声明式)和 Scripted Pipeline(脚本式)语法Pipeline 也有两种创建方法：可以直接在 Jenkins 的 Web UI 界面中输入脚本；也可以通过创建一个 Jenkinsfile 脚本文件放入项目源码库中（一般我们都推荐在 Jenkins 中直接从源代码控制(SCM)中直接载入 Jenkinsfile Pipeline 这种方法）。安装Pipeline插件Manage Jenkins-&gt;Manage Plugins-&gt;可选插件安装插件后，创建项目的时候多了“流水线”类型Pipeline语法快速入门1）Declarative声明式-Pipeline创建项目流水线-&gt;选择HelloWorld模板生成内容如下：12345678910pipeline &#123; agent any stages &#123; stage(&apos;Hello&apos;) &#123; steps &#123; echo &apos;Hello World&apos; &#125; &#125; &#125;&#125;stages：代表整个流水线的所有执行阶段。通常stages只有1个，里面包含多个stagestage：代表流水线中的某个阶段，可能出现n个。一般分为拉取代码，编译构建，部署等阶段。steps：代表一个阶段内需要执行的逻辑。steps里面是shell脚本，git拉取代码，ssh远程发布等任意内容。编写一个简单声明式Pipeline：1234567891011121314151617181920pipeline &#123; agent any stages &#123; stage(&apos;拉取代码&apos;) &#123; steps &#123; echo &apos;拉取代码&apos; &#125; &#125; stage(&apos;编译构建&apos;) &#123; steps &#123; echo &apos;编译构建&apos; &#125; &#125; stage(&apos;项目部署&apos;) &#123; steps &#123; echo &apos;项目部署&apos; &#125; &#125; &#125;&#125;点击构建，可以看到整个构建过程2）Scripted Pipeline脚本式-Pipeline创建项目这次选择”Scripted Pipeline”123456789node &#123; def mvnHome stage(&apos;Preparation&apos;) &#123; // for display purposes &#125; stage(&apos;Build&apos;) &#123; &#125; stage(&apos;Results&apos;) &#123; &#125;&#125;Node：节点，一个 Node 就是一个 Jenkins 节点，Master 或者 Agent，是执行 Step 的具体运行环境，后续讲到Jenkins的Master-Slave架构的时候用到。Stage：阶段，一个 Pipeline 可以划分为若干个 Stage，每个 Stage 代表一组操作，比如：Build、Test、Deploy，Stage 是一个逻辑分组的概念。Step：步骤，Step 是最基本的操作单元，可以是打印一句话，也可以是构建一个 Docker 镜像，由各类 Jenkins 插件提供，比如命令：sh ‘make’，就相当于我们平时 shell 终端中执行 make 命令一样。编写一个简单的脚本式Pipeline123456789101112node &#123; def mvnHome stage(&apos;拉取代码&apos;) &#123; // for display purposes echo &apos;拉取代码&apos; &#125; stage(&apos;编译构建&apos;) &#123; echo &apos;编译构建&apos; &#125; stage(&apos;项目部署&apos;) &#123; echo &apos;项目部署&apos; &#125;&#125;构建结果和声明式一样！拉取代码1234567891011pipeline &#123; agent any stages &#123; stage(&apos;拉取代码&apos;) &#123; steps &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name:&apos;*/master&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &apos;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&apos;, url:&apos;git@192.168.66.100:itheima_group/web_demo.git&apos;]]]) &#125; &#125; &#125;&#125;部署1234567891011121314151617181920pipeline &#123; agent any stages &#123; stage(&apos;拉取代码&apos;) &#123; steps &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &apos;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&apos;, url:&apos;git@192.168.66.100:itheima_group/web_demo.git&apos;]]]) &#125; &#125; stage(&apos;编译构建&apos;) &#123; steps &#123; sh label: &apos;&apos;, script: &apos;mvn clean package&apos; &#125; &#125; stage(&apos;项目部署&apos;) &#123; steps &#123; deploy adapters: [tomcat8(credentialsId: &apos;afc43e5e-4a4e-4de6-984fb1d5a254e434&apos;, path: &apos;&apos;, url: &apos;http://192.168.66.102:8080&apos;)], contextPath: null,war: &apos;target/*.war&apos; &#125; &#125; &#125;&#125;Pipeline Script from SCM刚才我们都是直接在Jenkins的UI界面编写Pipeline代码，这样不方便脚本维护，建议把Pipeline脚本放在项目中（一起进行版本控制）1）在项目根目录建立Jenkinsfile文件，把内容复制到该文件中把Jenkinsfile上传到Gitlab2）在项目中引用该文件Jenkins项目构建细节(1)-常用的构建触发器Jenkins内置4种构建触发器：触发远程构建其他工程构建后触发（Build after other projects are build）定时构建（Build periodically）轮询SCM（Poll SCM）触发远程构建触发构建url：http://192.168.66.101:8888/job/web_demo_pipeline/build?token=6666其他工程构建后触发1）创建pre_job流水线工程2）配置需要触发的工程定时构建定时字符串从左往右分别为： 分 时 日 月 周一些定时表达式的例子：每30分钟构建一次：H代表形参 H/30 10:02 10:32每2个小时构建一次: H H/2 每天的8点，12点，22点，一天构建3次： (多个时间点中间用逗号隔开) 0 8,12,22 每天中午12点定时构建一次 H 12 每天下午18点定时构建一次 H 18 在每个小时的前半个小时内的每10分钟 H(0-29)/10 每两小时一次，每个工作日上午9点到下午5点(也许是上午10:38，下午12:38，下午2:38，下午4:38) H H(9-16)/2 1-5轮询SCM轮询SCM，是指定时扫描本地代码仓库的代码是否有变更，如果代码有变更就触发项目构建。注意：这次构建触发器，Jenkins会定时扫描本地整个项目的代码，增大系统的开销，不建议使用。Jenkins项目构建细节(2)-Git hook自动触发构建(*)刚才我们看到在Jenkins的内置构建触发器中，轮询SCM可以实现Gitlab代码更新，项目自动构建，但是该方案的性能不佳。那有没有更好的方案呢？ 有的。就是利用Gitlab的webhook实现代码push到仓库，立即触发项目自动构建。安装Gitlab Hook插件需要安装两个插件：Gitlab Hook和GitLabJenkins设置自动构建等会需要把生成的webhook URL配置到Gitlab中。Gitlab配置webhook1）开启webhook功能使用root账户登录到后台，点击Admin Area -&gt; Settings -&gt; Network勾选”Allow requests to the local network from web hooks and services”2）在项目添加webhook点击项目-&gt;Settings-&gt;Integrations注意：以下设置必须完成，否则会报错！Manage Jenkins-&gt;Configure SystemJenkins项目构建细节(3)-Jenkins的参数化构建有时在项目构建的过程中，我们需要根据用户的输入动态传入一些参数，从而影响整个构建结果，这时我们可以使用参数化构建。Jenkins支持非常丰富的参数类型接下来演示通过输入gitlab项目的分支名称来部署不同分支项目。项目创建分支，并推送到Gitlab上新建分支：v1，代码稍微改动下，然后提交到gitlab上。这时看到gitlab上有一个两个分支：master和v1在Jenkins添加字符串类型参数改动pipeline流水线代码点击Build with Parameters输入分支名称，构建即可！构建完成后访问Tomcat查看结果Jenkins项目构建细节(4)-配置邮箱服务器发送构建结果安装Email Extension插件Jenkins设置邮箱相关参数Manage Jenkins-&gt;Configure System设置邮件参数设置Jenkins默认邮箱信息准备邮件内容在项目根目录编写email.html，并把文件推送到Gitlab，内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=\"UTF-8\"&gt;&lt;title&gt;$&#123;ENV, var=\"JOB_NAME\"&#125;-第$&#123;BUILD_NUMBER&#125;次构建日志&lt;/title&gt;&lt;/head&gt;&lt;body leftmargin=\"8\" marginwidth=\"0\" topmargin=\"8\" marginheight=\"4\"offset=\"0\"&gt;&lt;table width=\"95%\" cellpadding=\"0\" cellspacing=\"0\"style=\"font-size: 11pt; font-family: Tahoma, Arial, Helvetica, sansserif\"&gt;&lt;tr&gt;&lt;td&gt;(本邮件是程序自动下发的，请勿回复！)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;h2&gt;&lt;font color=\"#0000FF\"&gt;构建结果 - $&#123;BUILD_STATUS&#125;&lt;/font&gt;&lt;/h2&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;br /&gt;&lt;b&gt;&lt;font color=\"#0B610B\"&gt;构建信息&lt;/font&gt;&lt;/b&gt;&lt;hr size=\"2\" width=\"100%\" align=\"center\" /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;ul&gt;&lt;li&gt;项目名称&amp;nbsp;：&amp;nbsp;$&#123;PROJECT_NAME&#125;&lt;/li&gt;&lt;li&gt;构建编号&amp;nbsp;：&amp;nbsp;第$&#123;BUILD_NUMBER&#125;次构建&lt;/li&gt;&lt;li&gt;触发原因：&amp;nbsp;$&#123;CAUSE&#125;&lt;/li&gt;&lt;li&gt;构建日志：&amp;nbsp;&lt;ahref=\"$&#123;BUILD_URL&#125;console\"&gt;$&#123;BUILD_URL&#125;console&lt;/a&gt;&lt;/li&gt;&lt;li&gt;构建&amp;nbsp;&amp;nbsp;Url&amp;nbsp;：&amp;nbsp;&lt;ahref=\"$&#123;BUILD_URL&#125;\"&gt;$&#123;BUILD_URL&#125;&lt;/a&gt;&lt;/li&gt;&lt;li&gt;工作目录&amp;nbsp;：&amp;nbsp;&lt;ahref=\"$&#123;PROJECT_URL&#125;ws\"&gt;$&#123;PROJECT_URL&#125;ws&lt;/a&gt;&lt;/li&gt;&lt;li&gt;项目&amp;nbsp;&amp;nbsp;Url&amp;nbsp;：&amp;nbsp;&lt;ahref=\"$&#123;PROJECT_URL&#125;\"&gt;$&#123;PROJECT_URL&#125;&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;b&gt;&lt;font color=\"#0B610B\"&gt;Changes Since LastSuccessful Build:&lt;/font&gt;&lt;/b&gt;&lt;hr size=\"2\" width=\"100%\" align=\"center\" /&gt;&lt;/td&gt;&lt;/tr&gt;编写Jenkinsfile添加构建后发送邮件&lt;tr&gt;&lt;td&gt;&lt;ul&gt;&lt;li&gt;历史变更记录 : &lt;ahref=\"$&#123;PROJECT_URL&#125;changes\"&gt;$&#123;PROJECT_URL&#125;changes&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt; $&#123;CHANGES_SINCE_LAST_SUCCESS,reverse=true, format=\"Changes forBuild #%n:&lt;br /&gt;%c&lt;br /&gt;\",showPaths=true,changesFormat=\"&lt;pre&gt;[%a]&lt;br/&gt;%m&lt;/pre&gt;\",pathFormat=\"&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;%p\"&#125;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;b&gt;Failed Test Results&lt;/b&gt;&lt;hr size=\"2\" width=\"100%\" align=\"center\" /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;prestyle=\"font-size: 11pt; font-family: Tahoma, Arial, Helvetica,sans-serif\"&gt;$FAILED_TESTS&lt;/pre&gt;&lt;br /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;b&gt;&lt;font color=\"#0B610B\"&gt;构建日志 (最后 100行):&lt;/font&gt;&lt;/b&gt;&lt;hr size=\"2\" width=\"100%\" align=\"center\" /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;textarea cols=\"80\" rows=\"30\" readonly=\"readonly\"style=\"font-family: Courier New\"&gt;$&#123;BUILD_LOG,maxLines=100&#125;&lt;/textarea&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt;编写Jenkinsfile添加构建后发送邮件123456789101112131415161718192021222324252627pipeline &#123; agent any stages &#123; stage(&apos;拉取代码&apos;) &#123; steps &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &apos;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&apos;, url:&apos;git@192.168.66.100:itheima_group/web_demo.git&apos;]]]) &#125; &#125; stage(&apos;编译构建&apos;) &#123; steps &#123; sh label: &apos;&apos;, script: &apos;mvn clean package&apos; &#125; &#125; stage(&apos;项目部署&apos;) &#123; steps &#123; deploy adapters: [tomcat8(credentialsId: &apos;afc43e5e-4a4e-4de6-984fb1d5a254e434&apos;, path: &apos;&apos;, url: &apos;http://192.168.66.102:8080&apos;)], contextPath: null,war: &apos;target/*.war&apos; &#125; &#125; &#125; post &#123; always &#123; emailext( subject: &apos;构建通知：$&#123;PROJECT_NAME&#125; - Build # $&#123;BUILD_NUMBER&#125; -$&#123;BUILD_STATUS&#125;!&apos;,body: &apos;$&#123;FILE,path=&quot;email.html&quot;&#125;&apos;,to: &apos;xxx@qq.com&apos;) &#125; &#125; &#125;测试PS：邮件相关全局参数参考列表：系统设置-&gt;Extended E-mail Notification-&gt;Content Token Reference，点击旁边的?号Jenkins+SonarQube代码审查(1) - 安装SonarQubeSonaQube简介SonarQube是一个用于管理代码质量的开放平台，可以快速的定位代码中潜在的或者明显的错误。目前支持java,C#,C/C++,Python,PL/SQL,Cobol,JavaScrip,Groovy等二十几种编程语言的代码质量管理与检测。官网：https://www.sonarqube.org环境要求软件服务器版本JDK192.168.66.1011.8MySQL192.168.66.1015.7SonarQube192.168.66.1016.7.4安装SonarQube安装MySQL安装SonarQube在MySQL创建sonar数据库下载sonar压缩包：https://www.sonarqube.org/downloads/解压sonar，并设置权限yum install unzipunzip sonarqube-6.7.4.zip 解压mkdir /opt/sonar 创建目录mv sonarqube-6.7.4/* /opt/sonar 移动文件useradd sonar 创建sonar用户，必须sonar用于启动，否则报错chown -R sonar. /opt/sonar 更改sonar目录及文件权限修改sonar配置文件vi /opt/sonarqube-6.7.4/conf/sonar.properties内容如下：sonar.jdbc.username=root sonar.jdbc.password=Root@123sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance&amp;useSSL=false注意：sonar默认监听9000端口，如果9000端口被占用，需要更改。启动sonarcd /opt/sonarqube-6.7.4su sonar ./bin/linux-x86-64/sonar.sh start 启动su sonar ./bin/linux-x86-64/sonar.sh status 查看状态su sonar ./bin/linux-x86-64/sonar.sh stop 停止tail -f logs/sonar.logs 查看日志访问sonarhttp://192.168.66.101:9000默认账户：admin/admin创建tokentoken要记下来后面要使用例如：0151ae8c548a143eda9253e4334ad030b56047eeJenkins+SonarQube代码审查(2) - 实现代码审查安装SonarQube Scanner插件添加SonarQube凭证Jenkins进行SonarQube配置Manage Jenkins-&gt;Configure System-&gt;SonarQube serversManage Jenkins-&gt;Global Tool ConfigurationSonaQube关闭审查结果上传到SCM功能在项目添加SonaQube代码审查（非流水线项目）添加构建步骤：123456789101112131415# must be unique in a given SonarQube instancesonar.projectKey=web_demo# this is the name and version displayed in the SonarQube UI. Was mandatoryprior to SonarQube 6.1.sonar.projectName=web_demosonar.projectVersion=1.0# Path is relative to the sonar-project.properties file. Replace \"\\\" by \"/\" onWindows.# This property is optional if sonar.modules is set.sonar.sources=.sonar.exclusions=**/test/**,**/target/**sonar.java.source=1.8sonar.java.target=1.8# Encoding of the source code. Default is default system encodingsonar.sourceEncoding=UTF-8在项目添加SonaQube代码审查（流水线项目）1）项目根目录下，创建sonar-project.properties文件123456789101112131415# must be unique in a given SonarQube instancesonar.projectKey=web_demo# this is the name and version displayed in the SonarQube UI. Was mandatoryprior to SonarQube 6.1.sonar.projectName=web_demosonar.projectVersion=1.0# Path is relative to the sonar-project.properties file. Replace \"\\\" by \"/\" onWindows.# This property is optional if sonar.modules is set.sonar.sources=.sonar.exclusions=**/test/**,**/target/**sonar.java.source=1.8sonar.java.target=1.8# Encoding of the source code. Default is default system encodingsonar.sourceEncoding=UTF-82）修改Jenkinsfile，加入SonarQube代码审查阶段12345678910111213141516171819202122232425262728293031323334353637pipeline &#123; agent any stages &#123; stage(&apos;拉取代码&apos;) &#123; steps &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &apos;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&apos;, url:&apos;git@192.168.66.100:itheima_group/web_demo.git&apos;]]]) &#125; &#125; stage(&apos;编译构建&apos;) &#123; steps &#123; sh label: &apos;&apos;, script: &apos;mvn clean package&apos; &#125; &#125; stage(&apos;SonarQube代码审查&apos;) &#123; steps&#123; script &#123; scannerHome = tool &apos;sonarqube-scanner&apos; &#125; withSonarQubeEnv(&apos;sonarqube6.7.4&apos;) &#123; sh &quot;$&#123;scannerHome&#125;/bin/sonar-scanner&quot; &#125; &#125; &#125; stage(&apos;项目部署&apos;) &#123; steps &#123; deploy adapters: [tomcat8(credentialsId: &apos;afc43e5e-4a4e-4de6-984fb1d5a254e434&apos;, path: &apos;&apos;, url: &apos;http://192.168.66.102:8080&apos;)], contextPath: null,war: &apos;target/*.war&apos; &#125; &#125; &#125; post &#123; always &#123; emailext( subject: &apos;构建通知：$&#123;PROJECT_NAME&#125; - Build # $&#123;BUILD_NUMBER&#125; -$&#123;BUILD_STATUS&#125;!&apos;,body: &apos;$&#123;FILE,path=&quot;email.html&quot;&#125;&apos;,to: &apos;1014671449@qq.com&apos;) &#125; &#125; &#125;3）到SonarQube的UI界面查看审查结果Jenkins+Docker+SpringCloud微服务持续集成(上)Jenkins+Docker+SpringCloud持续集成流程说明大致流程说明：1）开发人员每天把代码提交到Gitlab代码仓库2）Jenkins从Gitlab中拉取项目源码，编译并打成jar包，然后构建成Docker镜像，将镜像上传到Harbor私有仓库。3）Jenkins发送SSH远程命令，让生产部署服务器到Harbor私有仓库拉取镜像到本地，然后创建容器。4）最后，用户可以访问到容器服务列表服务器名称IP地址安装的软件代码托管服务器192.168.66.100Gitlab持续集成服务器192.168.66.101Jenkins，Maven，Docker18.06.1-ceDocker仓库服务器192.168.66.102Docker18.06.1-ce，Harbor1.9.2生成部署服务器192.168.66.103Docker18.06.1-ceSpringCloud微服务源码概述项目架构：前后端分离后端技术栈：SpringBoot+SpringCloud+SpringDataJpa（Spring全家桶）微服务项目结构：tensquare_parent：父工程，存放基础配置tensquare_common：通用工程，存放工具类tensquare_eureka_server：SpringCloud的Eureka注册中心tensquare_zuul：SpringCloud的网关服务tensquare_admin_service：基础权限认证中心，负责用户认证（使用JWT认证）tensquare_gathering：一个简单的业务模块，活动微服务相关逻辑数据库结构：tensquare_user：用户认证数据库，存放用户账户数据。对应tensquare_admin_service微服务tensquare_gathering：活动微服务数据库。对应tensquare_gathering微服务微服务配置分析：tensquare_eurekatensquare_zuultensquare_admin_servicetensquare_gathering本地部署(1)-SpringCloud微服务部署本地运行微服务1）逐一启动微服务2）使用postman测试功能是否可用本地部署微服务1）SpringBoot微服务项目打包必须导入该插件1234&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&lt;/plugin&gt;打包后在target下产生jar包2）本地运行微服务的jar包java -jar xxx.jar3）查看效果本地部署(2)-前端静态web网站前端技术栈：NodeJS+VueJS+ElementUI使用Visual Studio Code打开源码1）本地运行npm run dev2）打包静态web网站npm run build打包后，产生dist目录的静态文件3）部署到nginx服务器把dist目录的静态文件拷贝到nginx的html目录，启动nginx4）启动nginx，并访问http://localhost:82环境准备(1)-Docker快速入门详细介绍：https://me.obey.fun/Docker%E5%85%A5%E9%97%A8%E4%B8%8E%E5%AE%9E%E8%B7%B5.html#moreDocker简介Docker 是一个开源的应用容器引擎，基于 Go 语言 并遵从 Apache2.0 协议开源。Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。虚拟机容器占用磁盘空间非常大，GB级小，MB甚至KB级启动速度慢，分钟级快，秒级运行形态运行于Hypervisor上直接运行在宿主机内核上并发性一台宿主机上十几个，最多几十个上百个，甚至数百上千个性能逊于宿主机接近宿主机本地进程资源利用率低高简单一句话总结：Docker技术就是让我们更加高效轻松地将任何应用在Linux服务器部署和使用。Docker安装1）卸载旧版本yum list installed | grep docker 列出当前所有docker的包yum -y remove docker的包名称 卸载docker包rm -rf /var/lib/docker 删除docker的所有镜像和容器2）安装必要的软件包sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm23）设置下载的镜像仓库sudo yum-config-manager \\ –add-repo \\ https://download.docker.com/linux/centos/dockerce.repo4）列出需要安装的版本列表yum list docker-ce –showduplicates | sort -r5）安装指定版本（这里使用18.0.1版本）sudo yum install docker-ce-18.06.1.ce6）查看版本docker -v7）启动Dockersudo systemctl start docker 启动sudo systemctl enable docker 设置开机启动8）添加阿里云镜像下载地址vi /etc/docker/daemon.json内容如下：123&#123;\"registry-mirrors\": [\"https://zydiol88.mirror.aliyuncs.com\"]&#125;9）重启Dockersudo systemctl restart dockerDocker基本命令快速入门1）镜像命令镜像：相当于应用的安装包，在Docker部署的任何应用都需要先构建成为镜像docker search 镜像名称 搜索镜像docker pull 镜像名称 拉取镜像docker images 查看本地所有镜像docker rmi -f 镜像名称 删除镜像docker pull openjdk:8-jdk-alpine2）容器命令容器：容器是由镜像创建而来。容器是Docker运行应用的载体，每个应用都分别运行在Docker的每个容器中。docker run -i 镜像名称:标签 运行容器（默认是前台运行）docker ps 查看运行的容器docker ps -a 查询所有容器常用的参数：-i：运行容器-d：后台守方式运行（守护式）–name：给容器添加名称-p：公开容器端口给当前宿主机-v：挂载目录docker exec -it 容器ID/容器名称 /bin/bash 进入容器内部docker start/stop/restart 容器名称/ID 启动/停止/重启容器docker rm -f 容器名称/ID 删除容器环境准备(2)-Dockerfile镜像脚本快速入门Dockerfile简介Dockerfile其实就是我们用来构建Docker镜像的源码，当然这不是所谓的编程源码，而是一些命令的组合，只要理解它的逻辑和语法格式，就可以编写Dockerfile了。简单点说，Dockerfile的作用：它可以让用户个性化定制Docker镜像。因为工作环境中的需求各式各样，网络上的镜像很难满足实际的需求。Dockerfile常见命令命令作用FROM image_name:tagMAINTAINER user_name声明镜像的作者ENV key value设置环境变量 (可以写多条)RUN command编译镜像时运行的脚本(可以写多条)CMD设置容器的启动命令ENTRYPOINT设置容器的入口程序ADD source_dir/file dest_dir/file将宿主机的文件复制到容器内，如果是一个压缩文件，将会在复 制后自动解压COPY source_dir/file dest_dir/file和ADD相似，但是如果有压缩文件并不能解压WORKDIR path_dir设置工作目录ARG设置编译镜像时加入的参数VOLUMN设置容器的挂载卷RUN、CMD、ENTRYPOINT的区别？RUN：用于指定 docker build 过程中要运行的命令，即是创建 Docker 镜像（image）的步骤CMD：设置容器的启动命令， Dockerfile 中只能有一条 CMD 命令，如果写了多条则最后一条生效， CMD不支持接收docker run的参数。ENTRYPOINT：入口程序是容器启动时执行的程序， docker run 中最后的命令将作为参数传递给入口 程序 ，ENTRYPOINY类似于 CMD 指令，但可以接收docker run的参数 。以下是mysql官方镜像的Dockerfile示例：1234567891011121314151617181920FROM oraclelinux:7-slimARG MYSQL_SERVER_PACKAGE=mysql-community-server-minimal-5.7.28ARG MYSQL_SHELL_PACKAGE=mysql-shell-8.0.18# Install serverRUN yum install -y https://repo.mysql.com/mysql-community-minimal-releaseel7.rpm \\https://repo.mysql.com/mysql-community-release-el7.rpm \\&amp;&amp; yum-config-manager --enable mysql57-server-minimal \\&amp;&amp; yum install -y \\$MYSQL_SERVER_PACKAGE \\$MYSQL_SHELL_PACKAGE \\libpwquality \\&amp;&amp; yum clean all \\&amp;&amp; mkdir /docker-entrypoint-initdb.dVOLUME /var/lib/mysqlCOPY docker-entrypoint.sh /entrypoint.shCOPY healthcheck.sh /healthcheck.shENTRYPOINT [\"/entrypoint.sh\"]HEALTHCHECK CMD /healthcheck.shEXPOSE 3306 33060CMD [\"mysqld\"]使用Dockerfile制作微服务镜像我们利用Dockerfile制作一个Eureka注册中心的镜像1）上传Eureka的微服务jar包到linux2）编写Dockerfile12345FROM openjdk:8-jdk-alpineARG JAR_FILECOPY $&#123;JAR_FILE&#125; app.jarEXPOSE 10086ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]3）构建镜像docker build –build-arg JAR_FILE=tensquare_eureka_server-1.0-SNAPSHOT.jar -t eureka:v1 .4）查看镜像是否创建成功docker images5）创建容器docker run -i –name=eureka -p 10086:10086 eureka:v16）访问容器http://192.168.66.101:10086环境准备(3)-Harbor镜像仓库安装及使用Harbor简介Harbor（港口，港湾）是一个用于存储和分发Docker镜像的企业级Registry服务器。除了Harbor这个私有镜像仓库之外，还有Docker官方提供的Registry。相对Registry，Harbor具有很多优势：提供分层传输机制，优化网络传输 Docker镜像是是分层的，而如果每次传输都使用全量文件(所以用FTP的方式并不适合)，显然不经济。必须提供识别分层传输的机制，以层的UUID为标识，确定传输的对象。提供WEB界面，优化用户体验 只用镜像的名字来进行上传下载显然很不方便，需要有一个用户界面可以支持登陆、搜索功能，包括区分公有、私有镜像。支持水平扩展集群 当有用户对镜像的上传下载操作集中在某服务器，需要对相应的访问压力作分解。良好的安全机制 企业中的开发团队有很多不同的职位，对于不同的职位人员，分配不同的权限，具有更好的安全性。Harbor安装Harbor需要安装在192.168.66.102上面1）先安装Docker并启动Docker（已完成）参考之前的安装过程2）先安装docker-compose12sudo curl -L https://github.com/docker/compose/releases/download/1.21.2/dockercompose-$(uname -s)-$(uname -m) -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose3）给docker-compose添加执行权限sudo chmod +x /usr/local/bin/docker-compose4）查看docker-compose是否安装成功docker-compose -version5）下载Harbor的压缩包（本课程版本为：v1.9.2）https://github.com/goharbor/harbor/releases6）上传压缩包到linux，并解压tar -xzf harbor-offline-installer-v1.9.2.tgzmkdir /opt/harbormv harbor/* /opt/harborcd /opt/harbor7）修改Harbor的配置vi harbor.yml修改hostname和porthostname: 192.168.66.102port: 858）安装Harbor./prepare./install.sh9）启动Harbordocker-compose up -d 启动docker-compose stop 停止docker-compose restart 重新启动10）访问Harborhttp://192.168.66.102:85默认账户密码：admin/Harbor12345在Harbor创建用户和项目1）创建项目Harbor的项目分为公开和私有的：公开项目：所有用户都可以访问，通常存放公共的镜像，默认有一个library公开项目。私有项目：只有授权用户才可以访问，通常存放项目本身的镜像。我们可以为微服务项目创建一个新的项目：2）创建用户创建的用户为： itcast/Itcast1233）给私有项目分配用户进入tensquare项目-&gt;成员角色权限说明访客对于指定项目拥有只读权限开发人员对于指定项目拥有读写权限维护人员对于指定项目拥有读写权限，创建 Webhooks项目管理员除了读写权限，同时拥有用户管理/镜像扫描等管理权限4）以新用户登录Harbor把镜像上传到Harbor1）给镜像打上标签docker tag eureka:v1 192.168.66.102:85/tensquare/eureka:v12）推送镜像docker push 192.168.66.102:85/tensquare/eureka:v1123The push refers to repository [192.168.66.102:85/tensquare/eureka]Get https://192.168.66.102:85/v2/: http: server gave HTTP response to HTTPSclient这时会出现以上报错，是因为Docker没有把Harbor加入信任列表中3）把Harbor地址加入到Docker信任列表vi /etc/docker/daemon.json1234&#123;\"registry-mirrors\": [\"https://zydiol88.mirror.aliyuncs.com\"],\"insecure-registries\": [\"192.168.66.102:85\"]&#125;需要重启Docker4）再次执行推送命令，会提示权限不足1denied: requested access to the resource is denied需要先登录Harbor，再推送镜像5）登录Harbordocker login -u 用户名 -p 密码 192.168.66.102:8512345WARNING! Using --password via the CLI is insecure. Use --password-stdin.WARNING! Your password will be stored unencrypted in /root/.docker/config.json.Configure a credential helper to remove this warning. Seehttps://docs.docker.com/engine/reference/commandline/login/#credentials-storeLogin Succeeded从Harbor下载镜像需求：在192.168.66.103服务器完成从Harbor下载镜像1）安装Docker，并启动Docker（已经完成）2）修改Docker配置vi /etc/docker/daemon.json1234&#123;\"registry-mirrors\": [\"https://zydiol88.mirror.aliyuncs.com\"],\"insecure-registries\": [\"192.168.66.102:85\"]&#125;重启docker3）先登录，再从Harbor下载镜像docker login -u 用户名 -p 密码 192.168.66.102:85docker pull 192.168.66.102:85/tensquare/eureka:v1微服务持续集成(1)-项目代码上传到Gitlab在IDEA操作即可，参考之前的步骤。包括后台微服务和前端web网站代码微服务持续集成(2)-从Gitlab拉取项目源码1）创建Jenkinsfile文件1234567//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;node &#123; stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &quot;$&#123;git_auth&#125;&quot;, url:&apos;git@192.168.66.100:itheima_group/tensquare_back.git&apos;]]]) &#125; &#125;2）拉取Jenkinsfile文件微服务持续集成(3)-提交到SonarQube代码审查1）创建项目，并设置参数创建tensquare_back项目，添加两个参数2）每个项目的根目录下添加sonar-project.properties1234567891011121314151617# must be unique in a given SonarQube instancesonar.projectKey=tensquare_zuul# this is the name and version displayed in the SonarQube UI. Was mandatoryprior to SonarQube 6.1.sonar.projectName=tensquare_zuulsonar.projectVersion=1.0# Path is relative to the sonar-project.properties file. Replace &quot;\\&quot; by &quot;/&quot; onWindows.# This property is optional if sonar.modules is set.sonar.sources=.sonar.exclusions=**/test/**,**/target/**sonar.java.binaries=.sonar.java.source=1.8sonar.java.target=1.8sonar.java.libraries=**/target/classes/**# Encoding of the source code. Default is default system encodingsonar.sourceEncoding=UTF-8注意：修改sonar.projectKey和sonar.projectName3）修改Jenkinsfile构建脚本1234567891011121314151617181920//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;//构建版本的名称def tag = &quot;latest&quot;node &#123; stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &quot;$&#123;git_auth&#125;&quot;, url:&apos;git@192.168.66.100:itheima_group/tensquare_back.git&apos;]]]) &#125; stage(&apos;代码审查&apos;) &#123; def scannerHome = tool &apos;sonarqube-scanner&apos; withSonarQubeEnv(&apos;sonarqube6.7.4&apos;) &#123; sh &quot;&quot;&quot; cd $&#123;project_name&#125; $&#123;scannerHome&#125;/bin/sonar-scanner &quot;&quot;&quot; &#125; &#125;&#125;微服务持续集成(4)-使用Dockerfile编译、生成镜像利用dockerfile-maven-plugin插件构建Docker镜像1）在每个微服务项目的pom.xml加入dockerfile-maven-plugin插件1234567891011&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.3.6&lt;/version&gt; &lt;configuration&gt; &lt;repository&gt;$&#123;project.artifactId&#125;&lt;/repository&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;target/$&#123;project.build.finalName&#125;.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt;&lt;/plugin&gt;2）在每个微服务项目根目录下建立Dockerfile文件123456#FROM java:8FROM openjdk:8-jdk-alpineARG JAR_FILECOPY $&#123;JAR_FILE&#125; app.jarEXPOSE 10086ENTRYPOINT [\"java\",\"-jar\",\"/app.jar\"]注意：每个项目公开的端口不一样3）修改Jenkinsfile构建脚本123456789101112131415161718192021222324252627282930//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;//构建版本的名称def tag = &quot;latest&quot;//Harbor私服地址def harbor_url = &quot;192.168.66.102:85/tensquare/&quot;node &#123; stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &quot;$&#123;git_auth&#125;&quot;, url:&apos;git@192.168.66.100:itheima_group/tensquare_back.git&apos;]]]) &#125; stage(&apos;代码审查&apos;) &#123; def scannerHome = tool &apos;sonarqube-scanner&apos; withSonarQubeEnv(&apos;sonarqube6.7.4&apos;) &#123; sh &quot;&quot;&quot; cd $&#123;project_name&#125; $&#123;scannerHome&#125;/bin/sonar-scanner &quot;&quot;&quot; &#125; &#125; stage(&apos;编译，构建镜像&apos;) &#123; //定义镜像名称 def imageName = &quot;$&#123;project_name&#125;:$&#123;tag&#125;&quot; //编译，安装公共工程 sh &quot;mvn -f tensquare_common clean install&quot; //编译，构建本地镜像 sh &quot;mvn -f $&#123;project_name&#125; clean package dockerfile:build&quot; &#125; &#125;注意：如果出现找不到父工程依赖，需要手动把父工程的依赖上传到仓库中微服务持续集成(5)-上传到Harbor镜像仓库1）修改Jenkinsfile构建脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;//构建版本的名称def tag = &quot;latest&quot;//Harbor私服地址def harbor_url = &quot;192.168.66.102:85&quot;//Harbor的项目名称def harbor_project_name = &quot;tensquare&quot;//Harbor的凭证def harbor_auth = &quot;ef499f29-f138-44dd-975e-ff1ca1d8c933&quot;node &#123; stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &quot;$&#123;git_auth&#125;&quot;, url:&apos;git@192.168.66.100:itheima_group/tensquare_back.git&apos;]]]) &#125; stage(&apos;代码审查&apos;) &#123; def scannerHome = tool &apos;sonarqube-scanner&apos; withSonarQubeEnv(&apos;sonarqube6.7.4&apos;) &#123; sh &quot;&quot;&quot; cd $&#123;project_name&#125; $&#123;scannerHome&#125;/bin/sonar-scanner &quot;&quot;&quot; &#125; &#125; stage(&apos;编译，构建镜像&apos;) &#123; //定义镜像名称 def imageName = &quot;$&#123;project_name&#125;:$&#123;tag&#125;&quot; //编译，安装公共工程 sh &quot;mvn -f tensquare_common clean install&quot; //编译，构建本地镜像 sh &quot;mvn -f $&#123;project_name&#125; clean package dockerfile:build&quot; //给镜像打标签 sh &quot;docker tag $&#123;imageName&#125; $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; //登录Harbor，并上传镜像 withCredentials([usernamePassword(credentialsId: &quot;$&#123;harbor_auth&#125;&quot;,passwordVariable: &apos;password&apos;, usernameVariable: &apos;username&apos;)]) &#123; //登录 sh &quot;docker login -u $&#123;username&#125; -p $&#123;password&#125; $&#123;harbor_url&#125;&quot; //上传镜像 sh &quot;docker push $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; &#125; //删除本地镜像 sh &quot;docker rmi -f $&#123;imageName&#125;&quot; sh &quot;docker rmi -f $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; &#125;2）使用凭证管理Harbor私服账户和密码先在凭证建立Harbor的凭证，在生成凭证脚本代码微服务持续集成(6)-拉取镜像和发布应用注意：192.168.66.103服务已经安装Docker并启动安装 Publish Over SSH 插件安装以下插件，可以实现远程发送Shell命令配置远程部署服务器1）拷贝公钥到远程服务器ssh-copy-id 192.168.66.1032）系统配置-&gt;添加远程服务器修改Jenkinsfile构建脚本生成远程调用模板代码添加一个port参数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;//构建版本的名称def tag = &quot;latest&quot;//Harbor私服地址def harbor_url = &quot;192.168.66.102:85&quot;//Harbor的项目名称def harbor_project_name = &quot;tensquare&quot;//Harbor的凭证def harbor_auth = &quot;ef499f29-f138-44dd-975e-ff1ca1d8c933&quot;node &#123; stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &quot;$&#123;git_auth&#125;&quot;, url:&apos;git@192.168.66.100:itheima_group/tensquare_back.git&apos;]]]) &#125; stage(&apos;代码审查&apos;) &#123; def scannerHome = tool &apos;sonarqube-scanner&apos; withSonarQubeEnv(&apos;sonarqube6.7.4&apos;) &#123; sh &quot;&quot;&quot; cd $&#123;project_name&#125; $&#123;scannerHome&#125;/bin/sonar-scanner &quot;&quot;&quot; &#125; &#125; stage(&apos;编译，构建镜像，部署服务&apos;) &#123; //定义镜像名称 def imageName = &quot;$&#123;project_name&#125;:$&#123;tag&#125;&quot; //编译并安装公共工程 sh &quot;mvn -f tensquare_common clean install&quot; //编译，构建本地镜像 sh &quot;mvn -f $&#123;project_name&#125; clean package dockerfile:build&quot; //给镜像打标签 sh &quot;docker tag $&#123;imageName&#125; $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; //登录Harbor，并上传镜像 withCredentials([usernamePassword(credentialsId: &quot;$&#123;harbor_auth&#125;&quot;,passwordVariable: &apos;password&apos;, usernameVariable: &apos;username&apos;)]) &#123; //登录 sh &quot;docker login -u $&#123;username&#125; -p $&#123;password&#125; $&#123;harbor_url&#125;&quot; //上传镜像 sh &quot;docker push $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; &#125; //删除本地镜像 sh &quot;docker rmi -f $&#123;imageName&#125;&quot; sh &quot;docker rmi -f $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; //=====以下为远程调用进行项目部署======== sshPublisher(publishers: [sshPublisherDesc(configName: &apos;master_server&apos;,transfers: [sshTransfer(cleanRemote: false, excludes: &apos;&apos;, execCommand:&quot;/opt/jenkins_shell/deploy.sh $harbor_url $harbor_project_name $project_name $tag $port&quot;, execTimeout: 120000, flatten: false, makeEmptyDirs: false,noDefaultExcludes: false, patternSeparator: &apos;[, ]+&apos;, remoteDirectory: &apos;&apos;, remoteDirectorySDF: false, removePrefix: &apos;&apos;, sourceFiles: &apos;&apos;)], usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)]) &#125; &#125;编写deploy.sh部署脚本1234567891011121314151617181920212223242526272829303132#! /bin/sh#接收外部参数harbor_url=$1harbor_project_name=$2project_name=$3tag=$4port=$5imageName=$harbor_url/$harbor_project_name/$project_name:$tagecho \"$imageName\"#查询容器是否存在，存在则删除containerId=`docker ps -a | grep -w $&#123;project_name&#125;:$&#123;tag&#125; | awk '&#123;print $1&#125;'`if [ \"$containerId\" != \"\" ] ; then#停掉容器docker stop $containerId#删除容器docker rm $containerIdecho \"成功删除容器\"fi#查询镜像是否存在，存在则删除imageId=`docker images | grep -w $project_name | awk '&#123;print $3&#125;'`if [ \"$imageId\" != \"\" ] ; then#删除镜像docker rmi -f $imageIdecho \"成功删除镜像\"fi# 登录Harbor私服docker login -u itcast -p Itcast123 $harbor_url# 下载镜像docker pull $imageName# 启动容器docker run -di -p $port:$port $imageNameecho \"容器启动成功\"上传deploy.sh文件到/opt/jenkins_shell目录下，且文件至少有执行权限！chmod +x deploy.sh 添加执行权限导入数据，测试微服务微服务持续集成(7)-部署前端静态web网站安装Nginx服务器yum install epel-releaseyum -y install nginx 安装修改nginx的端口，默认80，改为9090：vi /etc/nginx/nginx.conf12345server &#123; listen 9090 default_server; listen [::]:9090 default_server; server_name _; root /usr/share/nginx/html;还需要关闭selinux，将SELINUX=disabledsetenforce 0 先临时关闭vi /etc/selinux/config 编辑文件，永久关闭 SELINUX=disabled启动Nginxsystemctl enable nginx 设置开机启动systemctl start nginx 启动systemctl stop nginx 停止systemctl restart nginx 重启访问：http://192.168.66.103:9090/安装NodeJS插件Jenkins配置Nginx服务器Manage Jenkins-&gt;Global Tool Configuration创建前端流水线项目建立Jenkinsfile构建脚本123456789101112131415161718192021//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;node &#123; stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &quot;$&#123;git_auth&#125;&quot;, url:&apos;git@192.168.66.100:itheima_group/tensquare_front.git&apos;]]]) &#125; stage(&apos;打包，部署网站&apos;) &#123; //使用NodeJS的npm进行打包 nodejs(&apos;nodejs12&apos;)&#123; sh &apos;&apos;&apos; npm install npm run build &apos;&apos;&apos; &#125; //=====以下为远程调用进行项目部署======== sshPublisher(publishers: [sshPublisherDesc(configName: &apos;master_server&apos;,transfers: [sshTransfer(cleanRemote: false, excludes: &apos;&apos;, execCommand: &apos;&apos;,execTimeout: 120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes:false, patternSeparator: &apos;[, ]+&apos;, remoteDirectory: &apos;/usr/share/nginx/html&apos;,remoteDirectorySDF: false, removePrefix: &apos;dist&apos;, sourceFiles: &apos;dist/**&apos;)],usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)]) &#125;&#125;完成后，访问：http://192.168.66.103:9090 进行测试。5、Jenkins+Docker+SpringCloud微服务持续集成(下)Jenkins+Docker+SpringCloud部署方案优化上面部署方案存在的问题：1）一次只能选择一个微服务部署2）只有一台生产者部署服务器3）每个微服务只有一个实例，容错率低优化方案：1）在一个Jenkins工程中可以选择多个微服务同时发布2）在一个Jenkins工程中可以选择多台生产服务器同时部署3）每个微服务都是以集群高可用形式部署Jenkins+Docker+SpringCloud集群部署流程说明修改所有微服务配置注册中心配置(*)12345678910111213141516171819202122232425262728293031# 集群版spring: application: name: EUREKA-HA---server: port: 10086spring: # 指定profile=eureka-server1 profiles: eureka-server1eureka: instance: # 指定当profile=eureka-server1时，主机名是eureka-server1 hostname: 192.168.66.103 client: service-url: # 将自己注册到eureka-server1、eureka-server2这个Eureka上面去 defaultZone: http://192.168.66.103:10086/eureka/,http://192.168.66.104:10086/eureka/---server: port: 10086spring: profiles: eureka-server2eureka: instance: hostname: 192.168.66.104 client: service-url: defaultZone: http://192.168.66.103:10086/eureka/,http://192.168.66.104:10086/eureka/在启动微服务的时候，加入参数: spring.profiles.active 来读取对应的配置其他微服务配置除了Eureka注册中心以外，其他微服务配置都需要加入所有Eureka服务12345678# Eureka配置eureka: client: service-url: defaultZone: http://192.168.66.103:10086/eureka,http://192.168.66.104:10086/eureka # Eureka访问地址instance: prefer-ip-address: true把代码提交到Gitlab中设计Jenkins集群项目的构建参数1）安装Extended Choice Parameter插件支持多选框2）创建流水线项目3）添加参数字符串参数：分支名称多选框：项目名称12tensquare_eureka_server@10086,tensquare_zuul@10020,tensquare_admin_service@9001,tensquare_gathering@9002最后效果：完成微服务构建镜像，上传私服12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;//构建版本的名称def tag = &quot;latest&quot;//Harbor私服地址def harbor_url = &quot;192.168.66.102:85&quot;//Harbor的项目名称def harbor_project_name = &quot;tensquare&quot;//Harbor的凭证def harbor_auth = &quot;ef499f29-f138-44dd-975e-ff1ca1d8c933&quot;node &#123; //把选择的项目信息转为数组 def selectedProjects = &quot;$&#123;project_name&#125;&quot;.split(&apos;,&apos;) stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &apos;$&#123;git_auth&#125;&apos;, url:&apos;git@192.168.66.100:itheima_group/tensquare_back_cluster.git&apos;]]]) &#125; stage(&apos;代码审查&apos;) &#123; def scannerHome = tool &apos;sonarqube-scanner&apos; withSonarQubeEnv(&apos;sonarqube6.7.4&apos;) &#123; for(int i=0;i&lt;selectedProjects.size();i++)&#123; //取出每个项目的名称和端口 def currentProject = selectedProjects[i]; //项目名称 def currentProjectName = currentProject.split(&apos;@&apos;)[0] //项目启动端口 def currentProjectPort = currentProject.split(&apos;@&apos;)[1] sh &quot;&quot;&quot; cd $&#123;currentProjectName&#125; $&#123;scannerHome&#125;/bin/sonar-scanner &quot;&quot;&quot; echo &quot;$&#123;currentProjectName&#125;完成代码审查&quot; &#125; &#125; &#125; stage(&apos;编译，构建镜像，部署服务&apos;) &#123; //编译并安装公共工程 sh &quot;mvn -f tensquare_common clean install&quot; for(int i=0;i&lt;selectedProjects.size();i++)&#123; //取出每个项目的名称和端口 def currentProject = selectedProjects[i]; //项目名称 def currentProjectName = currentProject.split(&apos;@&apos;)[0] //项目启动端口 def currentProjectPort = currentProject.split(&apos;@&apos;)[1] //定义镜像名称 def imageName = &quot;$&#123;currentProjectName&#125;:$&#123;tag&#125;&quot; //编译，构建本地镜像 sh &quot;mvn -f $&#123;currentProjectName&#125; clean package dockerfile:build&quot; //给镜像打标签 sh &quot;docker tag $&#123;imageName&#125; $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; //登录Harbor，并上传镜像 withCredentials([usernamePassword(credentialsId: &quot;$&#123;harbor_auth&#125;&quot;, passwordVariable: &apos;password&apos;, usernameVariable: &apos;username&apos;)]) &#123; //登录 sh &quot;docker login -u $&#123;username&#125; -p $&#123;password&#125; $&#123;harbor_url&#125;&quot; //上传镜像 sh &quot;docker push $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; &#125; //删除本地镜像 sh &quot;docker rmi -f $&#123;imageName&#125;&quot; sh &quot;docker rmi -f $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; //=====以下为远程调用进行项目部署======== //sshPublisher(publishers: [sshPublisherDesc(configName:&apos;master_server&apos;, transfers: [sshTransfer(cleanRemote: false, excludes: &apos;&apos;,execCommand: &quot;/opt/jenkins_shell/deployCluster.sh $harbor_url$harbor_project_name $currentProjectName $tag $currentProjectPort&quot;, execTimeout:120000, flatten: false, makeEmptyDirs: false, noDefaultExcludes: false,patternSeparator: &apos;[, ]+&apos;, remoteDirectory: &apos;&apos;, remoteDirectorySDF: false,removePrefix: &apos;&apos;, sourceFiles: &apos;&apos;)], usePromotionTimestamp: false,useWorkspaceInPromotion: false, verbose: false)])echo &quot;$&#123;currentProjectName&#125;完成编译，构建镜像&quot; &#125; &#125;&#125;完成微服务多服务器远程发布1）配置远程部署服务器拷贝公钥到远程服务器ssh-copy-id 192.168.66.104系统配置-&gt;添加远程服务器1234&#123;\"registry-mirrors\": [\"https://zydiol88.mirror.aliyuncs.com\"],\"insecure-registries\": [\"192.168.66.102:85\"]&#125;重启Docker3）添加参数多选框：部署服务器最终效果：4）修改Jenkinsfile构建脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889//gitlab的凭证def git_auth = &quot;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&quot;//构建版本的名称def tag = &quot;latest&quot;//Harbor私服地址def harbor_url = &quot;192.168.66.102:85&quot;//Harbor的项目名称def harbor_project_name = &quot;tensquare&quot;//Harbor的凭证def harbor_auth = &quot;ef499f29-f138-44dd-975e-ff1ca1d8c933&quot;node &#123; //把选择的项目信息转为数组 def selectedProjects = &quot;$&#123;project_name&#125;&quot;.split(&apos;,&apos;) //把选择的服务区信息转为数组 def selectedServers = &quot;$&#123;publish_server&#125;&quot;.split(&apos;,&apos;) stage(&apos;拉取代码&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/$&#123;branch&#125;&apos;]], doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &apos;$&#123;git_auth&#125;&apos;, url:&apos;git@192.168.66.100:itheima_group/tensquare_back_cluster.git&apos;]]]) &#125; stage(&apos;代码审查&apos;) &#123; def scannerHome = tool &apos;sonarqube-scanner&apos; withSonarQubeEnv(&apos;sonarqube6.7.4&apos;) &#123; for(int i=0;i&lt;selectedProjects.size();i++)&#123; //取出每个项目的名称和端口 def currentProject = selectedProjects[i]; //项目名称 def currentProjectName = currentProject.split(&apos;@&apos;)[0] //项目启动端口 def currentProjectPort = currentProject.split(&apos;@&apos;)[1] sh &quot;&quot;&quot; cd $&#123;currentProjectName&#125; $&#123;scannerHome&#125;/bin/sonar-scanner &quot;&quot;&quot; echo &quot;$&#123;currentProjectName&#125;完成代码审查&quot; &#125; &#125; &#125; stage(&apos;编译，构建镜像，部署服务&apos;) &#123; //编译并安装公共工程 sh &quot;mvn -f tensquare_common clean install&quot; for(int i=0;i&lt;selectedProjects.size();i++)&#123; //取出每个项目的名称和端口 def currentProject = selectedProjects[i]; //项目名称 def currentProjectName = currentProject.split(&apos;@&apos;)[0] //项目启动端口 def currentProjectPort = currentProject.split(&apos;@&apos;)[1] //定义镜像名称 def imageName = &quot;$&#123;currentProjectName&#125;:$&#123;tag&#125;&quot; //编译，构建本地镜像 sh &quot;mvn -f $&#123;currentProjectName&#125; clean package dockerfile:build&quot; //给镜像打标签 sh &quot;docker tag $&#123;imageName&#125; $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; //登录Harbor，并上传镜像 withCredentials([usernamePassword(credentialsId:&quot;$&#123;harbor_auth&#125;&quot;, passwordVariable: &apos;password&apos;, usernameVariable: &apos;username&apos;)]) &#123; //登录 sh &quot;docker login -u $&#123;username&#125; -p $&#123;password&#125; $&#123;harbor_url&#125;&quot; //上传镜像 sh &quot;docker push $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; &#125; //删除本地镜像 sh &quot;docker rmi -f $&#123;imageName&#125;&quot; sh &quot;docker rmi -f $&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot; //=====以下为远程调用进行项目部署======== for(int j=0;j&lt;selectedServers.size();j++)&#123; //每个服务名称 def currentServer = selectedServers[j] //添加微服务运行时的参数：spring.profiles.active def activeProfile = &quot;--spring.profiles.active=&quot; if(currentServer==&quot;master_server&quot;)&#123; activeProfile = activeProfile+&quot;eureka-server1&quot; &#125;else if(currentServer==&quot;slave_server1&quot;)&#123; activeProfile = activeProfile+&quot;eureka-server2&quot; &#125; sshPublisher(publishers: [sshPublisherDesc(configName:&quot;$&#123;currentServer&#125;&quot;, transfers: [sshTransfer(cleanRemote: false, excludes: &apos;&apos;,execCommand: &quot;/opt/jenkins_shell/deployCluster.sh $harbor_url$harbor_project_name $currentProjectName $tag $currentProjectPort$activeProfile&quot;, execTimeout: 120000, flatten: false, makeEmptyDirs: false,noDefaultExcludes: false, patternSeparator: &apos;[, ]+&apos;, remoteDirectory: &apos;&apos;,remoteDirectorySDF: false, removePrefix: &apos;&apos;, sourceFiles: &apos;&apos;)],usePromotionTimestamp: false, useWorkspaceInPromotion: false, verbose: false)]) &#125; echo &quot;$&#123;currentProjectName&#125;完成编译，构建镜像&quot; &#125; &#125;&#125;5）编写deployCluster.sh部署脚本123456789101112131415161718192021222324252627282930313233#! /bin/sh#接收外部参数harbor_url=$1harbor_project_name=$2project_name=$3tag=$4port=$5profile=$6imageName=$harbor_url/$harbor_project_name/$project_name:$tagecho \"$imageName\"#查询容器是否存在，存在则删除containerId=`docker ps -a | grep -w $&#123;project_name&#125;:$&#123;tag&#125; | awk '&#123;print $1&#125;'`if [ \"$containerId\" != \"\" ] ; then#停掉容器docker stop $containerId#删除容器docker rm $containerIdecho \"成功删除容器\"fi#查询镜像是否存在，存在则删除imageId=`docker images | grep -w $project_name | awk '&#123;print $3&#125;'`if [ \"$imageId\" != \"\" ] ; then#删除镜像docker rmi -f $imageIdecho \"成功删除镜像\"fi# 登录Harbor私服docker login -u itcast -p Itcast123 $harbor_url# 下载镜像docker pull $imageName# 启动容器docker run -di -p $port:$port $imageName $profileecho \"容器启动成功\"6）集群效果Nginx+Zuul集群实现高可用网关1）安装Nginx（已完成）2）修改Nginx配置vi /etc/nginx/nginx.conf内容如下：123456789101112131415upstream zuulServer&#123;server 192.168.66.103:10020 weight=1;server 192.168.66.104:10020 weight=1;&#125;server &#123;listen 85 default_server;listen [::]:85 default_server;server_name _;root /usr/share/nginx/html;# Load configuration files for the default server block.include /etc/nginx/default.d/*.conf;location / &#123;### 指定服务器负载均衡服务器proxy_pass http://zuulServer/;&#125;3）重启Nginx： systemctl restart nginx4）修改前端Nginx的访问地址基于Kubernetes/K8S构建Jenkins持续集成平台(上)Jenkins的Master-Slave分布式构建什么是Master-Slave分布式构建Jenkins的Master-Slave分布式构建，就是通过将构建过程分配到从属Slave节点上，从而减轻Master节点的压力，而且可以同时构建多个，有点类似负载均衡的概念。如何实现Master-Slave分布式构建1）开启代理程序的TCP端口Manage Jenkins -&gt; Configure Global Security2）新建节点Manage Jenkins—Manage Nodes—新建节点有两种在Slave节点连接Master节点的方法我们选择第二种：2）安装和配置节点下载agent.jar，并上传到Slave节点，然后执行页面提示的命令：123java -jar agent.jar -jnlpUrl http://192.168.66.101:8888/computer/slave1/slaveagent.jnlp -secretf2ecbb99e0c81331e8b7a7917a94d478f39cb9763fc6c66d9a9741c61f9ae6d6 -workDir\"/root/jenkins\"刷新页面3）测试节点是否可用自由风格和Maven风格的项目：流水线风格的项目：123456node(&apos;slave1&apos;) &#123; stage(&apos;check out&apos;) &#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;*/master&apos;]],doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [],userRemoteConfigs: [[credentialsId: &apos;68f2087f-a034-4d39-a9ff-1f776dd3dfa8&apos;,url:&apos;git@192.168.66.100:itheima_group/tensquare_back_cluster.git&apos;]]]) &#125; &#125;Kubernetes实现Master-Slave分布式构建方案传统Jenkins的Master-Slave方案的缺陷Master节点发生单点故障时，整个流程都不可用了每个 Slave节点的配置环境不一样，来完成不同语言的编译打包等操作，但是这些差异化的配置导致管理起来非常不方便，维护起来也是比较费劲资源分配不均衡，有的 Slave节点要运行的job出现排队等待，而有的Slave节点处于空闲状态资源浪费，每台 Slave节点可能是实体机或者VM，当Slave节点处于空闲状态时，也不会完全释放掉资源以上种种问题，我们可以引入Kubernates来解决！Kubernates简介Kubernetes（简称，K8S）是Google开源的容器集群管理系统，在Docker技术的基础上，为容器化的应用提供部署运行、资源调度、服务发现和动态伸缩等一系列完整功能，提高了大规模容器集群管理的便捷性。 其主要功能如下：使用Docker对应用程序包装(package)、实例化(instantiate)、运行(run)。以集群的方式运行、管理跨机器的容器。以集群的方式运行、管理跨机器的容器。解决Docker跨机器容器之间的通讯问题。解决Docker跨机器容器之间的通讯问题。Kubernetes的自我修复机制使得容器集群总是运行在用户期望的状态。Kubernates+Docker+Jenkins持续集成架构图大致工作流程：手动/自动构建 -&gt; Jenkins 调度 K8S API -＞动态生成 Jenkins Slave pod -＞ Slave pod拉取 Git 代码／编译／打包镜像 -＞推送到镜像仓库 Harbor -＞ Slave 工作完成，Pod 自动销毁 -＞部署到测试或生产 Kubernetes平台。（完全自动化，无需人工干预）Kubernates+Docker+Jenkins持续集成方案好处服务高可用：当 Jenkins Master 出现故障时，Kubernetes 会自动创建一个新的 Jenkins Master容器，并且将 Volume 分配给新创建的容器，保证数据不丢失，从而达到集群服务高可用。动态伸缩，合理使用资源：每次运行 Job 时，会自动创建一个 Jenkins Slave，Job 完成后，Slave自动注销并删除容器，资源自动释放，而且 Kubernetes 会根据每个资源的使用情况，动态分配Slave 到空闲的节点上创建，降低出现因某节点资源利用率高，还排队等待在该节点的情况。扩展性好：当 Kubernetes 集群的资源严重不足而导致 Job 排队等待时，可以很容易的添加一个Kubernetes Node 到集群中，从而实现扩展。Kubeadm安装KubernetesKubernetes的架构API Server：用于暴露Kubernetes API，任何资源的请求的调用操作都是通过kube-apiserver提供的接口进行的。Etcd：是Kubernetes提供默认的存储系统，保存所有集群数据，使用时需要为etcd数据提供备份计划。Controller-Manager：作为集群内部的管理控制中心，负责集群内的Node、Pod副本、服务端点（Endpoint）、命名空间（Namespace）、服务账号（ServiceAccount）、资源定额（ResourceQuota）的管理，当某个Node意外宕机时，Controller Manager会及时发现并执行自动化修复流程，确保集群始终处于预期的工作状态。Scheduler：监视新创建没有分配到Node的Pod，为Pod选择一个Node。Kubelet：负责维护容器的生命周期，同时负责Volume和网络的管理Kube proxy：是Kubernetes的核心组件，部署在每个Node节点上，它是实现Kubernetes Service的通信与负载均衡机制的重要组件。安装环境说明主机名称IP地址安装的软件代码托管服务器192.168.66.100Gitlab-12.4.2Docker仓库服务器192.168.66.102Harbor1.9.2k8s-master192.168.66.101kube-apiserver、kube-controller-manager、kube-scheduler、docker、etcd、calico，NFSk8s-node1192.168.66.103kubelet、kubeproxy、Docker18.06.1-cek8s-node2192.168.66.104kubelet、kubeproxy、Docker18.06.1-ce三台机器都需要完成修改三台机器的hostname及hosts文件hostnamectl set-hostname k8s-masterhostnamectl set-hostname k8s-node1 hostnamectl set-hostname k8s-node2cat &gt;&gt;/etc/hosts&lt;&lt;EOF 192.168.66.101 k8s-master 192.168.66.103 k8s-node1192.168.66.104 k8s-node2 EOF关闭防火墙和关闭SELinuxsystemctl stop firewalldsystemctl disable firewalldsetenforce 0 临时关闭vi /etc/sysconfig/selinux 永久关闭改为SELINUX=disabled设置系统参数设置允许路由转发，不对bridge的数据进行处理创建文件vi /etc/sysctl.d/k8s.conf内容如下：net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1net.ipv4.ip_forward = 1 vm.swappiness = 0执行文件sysctl -p /etc/sysctl.d/k8s.confkube-proxy 开启ipvs的前置条件1234567891011cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF#!/bin/bashmodprobe -- ip_vsmodprobe -- ip_vs_rrmodprobe -- ip_vs_wrrmodprobe -- ip_vs_shmodprobe -- nf_conntrack_ipv4EOFchmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash/etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep -e ip_vs -enf_conntrack_ipv4所有节点关闭swapswapoff -a 临时关闭vi /etc/fstab 永久关闭注释掉以下字段/dev/mapper/cl-swap swap swap defaults 0 0安装kubelet、kubeadm、kubectlkubeadm: 用来初始化集群的指令。kubelet: 在集群中的每个节点上用来启动 pod 和 container 等。kubectl: 用来与集群通信的命令行工具。清空yum缓存1yum clean all设置 yum安装源12345678910cat &lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo[kubernetes]name=Kubernetesbaseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64/enabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpghttps://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpgEOF安装：1yum install -y kubelet kubeadm kubectlkubelet 设置开机启动（注意：先不启动，现在启动的话会报错）1systemctl enable kubelet查看版本1kubelet --version安装的是最新版本： Kubernetes v1.16.3（可能会变化）Master节点需要完成1）运行初始化命令12345kubeadm init --kubernetes-version=1.17.0 \\--apiserver-advertise-address=192.168.66.101 \\--image-repository registry.aliyuncs.com/google_containers \\--service-cidr=10.1.0.0/16 \\--pod-network-cidr=10.244.0.0/16注意： apiserver-advertise-address这个地址必须是master机器的IP常用错误：错误一：[WARNING IsDockerSystemdCheck]: detected “cgroupfs” as the Docker cgroup driver作为Docker cgroup驱动程序。，Kubernetes推荐的Docker驱动程序是“systemd”解决方案：修改Docker的配置: vi /etc/docker/daemon.json，加入123&#123;\"exec-opts\":[\"native.cgroupdriver=systemd\"]&#125;然后重启 Docker错误二：[ERROR NumCPU]: the number of available CPUs 1 is less than the required 2解决方案：修改虚拟机的CPU的个数，至少为2个安装过程日志：最后，会提示节点安装的命令，必须记下来123kubeadm join 192.168.66.101:6443 --token 754snw.9xq9cotze1ybwnti \\ --discovery-token-ca-cert-hashsha256:3372ff6717ea5997121213e2c9d63fa7c8cdfb031527e17f2e20254f382ea03a2）启动kubelet1systemctl restart kubelet3）配置kubectl工具123mkdir -p $HOME/.kubesudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/configsudo chown $(id -u):$(id -g) $HOME/.kube/config4）安装Calico1234567mkdir k8scd k8swget https://docs.projectcalico.org/v3.10/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yamlsed -i 's/192.168.0.0/10.244.0.0/g' calico.yamlkubectl apply -f calico.yaml5）等待几分钟，查看所有Pod的状态，确保所有Pod都是Running状态1kubectl get pod --all-namespaces -o wideSlave节点需要完成1）让所有节点让集群环境使用之前Master节点产生的命令加入集群123kubeadm join 192.168.66.101:6443 --token 754snw.9xq9cotze1ybwnti \\ --discovery-token-ca-cert-hashsha256:3372ff6717ea5997121213e2c9d63fa7c8cdfb031527e17f2e20254f382ea03a2 ）启动kubelet1systemctl start kubelet3）回到Master节点查看，如果Status全部为Ready，代表集群环境搭建成功！！！1kubectl get nodeskubectl常用命令123456789kubectl get nodes 查看所有主从节点的状态kubectl get ns 获取所有namespace资源kubectl get pods -n &#123;$nameSpace&#125; 获取指定namespace的podkubectl describe pod的名称 -n &#123;$nameSpace&#125; 查看某个pod的执行过程kubectl logs --tail=1000 pod的名称 | less 查看日志kubectl create -f xxx.yml 通过配置文件创建一个集群资源对象kubectl delete -f xxx.yml 通过配置文件删除一个集群资源对象kubectl delete pod名称 -n &#123;$nameSpace&#125; 通过pod删除集群资源kubectl get service -n &#123;$nameSpace&#125; 查看pod的service情况基于Kubernetes/K8S构建Jenkins持续集成平台(下)Jenkins-Master-Slave架构图回顾：安装和配置 NFSNFS简介NFS（Network File System），它最大的功能就是可以通过网络，让不同的机器、不同的操作系统可以共享彼此的文件。我们可以利用NFS共享Jenkins运行的配置文件、Maven的仓库依赖文件等NFS安装我们把 NFS服务器安装在192.168.66.101机器上1）安装NFS服务（在所有K8S的节点都需要安装）1yum install -y nfs-utils2 ）创建共享目录1234mkdir -p /opt/nfs/jenkinsvi /etc/exports 编写NFS的共享配置内容如下:/opt/nfs/jenkins *(rw,no_root_squash) *代表对所有IP都开放此目录，rw是读写3）启动服务12systemctl enable nfs 开机启动systemctl start nfs 启动4）查看NFS共享目录1showmount -e 192.168.66.101在Kubernetes安装Jenkins-Master创建NFS client provisionernfs-client-provisioner 是一个Kubernetes的简易NFS的外部provisioner，本身不提供NFS，需要现有的NFS服务器提供存储。1）上传nfs-client-provisioner构建文件其中注意修改 deployment.yaml，使用之前配置NFS服务器和目录2 ）构建nfs-client-provisioner的pod资源12cd nfs-clientkubectl create -f .3 ）查看pod是否创建成功安装Jenkins-Master1）上传Jenkins-Master构建文件其中有两点注意：第一、在StatefulSet.yaml文件，声明了利用nfs-client-provisioner进行Jenkins-Master文件存储第二、 Service发布方法采用NodePort，会随机产生节点访问端口2）创建kube-ops的namespace因为我们把Jenkins-Master的pod放到kube-ops下1kubectl create namespace kube-ops3）构建Jenkins-Master的pod资源12cd jenkins-masterkubectl create -f .4）查看pod是否创建成功1kubectl get pods -n kube-ops5）查看信息，并访问查看Pod运行在那个Node上1kubectl describe pods -n kube-ops查看分配的端口1kubectl get service -n kube-ops最终访问地址为： http://192.168.66.103:30136 （192.168.66.103为k8s-node1的IP）安装过程跟之前是一样的！6）先安装基本的插件Localization:ChineseGitPipelineExtended Choice ParameterJenkins与Kubernetes整合安装Kubernetes插件系统管理-&gt;插件管理-&gt;可选插件实现Jenkins与Kubernetes整合系统管理-&gt;系统配置-&gt;云-&gt;新建云-&gt;Kuberneteskubernetes 地址采用了kube的服务器发现： https://kubernetes.default.svc.cluster.localnamespace 填kube-ops，然后点击Test Connection，如果出现 Connection test successful 的提示信息证明 Jenkins 已经可以和 Kubernetes 系统正常通信Jenkins URL 地址： http://jenkins.kube-ops.svc.cluster.local:8080构建Jenkins-Slave自定义镜像Jenkins-Master在构建Job的时候，Kubernetes会创建Jenkins-Slave的Pod来完成Job的构建。我们选择运行Jenkins-Slave的镜像为官方推荐镜像：jenkins/jnlp-slave:latest，但是这个镜像里面并没有Maven环境，为了方便使用，我们需要自定义一个新的镜像：准备材料：Dockerfile 文件内容如下：1234567891011121314FROM jenkins/jnlp-slave:latestMAINTAINER itcast# 切换到 root 账户进行操作USER root# 安装 mavenCOPY apache-maven-3.6.2-bin.tar.gz .RUN tar -zxf apache-maven-3.6.2-bin.tar.gz &amp;&amp; \\ mv apache-maven-3.6.2 /usr/local &amp;&amp; \\ rm -f apache-maven-3.6.2-bin.tar.gz &amp;&amp; \\ ln -s /usr/local/apache-maven-3.6.2/bin/mvn /usr/bin/mvn &amp;&amp; \\ ln -s /usr/local/apache-maven-3.6.2 /usr/local/apache-maven &amp;&amp; \\ mkdir -p /usr/local/apache-maven/repoCOPY settings.xml /usr/local/apache-maven/conf/settings.xmlUSER jenkins构建出一个新镜像： jenkins-slave-maven:latest然把镜像上传到Harbor的公共库library中12docker tag jenkins-slave-maven:latest 192.168.66.102:85/library/jenkins-slave-maven:latestdocker push 192.168.66.102:85/library/jenkins-slave-maven:latest测试Jenkins-Slave是否可以创建1）创建一个Jenkins流水线项目2 ）编写Pipeline，从GItlab拉取代码123456789101112131415161718192021def git_address =\"http://192.168.66.100:82/itheima_group/tensquare_back_cluster.git\"def git_auth = \"9d9a2707-eab7-4dc9-b106-e52f329cbc95\"//创建一个Pod的模板，label为jenkins-slavepodTemplate(label: 'jenkins-slave', cloud: 'kubernetes', containers: [ containerTemplate( name: 'jnlp', image: \"192.168.66.102:85/library/jenkins-slave-maven:latest\" ) ])&#123; //引用jenkins-slave的pod模块来构建Jenkins-Slave的pod node(\"jenkins-slave\")&#123; // 第一步 stage('拉取代码')&#123; checkout([$class: 'GitSCM', branches: [[name: 'master']],userRemoteConfigs: [[credentialsId: \"$&#123;git_auth&#125;\", url: \"$&#123;git_address&#125;\"]]]) &#125; &#125;&#125;3 ）查看构建日志Jenkins+Kubernetes+Docker完成微服务持续集成拉取代码，构建镜像1）创建NFS共享目录让所有Jenkins-Slave构建指向NFS的Maven的共享仓库目录12345vi /etc/exports添加内容：/opt/nfs/jenkins *(rw,no_root_squash)/opt/nfs/maven *(rw,no_root_squash)systemctl restart nfs 重启NFS2）创建项目，编写构建Pipeline12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182def git_address =&quot;http://192.168.66.100:82/itheima_group/tensquare_back_cluster.git&quot;def git_auth = &quot;9d9a2707-eab7-4dc9-b106-e52f329cbc95&quot;//构建版本的名称def tag = &quot;latest&quot;//Harbor私服地址def harbor_url = &quot;192.168.66.102:85&quot;//Harbor的项目名称def harbor_project_name = &quot;tensquare&quot;//Harbor的凭证def harbor_auth = &quot;71eff071-ec17-4219-bae1-5d0093e3d060&quot;podTemplate(label: &apos;jenkins-slave&apos;, cloud: &apos;kubernetes&apos;, containers: [ containerTemplate( name: &apos;jnlp&apos;, image: &quot;192.168.66.102:85/library/jenkins-slave-maven:latest&quot; ), containerTemplate( name: &apos;docker&apos;, image: &quot;docker:stable&quot;, ttyEnabled: true, command: &apos;cat&apos; ),], volumes: [ hostPathVolume(mountPath: &apos;/var/run/docker.sock&apos;, hostPath:&apos;/var/run/docker.sock&apos;), nfsVolume(mountPath: &apos;/usr/local/apache-maven/repo&apos;, serverAddress:&apos;192.168.66.101&apos; , serverPath: &apos;/opt/nfs/maven&apos;),],)&#123; node(&quot;jenkins-slave&quot;)&#123; // 第一步 stage(&apos;拉取代码&apos;)&#123; checkout([$class: &apos;GitSCM&apos;, branches: [[name: &apos;$&#123;branch&#125;&apos;]],userRemoteConfigs: [[credentialsId: &quot;$&#123;git_auth&#125;&quot;, url: &quot;$&#123;git_address&#125;&quot;]]]) &#125; // 第二步 stage(&apos;代码编译&apos;)&#123; //编译并安装公共工程 sh &quot;mvn -f tensquare_common clean install&quot; &#125; // 第三步 stage(&apos;构建镜像，部署项目&apos;)&#123; //把选择的项目信息转为数组def selectedProjects = &quot;$&#123;project_name&#125;&quot;.split(&apos;,&apos;) for(int i=0;i&lt;selectedProjects.size();i++)&#123; //取出每个项目的名称和端口 def currentProject = selectedProjects[i]; //项目名称 def currentProjectName = currentProject.split(&apos;@&apos;)[0] //项目启动端口 def currentProjectPort = currentProject.split(&apos;@&apos;)[1] //定义镜像名称 def imageName = &quot;$&#123;currentProjectName&#125;:$&#123;tag&#125;&quot;//编译，构建本地镜像sh &quot;mvn -f $&#123;currentProjectName&#125; clean packagedockerfile:build&quot;container(&apos;docker&apos;) &#123;//给镜像打标签sh &quot;docker tag $&#123;imageName&#125;$&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot;//登录Harbor，并上传镜像withCredentials([usernamePassword(credentialsId:&quot;$&#123;harbor_auth&#125;&quot;, passwordVariable: &apos;password&apos;, usernameVariable: &apos;username&apos;)])&#123; //登录 sh &quot;docker login -u $&#123;username&#125; -p $&#123;password&#125;$&#123;harbor_url&#125;&quot; //上传镜像 sh &quot;docker push$&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot;&#125;//删除本地镜像sh &quot;docker rmi -f $&#123;imageName&#125;&quot;sh &quot;docker rmi -f$&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot;&#125; &#125; &#125;&#125;&#125;注意：在构建过程会发现无法创建仓库目录，是因为 NFS共享目录权限不足，需更改权限12chown -R jenkins:jenkins /opt/nfs/mavenchmod -R 777 /opt/nfs/maven还有 Docker命令执行权限问题1chmod 777 /var/run/docker.sock需要手动上传父工程依赖到 NFS的Maven共享仓库目录中微服务部署到K8S修改每个微服务的 application.ymlEureka12345678910111213141516171819202122232425server:port: $&#123;PORT:10086&#125;spring:application: name: eurekaeureka:server: # 续期时间，即扫描失效服务的间隔时间（缺省为60*1000ms） eviction-interval-timer-in-ms: 5000 enable-self-preservation: false use-read-only-response-cache: falseclient: # eureka client间隔多久去拉取服务注册信息 默认30s registry-fetch-interval-seconds: 5 serviceUrl: defaultZone: $&#123;EUREKA_SERVER:http://127.0.0.1:$&#123;server.port&#125;/eureka/&#125;instance: # 心跳间隔时间，即发送一次心跳之后，多久在发起下一次（缺省为30s） lease-renewal-interval-in-seconds: 5 # 在收到一次心跳之后，等待下一次心跳的空档时间，大于心跳间隔即可，即服务续约到期时间（缺省为90s） lease-expiration-duration-in-seconds: 10 instance-id:$&#123;EUREKA_INSTANCE_HOSTNAME:$&#123;spring.application.name&#125;&#125;:$&#123;server.port&#125;@$&#123;random.long(1000000,9999999)&#125; hostname: $&#123;EUREKA_INSTANCE_HOSTNAME:$&#123;spring.application.name&#125;&#125;其他微服务需要注册到所有 Eureka中1234567# Eureka配置eureka:client: serviceUrl: defaultZone: http://eureka-0.eureka:10086/eureka/,http://eureka-1.eureka:10086/eureka/ # Eureka访问地址instance: preferIpAddress: true1）安装Kubernetes Continuous Deploy插件2）修改后的流水线脚本1234567891011def deploy_image_name = &quot;$&#123;harbor_url&#125;/$&#123;harbor_project_name&#125;/$&#123;imageName&#125;&quot;//部署到K8S sh &quot;&quot;&quot; sed -i &apos;s#\\$IMAGE_NAME#$&#123;deploy_image_name&#125;#&apos;$&#123;currentProjectName&#125;/deploy.ymlsed -i &apos;s#\\$SECRET_NAME#$&#123;secret_name&#125;#&apos;$&#123;currentProjectName&#125;/deploy.yml &quot;&quot;&quot; kubernetesDeploy configs: &quot;$&#123;currentProjectName&#125;/deploy.yml&quot;,kubeconfigId: &quot;$&#123;k8s_auth&#125;&quot;3）建立k8s认证凭证kubeconfig 到k8s的Master节点复制1cat /root/.kube/config5）生成Docker凭证Docker凭证，用于Kubernetes到Docker私服拉取镜像12345docker login -u itcast -p Itcast123 192.168.66.102:85 登录Harborkubectl create secret docker-registry registry-auth-secret --docker-server=192.168.66.102:85 --docker-username=itcast --docker-password=Itcast123 --docker-email=itcast@itcast.cn 生成kubectl get secret 查看密钥6）在每个项目下建立deploy.xmlEureka的deply.yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748---apiVersion: v1kind: Servicemetadata:name: eurekalabels: app: eurekaspec:type: NodePortports: - port: 10086 name: eureka targetPort: 10086selector: app: eureka---apiVersion: apps/v1kind: StatefulSetmetadata:name: eurekaspec:serviceName: \"eureka\"replicas: 2selector: matchLabels: app: eurekatemplate: metadata: labels: app: eureka spec: imagePullSecrets: - name: $SECRET_NAME containers: - name: eureka image: $IMAGE_NAME ports: - containerPort: 10086 env: - name: MY_POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: EUREKA_SERVER value: \"http://eureka-0.eureka:10086/eureka/,http://eureka-1.eureka:10086/eureka/\" - name: EUREKA_INSTANCE_HOSTNAME value: $&#123;MY_POD_NAME&#125;.eurekapodManagementPolicy: \"Parallel\"其他项目的 deploy.yml主要把名字和端口修改：123456789101112131415161718192021222324252627282930313233343536373839---apiVersion: v1kind: Servicemetadata:name: zuullabels: app: zuulspec:type: NodePortports: - port: 10020 name: zuul targetPort: 10020selector: app: zuul---apiVersion: apps/v1kind: StatefulSetmetadata:name: zuulspec:serviceName: \"zuul\"replicas: 2selector: matchLabels: app: zuultemplate: metadata: labels: app: zuul spec: imagePullSecrets: - name: $SECRET_NAME containers: - name: zuul image: $IMAGE_NAME ports: - containerPort: 10020podManagementPolicy: \"Parallel\"7）项目构建后，查看服务创建情况12kubectl get pods -owidekubectl get service效果如下：","categories":[{"name":"CI/CD","slug":"CI-CD","permalink":"https://me.obey.fun/categories/CI-CD/"},{"name":"Java","slug":"CI-CD/Java","permalink":"https://me.obey.fun/categories/CI-CD/Java/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"https://me.obey.fun/tags/Jenkins/"},{"name":"持续集成/持续部署","slug":"持续集成-持续部署","permalink":"https://me.obey.fun/tags/持续集成-持续部署/"}],"keywords":[{"name":"CI/CD","slug":"CI-CD","permalink":"https://me.obey.fun/categories/CI-CD/"},{"name":"Java","slug":"CI-CD/Java","permalink":"https://me.obey.fun/categories/CI-CD/Java/"}]},{"title":"JVM探究","slug":"JVM探究","date":"2020-12-22T09:43:40.000Z","updated":"2020-12-22T12:26:59.332Z","comments":true,"path":"JVM探究.html","link":"","permalink":"https://me.obey.fun/JVM探究.html","excerpt":"","text":"面试常见：请你谈谈你对JVM的理解? java8虚拟机和之前的变化更新?什么是OOM，什么是栈溢出StackOverFlowError? 怎么分析?JVM的常用调优参数有哪些?内存快照如何抓取，怎么分析Dump文件？谈谈JVM中，类加载器你的认识?JVM的位置JVM的体系结构百分之99的JVM调优都是在堆中调优，Java栈、本地方法栈、程序计数器是不会有垃圾存在的。类加载器作用：加载Class文件~虚拟机自带的加载器启动类(根)加载器扩展类加载器应用程序加载器双亲委派机制双亲委派机制:安全APP–&gt;EXC—B0OT(最终执行)B0OTEXCAPP类加载器收到类加载的请求将这个请求向上委托给父类加载器去完成，一 直向上委托，知道启动类加载器启动加载器检查是否能够加载当前这个类，能加载就结束， 使用当前的加载器，否则，抛出异常，通知子加载器进行加载重复步骤3Class Not Found异常就是这么来的Java早期的名字：C++–Java = C++:去掉繁琐的东西，指针，内存管理~沙箱安全机制Java安全模型的核心就是Java沙箱(sandbox) ,什么是沙箱?沙箱是一个限制程序运行的环境。沙箱机制就是将Java代码限定在虚拟机(JVM)特定的运行范围中，并且严格限制代码对本地系统资源访问，通过这样的措施来保证对代码的有效隔离，防止对本地系统造成破坏。沙箱主要限制系统资源访问，那系统资源包括什么? CPU、内存、文件系统、网络。不同级别的沙箱对这些资源访问的限制也可以不一样。所有的Java程序运行都可以指定沙箱，可以定制安全策略。在Java中将执行程序分成本地代码和远程代码两种，本地代码默认视为可信任的，而远程代码则被看作是不受信的。对于授信的本地代码,可以访问一切本地资源。而对于非授信的远程代码在早期的Java实现中，安全依赖于沙箱Sandbox)机制。如下图所示JDK1.0安全模型但如此严格的安全机制也给程序的功能扩展带来障碍，比如当用户希望远程代码访问本地系统的文件时候，就无法实现。因此在后续的Java1.1版本中，针对安全机制做了改进，增加了安全策略，允许用户指定代码对本地资源的访问权限。如下图所示JDK1.1安全模型在Java1.2版本中，再次改进了安全机制，增加了代码签名。不论本地代码或是远程代码，都会按照用户的安全策略设定，由类加载器加载到虚拟机中权限不同的运行空间，来实现差异化的代码执行权限控制。如下图所示当前最新的安全机制实现，则引入了域(Domain)的概念。虚拟机会把所有代码加载到不同的系统域和应用域,系统域部分专门负责与关键资源进行交互，而各个应用域部分则通过系统域的部分代理来对各种需要的资源进行访问。虚拟机中不同的受保护域(Protected Domain),对应不一样的权限(Permission)。存在于不同域中的类文件就具有了当前域的全部权限，如下图所示最新的安全模型(jdk 1.6)组成沙箱的基本组件字节码校验器(bytecode verifier) :确保Java类文件遵循Java语言规范。这样可以帮助Java程序实现内存保护。但并不是所有的类文件都会经过字节码校验，比如核心类。类裝载器(class loader) :其中类装载器在3个方面对Java沙箱起作用它防止恶意代码去干涉善意的代码;它守护了被信任的类库边界;它将代码归入保护域,确定了代码可以进行哪些操作。虚拟机为不同的类加载器载入的类提供不同的命名空间，命名空间由一系列唯一的名称组成， 每一个被装载的类将有一个名字，这个命名空间是由Java虚拟机为每一个类装载器维护的，它们互相之间甚至不可见。类装载器采用的机制是双亲委派模式。从最内层JVM自带类加载器开始加载,外层恶意同名类得不到加载从而无法使用;由于严格通过包来区分了访问域,外层恶意的类通过内置代码也无法获得权限访问到内层类，破坏代码就自然无法生效。存取控制器(access controller) :存取控制器可以控制核心API对操作系统的存取权限，而这个控制的策略设定,可以由用户指定。安全管理器(security manager) : 是核心API和操作系统之间的主要接口。实现权限控制，比存取控制器优先级高。安全软件包(security package) : java.security下的类和扩展包下的类，允许用户为自己的应用增加新的安全特性，包括:安全提供者消息摘要数字签名加密鉴别Nativenative :凡是带了native关键字的，说明java的作用范围达不到了，回去调用底层c语言的库!会进入本地方法栈调用本地方法本地接口 JNI (Java Native Interface)JNI作用:开拓Java的使用，融合不同的编程语言为Java所用!最初: C、C++Java诞生的时候C、C++横行，想要立足，必须要有调用C、C++的程序它在内存区域中专门开辟了一块标记区域: Native Method Stack，登记native方法在最终执行的时候，加载本地方法库中的方法通过JNI例如：Java程序驱动打印机，管理系统，掌握即可，在企业级应用比较少private native void start0();调用其他接口:Socket. . WebService~. .http~Native Method Stack它的具体做法是Native Method Stack中登记native方法，在( Execution Engine )执行引擎执行的时候加载Native Libraies。[本地库]Native Interface本地接口本地接口的作用是融合不同的编程语言为Java所用，它的初衷是融合C/C++程序, Java在诞生的时候是C/C++横行的时候，想要立足，必须有调用C、C++的程序，于是就在内存中专门开辟了块区域处理标记为native的代码，它的具体做法是在Native Method Stack 中登记native方法,在( Execution Engine )执行引擎执行的时候加载Native Libraies。目前该方法使用的越来越少了，除非是与硬件有关的应用，比如通过Java程序驱动打印机或者Java系统管理生产设备，在企业级应用中已经比较少见。因为现在的异构领域间通信很发达，比如可以使用Socket通信,也可以使用Web Service等等，不多做介绍!PC寄存器程序计数器: Program Counter Register每个线程都有一个程序计数器，是线程私有的，就是一个指针, 指向方法区中的方法字节码(用来存储指向像一条指令的地址， 也即将要执行的指令代码)，在执行引擎读取下一条指令, 是一个非常小的内存空间，几乎可以忽略不计方法区 Method Area方法区是被所有线程共享,所有字段和方法字节码，以及一些特殊方法，如构造函数,接口代码也在此定义,简单说，所有定义的方法的信息都保存在该区域,此区域属于共享区间;静态变量、常量、类信息(构造方法、接口定义)、运行时的常量池存在方法区中，但是实例变量存在堆内存中，和方法区无关栈栈:先进后出桶:后进先出队列:先进先出( FIFO : First Input First Output )栈:栈内存,主管程序的运行,生命周期和线程同步;线程结束，栈内存也就是释放,对于栈来说,不存在垃圾回收问题一旦线程结束，栈就Over!栈内存中:8大基本类型+对象引用+实例的方法栈运行原理:栈帧栈满了: StackOverflowError三种JVMSun公司HotSpot Java Hotspot™ 64-Bit Server VM (build 25.181-b13,mixed mode)BEA JRockitIBM J9VM我们学习都是: Hotspot堆Heap, 一个JVM只有一个堆内存，堆内存的大小是可以调节的。类加载器读取了类文件后，一般会把什么东西放到堆中?类, 方法，常量,变量~，保存我们所有引用类型的真实对象;堆内存中还要细分为三个区域:新生区(伊甸园区) Young/New养老区old永久区PermGC垃圾回收,主要是在伊甸园区和养老区~假设内存满了,OOM,堆内存不够! java.lang.OutOfMemoryError:Java heap space永久存储区里存放的都是Java自带的 例如lang包中的类 如果不存在这些，Java就跑不起来了在JDK8以后，永久存储区改了个名字(元空间)新生区、老年区新生区类:诞生和成长的地方，甚至死亡;伊甸园，所有的对象都是在伊甸园区new出来的!幸存者区(0,1)伊甸园满了就触发轻GC，经过轻GC存活下来的就到了幸存者区，幸存者区满之后意味着新生区也满了，则触发重GC，经过重GC之后存活下来的就到了养老区。真理:经过研究，99%的对象都是临时对象!永久区这个区域常驻内存的。用来存放JDK自身携带的Class对象。Interface元数据，存储的是Java运行时的一些环境~ 这个区域不存在垃圾回收，关闭虚拟机就会释放内存jdk1.6之前:永久代,常量池是在方法区;jdk1.7:永久代,但是慢慢的退化了，去永久代，常量池在堆中jdk1.8之后:无永久代,常量池在元空间元空间：逻辑上存在，物理上不存在 (因为存储在本地磁盘内) 所以最后并不算在JVM虚拟机内存中堆内存调优测试代码123456public static void main(String[] args) &#123; String s = \"\"; while (true) &#123; s += \"11111111111111111111111111111111111111111111111111111\"; &#125;&#125;在一个项目中，突然出现了OOM故障,那么该如何排除 研究为什么出错~能够看到代码第几行出错:内存快照分析工具，MAT, JprofilerDubug, 一行行分析代码!MAT, Jprofiler作用分析Dump内存文件,快速定位内存泄露;获得堆中的数据获得大的对象~MAT是eclipse集成使用 在这里不学Jprofile使用在idea中下载jprofile插件联网下载jprofile客户端在idea中VM参数中写参数 -Xms1m -Xmx8m -XX: +HeapDumpOnOutOfMemoryError运行程序后在jprofile客户端中打开找到错误 告诉哪个位置报错命令参数详解// -Xms设置初始化内存分配大小/164// -Xmx设置最大分配内存，默以1/4// -XX: +PrintGCDetails // 打印GC垃圾回收信息// -XX: +HeapDumpOnOutOfMemoryError //oom DUMPGCJVM在进行GC时，并不是对这三个区域统一回收。 大部分时候，回收都是新生代~新生代幸存区(form，to)老年区GC两种类:轻GC (普通的GC)， 重GC (全局GC)GC常见面试题目:JVM的内存模型和分区~详细到每个区放什么?堆里面的分区有哪些?Eden, form, to, 老年区,说说他们的特点!GC的算法有哪些?标记清除法，标记整理,复制算法，引用计数器轻GC和重GC分别在什么时候发生?算法：引用计数器：复制算法：好处:没有内存的碎片~坏处:浪费了内存空间~ :多了一半空间永远是空to。假设对象100%存活(极端情况)复制算法最佳使用场景：对象存活度较低的时候 -&gt; 新生区标记清除算法：优点：不需要额外的空间。缺点：两次扫描，严重浪费时间，会产生内存碎片。标记压缩：标记 -&gt; 清除 -&gt; 压缩","categories":[{"name":"Java","slug":"Java","permalink":"https://me.obey.fun/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://me.obey.fun/categories/Java/JVM/"}],"tags":[{"name":"Heap","slug":"Heap","permalink":"https://me.obey.fun/tags/Heap/"},{"name":"Stack","slug":"Stack","permalink":"https://me.obey.fun/tags/Stack/"}],"keywords":[{"name":"Java","slug":"Java","permalink":"https://me.obey.fun/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://me.obey.fun/categories/Java/JVM/"}]},{"title":"POI和EasyExcel的简单使用","slug":"POI和EasyExcel的简单使用","date":"2020-11-15T14:39:42.000Z","updated":"2020-11-15T15:15:20.741Z","comments":true,"path":"POI和EasyExcel的简单使用.html","link":"","permalink":"https://me.obey.fun/POI和EasyExcel的简单使用.html","excerpt":"","text":"前言最近公司的一个业务需要使用Java操作Excel表格，于是去B站学习了以下两个框架POI常用操作将用户信息导出为excel表格（导出数据….）将Excel表中的信息录入到网站数据库（习题上传….）开发中经常会设计到excel的处理，如导出Excel，导入Excel到数据库中！操作Excel目前比较流行的就是 Apache POI 和 阿里巴巴的 easyExcel ！Apache POIApache POI 官网：https://poi.apache.org/easyExceleasyExcel 官网地址：https://github.com/alibaba/easyexcelEasyExcel 是阿里巴巴开源的一个excel处理框架，以使用简单、节省内存著称。EasyExcel 能大大减少占用内存的主要原因是在解析 Excel 时没有将文件数据一次性全部加载到内存中，而是从磁盘上一行行读取数据，逐个解析。下图是 EasyExcel 和 POI 在解析Excel时的对比图。官方文档：https://www.yuque.com/easyexcel/doc/easyexcelPOI-Excel写创建项目1、建立一个空项目 ，创建普通Maven的Moudle kuang-poi2、引入pom依赖1234567891011121314151617181920212223242526272829&lt;dependencies&gt; &lt;!--xls(03)--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi&lt;/artifactId&gt; &lt;version&gt;3.9&lt;/version&gt; &lt;/dependency&gt; &lt;!--xlsx(07)--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;3.9&lt;/version&gt; &lt;/dependency&gt; &lt;!--日期格式化工具--&gt; &lt;dependency&gt; &lt;groupId&gt;joda-time&lt;/groupId&gt; &lt;artifactId&gt;joda-time&lt;/artifactId&gt; &lt;version&gt;2.10.1&lt;/version&gt; &lt;/dependency&gt; &lt;!--test--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;03 | 07 版本的写，就是对象不同，方法一样的！需要注意：2003 版本和 2007 版本存在兼容性的问题！03最多只有 65535 行！1、工作簿：2、工作表：3、行：4、列：03版本：12345678910111213141516171819202122232425262728293031323334@Testpublic void testWrite03() throws Exception &#123; // 1、创建一个工作簿 Workbook workbook = new HSSFWorkbook(); // 2、创建一个工作表 Sheet sheet = workbook.createSheet(\"观众统计表\"); // 3、创建一个行 （1,1） Row row1 = sheet.createRow(0); // 4、创建一个单元格 Cell cell11 = row1.createCell(0); cell11.setCellValue(\"今日新增观众\"); // (1,2) Cell cell12 = row1.createCell(1); cell12.setCellValue(666); // 第二行 (2,1) Row row2 = sheet.createRow(1); Cell cell21 = row2.createCell(0); cell21.setCellValue(\"统计时间\"); // (2,2) Cell cell22 = row2.createCell(1); String time = new DateTime().toString(\"yyyy-MM-dd HH:mm:ss\"); cell22.setCellValue(time); // 生成一张表（IO 流） 03 版本就是使用 xls结尾！ FileOutputStream fileOutputStream = new FileOutputStream(PATH + \"观众统计表03.xls\"); // 输出 workbook.write(fileOutputStream); // 关闭流 fileOutputStream.close(); System.out.println(\"观众统计表03 生成完毕！\");&#125;07版本：12345678910111213141516171819202122232425262728293031323334@Testpublic void testWrite07() throws Exception &#123; // 1、创建一个工作簿 07 Workbook workbook = new XSSFWorkbook(); // 2、创建一个工作表 Sheet sheet = workbook.createSheet(\"观众统计表\"); // 3、创建一个行 （1,1） Row row1 = sheet.createRow(0); // 4、创建一个单元格 Cell cell11 = row1.createCell(0); cell11.setCellValue(\"今日新增观众\"); // (1,2) Cell cell12 = row1.createCell(1); cell12.setCellValue(666); // 第二行 (2,1) Row row2 = sheet.createRow(1); Cell cell21 = row2.createCell(0); cell21.setCellValue(\"统计时间\"); // (2,2) Cell cell22 = row2.createCell(1); String time = new DateTime().toString(\"yyyy-MM-dd HH:mm:ss\"); cell22.setCellValue(time); // 生成一张表（IO 流） 03 版本就是使用 xlsx结尾！ FileOutputStream fileOutputStream = new FileOutputStream(PATH + \"观众统计表07.xlsx\"); // 输出 workbook.write(fileOutputStream); // 关闭流 fileOutputStream.close(); System.out.println(\"观众统计表03 生成完毕！\");&#125;注意对象的一个区别，文件后缀！数据批量导入！大文件写HSSF缺点：最多只能处理65536行，否则会抛出异常1java.lang.IllegalArgumentException: Invalid row number (65536) outside allowable range (0..65535)优点：过程中写入缓存，不操作磁盘，最后一次性写入磁盘，速度快123456789101112131415161718192021222324@Testpublic void testWrite03BigData() throws IOException &#123; // 时间 long begin = System.currentTimeMillis(); // 创建一个薄 Workbook workbook = new HSSFWorkbook(); // 创建表 Sheet sheet = workbook.createSheet(); // 写入数据 for (int rowNum = 0; rowNum &lt; 65537; rowNum++) &#123; Row row = sheet.createRow(rowNum); for (int cellNum = 0; cellNum &lt; 10 ; cellNum++) &#123; Cell cell = row.createCell(cellNum); cell.setCellValue(cellNum); &#125; &#125; System.out.println(\"over\"); FileOutputStream outputStream = new FileOutputStream(PATH + \"testWrite03BigData.xls\"); workbook.write(outputStream); outputStream.close(); long end = System.currentTimeMillis(); System.out.println((double) (end-begin)/1000);&#125;大文件写XSSF缺点：写数据时速度非常慢，非常耗内存，也会发生内存溢出，如100万条优点：可以写较大的数据量，如20万条123456789101112131415161718192021222324@Testpublic void testWrite07BigData() throws IOException &#123; // 时间 long begin = System.currentTimeMillis(); // 创建一个薄 Workbook workbook = new XSSFWorkbook(); // 创建表 Sheet sheet = workbook.createSheet(); // 写入数据 for (int rowNum = 0; rowNum &lt; 100000; rowNum++) &#123; Row row = sheet.createRow(rowNum); for (int cellNum = 0; cellNum &lt; 10 ; cellNum++) &#123; Cell cell = row.createCell(cellNum); cell.setCellValue(cellNum); &#125; &#125; System.out.println(\"over\"); FileOutputStream outputStream = new FileOutputStream(PATH + \"testWrite07BigData.xlsx\"); workbook.write(outputStream); outputStream.close(); long end = System.currentTimeMillis(); System.out.println((double) (end-begin)/1000);&#125;大文件写SXSSF优点：可以写非常大的数据量，如100万条甚至更多条，写数据速度快，占用更少的内存注意：过程中会产生临时文件，需要清理临时文件默认由100条记录被保存在内存中，如果超过这数量，则最前面的数据被写入临时文件如果想自定义内存中数据的数量，可以使用new SXSSFWorkbook ( 数量 )1234567891011121314151617181920212223242526@Testpublic void testWrite07BigDataS() throws IOException &#123; // 时间 long begin = System.currentTimeMillis(); // 创建一个薄 Workbook workbook = new SXSSFWorkbook(); // 创建表 Sheet sheet = workbook.createSheet(); // 写入数据 for (int rowNum = 0; rowNum &lt; 100000; rowNum++) &#123; Row row = sheet.createRow(rowNum); for (int cellNum = 0; cellNum &lt; 10 ; cellNum++) &#123; Cell cell = row.createCell(cellNum); cell.setCellValue(cellNum); &#125; &#125; System.out.println(\"over\"); FileOutputStream outputStream = new FileOutputStream(PATH + \"testWrite07BigDataS.xlsx\"); workbook.write(outputStream); outputStream.close(); // 清除临时文件！ ((SXSSFWorkbook) workbook).dispose(); long end = System.currentTimeMillis(); System.out.println((double) (end-begin)/1000);&#125;SXSSFWorkbook-来至官方的解释：实现“BigGridDemo”策略的流式XSSFWorkbook版本。这允许写入非常大的文件而不会耗尽内存，因为任何时候只有可配置的行部分被保存在内存中。请注意，仍然可能会消耗大量内存，这些内存基于您正在使用的功能，例如合并区域，注释……仍然只存储在内存中，因此如果广泛使用，可能需要大量内存。再使用 POI的时候！内存问题 Jprofile！POI-Excel读03|07 版本03版本123456789101112131415161718192021@Testpublic void testRead03() throws Exception &#123; // 获取文件流 FileInputStream inputStream = new FileInputStream(PATH + \"poi-观众统计表03.xls\"); // 1、创建一个工作簿。 使用excel能操作的这边他都可以操作！ Workbook workbook = new HSSFWorkbook(inputStream); // 2、得到表 Sheet sheet = workbook.getSheetAt(0); // 3、得到行 Row row = sheet.getRow(0); // 4、得到列 Cell cell = row.getCell(1); // 读取值的时候，一定需要注意类型！ // getStringCellValue 字符串类型 // System.out.println(cell.getStringCellValue()); System.out.println(cell.getNumericCellValue()); inputStream.close();&#125;07版本123456789101112131415161718192021@Testpublic void testRead07() throws Exception &#123; // 获取文件流 FileInputStream inputStream = new FileInputStream(PATH + \"poi-观众统计表07.xlsx\"); // 1、创建一个工作簿。 使用excel能操作的这边他都可以操作！ Workbook workbook = new XSSFWorkbook(inputStream); // 2、得到表 Sheet sheet = workbook.getSheetAt(0); // 3、得到行 Row row = sheet.getRow(0); // 4、得到列 Cell cell = row.getCell(1); // 读取值的时候，一定需要注意类型！ // getStringCellValue 字符串类型 // System.out.println(cell.getStringCellValue()); System.out.println(cell.getNumericCellValue()); inputStream.close();&#125;注意获取值的类型即可读取不同的数据类型（最麻烦的就是这里了！）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576@Testpublic void testCellType() throws Exception &#123; // 获取文件流 FileInputStream inputStream = new FileInputStream(PATH + \"明细表.xls\"); // 创建一个工作簿。 使用excel能操作的这边他都可以操作！ Workbook workbook = new HSSFWorkbook(inputStream); Sheet sheet = workbook.getSheetAt(0); // 获取标题内容 Row rowTitle = sheet.getRow(0); if (rowTitle!=null) &#123; // 一定要掌握 int cellCount = rowTitle.getPhysicalNumberOfCells(); for (int cellNum = 0; cellNum &lt; cellCount; cellNum++) &#123; Cell cell = rowTitle.getCell(cellNum); if (cell!=null)&#123; int cellType = cell.getCellType(); String cellValue = cell.getStringCellValue(); System.out.print(cellValue + \" | \"); &#125; &#125; System.out.println(); &#125; // 获取表中的内容 int rowCount = sheet.getPhysicalNumberOfRows(); for (int rowNum = 1; rowNum &lt; rowCount ; rowNum++) &#123; Row rowData = sheet.getRow(rowNum); if (rowData!=null)&#123; // 读取列 int cellCount = rowTitle.getPhysicalNumberOfCells(); for (int cellNum = 0; cellNum &lt; cellCount ; cellNum++) &#123; System.out.print(\"[\" +(rowNum+1) + \"-\" + (cellNum+1) + \"]\"); Cell cell = rowData.getCell(cellNum); // 匹配列的数据类型 if (cell!=null) &#123; int cellType = cell.getCellType(); String cellValue = \"\"; switch (cellType) &#123; case HSSFCell.CELL_TYPE_STRING: // 字符串 System.out.print(\"【String】\"); cellValue = cell.getStringCellValue(); break; case HSSFCell.CELL_TYPE_BOOLEAN: // 布尔 System.out.print(\"【BOOLEAN】\"); cellValue = String.valueOf(cell.getBooleanCellValue()); break; case HSSFCell.CELL_TYPE_BLANK: // 空 System.out.print(\"【BLANK】\"); break; case HSSFCell.CELL_TYPE_NUMERIC: // 数字（日期、普通数字） System.out.print(\"【NUMERIC】\"); if (HSSFDateUtil.isCellDateFormatted(cell))&#123; // 日期 System.out.print(\"【日期】\"); Date date = cell.getDateCellValue(); cellValue = new DateTime(date).toString(\"yyyy-MM-dd\"); &#125;else &#123; // 不是日期格式，防止数字过长！ System.out.print(\"【转换为字符串输出】\"); cell.setCellType(HSSFCell.CELL_TYPE_STRING); cellValue = cell.toString(); &#125; break; case HSSFCell.CELL_TYPE_ERROR: System.out.print(\"【数据类型错误】\"); break; &#125; System.out.println(cellValue); &#125; &#125; &#125; &#125; inputStream.close();&#125;注意，类型转换问题；计算公式 （了解即可！）123456789101112131415161718192021222324252627@Testpublic void testFormula() throws Exception &#123; FileInputStream inputStream = new FileInputStream(PATH + \"公式.xls\"); Workbook workbook = new HSSFWorkbook(inputStream); Sheet sheet = workbook.getSheetAt(0); Row row = sheet.getRow(4); Cell cell = row.getCell(0); // 拿到计算公司 eval FormulaEvaluator FormulaEvaluator = new HSSFFormulaEvaluator((HSSFWorkbook)workbook); // 输出单元格的内容 int cellType = cell.getCellType(); switch (cellType)&#123; case Cell.CELL_TYPE_FORMULA: // 公式 String formula = cell.getCellFormula(); System.out.println(formula); // 计算 CellValue evaluate = FormulaEvaluator.evaluate(cell); String cellValue = evaluate.formatAsString(); System.out.println(cellValue); break; &#125;&#125;EasyExcel操作导入依赖12345&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;easyexcel&lt;/artifactId&gt; &lt;version&gt;2.2.0-beta2&lt;/version&gt;&lt;/dependency&gt;写入测试https://www.yuque.com/easyexcel/doc/read创建对象1234567891011121314@Datapublic class DemoData &#123; @ExcelProperty(\"字符串标题\") private String string; @ExcelProperty(\"日期标题\") private Date date; @ExcelProperty(\"数字标题\") private Double doubleData; /** * 忽略这个字段 */ @ExcelIgnore private String ignore;&#125;拿到实体类里的值12345678910111213String PATH =\"D:\\\\Project\\\\IdeaProject\\\\Java_work\\\\\"; private List&lt;DemoData&gt; data() &#123; List&lt;DemoData&gt; list = new ArrayList&lt;DemoData&gt;(); for (int i = 0; i &lt; 10; i++) &#123; DemoData data = new DemoData(); data.setString(\"字符串\" + i); data.setDate(new Date()); data.setDoubleData(0.56); list.add(data); &#125; return list; &#125;将list写入Excel1234567891011// 根据list 写入excel @Test public void simpleWrite() &#123; // 写法1 String fileName = PATH + \"EasyTest.xlsx\"; // 这里 需要指定写用哪个class去写，然后写到第一个sheet，名字为模板 然后文件流会自动关闭 // write (fileName, 格式类) // sheet (表明) // doWrite (数据) EasyExcel.write(fileName, DemoData.class).sheet(\"模板\").doWrite(data()); &#125;读取测试https://www.yuque.com/easyexcel/doc/read对象监听器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去public class DemoDataListener extends AnalysisEventListener&lt;DemoData&gt; &#123; private static final Logger LOGGER = LoggerFactory.getLogger(DemoDataListener.class); private static final int BATCH_COUNT = 5; List&lt;DemoData&gt; list = new ArrayList&lt;DemoData&gt;(); private DemoDAO demoDAO; public DemoDataListener() &#123; // 这里是demo，所以随便new一个。实际使用如果到了spring,请使用下面的有参构造函数 demoDAO = new DemoDAO(); &#125; public DemoDataListener(DemoDAO demoDAO) &#123; this.demoDAO = demoDAO; &#125; // 读取数据会执行 invoke 方法 // DemoData 类型 // AnalysisContext 分析上问 @Override public void invoke(DemoData data, AnalysisContext context) &#123; System.out.println(JSON.toJSONString(data)); list.add(data); // 达到BATCH_COUNT了，需要去存储一次数据库，防止数据几万条数据在内存，容易OOM if (list.size() &gt;= BATCH_COUNT) &#123; saveData(); // 持久化逻辑! // 存储完成清理 list list.clear(); &#125; &#125; /** * 所有数据解析完成了 都会来调用 * * @param context */ @Override public void doAfterAllAnalysed(AnalysisContext context) &#123; // 这里也要保存数据，确保最后遗留的数据也存储到数据库 saveData(); LOGGER.info(\"所有数据解析完成！\"); &#125; /** * 加上存储数据库 */ private void saveData() &#123; LOGGER.info(\"&#123;&#125;条数据，开始存储数据库！\", list.size()); demoDAO.save(list); LOGGER.info(\"存储数据库成功！\"); &#125;&#125;持久层123456789/** * 假设这个是你的DAO存储。当然还要这个类让spring管理，当然你不用需要存储，也不需要这个类。 **/public class DemoDAO &#123; public void save(List&lt;DemoData&gt; list) &#123; // 持久化操作！ // 如果是mybatis,尽量别直接调用多次insert,自己写一个mapper里面新增一个方法batchInsert,所有数据一次性插入 &#125;&#125;测试代码12345678910@Test public void simpleRead() &#123; // 有个很重要的点 DemoDataListener 不能被spring管理，要每次读取excel都要new,然后里面用到spring可以构造方法传进去 // 写法1： String fileName = PATH + \"EasyTest.xlsx\"; // 这里 需要指定读用哪个class去读，然后读取第一个sheet 文件流会自动关闭 // 重点注意读取的逻辑 DemoDataListener EasyExcel.read(fileName, DemoData.class, new DemoDataListener()).sheet().doRead(); &#125;固定套路：1、写入，固定类格式进行写入2、读取，根据监听器设置的规则进行读取！一、POI","categories":[{"name":"Apache","slug":"Apache","permalink":"https://me.obey.fun/categories/Apache/"},{"name":"POI","slug":"Apache/POI","permalink":"https://me.obey.fun/categories/Apache/POI/"}],"tags":[{"name":"POI","slug":"POI","permalink":"https://me.obey.fun/tags/POI/"},{"name":"EasyExcel","slug":"EasyExcel","permalink":"https://me.obey.fun/tags/EasyExcel/"}],"keywords":[{"name":"Apache","slug":"Apache","permalink":"https://me.obey.fun/categories/Apache/"},{"name":"POI","slug":"Apache/POI","permalink":"https://me.obey.fun/categories/Apache/POI/"}]},{"title":"Docker入门与实践","slug":"Docker入门与实践","date":"2020-10-24T09:46:04.000Z","updated":"2020-11-09T03:27:46.536Z","comments":true,"path":"Docker入门与实践.html","link":"","permalink":"https://me.obey.fun/Docker入门与实践.html","excerpt":"","text":"Docker参考资料官方文档：https://docs.docker.com/docker-for-windows/【官方文档超级详细】仓库地址：https://hub.docker.com/【发布到仓库，git pull push】前期基础linux基本命令，类似cd，mkdir等Docker概述Docker为什么会出现一款产品，开发和上线两套环境，应用环境配置费时费力，而且容易出问题尤其对于机器学习和深度学习的库更是如此，很可能存在版本问题、底层依赖冲突问题所以发布项目时，不只是一套代码过去，而是代码+环境整体打包过去所谓开发即运维，保证系统稳定性，提高部署效率使用Docker后的流程：开发：建立模型–环境–打包带上环境，即镜像–放到Docker仓库部署：下载Docker中的镜像，直接运行即可Docker的思想来自于集装箱，集装箱，对环境进行隔离Docker通过隔离机制，可以将服务器利用到极致。Docker的历史2010年，几个搞IT的人，在美国成立一家公司dotCloud做一些pass的云计算服务他们将自己的容器化技术命名为DockerDocker基于Go语言开发Docker刚刚诞生的时候，没有引起行业的注意，dotCloud活不下去然后他们决定开源2013年，创始人将Docker开源，不开则以，一开惊人，刚开源的时候，每个月都会更新一个版本2014年4月9日，Docker 1.0发布容器vs虚拟机在容器技术出来之前，用的是虚拟机技术虚拟机原理示意图缺点：资源占用多冗余步骤多启动很慢容器化技术示意图不是模拟的完整的操作系统二者对比比较虚拟机和Docker的不同传统虚拟机Docker虚拟内容硬件+完整的操作系统+软件APP+LIB大小笨重，通常几个G轻便几个M或KB启动速度慢，分钟级快，秒级Docker安装Docker的基本组成明确几个概念：镜像(image)：docker镜像好比一个模板，可以通过这个模板来创建容器(container)，一个镜像可以创建多个容器，类似Python中的Class容器(container)：类似Python中通过Class创建的实例，Object；容器可以理解为一个简易的系统仓库(repository)：存放镜像的地方，分为共有仓库和私有仓库Docker Hub：国外的阿里云：配置镜像加速环境准备我们要有一台服务器，并且可以操作它Linux命令基础，购买linux阿里云的服务器CentOS 7使用Xshell链接远程服务器安装xshell下载CentOS7 https://www.jianshu.com/p/a63f47e096e8下载VMwareVMware配置虚拟机 https://blog.csdn.net/babyxue/article/details/80970526xshell链接服务器 https://blog.csdn.net/zzy1078689276/article/details/772808141234567[root@192 ~]# cd /[root@192 /]# pwd/[root@192 /]# lsbin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var[root@192 /]# uname -r3.10.0-1127.el7.x86_64查看ip：vmware里面输入，ip addrCentos安装https://docs.docker.com/engine/install/centos/卸载旧的版本123456789# 卸载旧的版本$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine安装基本环境12# 安装基本的安装包$ sudo yum install -y yum-utils设置镜像的仓库注意！！下载默认用国外的，太慢不要用！用国内镜像，百度搜索，docker的阿里云镜像地址12345678910# 不要用官网默认这个！$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo # 默认是国外的# 换成下面的$ sudo yum-config-manager \\ --add-repo \\ https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # 阿里云镜像直接复制粘贴就OK了更像软件包索引1yum makecache fast没有问题的话就是可以用的安装docker引擎1yum install docker-ce docker-ce-cli containerd.io # docker-ce 社区版 ee 企业版注意这里会有几个个y/n的判断，直接同意即可，或者安装直接加-y参数。启动Docker1systemctl start docker # 代表启动成功1docker version123456789101112131415161718192021222324252627Client: Docker Engine - Community Version: 19.03.11 API version: 1.40 Go version: go1.13.10 Git commit: 42e35e61f3 Built: Mon Jun 1 09:13:48 2020 OS/Arch: linux/amd64 Experimental: falseServer: Docker Engine - Community Engine: Version: 19.03.11 API version: 1.40 (minimum version 1.12) Go version: go1.13.10 Git commit: 42e35e61f3 Built: Mon Jun 1 09:12:26 2020 OS/Arch: linux/amd64 Experimental: false containerd: Version: 1.2.13 GitCommit: 7ad184331fa3e55e52b890ea95e65ba581ae3429 runc: Version: 1.0.0-rc10 GitCommit: dc9208a3303feef5b3839f4323d9beb36df0a9dd docker-init: Version: 0.18.0 GitCommit: fec36831docker run hello-world中间一堆是签名信息（sha256加密）run的运行流程图查看下载的镜像1docker images卸载Docker12345# 卸载依赖yum remove docker-ce docker-ce-cli containerd.io# 删除资源rm -rf /var/lib/docker # docker 的默认工作路径阿里云镜像加速支付宝扫码登录，短信验证，确认授权我有两个问题阿里云镜像加速必须配置嘛？加速快要是翻墙就无所谓了这个阿里云必须要买嘛，买哪个，我看阿里云好多产品不需要买免费的阿里云搜索容器服务有一个镜像加速这个地址是哪来的呀控制台搜索 容器镜像服务找到加速地址123456789sudo mkdir -p /etc/docker # 创建一个陌路sudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; \"registry-mirrors\": [\"https://uyfgafsw.mirror.aliyuncs.com\"]&#125;EOF # 编写配置文件sudo systemctl daemon-reload # 重启服务sudo systemctl restart docker # 重启dockerDocker是真么工作的？Docker是一个Client-Server结构的系统，Docker的守护进程在主机上。通过Socket从客户端访问！DockerServer接受到Docker-Client的指令，Docker为什么比VM快？Docker有着比虚拟机更少的抽象层docker主要用的是宿主机的内核，vm需要Guest OS所以说新建一个容器的时候，docker不需要像虚拟机一样重新加载一个操作系统内核，避免引导Docker命令帮助命令123docker version # 显示docker的基本信息docker info # 系统信息，镜像和容器的数量docker 命令 --help # 全部信息官网文档镜像命令docker images查看所有本地主机上的镜像1[root@192 ~]# docker images123456# 解释REPOSITORY # 镜像仓库源TAG # 镜像的标签IMAGE ID # 镜像的IDCREATED # 镜像的创建时间SIZE # 镜像的大小123456--all , -a Show all images (default hides intermediate images) # 显示所有--digests Show digests--filter , -f Filter output based on conditions provided--format Pretty-print images using a Go template--no-trunc Don’t truncate output--quiet , -q Only show numeric IDs # 只显示iddocker search搜索仓库中的镜像，相当于网页搜索网页搜索mysql1docker search mysql1docker search --help123456# 解释Options: -f, --filter filter Filter output based on conditions provided --format string Pretty-print search using a Go template --limit int Max number of search results (default 25) --no-trunc Don't truncate output1docker search mysql --filter=STARS=3000 # 搜索出Stars大于3000的docker pull下载镜像1docker pull mysql # 下载mysql镜像，default tag，默认最新版latest12345678910111213141516171819202122232425[root@192 ~]# sudo systemctl daemon-reload[root@192 ~]# sudo systemctl restart docker[root@192 ~]# docker pull mysqlUsing default tag: latest # 不写tag默认最新版latest: Pulling from library/mysql8559a31e96f4: Pull complete # layer 分层下载，docker image的核心 联合文件系统d51ce1c2e575: Pull complete c2344adc4858: Pull complete fcf3ceff18fc: Pull complete 16da0c38dc5b: Pull complete b905d1797e97: Pull complete 4b50d1c6b05c: Pull complete c75914a65ca2: Pull complete 1ae8042bdd09: Pull complete 453ac13c00a3: Pull complete 9e680cd72f08: Pull complete a6b5dc864b6c: Pull complete Digest: sha256:8b7b328a7ff6de46ef96bcf83af048cb00a1c86282bfca0cb119c84568b4caf6#签名Status: Downloaded newer image for mysql:latestdocker.io/library/mysql:latest # 真实地址# 即docker pull mysql# 等价于docker pull docker.io/library/mysql:latest12# 指定版本下载 docker pull mysql:5.7版本来自于官网，版本库https://hub.docker.com/_/mysql1docker images此时查看镜像，可以看到新下载的两个docker rmiremove images123456# 删除一个 可以通过名称 也可以指定id -f表示删除所有docker rmi -f 9cfcce23593a# 删除多个 用空格分隔iddocker rmi -f id id id# 删除所有 docker rmi -f $(docker images -aq) # images -aq就是查所有镜像id，从而递归删除容器命令说明：有了镜像才能创建容器，linux，下载一个centos镜像来测试学习1docker pull centos新建容器并启动123456789101112docker run [可选参数] image# 参数说明--name=“Name” # 容器名字，用于区分容器-d 后台方式运行-it 使用交互方式运行，进入容器查看内容-p 指定容器的端口 如-p 8080::8080 -p ip:主机端口：容器端口 -p 主机端口:容器端口 -p 容器端口 -p 随机指定端口进入退出容器123456# 进入docker run -it centos /bin/bash # 查看目录ls# 退出exit注意这里面主机名，编程了centos的id这里面就是一个容器，套娃啊查看运行的容器12345678# 查看正在运行的容器docker ps# 查看曾经运行的容器docker ps -a# 显示最近创建的容器，设置显示个数docker ps -a - n=? # 只显示容器的编号docker ps -aq123456789101112131415[root@192 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@192 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9939864fa2e6 centos \"bin/bash\" 4 minutes ago Exited (0) 4 minutes ago unruffled_knuth5f42e9930435 centos \"/bin/bash\" 8 minutes ago Exited (0) 4 minutes ago lucid_cannona89ddb393d3d bf756fb1ae65 \"/hello\" 19 hours ago Exited (0) 19 hours ago gracious_bhabha[root@192 ~]# docker ps -a -n=2CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES9939864fa2e6 centos \"bin/bash\" 6 minutes ago Exited (0) 6 minutes ago unruffled_knuth5f42e9930435 centos \"/bin/bash\" 10 minutes ago Exited (0) 7 minutes ago [root@192 ~]# docker ps -aq9939864fa2e65f42e9930435a89ddb393d3d退出容器1234# 容器停止退出exit# 容器不停止退出 注意必须在英文输入法下，中文输入法不行Ctrl + P + Q12345678[root@192 ~]# docker run -it centos /bin/bash[root@bfcea13c40cd /]# [root@192 ~]# docker ps ##注意这里会自动给个命令，删掉CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbfcea13c40cd centos \"/bin/bash\" About a minute ago Up About a minute stoic_wilsonedbd9366d959 centos \"/bin/bash\" 7 minutes ago Up 7 minutes affectionate_bartik[root@192 ~]# docker exec -it edbd9366d959 /bin/bash ## 再次进入[root@edbd9366d959 /]# exit ##停止并推出exit删除容器123456# 删除指定容器 不能删除正在运行的容器，如果强制删除 rm -fdocker rm 容器id# 删除所有容器docker rm -f $(docker ps -aq)# 删除所有容器docker ps -a -q|xargs docker rm1234567891011[root@192 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbfcea13c40cd centos \"/bin/bash\" 29 minutes ago Up 29 minutes stoic_wilsonedbd9366d959 centos \"/bin/bash\" 35 minutes ago Up 35 minutes affectionate_bartik9939864fa2e6 centos \"bin/bash\" 48 minutes ago Exited (0) 48 minutes ago unruffled_knuth5f42e9930435 centos \"/bin/bash\" 52 minutes ago Exited (0) 49 minutes ago lucid_cannona89ddb393d3d bf756fb1ae65 \"/hello\" 20 hours ago Exited (0) 20 hours ago gracious_bhabha[root@192 ~]# docker rm 5f42e99304355f42e9930435[root@192 ~]# docker rm edbd9366d959 # 注意正在运行的容器不能删除Error response from daemon: You cannot remove a running container edbd9366d9596c744dd449119269b04de2f2a494e7fc471f6396bcefd94c33fe. Stop the container before attempting removal or force remove12345678910[root@192 ~]# docker ps -aq # 所有容器idbfcea13c40cdedbd9366d9599939864fa2e6a89ddb393d3d[root@192 ~]# docker rm -f $(docker ps -aq) # 全部删除bfcea13c40cdedbd9366d9599939864fa2e6a89ddb393d3d启动和停止容器的操作1234docker startdocker restartdocker stopdocker kill1234567891011121314151617[root@192 ~]# docker run -it centos /bin/bash[root@7b1a7dd10ea4 /]# exitexit[root@192 ~]# docker ps #查看正在运行的CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@192 ~]# docker ps -a # 查看历史运行过的CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7b1a7dd10ea4 centos \"/bin/bash\" 54 seconds ago Exited (0) 42 seconds ago fervent_mirzakhani[root@192 ~]# docker start 7b1a7dd10ea4 # 启动当前这个容器 container id 粘过 来7b1a7dd10ea4[root@192 ~]# docker ps # 查看当前运行容器 发现启动成功CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES7b1a7dd10ea4 centos \"/bin/bash\" 2 minutes ago Up 28 seconds fervent_mirzakhani[root@192 ~]# docker stop 7b1a7dd10ea4 # 停止运行7b1a7dd10ea4[root@192 ~]# docker ps # 再次查看 没有这个容器了CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES常用其他命令后台启动docker1234docker run -d 镜像名# 用docker ps 查看的时候 发现停止了# 后台运行，docker发现前台没有，容器启动后，发现自己没有提供服务，会立刻停止12345678Last login: Wed Jun 17 19:47:35 2020[root@192 ~]# systemctl start docker # 关机后重启了，需要启动docker[root@192 ~]# docker run -d centos # 运行8ce188e5fee31c2fac93c0a405ee1a95c38dbc50cb47c35b19c0039c27558ded[root@192 ~]# docker ps -a # 查看正在运行的CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8ce188e5fee3 centos \"/bin/bash\" 19 seconds ago Exited (0) 18 seconds ago tender_dirac7b1a7dd10ea4 centos \"/bin/bash\" 8 hours ago Exited (0) 8 hours ago fervent_mirzakhani查看日志12docker logsdocker logs -f -t --tail n 【id】123456789101112131415161718[root@192 ~]# docker logs --helpUsage: docker logs [OPTIONS] CONTAINERFetch the logs of a containerOptions: --details Show extra details provided to logs -f, --follow Follow log output --since string Show logs since timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes) --tail string Number of lines to show from the end of the logs (default \"all\") -t, --timestamps Show timestamps # 时间戳 --until string Show logs before a timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes)1whiel true;do echo shenzai;sleep123456789101112131415161718192021222324252627282930313233343536# 运行一个[root@192 ~]# docker run -it centos /bin/bash[root@c2887d35c71d /]# [root@192 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc2887d35c71d centos \"/bin/bash\" 57 seconds ago Up 56 seconds vigorous_kare# 查看日志，由于没有运行脚本，所以啥也没显示[root@192 ~]# docker logs -f -t --tail 10 c2887d35c71d^C # ctrl+c退出# 运行centos里面加个脚本[root@192 ~]# docker run -d centos /bin/sh -c \"while true;do echo shenzai;sleep 1;done\"cb6d7fbc3f27a064137d58282de97b97365dea2705211ebfbad642079cc1b388[root@192 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMEScb6d7fbc3f27 centos \"/bin/sh -c 'while t…\" 7 seconds ago Up 6 seconds dreamy_almeidac2887d35c71d centos \"/bin/bash\" 3 minutes ago Up 3 minutes vigorous_kare# 查看日志 发现隔一秒打印一条[root@192 ~]# docker logs -f -t --tail 10 cb6d7fbc3f272020-06-17T12:02:11.293765084Z shenzai2020-06-17T12:02:12.297675608Z shenzai2020-06-17T12:02:13.301845582Z shenzai2020-06-17T12:02:14.304800996Z shenzai2020-06-17T12:02:15.307130238Z shenzai2020-06-17T12:02:16.310574235Z shenzai2020-06-17T12:02:17.312946923Z shenzai2020-06-17T12:02:18.314841295Z shenzai2020-06-17T12:02:19.317021705Z shenzai2020-06-17T12:02:20.319670013Z shenzai2020-06-17T12:02:21.322651649Z shenzai2020-06-17T12:02:22.325466918Z shenzai2020-06-17T12:02:23.327984704Z shenzai2020-06-17T12:02:24.329656919Z shenzai查看正在运行的容器信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230[root@192 ~]# docker inspect cb6d7fbc3f27[ &#123; # 容器的完整id \"Id\": \"cb6d7fbc3f27a064137d58282de97b97365dea2705211ebfbad642079cc1b388\", # 创建时间 \"Created\": \"2020-06-17T12:00:50.706906186Z\", # 脚本位置 \"Path\": \"/bin/sh\", # 运行的脚本 \"Args\": [ \"-c\", \"while true;do echo shenzai;sleep 1;done\" ], \"State\": &#123; \"Status\": \"running\", # 状态，正在运行 \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 1909, # 父进程id \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2020-06-17T12:00:51.093617477Z\", \"FinishedAt\": \"0001-01-01T00:00:00Z\" &#125;, # 来源镜像 \"Image\": \"sha256:831691599b88ad6cc2a4abbd0e89661a121aff14cfa289ad840fd3946f274f1f\", \"ResolvConfPath\": \"/var/lib/docker/containers/cb6d7fbc3f27a064137d58282de97b97365dea2705211ebfbad642079cc1b388/resolv.conf\", \"HostnamePath\": \"/var/lib/docker/containers/cb6d7fbc3f27a064137d58282de97b97365dea2705211ebfbad642079cc1b388/hostname\", \"HostsPath\": \"/var/lib/docker/containers/cb6d7fbc3f27a064137d58282de97b97365dea2705211ebfbad642079cc1b388/hosts\", \"LogPath\": \"/var/lib/docker/containers/cb6d7fbc3f27a064137d58282de97b97365dea2705211ebfbad642079cc1b388/cb6d7fbc3f27a064137d58282de97b97365dea2705211ebfbad642079cc1b388-json.log\", \"Name\": \"/dreamy_almeida\", \"RestartCount\": 0, \"Driver\": \"overlay2\", \"Platform\": \"linux\", \"MountLabel\": \"\", \"ProcessLabel\": \"\", \"AppArmorProfile\": \"\", \"ExecIDs\": null, # 主机配置 \"HostConfig\": &#123; \"Binds\": null, \"ContainerIDFile\": \"\", \"LogConfig\": &#123; \"Type\": \"json-file\", \"Config\": &#123;&#125; &#125;, \"NetworkMode\": \"default\", \"PortBindings\": &#123;&#125;, \"RestartPolicy\": &#123; \"Name\": \"no\", \"MaximumRetryCount\": 0 &#125;, \"AutoRemove\": false, \"VolumeDriver\": \"\", \"VolumesFrom\": null, \"CapAdd\": null, \"CapDrop\": null, \"Capabilities\": null, \"Dns\": [], \"DnsOptions\": [], \"DnsSearch\": [], \"ExtraHosts\": null, \"GroupAdd\": null, \"IpcMode\": \"private\", \"Cgroup\": \"\", \"Links\": null, \"OomScoreAdj\": 0, \"PidMode\": \"\", \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"SecurityOpt\": null, \"UTSMode\": \"\", \"UsernsMode\": \"\", \"ShmSize\": 67108864, \"Runtime\": \"runc\", \"ConsoleSize\": [ 0, 0 ], \"Isolation\": \"\", \"CpuShares\": 0, \"Memory\": 0, \"NanoCpus\": 0, \"CgroupParent\": \"\", \"BlkioWeight\": 0, \"BlkioWeightDevice\": [], \"BlkioDeviceReadBps\": null, \"BlkioDeviceWriteBps\": null, \"BlkioDeviceReadIOps\": null, \"BlkioDeviceWriteIOps\": null, \"CpuPeriod\": 0, \"CpuQuota\": 0, \"CpuRealtimePeriod\": 0, \"CpuRealtimeRuntime\": 0, \"CpusetCpus\": \"\", \"CpusetMems\": \"\", \"Devices\": [], \"DeviceCgroupRules\": null, \"DeviceRequests\": null, \"KernelMemory\": 0, \"KernelMemoryTCP\": 0, \"MemoryReservation\": 0, \"MemorySwap\": 0, \"MemorySwappiness\": null, \"OomKillDisable\": false, \"PidsLimit\": null, \"Ulimits\": null, \"CpuCount\": 0, \"CpuPercent\": 0, \"IOMaximumIOps\": 0, \"IOMaximumBandwidth\": 0, \"MaskedPaths\": [ \"/proc/asound\", \"/proc/acpi\", \"/proc/kcore\", \"/proc/keys\", \"/proc/latency_stats\", \"/proc/timer_list\", \"/proc/timer_stats\", \"/proc/sched_debug\", \"/proc/scsi\", \"/sys/firmware\" ], \"ReadonlyPaths\": [ \"/proc/bus\", \"/proc/fs\", \"/proc/irq\", \"/proc/sys\", \"/proc/sysrq-trigger\" ] &#125;, # 其他配置 \"GraphDriver\": &#123; \"Data\": &#123; \"LowerDir\": \"/var/lib/docker/overlay2/3675586ebbd79cd72d2562a90c9380627a331c563724c0dac091f92600af4907-init/diff:/var/lib/docker/overlay2/7f79322e0f58d651a84a555dadd83d92537788172525945d3f538dd95dce336c/diff\", \"MergedDir\": \"/var/lib/docker/overlay2/3675586ebbd79cd72d2562a90c9380627a331c563724c0dac091f92600af4907/merged\", \"UpperDir\": \"/var/lib/docker/overlay2/3675586ebbd79cd72d2562a90c9380627a331c563724c0dac091f92600af4907/diff\", \"WorkDir\": \"/var/lib/docker/overlay2/3675586ebbd79cd72d2562a90c9380627a331c563724c0dac091f92600af4907/work\" &#125;, \"Name\": \"overlay2\" &#125;, \"Mounts\": [], # 挂载 # 基本配置 \"Config\": &#123; \"Hostname\": \"cb6d7fbc3f27\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], # 基本环境变量，这里没有Java # 基本命令 \"Cmd\": [ \"/bin/sh\", \"-c\", \"while true;do echo shenzai;sleep 1;done\" ], \"Image\": \"centos\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": &#123; \"org.label-schema.build-date\": \"20200611\", \"org.label-schema.license\": \"GPLv2\", \"org.label-schema.name\": \"CentOS Base Image\", \"org.label-schema.schema-version\": \"1.0\", \"org.label-schema.vendor\": \"CentOS\" &#125; &#125;, # 网卡，比如现在用的是桥接的网卡 \"NetworkSettings\": &#123; \"Bridge\": \"\", \"SandboxID\": \"4d701985d7e77aa153790b697b2f38a61e20555c224b7675e4bf650b82799882\", \"HairpinMode\": false, \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"Ports\": &#123;&#125;, \"SandboxKey\": \"/var/run/docker/netns/4d701985d7e7\", \"SecondaryIPAddresses\": null, \"SecondaryIPv6Addresses\": null, \"EndpointID\": \"8a6c71e2bafb19ca7dfd85445ccc4bef6d17467360a243d624089e676a24a018\", \"Gateway\": \"172.17.0.1\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"172.17.0.3\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"MacAddress\": \"02:42:ac:11:00:03\", \"Networks\": &#123; \"bridge\": &#123; \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"22b0fd2290ccbc4e066a75d3f01bd8bf32ee4352c5bbcfc9f911287219219571\", \"EndpointID\": \"8a6c71e2bafb19ca7dfd85445ccc4bef6d17467360a243d624089e676a24a018\", \"Gateway\": \"172.17.0.1\", \"IPAddress\": \"172.17.0.3\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:11:00:03\", \"DriverOpts\": null &#125; &#125; &#125; &#125;]123# 停止正在疯狂输出的那个容器[root@192 ~]# docker stop cb6d7fbc3f27cb6d7fbc3f27进入当前正在运行的容器12345678910111213141516171819202122232425262728# 我们通常容器都是使用后台方式运行的edocker exec -it 容器id bashSHELL# 测试[root@192 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESc2887d35c71d centos \"/bin/bash\" 35 minutes ago Up 35 minutes vigorous_kare[root@192 ~]# docker exec -it c2887d35c71d /bin/bash[root@c2887d35c71d /]# lsbin etc lib lost+found mnt proc run srv tmp vardev home lib64 media opt root sbin sys usr[root@c2887d35c71d /]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 0 11:57 pts/0 00:00:00 /bin/bashroot 14 0 0 12:32 pts/1 00:00:00 /bin/bashroot 28 14 0 12:32 pts/1 00:00:00 ps -ef[root@c2887d35c71d /]# c2887d35c71d[root@c2887d35c71d /]# exitexit# 方式二[root@192 ~]# docker attach c2887d35c71d[root@c2887d35c71d /]# # 区别# docker exec # 进入容器后开启一个新的终端，可以在里面操作(常用)# docker attach 进入容器正在执行的终端，不会启动新的进程从容器内拷贝文件到主机上123456789101112131415161718192021222324252627282930313233343536373839404142434445# 运行[root@192 ~]# docker run -it centos# ctrl P Q 不关闭退出，查看[root@0569081aa89c /]# [root@192 ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0569081aa89c centos \"/bin/bash\" 19 seconds ago Up 19 seconds hopeful_chebyshev# 查看主机home下无文件[root@192 ~]# cd /home[root@192 home]# ls# 进入正在运行的容器[root@192 home]# docker attach 0569081aa89c# 进入容器home目录[root@0569081aa89c /]# cd /home# 在目录中创建java文件[root@0569081aa89c home]# touch test.java# 退出并停止容器[root@0569081aa89c home]# exitexit# 查看现在运行的容器[root@192 home]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES# 容器虽然被停止，但是数据都会保留[root@192 home]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0569081aa89c centos \"/bin/bash\" 3 minutes ago Exited (0) 8 seconds ago hopeful_chebyshevf589e5684a01 centos \"/bin/bash\" 44 minutes ago Exited (0) 44 minutes ago cranky_easleycb6d7fbc3f27 centos \"/bin/sh -c 'while t…\" 54 minutes ago Exited (137) 42 minutes ago dreamy_almeidac2887d35c71d centos \"/bin/bash\" 58 minutes ago Exited (127) 16 minutes ago vigorous_kare8ce188e5fee3 centos \"/bin/bash\" About an hour ago Exited (0) About an hour ago tender_dirac7b1a7dd10ea4 centos \"/bin/bash\" 9 hours ago Exited (0) 9 hours ago fervent_mirzakhani# 容器数据拷贝到主机[root@192 home]# docker cp 0569081aa89c:/home/test.java /home[root@192 home]# lstest.java# 拷贝是一个手动过程，未来我们使用 -v 卷的技术，可以实现自动同步 /home /home查看内容占用1docker stats小结12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788[root@192 home]# docker --helpUsage: docker [OPTIONS] COMMANDA self-sufficient runtime for containersOptions: --config string Location of client config files (default \"/root/.docker\") -c, --context string Name of the context to use to connect to the daemon (overrides DOCKER_HOST env var and default context set with \"docker context use\") -D, --debug Enable debug mode -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (\"debug\"|\"info\"|\"warn\"|\"error\"|\"fatal\") (default \"info\") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default \"/root/.docker/ca.pem\") --tlscert string Path to TLS certificate file (default \"/root/.docker/cert.pem\") --tlskey string Path to TLS key file (default \"/root/.docker/key.pem\") --tlsverify Use TLS and verify the remote -v, --version Print version information and quitManagement Commands: builder Manage builds config Manage Docker configs container Manage containers context Manage contexts engine Manage the docker engine image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker trust Manage trust on Docker images volume Manage volumesCommands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes to files or directories on a container's filesystem events Get real time events from the server exec Run a command in a running container export Export a container's filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codes部署实践部署Nginx1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556# 官网搜索nginx，可以看到帮助文档# 下载镜像[root@192 home]# docker pull nginxUsing default tag: latestlatest: Pulling from library/nginx8559a31e96f4: Pull complete 8d69e59170f7: Pull complete 3f9f1ec1d262: Pull complete d1f5ff4f210d: Pull complete 1e22bfa8652e: Pull complete Digest: sha256:21f32f6c08406306d822a0e6e8b7dc81f53f336570e852e25fbe1e3e3d0d0133Status: Downloaded newer image for nginx:latestdocker.io/library/nginx:latest# 查看镜像[root@192 home]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos latest 831691599b88 13 hours ago 215MBnginx latest 2622e6cca7eb 7 days ago 132MB# 运行测试# -d 后台运行，--name 命名，-p 暴露端口，3344服务器、宿主机的端口，容器内部端口[root@192 home]# docker run -d --name nginx01 -p:3344:80 nginx38dbf7bdcaef232d269b7184d91e44e06087181b5ee929494e177ad526810fa8[root@192 home]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES38dbf7bdcaef nginx \"/docker-entrypoint.…\" 7 seconds ago Up 6 seconds 0.0.0.0:3344-&gt;80/tcp nginx01# 使用3344可以访问成功[root@192 home]# curl localhost:3344&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Welcome to nginx!&lt;/title&gt;&lt;style&gt; body &#123; width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;&lt;p&gt;If you see this page, the nginx web server is successfully installed andworking. Further configuration is required.&lt;/p&gt;&lt;p&gt;For online documentation and support please refer to&lt;a href=\"http://nginx.org/\"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;Commercial support is available at&lt;a href=\"http://nginx.com/\"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;端口暴露可以公网访问找到服务器地址浏览器输入 192.168.147.132:3344/123456789101112131415161718192021222324[root@192 home]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES38dbf7bdcaef nginx \"/docker-entrypoint.…\" 21 minutes ago Up 21 minutes 0.0.0.0:3344-&gt;80/tcp nginx01# 进入容器[root@192 home]# docker exec -it nginx01 /bin/bash# 查一下nginx在哪root@38dbf7bdcaef:/# whereis nginxnginx: /usr/sbin/nginx /usr/lib/nginx /etc/nginx /usr/share/nginx# 到这个目录root@38dbf7bdcaef:/# cd /etc/nginxroot@38dbf7bdcaef:/etc/nginx# lsconf.d koi-utf mime.types nginx.conf uwsgi_paramsfastcgi_params koi-win modules scgi_params win-utf# 退出root@38dbf7bdcaef:/etc/nginx# exitexit# 停止[root@192 home]# docker stop 38dbf7bdcaef38dbf7bdcaef再次刷新网页，服务关闭思考问题：每次改动nginx配置文件，都需要进入容器内部，十分麻烦，要是可以在容器外部提供一个映射路径，达到在容器修改文件名，容器内部就可以自动修改？-v 数据卷技术！部署tomcat在docker hub上查看版本号和使用方法官方文档一定要翻烂，超多版本，我的天呐~官方方法123456789docker run -it --rm tomcat:9.0# docker run 可以不用pull，能自动下载# -it 直接进去运行# --rm 是什么意思？入门的意思？# 我们之前的启动都是后台，停止了容器之后，容器还是可以查到# 写了--rm，类似阅后即焚模式，用完即删除，这种通常用来测试# 最后冒号查好的版本号ctrl+c退出1docker ps -a可以看到并没有tomcat，印证阅后即焚模式，容器会删除，镜像不会删除平时不建议这样搞正常方法1docker pull tomcat:9.0 # 之前下过了，应该不用下了，这里老师讲错了12# 启动运行，应该加上版本号docker run -d -p 3355:8080 --name tomcat01 tomcat12# 进入容器docker exec -it tomcat01 /bin/bash发现问题linux命令少了没有webapps这是阿里云镜像的原因：默认使用最小镜像，所有不必要的都剔除了，保证最小可运行环境再次找到结构在浏览器中输入：http://192.168.147.132:3355/思考问题：我们以后部署项目，如果每次都要进入容器是不是身份麻烦？我要是可以在容器外部提供一个映射路径，webapps，我们在外部放置项目，就自动同步到内部就好了！docker容器 tomcat+网站docker mysql部署es+kibana123456789# es 暴露的端口很多# es 十分耗内存# es 的数据一般需要放置到安全目录！挂载# 启动 elasticsearch$ docker run -d --name elasticsearch01 -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" elasticsearch:7.6.2# 查看内存占用情况docker stats12# 先感觉stop一下docker stop ba18713ca53612# 通过 -e 限制内存$ docker run -d --name elasticsearch02 -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=“-Xms64m -Xmx512m” elasticsearch:7.6.2没成功啊，SEI能告诉我为啥！！1docker run -d --name elasticsearch02 -p 9200:9200 -p 9300:9300 -e \"discovery.type=single-node\" -e ES_JAVA_OPTS=\"-Xms64m -Xmx512m\" elasticsearch:7.6.2百度答案:设置启动内存更小:ES_JAVA_OPTS=-Xms64m -Xmx512m引号提前试试原因是引号！！你没觉得怪怪的嘛此时查看stats，发现内存占用在控制范围内ctrl + C退出，记得stop思考：用kibana链接elasticsearch可视化portainer(先用这个)Rancher(CI/CD时用)portainerDocker图像化界面管理工具，提供一个后台面板供我们操作！1docker run -d -p 8088:9000 --restart=always -v /var/run/docker.sock:/var/run/docker --privileged=true portainer/portainer访问外网8088用户名密码【中午吃饭重连了一下，失败，不知道发生了啥】【平时不会用这个，好吧，先往下】Docker镜像原理UnionFS 联合文件系统bootfs：boot file systemrootfs：root file systemDocker镜像都是只读的，当容器启动时，一个新的可写层被加到镜像的顶部，这一层就是我们通常说的容器层，容器层之下的都叫镜像层commit提交镜像12docker commit # 提交容器成为一个新的副本docker commit -m=\"提交的描述信息\" -a=\"作者\" 容器id 目标镜像名：[TAG]12docker imagesdocker run -it -p 8080:8080 tomcat这是一个前台程序将webapps.dist里面所有的文件拷贝到webapps里面，其中-r必须有，表示目录递归拷贝1docker commit -a=\"paidaxing\" -m=\"add webapps app\" 当前容器的id tomcat02:1.0发现新的版本，比之前的大了一些，因为里面记录了我们的改动如果想保存当前容器的状态，可以通过commit提交，获得一个镜像好比我们以前学习VM的时候的快照到这里算是入门了接下来三个部分是docker的精髓容器数据卷什么是容器卷docker是要将应用和环境打包成一个镜像这样，数据就不应该在容器中，否则容器删除，数据就会丢失，这就是删库跑路故容器之间要有一个数据共享技术在Docker容器中产生的数据，同步到本地，这就是卷技术本质上是一个目录挂载，将容器内的目录挂载到虚拟机上目的：容器的持久化和同步操作容器间可以数据共享使用数据卷方式一：直接使用命令来挂载1234docker run -it -v -p# -it 交互式进入# -v volume卷技术# -p 主机端口新开一个窗口1docker inspect 容器id找到挂载信息Mounts测试容器停止后，修改主机文件，再启动容器的时候，数据同样改变双向同步实战安装mysqlMySQL的数据持久化命令12345678910111213docker search mysql# 拉取docker pull mysql:5.7# 挂载docker run -d -p 3310:3306 -v /home/mysql/conf:/etc/mysql/conf.d -v /home/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 --name mysql01 mysql5.7-d 后台运行-p 端口映射-v 卷挂载-e 环境配置 安装启动mysql需要配置密码--name 容器名字链接测试：打开SQLyog点 测试链接点 链接具名和匿名挂载DockerFile使用来构建docker镜像的文件1yum install vim # 编辑文件的，没有装一下安装完之后就可以运行这个命令了12345678910# 镜像是一层一层的，脚本是一行一行的# 指令都是大写的# 这里的每个命令可以理解为镜像的一层FROM centosVOLUME [\"volume01\",\"volume02\"] # 再创建镜像的时候就挂载出来CMD echo \"---end---\"CMD /bin/bash想保存并退出Wesley.:shift 加 冒号123cat dockerfile1docker build -f dockerfile1 -t padaxing/centos:1.0 . # 最后的点很重要 镜像名不能有/1docker images启动生成的镜像在容器内部创建一个文件查看Mounts，Source对应容器外目录，匿名挂载卷测试一下，在container volume01下生成文件在主机挂载路径下，也同样生成多个容器数据共享看一下有啥images启动docker01，用之前建的padaxing/centos 1.0 镜像1docker run -it --name docker01 padaxing/centos:1.0 # 1.0必须写当前这个ctrl+p+q不停止退出依次启动docker02、docker031docker run -it --name docker02 --volumes-from docker01 padaxing/centos:1.0docker02继承docker01的volumes可以验证，在docker01下加一个数据，在docker02下也会出现创建docker03，同样继承docker011docker run -it --name docker03 --volumes-from docker01 padaxing/centos:1.0在docker03的volume01下建立文件，在docker01的volume01下同样也有即通过–volumes-from 可以实现不同容器间的数据共享删除docker01，数据还在1docker rm -f可以看到，删除docker01，进入docker02，数据依然在结论：容器之间配置信息的传递，数据卷容器的生命周期一直持续到没有容器使用位置但是如果持久化到了本地，即使所有容器删除了，本地数据是不会删除的DockerFile是用来构建docker镜像的文件，可以理解为命令参数脚本构建步骤：编写一个dockerfile文件docker build 构建成为一个镜像docker run运行镜像docker push 发布镜像（DockerHub、阿里云镜像仓库 私有/共有）这个写一个项目时一样的官方DockerFile示例看一下官方的DockerFile可以看到官方镜像都是基础包，很多功能没有，我们通常会自己搭建自己的镜像官方既然可以制作镜像，我们亦可以DockerFile基础知识每个指令都必须是大写字母按照从上到下顺序执行#表示注释每一个指令都会创建体检一个新的镜像层，并提交docker是面向开发的，我们以后要发布项目，做镜像，就要编写dockerfile文件，这个文件十分简单！Docker镜像逐渐成为企业的交付标准，必须掌握！DockerFile命令12345678910111213FROM # 基础镜像 比如centosMAINTAINER # 镜像是谁写的 姓名+邮箱RUN # 镜像构建时需要运行的命令ADD # 添加，比如添加一个tomcat压缩包WORKDIR # 镜像的工作目录VOLUME # 挂载的目录EXPOSE # 指定暴露端口，跟-p一个道理RUN # 最终要运行的CMD # 指定这个容器启动的时候要运行的命令，只有最后一个会生效，而且可被替代ENTRYPOINT # 指定这个容器启动的时候要运行的命令，可以追加命令ONBUILD # 当构建一个被继承Dockerfile 这个时候运行ONBUILD指定，触发指令COPY # 将文件拷贝到镜像中ENV # 构建的时候设置环境变量实战构建自己的centosDocker Hub中99%的镜像都是从FROM scratch开始的添加centos7的压缩包1234567891011# 创建一个自己的centos# 进入home目录cd /home# 创建一个目录，之后的东西都保存到这里mkdir dockerfile# 进入这个目录cd dockerfile/# 创建一个dockerfile，名字叫mydockerfilevim mydockerfile-centosxshell新开一个界面12345# 官方默认centosdocker run -it centospwd # 官方默认有pwd命令vim # 官方默认没有vim命令ifconfig # 官方默认没有ifconfig命令回到mydockerfile123456789101112131415# 下面给官方centos加上自定义的内容FROM centosMAINTAINER padaxing&lt;010301200@hai.com&gt;ENV MYPATH /usr/localWORKDIR $MYPATHRUN yum -y install vimRUN yum -y install net-toolsEXPOSE 80CMD echo $MYPATHCMD echo \"---end---\"CMD /bin/bashESC, shif + : 输入wq保存并退出如果写错了需要修改、12vim mydockerfile-centos# 进入之后按i或者INSERT键即可修改下面通过这个这个文件创建镜像1docker build -f dockerfile-centos -t mycentos:0.1 .依次执行命令最终返回Successfully表示成功1234docker run -it mycentos:0.1 # 版本号必须写，不然他会去找最新的pwdvimifconfig这时可以看到这些功能都有了可以通过查看docker构建历史可以看到当前这个镜像是怎么一步一步构建起来的我们平时拿到一个镜像也可以通过这个方法研究一下他是怎么做的CMD与ENTRYPOINT12FROM centosCMD [\"ls\",\"-a\"] # 启动centos展示目录测试ENTRYPOINTrun的时候可以直接加命令Docker中许多命令都十分相似，我们需要了解他们的区别，最好的方式就是这样对比测试","categories":[{"name":"容器化技术","slug":"容器化技术","permalink":"https://me.obey.fun/categories/容器化技术/"},{"name":"docker","slug":"容器化技术/docker","permalink":"https://me.obey.fun/categories/容器化技术/docker/"}],"tags":[{"name":"集装箱","slug":"集装箱","permalink":"https://me.obey.fun/tags/集装箱/"},{"name":"容器化部署","slug":"容器化部署","permalink":"https://me.obey.fun/tags/容器化部署/"}],"keywords":[{"name":"容器化技术","slug":"容器化技术","permalink":"https://me.obey.fun/categories/容器化技术/"},{"name":"docker","slug":"容器化技术/docker","permalink":"https://me.obey.fun/categories/容器化技术/docker/"}]},{"title":"RocketMQ高级特性","slug":"RocketMQ高级特性","date":"2020-06-15T12:58:23.000Z","updated":"2020-06-17T02:13:46.000Z","comments":true,"path":"RocketMQ高级特性.html","link":"","permalink":"https://me.obey.fun/RocketMQ高级特性.html","excerpt":"","text":"高级功能消息存储分布式队列因为有高可靠性的要求，所以数据要进行持久化存储。消息生成者发送消息MQ收到消息，将消息进行持久化，在存储中新增一条记录返回ACK给生产者MQ push 消息给对应的消费者，然后等待消费者返回ACK如果消息消费者在指定时间内成功返回ack，那么MQ认为消息消费成功，在存储中删除消息，即执行第6步；如果MQ在指定时间内没有收到ACK，则认为消息消费失败，会尝试重新push消息,重复执行4、5、6步骤MQ删除消息存储介质关系型数据库DBApache下开源的另外一款MQ—ActiveMQ（默认采用的KahaDB做消息存储）可选用JDBC的方式来做消息持久化，通过简单的xml配置信息即可实现JDBC消息存储。由于，普通关系型数据库（如Mysql）在单表数据量达到千万级别的情况下，其IO读写性能往往会出现瓶颈。在可靠性方面，该种方案非常依赖DB，如果一旦DB出现故障，则MQ的消息就无法落盘存储会导致线上故障文件系统目前业界较为常用的几款产品（RocketMQ/Kafka/RabbitMQ）均采用的是消息刷盘至所部署虚拟机/物理机的文件系统来做持久化（刷盘一般可以分为异步刷盘和同步刷盘两种模式）。消息刷盘为消息存储提供了一种高效率、高可靠性和高性能的数据持久化方式。除非部署MQ机器本身或是本地磁盘挂了，否则一般是不会出现无法持久化的故障问题。性能对比文件系统&gt;关系型数据库DB消息的存储和发送消息存储磁盘如果使用得当，磁盘的速度完全可以匹配上网络 的数据传输速度。目前的高性能磁盘，顺序写速度可以达到600MB/s， 超过了一般网卡的传输速度。但是磁盘随机写的速度只有大概100KB/s，和顺序写的性能相差6000倍！因为有如此巨大的速度差别，好的消息队列系统会比普通的消息队列系统速度快多个数量级。RocketMQ的消息用顺序写,保证了消息存储的速度。消息发送Linux操作系统分为【用户态】和【内核态】，文件操作、网络操作需要涉及这两种形态的切换，免不了进行数据复制。一台服务器 把本机磁盘文件的内容发送到客户端，一般分为两个步骤：1）read；读取本地文件内容；2）write；将读取的内容通过网络发送出去。这两个看似简单的操作，实际进行了4 次数据复制，分别是：从磁盘复制数据到内核态内存；从内核态内存复 制到用户态内存；然后从用户态 内存复制到网络驱动的内核态内存；最后是从网络驱动的内核态内存复 制到网卡中进行传输。通过使用mmap的方式，可以省去向用户态的内存复制，提高速度。这种机制在Java中是通过MappedByteBuffer实现的RocketMQ充分利用了上述特性，也就是所谓的“零拷贝”技术，提高消息存盘和网络发送的速度。这里需要注意的是，采用MappedByteBuffer这种内存映射的方式有几个限制，其中之一是一次只能映射1.5~2G 的文件至用户态的虚拟内存，这也是为何RocketMQ默认设置单个CommitLog日志数据文件为1G的原因了消息存储结构RocketMQ消息的存储是由ConsumeQueue和CommitLog配合完成 的，消息真正的物理存储文件是CommitLog，ConsumeQueue是消息的逻辑队列，类似数据库的索引文件，存储的是指向物理存储的地址。每 个Topic下的每个Message Queue都有一个对应的ConsumeQueue文件。CommitLog：存储消息的元数据ConsumerQueue：存储消息在CommitLog的索引IndexFile：为了消息查询提供了一种通过key或时间区间来查询消息的方法，这种通过IndexFile来查找消息的方法不影响发送与消费消息的主流程刷盘机制RocketMQ的消息是存储到磁盘上的，这样既能保证断电后恢复， 又可以让存储的消息量超出内存的限制。RocketMQ为了提高性能，会尽可能地保证磁盘的顺序写。消息在通过Producer写入RocketMQ的时 候，有两种写磁盘方式，分布式同步刷盘和异步刷盘。同步刷盘在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写 成功的状态。异步刷盘在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入。配置同步刷盘还是异步刷盘，都是通过Broker配置文件里的flushDiskType 参数设置的，这个参数被配置成SYNC_FLUSH、ASYNC_FLUSH中的 一个。高可用性机制RocketMQ分布式集群是通过Master和Slave的配合达到高可用性的。Master和Slave的区别：在Broker的配置文件中，参数 brokerId的值为0表明这个Broker是Master，大于0表明这个Broker是 Slave，同时brokerRole参数也会说明这个Broker是Master还是Slave。Master角色的Broker支持读和写，Slave角色的Broker仅支持读，也就是 Producer只能和Master角色的Broker连接写入消息；Consumer可以连接 Master角色的Broker，也可以连接Slave角色的Broker来读取消息。消息消费高可用在Consumer的配置文件中，并不需要设置是从Master读还是从Slave 读，当Master不可用或者繁忙的时候，Consumer会被自动切换到从Slave 读。有了自动切换Consumer这种机制，当一个Master角色的机器出现故障后，Consumer仍然可以从Slave读取消息，不影响Consumer程序。这就达到了消费端的高可用性。消息发送高可用在创建Topic的时候，把Topic的多个Message Queue创建在多个Broker组上（相同Broker名称，不同 brokerId的机器组成一个Broker组），这样当一个Broker组的Master不可 用后，其他组的Master仍然可用，Producer仍然可以发送消息。 RocketMQ目前还不支持把Slave自动转成Master，如果机器资源不足， 需要把Slave转成Master，则要手动停止Slave角色的Broker，更改配置文 件，用新的配置文件启动Broker。消息主从复制如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式。同步复制同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态；在同步复制方式下，如果Master出故障， Slave上有全部的备份数据，容易恢复，但是同步复制会增大数据写入 延迟，降低系统吞吐量。异步复制异步复制方式是只要Master写成功 即可反馈给客户端写成功状态。在异步复制方式下，系统拥有较低的延迟和较高的吞吐量，但是如果Master出了故障，有些数据因为没有被写 入Slave，有可能会丢失；配置同步复制和异步复制是通过Broker配置文件里的brokerRole参数进行设置的，这个参数可以被设置成ASYNC_MASTER、 SYNC_MASTER、SLAVE三个值中的一个。总结实际应用中要结合业务场景，合理设置刷盘方式和主从复制方式， 尤其是SYNC_FLUSH方式，由于频繁地触发磁盘写动作，会明显降低 性能。通常情况下，应该把Master和Save配置成ASYNC_FLUSH的刷盘 方式，主从之间配置成SYNC_MASTER的复制方式，这样即使有一台 机器出故障，仍然能保证数据不丢，是个不错的选择。负载均衡Producer负载均衡Producer端，每个实例在发消息的时候，默认会轮询所有的message queue发送，以达到让消息平均落在不同的queue上。而由于queue可以散落在不同的broker，所以消息就发送到不同的broker下，如下图：图中箭头线条上的标号代表顺序，发布方会把第一条消息发送至 Queue 0，然后第二条消息发送至 Queue 1，以此类推。Consumer负载均衡集群模式在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。RocketMQ采用主动拉取的方式拉取并消费消息，在拉取的时候需要明确指定拉取哪一条message queue。而每当实例的数量有变更，都会触发一次所有实例的负载均衡，这时候会按照queue的数量和实例的数量平均分配queue给每个实例。默认的分配算法是AllocateMessageQueueAveragely，如下图：还有另外一种平均的算法是AllocateMessageQueueAveragelyByCircle，也是平均分摊每一条queue，只是以环状轮流分queue的形式，如下图：需要注意的是，集群模式下，queue都是只允许分配只一个实例，这是由于如果多个实例同时消费一个queue的消息，由于拉取哪些消息是consumer主动控制的，那样会导致同一个消息在不同的实例下被消费多次，所以算法上都是一个queue只分给一个consumer实例，一个consumer实例可以允许同时分到不同的queue。通过增加consumer实例去分摊queue的消费，可以起到水平扩展的消费能力的作用。而有实例下线的时候，会重新触发负载均衡，这时候原来分配到的queue将分配到其他实例上继续消费。但是如果consumer实例的数量比message queue的总数量还多的话，多出来的consumer实例将无法分到queue，也就无法消费到消息，也就无法起到分摊负载的作用了。所以需要控制让queue的总数量大于等于consumer的数量。广播模式由于广播模式下要求一条消息需要投递到一个消费组下面所有的消费者实例，所以也就没有消息被分摊消费的说法。在实现上，其中一个不同就是在consumer分配queue的时候，所有consumer都分到所有的queue。消息重试顺序消息的重试对于顺序消息，当消费者消费消息失败后，消息队列 RocketMQ 会自动不断进行消息重试（每次间隔时间为 1 秒），这时，应用会出现消息消费被阻塞的情况。因此，在使用顺序消息时，务必保证应用能够及时监控并处理消费失败的情况，避免阻塞现象的发生。无序消息的重试对于无序消息（普通、定时、延时、事务消息），当消费者消费消息失败时，您可以通过设置返回状态达到消息重试的结果。无序消息的重试只针对集群消费方式生效；广播方式不提供失败重试特性，即消费失败后，失败消息不再重试，继续消费新的消息。重试次数消息队列 RocketMQ 默认允许每条消息最多重试 16 次，每次重试的间隔时间如下：第几次重试与上次重试的间隔时间第几次重试与上次重试的间隔时间110 秒97 分钟230 秒108 分钟31 分钟119 分钟42 分钟1210 分钟53 分钟1320 分钟64 分钟1430 分钟75 分钟151 小时86 分钟162 小时如果消息重试 16 次后仍然失败，消息将不再投递。如果严格按照上述重试时间间隔计算，某条消息在一直消费失败的前提下，将会在接下来的 4 小时 46 分钟之内进行 16 次重试，超过这个时间范围消息将不再重试投递。注意： 一条消息无论重试多少次，这些重试消息的 Message ID 不会改变。配置方式消费失败后，重试配置方式集群消费方式下，消息消费失败后期望消息重试，需要在消息监听器接口的实现中明确进行配置（三种方式任选一种）：返回 Action.ReconsumeLater （推荐）返回 Null抛出异常12345678910111213public class MessageListenerImpl implements MessageListener &#123; @Override public Action consume(Message message, ConsumeContext context) &#123; //处理消息 doConsumeMessage(message); //方式1：返回 Action.ReconsumeLater，消息将重试 return Action.ReconsumeLater; //方式2：返回 null，消息将重试 return null; //方式3：直接抛出异常， 消息将重试 throw new RuntimeException(\"Consumer Message exceotion\"); &#125;&#125;消费失败后，不重试配置方式集群消费方式下，消息失败后期望消息不重试，需要捕获消费逻辑中可能抛出的异常，最终返回 Action.CommitMessage，此后这条消息将不会再重试。12345678910111213public class MessageListenerImpl implements MessageListener &#123; @Override public Action consume(Message message, ConsumeContext context) &#123; try &#123; doConsumeMessage(message); &#125; catch (Throwable e) &#123; //捕获消费逻辑中的所有异常，并返回 Action.CommitMessage; return Action.CommitMessage; &#125; //消息处理正常，直接返回 Action.CommitMessage; return Action.CommitMessage; &#125;&#125;自定义消息最大重试次数消息队列 RocketMQ 允许 Consumer 启动的时候设置最大重试次数，重试时间间隔将按照如下策略：最大重试次数小于等于 16 次，则重试时间间隔同上表描述。最大重试次数大于 16 次，超过 16 次的重试时间间隔均为每次 2 小时。1234Properties properties = new Properties();//配置对应 Group ID 的最大消息重试次数为 20 次properties.put(PropertyKeyConst.MaxReconsumeTimes,\"20\");Consumer consumer =ONSFactory.createConsumer(properties);注意：消息最大重试次数的设置对相同 Group ID 下的所有 Consumer 实例有效。如果只对相同 Group ID 下两个 Consumer 实例中的其中一个设置了 MaxReconsumeTimes，那么该配置对两个 Consumer 实例均生效。配置采用覆盖的方式生效，即最后启动的 Consumer 实例会覆盖之前的启动实例的配置获取消息重试次数消费者收到消息后，可按照如下方式获取消息的重试次数：12345678public class MessageListenerImpl implements MessageListener &#123; @Override public Action consume(Message message, ConsumeContext context) &#123; //获取消息的重试次数 System.out.println(message.getReconsumeTimes()); return Action.CommitMessage; &#125;&#125;死信队列当一条消息初次消费失败，消息队列 RocketMQ 会自动进行消息重试；达到最大重试次数后，若消费依然失败，则表明消费者在正常情况下无法正确地消费该消息，此时，消息队列 RocketMQ 不会立刻将消息丢弃，而是将其发送到该消费者对应的特殊队列中。在消息队列 RocketMQ 中，这种正常情况下无法被消费的消息称为死信消息（Dead-Letter Message），存储死信消息的特殊队列称为死信队列（Dead-Letter Queue）。死信特性死信消息具有以下特性不会再被消费者正常消费。有效期与正常消息相同，均为 3 天，3 天后会被自动删除。因此，请在死信消息产生后的 3 天内及时处理。死信队列具有以下特性：一个死信队列对应一个 Group ID， 而不是对应单个消费者实例。如果一个 Group ID 未产生死信消息，消息队列 RocketMQ 不会为其创建相应的死信队列。一个死信队列包含了对应 Group ID 产生的所有死信消息，不论该消息属于哪个 Topic。查看死信信息在控制台查询出现死信队列的主题信息在消息界面根据主题查询死信消息选择重新发送消息一条消息进入死信队列，意味着某些因素导致消费者无法正常消费该消息，因此，通常需要您对其进行特殊处理。排查可疑因素并解决问题后，可以在消息队列 RocketMQ 控制台重新发送该消息，让消费者重新消费一次。消费幂等消息队列 RocketMQ 消费者在接收到消息以后，有必要根据业务上的唯一 Key 对消息做幂等处理的必要性。消费幂等的必要性在互联网应用中，尤其在网络不稳定的情况下，消息队列 RocketMQ 的消息有可能会出现重复，这个重复简单可以概括为以下情况：发送时消息重复当一条消息已被成功发送到服务端并完成持久化，此时出现了网络闪断或者客户端宕机，导致服务端对客户端应答失败。 如果此时生产者意识到消息发送失败并尝试再次发送消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。投递时消息重复消息消费的场景下，消息已投递到消费者并完成业务处理，当客户端给服务端反馈应答的时候网络闪断。 为了保证消息至少被消费一次，消息队列 RocketMQ 的服务端将在网络恢复后再次尝试投递之前已被处理过的消息，消费者后续会收到两条内容相同并且 Message ID 也相同的消息。负载均衡时消息重复（包括但不限于网络抖动、Broker 重启以及订阅方应用重启）当消息队列 RocketMQ 的 Broker 或客户端重启、扩容或缩容时，会触发 Rebalance，此时消费者可能会收到重复消息。处理方式因为 Message ID 有可能出现冲突（重复）的情况，所以真正安全的幂等处理，不建议以 Message ID 作为处理依据。 最好的方式是以业务唯一标识作为幂等处理的关键依据，而业务的唯一标识可以通过消息 Key 进行设置：123Message message = new Message();message.setKey(\"ORDERID_100\");SendResult sendResult = producer.send(message);订阅方收到消息时可以根据消息的 Key 进行幂等处理：123456consumer.subscribe(\"ons_test\", \"*\", new MessageListener() &#123; public Action consume(Message message, ConsumeContext context) &#123; String key = message.getKey() // 根据业务唯一标识的 key 做幂等处理 &#125;&#125;);源码分析环境搭建依赖工具JDK ：1.8+MavenIntelliJ IDEA源码拉取从官方仓库 https://github.com/apache/rocketmq clone或者download源码。源码目录结构：broker: broker 模块（broke 启动进程）client ：消息客户端，包含消息生产者、消息消费者相关类common ：公共包dev ：开发者信息（非源代码）distribution ：部署实例文件夹（非源代码）example: RocketMQ 例代码filter ：消息过滤相关基础类filtersrv：消息过滤服务器实现相关类（Filter启动进程）logappender：日志实现相关类namesrv：NameServer实现相关类（NameServer启动进程）openmessageing：消息开放标准remoting：远程通信模块，给予Nettysrcutil：服务工具类store：消息存储实现相关类style：checkstyle相关实现test：测试相关类tools：工具类，监控命令相关实现类导入IDEA执行安装1clean install -Dmaven.test.skip=true调试创建conf配置文件夹,从distribution拷贝broker.conf和logback_broker.xml和logback_namesrv.xml启动NameServer展开namesrv模块，右键NamesrvStartup.java配置ROCKETMQ_HOME重新启动控制台打印结果1The Name Server boot success. serializeType=JSON启动Brokerbroker.conf配置文件内容1234567891011121314151617181920212223brokerClusterName = DefaultClusterbrokerName = broker-abrokerId = 0# namesrvAddr地址namesrvAddr=127.0.0.1:9876deleteWhen = 04fileReservedTime = 48brokerRole = ASYNC_MASTERflushDiskType = ASYNC_FLUSHautoCreateTopicEnable=true# 存储路径storePathRootDir=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir# commitLog路径storePathCommitLog=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\commitlog# 消息队列存储路径storePathConsumeQueue=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\consumequeue# 消息索引存储路径storePathIndex=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\index# checkpoint文件路径storeCheckpoint=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\checkpoint# abort文件存储路径abortFile=E:\\\\RocketMQ\\\\data\\\\rocketmq\\\\dataDir\\\\abort创建数据文件夹dataDir启动BrokerStartup,配置broker.conf和ROCKETMQ_HOME发送消息进入example模块的org.apache.rocketmq.example.quickstart指定Namesrv地址12DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.setNamesrvAddr(\"127.0.0.1:9876\");运行main方法，发送消息消费消息进入example模块的org.apache.rocketmq.example.quickstart指定Namesrv地址12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");consumer.setNamesrvAddr(\"127.0.0.1:9876\");运行main方法，消费消息NameServer架构设计消息中间件的设计思路一般是基于主题订阅发布的机制，消息生产者（Producer）发送某一个主题到消息服务器，消息服务器负责将消息持久化存储，消息消费者（Consumer）订阅该兴趣的主题，消息服务器根据订阅信息（路由信息）将消息推送到消费者（Push模式）或者消费者主动向消息服务器拉去（Pull模式），从而实现消息生产者与消息消费者解耦。为了避免消息服务器的单点故障导致的整个系统瘫痪，通常会部署多台消息服务器共同承担消息的存储。那消息生产者如何知道消息要发送到哪台消息服务器呢？如果某一台消息服务器宕机了，那么消息生产者如何在不重启服务情况下感知呢？NameServer就是为了解决以上问题设计的。Broker消息服务器在启动的时向所有NameServer注册，消息生产者（Producer）在发送消息时之前先从NameServer获取Broker服务器地址列表，然后根据负载均衡算法从列表中选择一台服务器进行发送。NameServer与每台Broker保持长连接，并间隔30S检测Broker是否存活，如果检测到Broker宕机，则从路由注册表中删除。但是路由变化不会马上通知消息生产者。这样设计的目的是为了降低NameServer实现的复杂度，在消息发送端提供容错机制保证消息发送的可用性。NameServer本身的高可用是通过部署多台NameServer来实现，但彼此之间不通讯，也就是NameServer服务器之间在某一个时刻的数据并不完全相同，但这对消息发送并不会造成任何影响，这也是NameServer设计的一个亮点，总之，RocketMQ设计追求简单高效。启动流程启动类：org.apache.rocketmq.namesrv.NamesrvStartup步骤一解析配置文件，填充NameServerConfig、NettyServerConfig属性值，并创建NamesrvController代码：NamesrvController#createNamesrvController12345678910111213141516171819202122232425262728293031323334//创建NamesrvConfigfinal NamesrvConfig namesrvConfig = new NamesrvConfig();//创建NettyServerConfigfinal NettyServerConfig nettyServerConfig = new NettyServerConfig();//设置启动端口号nettyServerConfig.setListenPort(9876);//解析启动-c参数if (commandLine.hasOption('c')) &#123; String file = commandLine.getOptionValue('c'); if (file != null) &#123; InputStream in = new BufferedInputStream(new FileInputStream(file)); properties = new Properties(); properties.load(in); MixAll.properties2Object(properties, namesrvConfig); MixAll.properties2Object(properties, nettyServerConfig); namesrvConfig.setConfigStorePath(file); System.out.printf(\"load config properties file OK, %s%n\", file); in.close(); &#125;&#125;//解析启动-p参数if (commandLine.hasOption('p')) &#123; InternalLogger console = InternalLoggerFactory.getLogger(LoggerName.NAMESRV_CONSOLE_NAME); MixAll.printObjectProperties(console, namesrvConfig); MixAll.printObjectProperties(console, nettyServerConfig); System.exit(0);&#125;//将启动参数填充到namesrvConfig,nettyServerConfigMixAll.properties2Object(ServerUtil.commandLine2Properties(commandLine), namesrvConfig);//创建NameServerControllerfinal NamesrvController controller = new NamesrvController(namesrvConfig, nettyServerConfig);NamesrvConfig属性123456private String rocketmqHome = System.getProperty(MixAll.ROCKETMQ_HOME_PROPERTY, System.getenv(MixAll.ROCKETMQ_HOME_ENV));private String kvConfigPath = System.getProperty(\"user.home\") + File.separator + \"namesrv\" + File.separator + \"kvConfig.json\";private String configStorePath = System.getProperty(\"user.home\") + File.separator + \"namesrv\" + File.separator + \"namesrv.properties\";private String productEnvName = \"center\";private boolean clusterTest = false;private boolean orderMessageEnable = false;rocketmqHome：rocketmq主目录kvConfig：NameServer存储KV配置属性的持久化路径configStorePath：nameServer默认配置文件路径orderMessageEnable：是否支持顺序消息NettyServerConfig属性1234567891011private int listenPort = 8888;private int serverWorkerThreads = 8;private int serverCallbackExecutorThreads = 0;private int serverSelectorThreads = 3;private int serverOnewaySemaphoreValue = 256;private int serverAsyncSemaphoreValue = 64;private int serverChannelMaxIdleTimeSeconds = 120;private int serverSocketSndBufSize = NettySystemConfig.socketSndbufSize;private int serverSocketRcvBufSize = NettySystemConfig.socketRcvbufSize;private boolean serverPooledByteBufAllocatorEnable = true;private boolean useEpollNativeSelector = false;listenPort：NameServer监听端口，该值默认会被初始化为9876serverWorkerThreads：Netty业务线程池线程个数serverCallbackExecutorThreads：Netty public任务线程池线程个数，Netty网络设计，根据业务类型会创建不同的线程池，比如处理消息发送、消息消费、心跳检测等。如果该业务类型未注册线程池，则由public线程池执行。serverSelectorThreads：IO线程池个数，主要是NameServer、Broker端解析请求、返回相应的线程个数，这类线程主要是处理网路请求的，解析请求包，然后转发到各个业务线程池完成具体的操作，然后将结果返回给调用方;serverOnewaySemaphoreValue：send oneway消息请求并发读（Broker端参数）;serverAsyncSemaphoreValue：异步消息发送最大并发度;serverChannelMaxIdleTimeSeconds ：网络连接最大的空闲时间，默认120s。serverSocketSndBufSize：网络socket发送缓冲区大小。serverSocketRcvBufSize： 网络接收端缓存区大小。serverPooledByteBufAllocatorEnable：ByteBuffer是否开启缓存;useEpollNativeSelector：是否启用Epoll IO模型。步骤二根据启动属性创建NamesrvController实例，并初始化该实例。NameServerController实例为NameServer核心控制器代码：NamesrvController#initialize12345678910111213141516171819202122232425public boolean initialize() &#123; //加载KV配置 this.kvConfigManager.load(); //创建NettyServer网络处理对象 this.remotingServer = new NettyRemotingServer(this.nettyServerConfig, this.brokerHousekeepingService); //开启定时任务:每隔10s扫描一次Broker,移除不活跃的Broker this.remotingExecutor = Executors.newFixedThreadPool(nettyServerConfig.getServerWorkerThreads(), new ThreadFactoryImpl(\"RemotingExecutorThread_\")); this.registerProcessor(); this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; NamesrvController.this.routeInfoManager.scanNotActiveBroker(); &#125; &#125;, 5, 10, TimeUnit.SECONDS); //开启定时任务:每隔10min打印一次KV配置 this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; NamesrvController.this.kvConfigManager.printAllPeriodically(); &#125; &#125;, 1, 10, TimeUnit.MINUTES); return true;&#125;步骤三在JVM进程关闭之前，先将线程池关闭，及时释放资源代码：NamesrvStartup#start123456789//注册JVM钩子函数代码Runtime.getRuntime().addShutdownHook(new ShutdownHookThread(log, new Callable&lt;Void&gt;() &#123; @Override public Void call() throws Exception &#123; //释放资源 controller.shutdown(); return null; &#125;&#125;));路由管理NameServer的主要作用是为消息的生产者和消息消费者提供关于主题Topic的路由信息，那么NameServer需要存储路由的基础信息，还要管理Broker节点，包括路由注册、路由删除等。路由元信息代码：RouteInfoManager12345private final HashMap&lt;String/* topic */, List&lt;QueueData&gt;&gt; topicQueueTable;private final HashMap&lt;String/* brokerName */, BrokerData&gt; brokerAddrTable;private final HashMap&lt;String/* clusterName */, Set&lt;String/* brokerName */&gt;&gt; clusterAddrTable;private final HashMap&lt;String/* brokerAddr */, BrokerLiveInfo&gt; brokerLiveTable;private final HashMap&lt;String/* brokerAddr */, List&lt;String&gt;/* Filter Server */&gt; filterServerTable;topicQueueTable：Topic消息队列路由信息，消息发送时根据路由表进行负载均衡brokerAddrTable：Broker基础信息，包括brokerName、所属集群名称、主备Broker地址clusterAddrTable：Broker集群信息，存储集群中所有Broker名称brokerLiveTable：Broker状态信息，NameServer每次收到心跳包是会替换该信息filterServerTable：Broker上的FilterServer列表，用于类模式消息过滤。RocketMQ基于定于发布机制，一个Topic拥有多个消息队列，一个Broker为每一个主题创建4个读队列和4个写队列。多个Broker组成一个集群，集群由相同的多台Broker组成Master-Slave架构，brokerId为0代表Master，大于0为Slave。BrokerLiveInfo中的lastUpdateTimestamp存储上次收到Broker心跳包的时间。路由注册发送心跳包RocketMQ路由注册是通过Broker与NameServer的心跳功能实现的。Broker启动时向集群中所有的NameServer发送心跳信息，每隔30s向集群中所有NameServer发送心跳包，NameServer收到心跳包时会更新brokerLiveTable缓存中BrokerLiveInfo的lastUpdataTimeStamp信息，然后NameServer每隔10s扫描brokerLiveTable，如果连续120S没有收到心跳包，NameServer将移除Broker的路由信息同时关闭Socket连接。代码：BrokerController#start123456789101112131415//注册Broker信息this.registerBrokerAll(true, false, true);//每隔30s上报Broker信息到NameServerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; try &#123; BrokerController.this.registerBrokerAll(true, false, brokerConfig.isForceRegister()); &#125; catch (Throwable e) &#123; log.error(\"registerBrokerAll Exception\", e); &#125; &#125;&#125;, 1000 * 10, Math.max(10000, Math.min(brokerConfig.getRegisterNameServerPeriod(), 60000)), TimeUnit.MILLISECONDS);代码：BrokerOuterAPI#registerBrokerAll1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//获得nameServer地址信息List&lt;String&gt; nameServerAddressList = this.remotingClient.getNameServerAddressList();//遍历所有nameserver列表if (nameServerAddressList != null &amp;&amp; nameServerAddressList.size() &gt; 0) &#123; //封装请求头 final RegisterBrokerRequestHeader requestHeader = new RegisterBrokerRequestHeader(); requestHeader.setBrokerAddr(brokerAddr); requestHeader.setBrokerId(brokerId); requestHeader.setBrokerName(brokerName); requestHeader.setClusterName(clusterName); requestHeader.setHaServerAddr(haServerAddr); requestHeader.setCompressed(compressed); //封装请求体 RegisterBrokerBody requestBody = new RegisterBrokerBody(); requestBody.setTopicConfigSerializeWrapper(topicConfigWrapper); requestBody.setFilterServerList(filterServerList); final byte[] body = requestBody.encode(compressed); final int bodyCrc32 = UtilAll.crc32(body); requestHeader.setBodyCrc32(bodyCrc32); final CountDownLatch countDownLatch = new CountDownLatch(nameServerAddressList.size()); for (final String namesrvAddr : nameServerAddressList) &#123; brokerOuterExecutor.execute(new Runnable() &#123; @Override public void run() &#123; try &#123; //分别向NameServer注册 RegisterBrokerResult result = registerBroker(namesrvAddr,oneway, timeoutMills,requestHeader,body); if (result != null) &#123; registerBrokerResultList.add(result); &#125; log.info(\"register broker[&#123;&#125;]to name server &#123;&#125; OK\", brokerId, namesrvAddr); &#125; catch (Exception e) &#123; log.warn(\"registerBroker Exception, &#123;&#125;\", namesrvAddr, e); &#125; finally &#123; countDownLatch.countDown(); &#125; &#125; &#125;); &#125; try &#123; countDownLatch.await(timeoutMills, TimeUnit.MILLISECONDS); &#125; catch (InterruptedException e) &#123; &#125;&#125;代码：BrokerOutAPI#registerBroker123456789if (oneway) &#123; try &#123; this.remotingClient.invokeOneway(namesrvAddr, request, timeoutMills); &#125; catch (RemotingTooMuchRequestException e) &#123; // Ignore &#125; return null;&#125;RemotingCommand response = this.remotingClient.invokeSync(namesrvAddr, request, timeoutMills);处理心跳包org.apache.rocketmq.namesrv.processor.DefaultRequestProcessor网路处理类解析请求类型，如果请求类型是为REGISTER_BROKER，则将请求转发到RouteInfoManager#regiesterBroker代码：DefaultRequestProcessor#processRequest123456789//判断是注册Broker信息case RequestCode.REGISTER_BROKER: Version brokerVersion = MQVersion.value2Version(request.getVersion()); if (brokerVersion.ordinal() &gt;= MQVersion.Version.V3_0_11.ordinal()) &#123; return this.registerBrokerWithFilterServer(ctx, request); &#125; else &#123; //注册Broker信息 return this.registerBroker(ctx, request); &#125;代码：DefaultRequestProcessor#registerBroker12345678910RegisterBrokerResult result = this.namesrvController.getRouteInfoManager().registerBroker( requestHeader.getClusterName(), requestHeader.getBrokerAddr(), requestHeader.getBrokerName(), requestHeader.getBrokerId(), requestHeader.getHaServerAddr(), topicConfigWrapper, null, ctx.channel());代码：RouteInfoManager#registerBroker维护路由信息123456789//加锁this.lock.writeLock().lockInterruptibly();//维护clusterAddrTableSet&lt;String&gt; brokerNames = this.clusterAddrTable.get(clusterName);if (null == brokerNames) &#123; brokerNames = new HashSet&lt;String&gt;(); this.clusterAddrTable.put(clusterName, brokerNames);&#125;brokerNames.add(brokerName);12345678910111213141516171819//维护brokerAddrTableBrokerData brokerData = this.brokerAddrTable.get(brokerName);//第一次注册,则创建brokerDataif (null == brokerData) &#123; registerFirst = true; brokerData = new BrokerData(clusterName, brokerName, new HashMap&lt;Long, String&gt;()); this.brokerAddrTable.put(brokerName, brokerData);&#125;//非第一次注册,更新BrokerMap&lt;Long, String&gt; brokerAddrsMap = brokerData.getBrokerAddrs();Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerAddrsMap.entrySet().iterator();while (it.hasNext()) &#123; Entry&lt;Long, String&gt; item = it.next(); if (null != brokerAddr &amp;&amp; brokerAddr.equals(item.getValue()) &amp;&amp; brokerId != item.getKey()) &#123; it.remove(); &#125;&#125;String oldAddr = brokerData.getBrokerAddrs().put(brokerId, brokerAddr);registerFirst = registerFirst || (null == oldAddr);123456789101112//维护topicQueueTableif (null != topicConfigWrapper &amp;&amp; MixAll.MASTER_ID == brokerId) &#123; if (this.isBrokerTopicConfigChanged(brokerAddr, topicConfigWrapper.getDataVersion()) || registerFirst) &#123; ConcurrentMap&lt;String, TopicConfig&gt; tcTable = topicConfigWrapper.getTopicConfigTable(); if (tcTable != null) &#123; for (Map.Entry&lt;String, TopicConfig&gt; entry : tcTable.entrySet()) &#123; this.createAndUpdateQueueData(brokerName, entry.getValue()); &#125; &#125; &#125;&#125;代码：RouteInfoManager#createAndUpdateQueueData123456789101112131415161718192021222324252627282930313233343536373839private void createAndUpdateQueueData(final String brokerName, final TopicConfig topicConfig) &#123; //创建QueueData QueueData queueData = new QueueData(); queueData.setBrokerName(brokerName); queueData.setWriteQueueNums(topicConfig.getWriteQueueNums()); queueData.setReadQueueNums(topicConfig.getReadQueueNums()); queueData.setPerm(topicConfig.getPerm()); queueData.setTopicSynFlag(topicConfig.getTopicSysFlag()); //获得topicQueueTable中队列集合 List&lt;QueueData&gt; queueDataList = this.topicQueueTable.get(topicConfig.getTopicName()); //topicQueueTable为空,则直接添加queueData到队列集合 if (null == queueDataList) &#123; queueDataList = new LinkedList&lt;QueueData&gt;(); queueDataList.add(queueData); this.topicQueueTable.put(topicConfig.getTopicName(), queueDataList); log.info(\"new topic registered, &#123;&#125; &#123;&#125;\", topicConfig.getTopicName(), queueData); &#125; else &#123; //判断是否是新的队列 boolean addNewOne = true; Iterator&lt;QueueData&gt; it = queueDataList.iterator(); while (it.hasNext()) &#123; QueueData qd = it.next(); //如果brokerName相同,代表不是新的队列 if (qd.getBrokerName().equals(brokerName)) &#123; if (qd.equals(queueData)) &#123; addNewOne = false; &#125; else &#123; log.info(\"topic changed, &#123;&#125; OLD: &#123;&#125; NEW: &#123;&#125;\", topicConfig.getTopicName(), qd, queueData); it.remove(); &#125; &#125; &#125; //如果是新的队列,则添加队列到queueDataList if (addNewOne) &#123; queueDataList.add(queueData); &#125; &#125;&#125;123456//维护brokerLiveTableBrokerLiveInfo prevBrokerLiveInfo = this.brokerLiveTable.put(brokerAddr,new BrokerLiveInfo( System.currentTimeMillis(), topicConfigWrapper.getDataVersion(), channel, haServerAddr));12345678910111213141516171819//维护filterServerListif (filterServerList != null) &#123; if (filterServerList.isEmpty()) &#123; this.filterServerTable.remove(brokerAddr); &#125; else &#123; this.filterServerTable.put(brokerAddr, filterServerList); &#125;&#125;if (MixAll.MASTER_ID != brokerId) &#123; String masterAddr = brokerData.getBrokerAddrs().get(MixAll.MASTER_ID); if (masterAddr != null) &#123; BrokerLiveInfo brokerLiveInfo = this.brokerLiveTable.get(masterAddr); if (brokerLiveInfo != null) &#123; result.setHaServerAddr(brokerLiveInfo.getHaServerAddr()); result.setMasterAddr(masterAddr); &#125; &#125;&#125;路由删除123456789101112131415161718192021**RocketMQ有两个触发点来删除路由信息**：* NameServer定期扫描brokerLiveTable检测上次心跳包与当前系统的时间差，如果时间超过120s，则需要移除broker。* Broker在正常关闭的情况下，会执行unregisterBroker指令这两种方式路由删除的方法都是一样的，就是从相关路由表中删除与该broker相关的信息。&lt;img src=&quot;https://tva3.sinaimg.cn/large/006MOU0zgy1gjp21pcl6kj30js0hg0tj.jpg&quot; alt=&quot;路由删除&quot; referrerpolicy=&quot;no-referrer&quot; /&gt;***代码：NamesrvController#initialize***```java//每隔10s扫描一次为活跃Brokerthis.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; NamesrvController.this.routeInfoManager.scanNotActiveBroker(); &#125;&#125;, 5, 10, TimeUnit.SECONDS);代码：RouteInfoManager#scanNotActiveBroker123456789101112131415161718public void scanNotActiveBroker() &#123; //获得brokerLiveTable Iterator&lt;Entry&lt;String, BrokerLiveInfo&gt;&gt; it = this.brokerLiveTable.entrySet().iterator(); //遍历brokerLiveTable while (it.hasNext()) &#123; Entry&lt;String, BrokerLiveInfo&gt; next = it.next(); long last = next.getValue().getLastUpdateTimestamp(); //如果收到心跳包的时间距当时时间是否超过120s if ((last + BROKER_CHANNEL_EXPIRED_TIME) &lt; System.currentTimeMillis()) &#123; //关闭连接 RemotingUtil.closeChannel(next.getValue().getChannel()); //移除broker it.remove(); //维护路由表 this.onChannelDestroy(next.getKey(), next.getValue().getChannel()); &#125; &#125;&#125;代码：RouteInfoManager#onChannelDestroy1234//申请写锁,根据brokerAddress从brokerLiveTable和filterServerTable移除this.lock.writeLock().lockInterruptibly();this.brokerLiveTable.remove(brokerAddrFound);this.filterServerTable.remove(brokerAddrFound);123456789101112131415161718192021222324252627282930//维护brokerAddrTableString brokerNameFound = null;boolean removeBrokerName = false;Iterator&lt;Entry&lt;String, BrokerData&gt;&gt; itBrokerAddrTable =this.brokerAddrTable.entrySet().iterator();//遍历brokerAddrTablewhile (itBrokerAddrTable.hasNext() &amp;&amp; (null == brokerNameFound)) &#123; BrokerData brokerData = itBrokerAddrTable.next().getValue(); //遍历broker地址 Iterator&lt;Entry&lt;Long, String&gt;&gt; it = brokerData.getBrokerAddrs().entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;Long, String&gt; entry = it.next(); Long brokerId = entry.getKey(); String brokerAddr = entry.getValue(); //根据broker地址移除brokerAddr if (brokerAddr.equals(brokerAddrFound)) &#123; brokerNameFound = brokerData.getBrokerName(); it.remove(); log.info(\"remove brokerAddr[&#123;&#125;, &#123;&#125;] from brokerAddrTable, because channel destroyed\", brokerId, brokerAddr); break; &#125; &#125; //如果当前主题只包含待移除的broker,则移除该topic if (brokerData.getBrokerAddrs().isEmpty()) &#123; removeBrokerName = true; itBrokerAddrTable.remove(); log.info(\"remove brokerName[&#123;&#125;] from brokerAddrTable, because channel destroyed\", brokerData.getBrokerName()); &#125;&#125;123456789101112131415161718192021222324252627//维护clusterAddrTableif (brokerNameFound != null &amp;&amp; removeBrokerName) &#123; Iterator&lt;Entry&lt;String, Set&lt;String&gt;&gt;&gt; it = this.clusterAddrTable.entrySet().iterator(); //遍历clusterAddrTable while (it.hasNext()) &#123; Entry&lt;String, Set&lt;String&gt;&gt; entry = it.next(); //获得集群名称 String clusterName = entry.getKey(); //获得集群中brokerName集合 Set&lt;String&gt; brokerNames = entry.getValue(); //从brokerNames中移除brokerNameFound boolean removed = brokerNames.remove(brokerNameFound); if (removed) &#123; log.info(\"remove brokerName[&#123;&#125;], clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed\", brokerNameFound, clusterName); if (brokerNames.isEmpty()) &#123; log.info(\"remove the clusterName[&#123;&#125;] from clusterAddrTable, because channel destroyed and no broker in this cluster\", clusterName); //如果集群中不包含任何broker,则移除该集群 it.remove(); &#125; break; &#125; &#125;&#125;123456789101112131415161718192021222324252627282930//维护topicQueueTable队列if (removeBrokerName) &#123; //遍历topicQueueTable Iterator&lt;Entry&lt;String, List&lt;QueueData&gt;&gt;&gt; itTopicQueueTable = this.topicQueueTable.entrySet().iterator(); while (itTopicQueueTable.hasNext()) &#123; Entry&lt;String, List&lt;QueueData&gt;&gt; entry = itTopicQueueTable.next(); //主题名称 String topic = entry.getKey(); //队列集合 List&lt;QueueData&gt; queueDataList = entry.getValue(); //遍历该主题队列 Iterator&lt;QueueData&gt; itQueueData = queueDataList.iterator(); while (itQueueData.hasNext()) &#123; //从队列中移除为活跃broker信息 QueueData queueData = itQueueData.next(); if (queueData.getBrokerName().equals(brokerNameFound)) &#123; itQueueData.remove(); log.info(\"remove topic[&#123;&#125; &#123;&#125;], from topicQueueTable, because channel destroyed\", topic, queueData); &#125; &#125; //如果该topic的队列为空,则移除该topic if (queueDataList.isEmpty()) &#123; itTopicQueueTable.remove(); log.info(\"remove topic[&#123;&#125;] all queue, from topicQueueTable, because channel destroyed\", topic); &#125; &#125;&#125;1234//释放写锁finally &#123; this.lock.writeLock().unlock();&#125;路由发现RocketMQ路由发现是非实时的，当Topic路由出现变化后，NameServer不会主动推送给客户端，而是由客户端定时拉取主题最新的路由。代码：DefaultRequestProcessor#getRouteInfoByTopic12345678910111213141516171819202122232425262728public RemotingCommand getRouteInfoByTopic(ChannelHandlerContext ctx, RemotingCommand request) throws RemotingCommandException &#123; final RemotingCommand response = RemotingCommand.createResponseCommand(null); final GetRouteInfoRequestHeader requestHeader = (GetRouteInfoRequestHeader) request.decodeCommandCustomHeader(GetRouteInfoRequestHeader.class); //调用RouteInfoManager的方法,从路由表topicQueueTable、brokerAddrTable、filterServerTable中分别填充TopicRouteData的List&lt;QueueData&gt;、List&lt;BrokerData&gt;、filterServer TopicRouteData topicRouteData = this.namesrvController.getRouteInfoManager().pickupTopicRouteData(requestHeader.getTopic()); //如果找到主题对应你的路由信息并且该主题为顺序消息，则从NameServer KVConfig中获取关于顺序消息相关的配置填充路由信息 if (topicRouteData != null) &#123; if (this.namesrvController.getNamesrvConfig().isOrderMessageEnable()) &#123; String orderTopicConf = this.namesrvController.getKvConfigManager().getKVConfig(NamesrvUtil.NAMESPACE_ORDER_TOPIC_CONFIG, requestHeader.getTopic()); topicRouteData.setOrderTopicConf(orderTopicConf); &#125; byte[] content = topicRouteData.encode(); response.setBody(content); response.setCode(ResponseCode.SUCCESS); response.setRemark(null); return response; &#125; response.setCode(ResponseCode.TOPIC_NOT_EXIST); response.setRemark(\"No topic route info in name server for the topic: \" + requestHeader.getTopic() + FAQUrl.suggestTodo(FAQUrl.APPLY_TOPIC_URL)); return response;&#125;小结Producer消息生产者的代码都在client模块中，相对于RocketMQ来讲，消息生产者就是客户端，也是消息的提供者。方法和属性主要方法介绍12345678910111213141516171819202122//创建主题void createTopic(final String key, final String newTopic, final int queueNum) throws MQClientException;//根据时间戳从队列中查找消息偏移量long searchOffset(final MessageQueue mq, final long timestamp)//查找消息队列中最大的偏移量long maxOffset(final MessageQueue mq) throws MQClientException;//查找消息队列中最小的偏移量long minOffset(final MessageQueue mq) //根据偏移量查找消息MessageExt viewMessage(final String offsetMsgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException;//根据条件查找消息QueryResult queryMessage(final String topic, final String key, final int maxNum, final long begin, final long end) throws MQClientException, InterruptedException;//根据消息ID和主题查找消息MessageExt viewMessage(String topic,String msgId) throws RemotingException, MQBrokerException, InterruptedException, MQClientException;12345678910111213141516171819202122232425262728293031323334353637383940414243//启动void start() throws MQClientException;//关闭void shutdown();//查找该主题下所有消息List&lt;MessageQueue&gt; fetchPublishMessageQueues(final String topic) throws MQClientException;//同步发送消息SendResult send(final Message msg) throws MQClientException, RemotingException, MQBrokerException, InterruptedException;//同步超时发送消息SendResult send(final Message msg, final long timeout) throws MQClientException, RemotingException, MQBrokerException, InterruptedException;//异步发送消息void send(final Message msg, final SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException;//异步超时发送消息void send(final Message msg, final SendCallback sendCallback, final long timeout) throws MQClientException, RemotingException, InterruptedException;//发送单向消息void sendOneway(final Message msg) throws MQClientException, RemotingException, InterruptedException;//选择指定队列同步发送消息SendResult send(final Message msg, final MessageQueue mq) throws MQClientException, RemotingException, MQBrokerException, InterruptedException;//选择指定队列异步发送消息void send(final Message msg, final MessageQueue mq, final SendCallback sendCallback) throws MQClientException, RemotingException, InterruptedException;//选择指定队列单项发送消息void sendOneway(final Message msg, final MessageQueue mq) throws MQClientException, RemotingException, InterruptedException;//批量发送消息SendResult send(final Collection&lt;Message&gt; msgs) throws MQClientException, RemotingException, MQBrokerException,InterruptedException;属性介绍123456789producerGroup：生产者所属组createTopicKey：默认TopicdefaultTopicQueueNums：默认主题在每一个Broker队列数量sendMsgTimeout：发送消息默认超时时间，默认3scompressMsgBodyOverHowmuch：消息体超过该值则启用压缩，默认4kretryTimesWhenSendFailed：同步方式发送消息重试次数，默认为2，总共执行3次retryTimesWhenSendAsyncFailed：异步方法发送消息重试次数，默认为2retryAnotherBrokerWhenNotStoreOK：消息重试时选择另外一个Broker时，是否不等待存储结果就返回，默认为falsemaxMessageSize：允许发送的最大消息长度，默认为4M启动流程代码：DefaultMQProducerImpl#start12345678//检查生产者组是否满足要求this.checkConfig();//更改当前instanceName为进程IDif (!this.defaultMQProducer.getProducerGroup().equals(MixAll.CLIENT_INNER_PRODUCER_GROUP)) &#123; this.defaultMQProducer.changeInstanceNameToPID();&#125;//获得MQ客户端实例this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQProducer, rpcHook);整个JVM中只存在一个MQClientManager实例，维护一个MQClientInstance缓存表ConcurrentMap&lt;String/ clientId /, MQClientInstance&gt; factoryTable = new ConcurrentHashMap&lt;String,MQClientInstance&gt;();同一个clientId只会创建一个MQClientInstance。MQClientInstance封装了RocketMQ网络处理API，是消息生产者和消息消费者与NameServer、Broker打交道的网络通道代码：MQClientManager#getAndCreateMQClientInstance12345678910111213141516171819202122public MQClientInstance getAndCreateMQClientInstance(final ClientConfig clientConfig, RPCHook rpcHook) &#123; //构建客户端ID String clientId = clientConfig.buildMQClientId(); //根据客户端ID或者客户端实例 MQClientInstance instance = this.factoryTable.get(clientId); //实例如果为空就创建新的实例,并添加到实例表中 if (null == instance) &#123; instance = new MQClientInstance(clientConfig.cloneClientConfig(), this.factoryIndexGenerator.getAndIncrement(), clientId, rpcHook); MQClientInstance prev = this.factoryTable.putIfAbsent(clientId, instance); if (prev != null) &#123; instance = prev; log.warn(\"Returned Previous MQClientInstance for clientId:[&#123;&#125;]\", clientId); &#125; else &#123; log.info(\"Created new MQClientInstance for clientId:[&#123;&#125;]\", clientId); &#125; &#125; return instance;&#125;代码：DefaultMQProducerImpl#start123456789101112//注册当前生产者到到MQClientInstance管理中,方便后续调用网路请求boolean registerOK = mQClientFactory.registerProducer(this.defaultMQProducer.getProducerGroup(), this);if (!registerOK) &#123; this.serviceState = ServiceState.CREATE_JUST; throw new MQClientException(\"The producer group[\" + this.defaultMQProducer.getProducerGroup() + \"] has been created before, specify another name please.\" + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL), null);&#125;//启动生产者if (startFactory) &#123; mQClientFactory.start();&#125;消息发送代码：DefaultMQProducerImpl#send(Message msg)1234//发送消息public SendResult send(Message msg) &#123; return send(msg, this.defaultMQProducer.getSendMsgTimeout());&#125;代码：DefaultMQProducerImpl#send(Message msg,long timeout)1234//发送消息,默认超时时间为3spublic SendResult send(Message msg,long timeout)&#123; return this.sendDefaultImpl(msg, CommunicationMode.SYNC, null, timeout);&#125;代码：DefaultMQProducerImpl#sendDefaultImpl12//校验消息Validators.checkMessage(msg, this.defaultMQProducer);验证消息代码：Validators#checkMessage1234567891011121314151617181920212223public static void checkMessage(Message msg, DefaultMQProducer defaultMQProducer) throws MQClientException &#123; //判断是否为空 if (null == msg) &#123; throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, \"the message is null\"); &#125; // 校验主题 Validators.checkTopic(msg.getTopic()); // 校验消息体 if (null == msg.getBody()) &#123; throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, \"the message body is null\"); &#125; if (0 == msg.getBody().length) &#123; throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, \"the message body length is zero\"); &#125; if (msg.getBody().length &gt; defaultMQProducer.getMaxMessageSize()) &#123; throw new MQClientException(ResponseCode.MESSAGE_ILLEGAL, \"the message body size over max value, MAX: \" + defaultMQProducer.getMaxMessageSize()); &#125;&#125;查找路由代码：DefaultMQProducerImpl#tryToFindTopicPublishInfo12345678910111213141516171819private TopicPublishInfo tryToFindTopicPublishInfo(final String topic) &#123; //从缓存中获得主题的路由信息 TopicPublishInfo topicPublishInfo = this.topicPublishInfoTable.get(topic); //路由信息为空,则从NameServer获取路由 if (null == topicPublishInfo || !topicPublishInfo.ok()) &#123; this.topicPublishInfoTable.putIfAbsent(topic, new TopicPublishInfo()); this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic); topicPublishInfo = this.topicPublishInfoTable.get(topic); &#125; if (topicPublishInfo.isHaveTopicRouterInfo() || topicPublishInfo.ok()) &#123; return topicPublishInfo; &#125; else &#123; //如果未找到当前主题的路由信息,则用默认主题继续查找 this.mQClientFactory.updateTopicRouteInfoFromNameServer(topic, true, this.defaultMQProducer); topicPublishInfo = this.topicPublishInfoTable.get(topic); return topicPublishInfo; &#125;&#125;代码：TopicPublishInfo1234567public class TopicPublishInfo &#123; private boolean orderTopic = false; //是否是顺序消息 private boolean haveTopicRouterInfo = false; private List&lt;MessageQueue&gt; messageQueueList = new ArrayList&lt;MessageQueue&gt;(); //该主题消息队列 private volatile ThreadLocalIndex sendWhichQueue = new ThreadLocalIndex();//每选择一次消息队列,该值+1 private TopicRouteData topicRouteData;//关联Topic路由元信息&#125;代码：MQClientInstance#updateTopicRouteInfoFromNameServer12345678910111213141516TopicRouteData topicRouteData;//使用默认主题从NameServer获取路由信息if (isDefault &amp;&amp; defaultMQProducer != null) &#123; topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(), 1000 * 3); if (topicRouteData != null) &#123; for (QueueData data : topicRouteData.getQueueDatas()) &#123; int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums()); data.setReadQueueNums(queueNums); data.setWriteQueueNums(queueNums); &#125; &#125;&#125; else &#123; //使用指定主题从NameServer获取路由信息 topicRouteData = this.mQClientAPIImpl.getTopicRouteInfoFromNameServer(topic, 1000 * 3);&#125;代码：MQClientInstance#updateTopicRouteInfoFromNameServer12345678//判断路由是否需要更改TopicRouteData old = this.topicRouteTable.get(topic);boolean changed = topicRouteDataIsChange(old, topicRouteData);if (!changed) &#123; changed = this.isNeedUpdateTopicRouteInfo(topic);&#125; else &#123; log.info(\"the topic[&#123;&#125;] route info changed, old[&#123;&#125;] ,new[&#123;&#125;]\", topic, old, topicRouteData);&#125;代码：MQClientInstance#updateTopicRouteInfoFromNameServer123456789101112131415if (changed) &#123; //将topicRouteData转换为发布队列 TopicPublishInfo publishInfo = topicRouteData2TopicPublishInfo(topic, topicRouteData); publishInfo.setHaveTopicRouterInfo(true); //遍历生产 Iterator&lt;Entry&lt;String, MQProducerInner&gt;&gt; it = this.producerTable.entrySet().iterator(); while (it.hasNext()) &#123; Entry&lt;String, MQProducerInner&gt; entry = it.next(); MQProducerInner impl = entry.getValue(); if (impl != null) &#123; //生产者不为空时,更新publishInfo信息 impl.updateTopicPublishInfo(topic, publishInfo); &#125; &#125;&#125;代码：MQClientInstance#topicRouteData2TopicPublishInfo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public static TopicPublishInfo topicRouteData2TopicPublishInfo(final String topic, final TopicRouteData route) &#123; //创建TopicPublishInfo对象 TopicPublishInfo info = new TopicPublishInfo(); //关联topicRoute info.setTopicRouteData(route); //顺序消息,更新TopicPublishInfo if (route.getOrderTopicConf() != null &amp;&amp; route.getOrderTopicConf().length() &gt; 0) &#123; String[] brokers = route.getOrderTopicConf().split(\";\"); for (String broker : brokers) &#123; String[] item = broker.split(\":\"); int nums = Integer.parseInt(item[1]); for (int i = 0; i &lt; nums; i++) &#123; MessageQueue mq = new MessageQueue(topic, item[0], i); info.getMessageQueueList().add(mq); &#125; &#125; info.setOrderTopic(true); &#125; else &#123; //非顺序消息更新TopicPublishInfo List&lt;QueueData&gt; qds = route.getQueueDatas(); Collections.sort(qds); //遍历topic队列信息 for (QueueData qd : qds) &#123; //是否是写队列 if (PermName.isWriteable(qd.getPerm())) &#123; BrokerData brokerData = null; //遍历写队列Broker for (BrokerData bd : route.getBrokerDatas()) &#123; //根据名称获得读队列对应的Broker if (bd.getBrokerName().equals(qd.getBrokerName())) &#123; brokerData = bd; break; &#125; &#125; if (null == brokerData) &#123; continue; &#125; if (!brokerData.getBrokerAddrs().containsKey(MixAll.MASTER_ID)) &#123; continue; &#125; //封装TopicPublishInfo写队列 for (int i = 0; i &lt; qd.getWriteQueueNums(); i++) &#123; MessageQueue mq = new MessageQueue(topic, qd.getBrokerName(), i); info.getMessageQueueList().add(mq); &#125; &#125; &#125; info.setOrderTopic(false); &#125; //返回TopicPublishInfo对象 return info;&#125;选择队列默认不启用Broker故障延迟机制代码：TopicPublishInfo#selectOneMessageQueue(lastBrokerName)1234567891011121314151617181920212223public MessageQueue selectOneMessageQueue(final String lastBrokerName) &#123; //第一次选择队列 if (lastBrokerName == null) &#123; return selectOneMessageQueue(); &#125; else &#123; //sendWhichQueue int index = this.sendWhichQueue.getAndIncrement(); //遍历消息队列集合 for (int i = 0; i &lt; this.messageQueueList.size(); i++) &#123; //sendWhichQueue自增后取模 int pos = Math.abs(index++) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; //规避上次Broker队列 MessageQueue mq = this.messageQueueList.get(pos); if (!mq.getBrokerName().equals(lastBrokerName)) &#123; return mq; &#125; &#125; //如果以上情况都不满足,返回sendWhichQueue取模后的队列 return selectOneMessageQueue(); &#125;&#125;代码：TopicPublishInfo#selectOneMessageQueue()1234567891011//第一次选择队列public MessageQueue selectOneMessageQueue() &#123; //sendWhichQueue自增 int index = this.sendWhichQueue.getAndIncrement(); //对队列大小取模 int pos = Math.abs(index) % this.messageQueueList.size(); if (pos &lt; 0) pos = 0; //返回对应的队列 return this.messageQueueList.get(pos);&#125;启用Broker故障延迟机制12345678910111213141516171819202122232425262728293031323334353637383940414243public MessageQueue selectOneMessageQueue(final TopicPublishInfo tpInfo, final String lastBrokerName) &#123; //Broker故障延迟机制 if (this.sendLatencyFaultEnable) &#123; try &#123; //对sendWhichQueue自增 int index = tpInfo.getSendWhichQueue().getAndIncrement(); //对消息队列轮询获取一个队列 for (int i = 0; i &lt; tpInfo.getMessageQueueList().size(); i++) &#123; int pos = Math.abs(index++) % tpInfo.getMessageQueueList().size(); if (pos &lt; 0) pos = 0; MessageQueue mq = tpInfo.getMessageQueueList().get(pos); //验证该队列是否可用 if (latencyFaultTolerance.isAvailable(mq.getBrokerName())) &#123; //可用 if (null == lastBrokerName || mq.getBrokerName().equals(lastBrokerName)) return mq; &#125; &#125; //从规避的Broker中选择一个可用的Broker final String notBestBroker = latencyFaultTolerance.pickOneAtLeast(); //获得Broker的写队列集合 int writeQueueNums = tpInfo.getQueueIdByBroker(notBestBroker); if (writeQueueNums &gt; 0) &#123; //获得一个队列,指定broker和队列ID并返回 final MessageQueue mq = tpInfo.selectOneMessageQueue(); if (notBestBroker != null) &#123; mq.setBrokerName(notBestBroker); mq.setQueueId(tpInfo.getSendWhichQueue().getAndIncrement() % writeQueueNums); &#125; return mq; &#125; else &#123; latencyFaultTolerance.remove(notBestBroker); &#125; &#125; catch (Exception e) &#123; log.error(\"Error occurred when selecting message queue\", e); &#125; return tpInfo.selectOneMessageQueue(); &#125; return tpInfo.selectOneMessageQueue(lastBrokerName);&#125;延迟机制接口规范12345678910public interface LatencyFaultTolerance&lt;T&gt; &#123; //更新失败条目 void updateFaultItem(final T name, final long currentLatency, final long notAvailableDuration); //判断Broker是否可用 boolean isAvailable(final T name); //移除Fault条目 void remove(final T name); //尝试从规避的Broker中选择一个可用的Broker T pickOneAtLeast();&#125;FaultItem：失败条目12345678class FaultItem implements Comparable&lt;FaultItem&gt; &#123; //条目唯一键,这里为brokerName private final String name; //本次消息发送延迟 private volatile long currentLatency; //故障规避开始时间 private volatile long startTimestamp;&#125;消息失败策略123456public class MQFaultStrategy &#123; //根据currentLatency本地消息发送延迟,从latencyMax尾部向前找到第一个比currentLatency小的索引,如果没有找到,返回0 private long[] latencyMax = &#123;50L, 100L, 550L, 1000L, 2000L, 3000L, 15000L&#125;; //根据这个索引从notAvailableDuration取出对应的时间,在该时长内,Broker设置为不可用 private long[] notAvailableDuration = &#123;0L, 0L, 30000L, 60000L, 120000L, 180000L, 600000L&#125;;&#125;原理分析代码：DefaultMQProducerImpl#sendDefaultImpl12345678sendResult = this.sendKernelImpl(msg, mq, communicationMode, sendCallback, topicPublishInfo, timeout - costTime);endTimestamp = System.currentTimeMillis();this.updateFaultItem(mq.getBrokerName(), endTimestamp - beginTimestampPrev, false);如果上述发送过程出现异常，则调用DefaultMQProducerImpl#updateFaultItem123456public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123; //参数一：broker名称 //参数二:本次消息发送延迟时间 //参数三:是否隔离 this.mqFaultStrategy.updateFaultItem(brokerName, currentLatency, isolation);&#125;代码：MQFaultStrategy#updateFaultItem12345678public void updateFaultItem(final String brokerName, final long currentLatency, boolean isolation) &#123; if (this.sendLatencyFaultEnable) &#123; //计算broker规避的时长 long duration = computeNotAvailableDuration(isolation ? 30000 : currentLatency); //更新该FaultItem规避时长 this.latencyFaultTolerance.updateFaultItem(brokerName, currentLatency, duration); &#125;&#125;代码：MQFaultStrategy#computeNotAvailableDuration12345678910private long computeNotAvailableDuration(final long currentLatency) &#123; //遍历latencyMax for (int i = latencyMax.length - 1; i &gt;= 0; i--) &#123; //找到第一个比currentLatency的latencyMax值 if (currentLatency &gt;= latencyMax[i]) return this.notAvailableDuration[i]; &#125; //没有找到则返回0 return 0;&#125;代码：LatencyFaultToleranceImpl#updateFaultItem1234567891011121314151617181920public void updateFaultItem(final String name, final long currentLatency, final long notAvailableDuration) &#123; //获得原FaultItem FaultItem old = this.faultItemTable.get(name); //为空新建faultItem对象,设置规避时长和开始时间 if (null == old) &#123; final FaultItem faultItem = new FaultItem(name); faultItem.setCurrentLatency(currentLatency); faultItem.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration); old = this.faultItemTable.putIfAbsent(name, faultItem); if (old != null) &#123; old.setCurrentLatency(currentLatency); old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration); &#125; &#125; else &#123; //更新规避时长和开始时间 old.setCurrentLatency(currentLatency); old.setStartTimestamp(System.currentTimeMillis() + notAvailableDuration); &#125;&#125;发送消息消息发送API核心入口DefaultMQProducerImpl#sendKernelImpl12345678private SendResult sendKernelImpl( final Message msg, //待发送消息 final MessageQueue mq, //消息发送队列 final CommunicationMode communicationMode, //消息发送内模式 final SendCallback sendCallback, pp //异步消息回调函数 final TopicPublishInfo topicPublishInfo, //主题路由信息 final long timeout //超时时间 )代码：DefaultMQProducerImpl#sendKernelImpl1234567//获得broker网络地址信息String brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());if (null == brokerAddr) &#123; //没有找到从NameServer更新broker网络地址信息 tryToFindTopicPublishInfo(mq.getTopic()); brokerAddr = this.mQClientFactory.findBrokerAddressInPublish(mq.getBrokerName());&#125;12345678910111213141516171819202122//为消息分类唯一IDif (!(msg instanceof MessageBatch)) &#123; MessageClientIDSetter.setUniqID(msg);&#125;boolean topicWithNamespace = false;if (null != this.mQClientFactory.getClientConfig().getNamespace()) &#123; msg.setInstanceId(this.mQClientFactory.getClientConfig().getNamespace()); topicWithNamespace = true;&#125;//消息大小超过4K,启用消息压缩int sysFlag = 0;boolean msgBodyCompressed = false;if (this.tryToCompressMessage(msg)) &#123; sysFlag |= MessageSysFlag.COMPRESSED_FLAG; msgBodyCompressed = true;&#125;//如果是事务消息,设置消息标记MessageSysFlag.TRANSACTION_PREPARED_TYPEfinal String tranMsg = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED);if (tranMsg != null &amp;&amp; Boolean.parseBoolean(tranMsg)) &#123; sysFlag |= MessageSysFlag.TRANSACTION_PREPARED_TYPE;&#125;123456789101112131415161718192021//如果注册了消息发送钩子函数,在执行消息发送前的增强逻辑if (this.hasSendMessageHook()) &#123; context = new SendMessageContext(); context.setProducer(this); context.setProducerGroup(this.defaultMQProducer.getProducerGroup()); context.setCommunicationMode(communicationMode); context.setBornHost(this.defaultMQProducer.getClientIP()); context.setBrokerAddr(brokerAddr); context.setMessage(msg); context.setMq(mq); context.setNamespace(this.defaultMQProducer.getNamespace()); String isTrans = msg.getProperty(MessageConst.PROPERTY_TRANSACTION_PREPARED); if (isTrans != null &amp;&amp; isTrans.equals(\"true\")) &#123; context.setMsgType(MessageType.Trans_Msg_Half); &#125; if (msg.getProperty(\"__STARTDELIVERTIME\") != null || msg.getProperty(MessageConst.PROPERTY_DELAY_TIME_LEVEL) != null) &#123; context.setMsgType(MessageType.Delay_Msg); &#125; this.executeSendMessageHookBefore(context);&#125;代码：SendMessageHook1234567public interface SendMessageHook &#123; String hookName(); void sendMessageBefore(final SendMessageContext context); void sendMessageAfter(final SendMessageContext context);&#125;代码：DefaultMQProducerImpl#sendKernelImpl1234567891011121314151617181920212223242526272829303132333435363738//构建消息发送请求包SendMessageRequestHeader requestHeader = new SendMessageRequestHeader();//生产者组requestHeader.setProducerGroup(this.defaultMQProducer.getProducerGroup());//主题requestHeader.setTopic(msg.getTopic());//默认创建主题KeyrequestHeader.setDefaultTopic(this.defaultMQProducer.getCreateTopicKey());//该主题在单个Broker默认队列树requestHeader.setDefaultTopicQueueNums(this.defaultMQProducer.getDefaultTopicQueueNums());//队列IDrequestHeader.setQueueId(mq.getQueueId());//消息系统标记requestHeader.setSysFlag(sysFlag);//消息发送时间requestHeader.setBornTimestamp(System.currentTimeMillis());//消息标记requestHeader.setFlag(msg.getFlag());//消息扩展信息requestHeader.setProperties(MessageDecoder.messageProperties2String(msg.getProperties()));//消息重试次数requestHeader.setReconsumeTimes(0);requestHeader.setUnitMode(this.isUnitMode());//是否是批量消息等requestHeader.setBatch(msg instanceof MessageBatch);if (requestHeader.getTopic().startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; String reconsumeTimes = MessageAccessor.getReconsumeTime(msg); if (reconsumeTimes != null) &#123; requestHeader.setReconsumeTimes(Integer.valueOf(reconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_RECONSUME_TIME); &#125; String maxReconsumeTimes = MessageAccessor.getMaxReconsumeTimes(msg); if (maxReconsumeTimes != null) &#123; requestHeader.setMaxReconsumeTimes(Integer.valueOf(maxReconsumeTimes)); MessageAccessor.clearProperty(msg, MessageConst.PROPERTY_MAX_RECONSUME_TIMES); &#125;&#125;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859case ASYNC: //异步发送 Message tmpMessage = msg; boolean messageCloned = false; if (msgBodyCompressed) &#123; //If msg body was compressed, msgbody should be reset using prevBody. //Clone new message using commpressed message body and recover origin massage. //Fix bug:https://github.com/apache/rocketmq-externals/issues/66 tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; msg.setBody(prevBody); &#125; if (topicWithNamespace) &#123; if (!messageCloned) &#123; tmpMessage = MessageAccessor.cloneMessage(msg); messageCloned = true; &#125; msg.setTopic(NamespaceUtil.withoutNamespace(msg.getTopic(), this.defaultMQProducer.getNamespace())); &#125; long costTimeAsync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeAsync) &#123; throw new RemotingTooMuchRequestException(\"sendKernelImpl call timeout\"); &#125; sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage( brokerAddr, mq.getBrokerName(), tmpMessage, requestHeader, timeout - costTimeAsync, communicationMode, sendCallback, topicPublishInfo, this.mQClientFactory, this.defaultMQProducer.getRetryTimesWhenSendAsyncFailed(), context, this); break;case ONEWAY:case SYNC: //同步发送 long costTimeSync = System.currentTimeMillis() - beginStartTime; if (timeout &lt; costTimeSync) &#123; throw new RemotingTooMuchRequestException(\"sendKernelImpl call timeout\"); &#125; sendResult = this.mQClientFactory.getMQClientAPIImpl().sendMessage( brokerAddr, mq.getBrokerName(), msg, requestHeader, timeout - costTimeSync, communicationMode, context, this); break; default: assert false; break;&#125;12345//如果注册了钩子函数,则发送完毕后执行钩子函数if (this.hasSendMessageHook()) &#123; context.setSendResult(sendResult); this.executeSendMessageHookAfter(context);&#125;批量消息发送批量消息发送是将同一个主题的多条消息一起打包发送到消息服务端，减少网络调用次数，提高网络传输效率。当然，并不是在同一批次中发送的消息数量越多越好，其判断依据是单条消息的长度，如果单条消息内容比较长，则打包多条消息发送会影响其他线程发送消息的响应时间，并且单批次消息总长度不能超过DefaultMQProducer#maxMessageSize。批量消息发送要解决的问题是如何将这些消息编码以便服务端能够正确解码出每条消息的消息内容。代码：DefaultMQProducer#send12345public SendResult send(Collection&lt;Message&gt; msgs) throws MQClientException, RemotingException, MQBrokerException, InterruptedException &#123; //压缩消息集合成一条消息,然后发送出去 return this.defaultMQProducerImpl.send(batch(msgs));&#125;代码：DefaultMQProducer#batch1234567891011121314151617181920private MessageBatch batch(Collection&lt;Message&gt; msgs) throws MQClientException &#123; MessageBatch msgBatch; try &#123; //将集合消息封装到MessageBatch msgBatch = MessageBatch.generateFromList(msgs); //遍历消息集合,检查消息合法性,设置消息ID,设置Topic for (Message message : msgBatch) &#123; Validators.checkMessage(message, this); MessageClientIDSetter.setUniqID(message); message.setTopic(withNamespace(message.getTopic())); &#125; //压缩消息,设置消息body msgBatch.setBody(msgBatch.encode()); &#125; catch (Exception e) &#123; throw new MQClientException(\"Failed to initiate the MessageBatch\", e); &#125; //设置msgBatch的topic msgBatch.setTopic(withNamespace(msgBatch.getTopic())); return msgBatch;&#125;消息存储消息存储核心类123456789101112131415161718private final MessageStoreConfig messageStoreConfig; //消息配置属性private final CommitLog commitLog; //CommitLog文件存储的实现类private final ConcurrentMap&lt;String/* topic */, ConcurrentMap&lt;Integer/* queueId */, ConsumeQueue&gt;&gt; consumeQueueTable; //消息队列存储缓存表,按照消息主题分组private final FlushConsumeQueueService flushConsumeQueueService; //消息队列文件刷盘线程private final CleanCommitLogService cleanCommitLogService; //清除CommitLog文件服务private final CleanConsumeQueueService cleanConsumeQueueService; //清除ConsumerQueue队列文件服务private final IndexService indexService; //索引实现类private final AllocateMappedFileService allocateMappedFileService; //MappedFile分配服务private final ReputMessageService reputMessageService;//CommitLog消息分发,根据CommitLog文件构建ConsumerQueue、IndexFile文件private final HAService haService; //存储HA机制private final ScheduleMessageService scheduleMessageService; //消息服务调度线程private final StoreStatsService storeStatsService; //消息存储服务private final TransientStorePool transientStorePool; //消息堆外内存缓存private final BrokerStatsManager brokerStatsManager; //Broker状态管理器private final MessageArrivingListener messageArrivingListener; //消息拉取长轮询模式消息达到监听器private final BrokerConfig brokerConfig; //Broker配置类private StoreCheckpoint storeCheckpoint; //文件刷盘监测点private final LinkedList&lt;CommitLogDispatcher&gt; dispatcherList; //CommitLog文件转发请求消息存储流程消息存储入口：DefaultMessageStore#putMessage12345678910111213141516171819202122232425262728293031323334//判断Broker角色如果是从节点,则无需写入if (BrokerRole.SLAVE == this.messageStoreConfig.getBrokerRole()) &#123; long value = this.printTimes.getAndIncrement(); if ((value % 50000) == 0) &#123; log.warn(\"message store is slave mode, so putMessage is forbidden \"); &#125; return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125;//判断当前写入状态如果是正在写入,则不能继续if (!this.runningFlags.isWriteable()) &#123; long value = this.printTimes.getAndIncrement(); return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);&#125; else &#123; this.printTimes.set(0);&#125;//判断消息主题长度是否超过最大限制if (msg.getTopic().length() &gt; Byte.MAX_VALUE) &#123; log.warn(\"putMessage message topic length too long \" + msg.getTopic().length()); return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);&#125;//判断消息属性长度是否超过限制if (msg.getPropertiesString() != null &amp;&amp; msg.getPropertiesString().length() &gt; Short.MAX_VALUE) &#123; log.warn(\"putMessage message properties length too long \" + msg.getPropertiesString().length()); return new PutMessageResult(PutMessageStatus.PROPERTIES_SIZE_EXCEEDED, null);&#125;//判断系统PageCache缓存去是否占用if (this.isOSPageCacheBusy()) &#123; return new PutMessageResult(PutMessageStatus.OS_PAGECACHE_BUSY, null);&#125;//将消息写入CommitLog文件PutMessageResult result = this.commitLog.putMessage(msg);代码：CommitLog#putMessage12345678910111213141516//记录消息存储时间msg.setStoreTimestamp(beginLockTimestamp);//判断如果mappedFile如果为空或者已满,创建新的mappedFile文件if (null == mappedFile || mappedFile.isFull()) &#123; mappedFile = this.mappedFileQueue.getLastMappedFile(0); &#125;//如果创建失败,直接返回if (null == mappedFile) &#123; log.error(\"create mapped file1 error, topic: \" + msg.getTopic() + \" clientAddr: \" + msg.getBornHostString()); beginTimeInLock = 0; return new PutMessageResult(PutMessageStatus.CREATE_MAPEDFILE_FAILED, null);&#125;//写入消息到mappedFile中result = mappedFile.appendMessage(msg, this.appendMessageCallback);代码：MappedFile#appendMessagesInner123456789101112131415161718192021//获得文件的写入指针int currentPos = this.wrotePosition.get();//如果指针大于文件大小则直接返回if (currentPos &lt; this.fileSize) &#123; //通过writeBuffer.slice()创建一个与MappedFile共享的内存区,并设置position为当前指针 ByteBuffer byteBuffer = writeBuffer != null ? writeBuffer.slice() : this.mappedByteBuffer.slice(); byteBuffer.position(currentPos); AppendMessageResult result = null; if (messageExt instanceof MessageExtBrokerInner) &#123; //通过回调方法写入 result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBrokerInner) messageExt); &#125; else if (messageExt instanceof MessageExtBatch) &#123; result = cb.doAppend(this.getFileFromOffset(), byteBuffer, this.fileSize - currentPos, (MessageExtBatch) messageExt); &#125; else &#123; return new AppendMessageResult(AppendMessageStatus.UNKNOWN_ERROR); &#125; this.wrotePosition.addAndGet(result.getWroteBytes()); this.storeTimestamp = result.getStoreTimestamp(); return result;&#125;代码：CommitLog#doAppend123456789101112131415161718192021222324252627282930313233343536//文件写入位置long wroteOffset = fileFromOffset + byteBuffer.position();//设置消息IDthis.resetByteBuffer(hostHolder, 8);String msgId = MessageDecoder.createMessageId(this.msgIdMemory, msgInner.getStoreHostBytes(hostHolder), wroteOffset);//获得该消息在消息队列中的偏移量keyBuilder.setLength(0);keyBuilder.append(msgInner.getTopic());keyBuilder.append('-');keyBuilder.append(msgInner.getQueueId());String key = keyBuilder.toString();Long queueOffset = CommitLog.this.topicQueueTable.get(key);if (null == queueOffset) &#123; queueOffset = 0L; CommitLog.this.topicQueueTable.put(key, queueOffset);&#125;//获得消息属性长度final byte[] propertiesData =msgInner.getPropertiesString() == null ? null : msgInner.getPropertiesString().getBytes(MessageDecoder.CHARSET_UTF8);final int propertiesLength = propertiesData == null ? 0 : propertiesData.length;if (propertiesLength &gt; Short.MAX_VALUE) &#123; log.warn(\"putMessage message properties length too long. length=&#123;&#125;\", propertiesData.length); return new AppendMessageResult(AppendMessageStatus.PROPERTIES_SIZE_EXCEEDED);&#125;//获得消息主题大小final byte[] topicData = msgInner.getTopic().getBytes(MessageDecoder.CHARSET_UTF8);final int topicLength = topicData.length;//获得消息体大小final int bodyLength = msgInner.getBody() == null ? 0 : msgInner.getBody().length;//计算消息总长度final int msgLen = calMsgLength(bodyLength, topicLength, propertiesLength);代码：CommitLog#calMsgLength123456789101112131415161718192021protected static int calMsgLength(int bodyLength, int topicLength, int propertiesLength) &#123; final int msgLen = 4 //TOTALSIZE + 4 //MAGICCODE + 4 //BODYCRC + 4 //QUEUEID + 4 //FLAG + 8 //QUEUEOFFSET + 8 //PHYSICALOFFSET + 4 //SYSFLAG + 8 //BORNTIMESTAMP + 8 //BORNHOST + 8 //STORETIMESTAMP + 8 //STOREHOSTADDRESS + 4 //RECONSUMETIMES + 8 //Prepared Transaction Offset + 4 + (bodyLength &gt; 0 ? bodyLength : 0) //BODY + 1 + topicLength //TOPIC + 2 + (propertiesLength &gt; 0 ? propertiesLength : 0) //propertiesLength + 0; return msgLen;&#125;代码：CommitLog#doAppend12345678910111213141516171819202122232425262728293031323334353637383940414243//消息长度不能超过4Mif (msgLen &gt; this.maxMessageSize) &#123; CommitLog.log.warn(\"message size exceeded, msg total size: \" + msgLen + \", msg body size: \" + bodyLength + \", maxMessageSize: \" + this.maxMessageSize); return new AppendMessageResult(AppendMessageStatus.MESSAGE_SIZE_EXCEEDED);&#125;//消息是如果没有足够的存储空间则新创建CommitLog文件if ((msgLen + END_FILE_MIN_BLANK_LENGTH) &gt; maxBlank) &#123; this.resetByteBuffer(this.msgStoreItemMemory, maxBlank); // 1 TOTALSIZE this.msgStoreItemMemory.putInt(maxBlank); // 2 MAGICCODE this.msgStoreItemMemory.putInt(CommitLog.BLANK_MAGIC_CODE); // 3 The remaining space may be any value // Here the length of the specially set maxBlank final long beginTimeMills = CommitLog.this.defaultMessageStore.now(); byteBuffer.put(this.msgStoreItemMemory.array(), 0, maxBlank); return new AppendMessageResult(AppendMessageStatus.END_OF_FILE, wroteOffset, maxBlank, msgId, msgInner.getStoreTimestamp(), queueOffset, CommitLog.this.defaultMessageStore.now() - beginTimeMills);&#125;//将消息存储到ByteBuffer中,返回AppendMessageResultfinal long beginTimeMills = CommitLog.this.defaultMessageStore.now();// Write messages to the queue bufferbyteBuffer.put(this.msgStoreItemMemory.array(), 0, msgLen);AppendMessageResult result = new AppendMessageResult(AppendMessageStatus.PUT_OK, wroteOffset, msgLen, msgId,msgInner.getStoreTimestamp(), queueOffset, CommitLog.this.defaultMessageStore.now() -beginTimeMills);switch (tranType) &#123; case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: break; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: //更新消息队列偏移量 CommitLog.this.topicQueueTable.put(key, ++queueOffset); break; default: break;&#125;代码：CommitLog#putMessage123456//释放锁putMessageLock.unlock();//刷盘handleDiskFlush(result, putMessageResult, msg);//执行HA主从同步handleHA(result, putMessageResult, msg);存储文件commitLog：消息存储目录config：运行期间一些配置信息consumerqueue：消息消费队列存储目录index：消息索引文件存储目录abort：如果存在改文件寿命Broker非正常关闭checkpoint：文件检查点，存储CommitLog文件最后一次刷盘时间戳、consumerquueue最后一次刷盘时间，index索引文件最后一次刷盘时间戳。存储文件内存映射RocketMQ通过使用内存映射文件提高IO访问性能，无论是CommitLog、ConsumerQueue还是IndexFile，单个文件都被设计为固定长度，如果一个文件写满以后再创建一个新文件，文件名就为该文件第一条消息对应的全局物理偏移量。MappedFileQueue123456String storePath; //存储目录int mappedFileSize; // 单个文件大小CopyOnWriteArrayList&lt;MappedFile&gt; mappedFiles; //MappedFile文件集合AllocateMappedFileService allocateMappedFileService; //创建MapFile服务类long flushedWhere = 0; //当前刷盘指针long committedWhere = 0; //当前数据提交指针,内存中ByteBuffer当前的写指针,该值大于等于flushWhere根据存储时间查询MappedFile12345678910111213141516public MappedFile getMappedFileByTime(final long timestamp) &#123; Object[] mfs = this.copyMappedFiles(0); if (null == mfs) return null; //遍历MappedFile文件数组 for (int i = 0; i &lt; mfs.length; i++) &#123; MappedFile mappedFile = (MappedFile) mfs[i]; //MappedFile文件的最后修改时间大于指定时间戳则返回该文件 if (mappedFile.getLastModifiedTimestamp() &gt;= timestamp) &#123; return mappedFile; &#125; &#125; return (MappedFile) mfs[mfs.length - 1];&#125;根据消息偏移量offset查找MappedFile1234567891011121314151617181920212223242526272829303132333435363738394041424344public MappedFile findMappedFileByOffset(final long offset, final boolean returnFirstOnNotFound) &#123; try &#123; //获得第一个MappedFile文件 MappedFile firstMappedFile = this.getFirstMappedFile(); //获得最后一个MappedFile文件 MappedFile lastMappedFile = this.getLastMappedFile(); //第一个文件和最后一个文件均不为空,则进行处理 if (firstMappedFile != null &amp;&amp; lastMappedFile != null) &#123; if (offset &lt; firstMappedFile.getFileFromOffset() || offset &gt;= lastMappedFile.getFileFromOffset() + this.mappedFileSize) &#123; &#125; else &#123; //获得文件索引 int index = (int) ((offset / this.mappedFileSize) - (firstMappedFile.getFileFromOffset() / this.mappedFileSize)); MappedFile targetFile = null; try &#123; //根据索引返回目标文件 targetFile = this.mappedFiles.get(index); &#125; catch (Exception ignored) &#123; &#125; if (targetFile != null &amp;&amp; offset &gt;= targetFile.getFileFromOffset() &amp;&amp; offset &lt; targetFile.getFileFromOffset() + this.mappedFileSize) &#123; return targetFile; &#125; for (MappedFile tmpMappedFile : this.mappedFiles) &#123; if (offset &gt;= tmpMappedFile.getFileFromOffset() &amp;&amp; offset &lt; tmpMappedFile.getFileFromOffset() + this.mappedFileSize) &#123; return tmpMappedFile; &#125; &#125; &#125; if (returnFirstOnNotFound) &#123; return firstMappedFile; &#125; &#125; &#125; catch (Exception e) &#123; log.error(\"findMappedFileByOffset Exception\", e); &#125; return null;&#125;获取存储文件最小偏移量12345678910111213public long getMinOffset() &#123; if (!this.mappedFiles.isEmpty()) &#123; try &#123; return this.mappedFiles.get(0).getFileFromOffset(); &#125; catch (IndexOutOfBoundsException e) &#123; //continue; &#125; catch (Exception e) &#123; log.error(\"getMinOffset has exception.\", e); &#125; &#125; return -1;&#125;获取存储文件最大偏移量1234567public long getMaxOffset() &#123; MappedFile mappedFile = getLastMappedFile(); if (mappedFile != null) &#123; return mappedFile.getFileFromOffset() + mappedFile.getReadPosition(); &#125; return 0;&#125;返回存储文件当前写指针1234567public long getMaxWrotePosition() &#123; MappedFile mappedFile = getLastMappedFile(); if (mappedFile != null) &#123; return mappedFile.getFileFromOffset() + mappedFile.getWrotePosition(); &#125; return 0;&#125;MappedFile12345678910111213141516int OS_PAGE_SIZE = 1024 * 4; //操作系统每页大小,默认4KAtomicLong TOTAL_MAPPED_VIRTUAL_MEMORY = new AtomicLong(0); //当前JVM实例中MappedFile虚拟内存AtomicInteger TOTAL_MAPPED_FILES = new AtomicInteger(0); //当前JVM实例中MappedFile对象个数AtomicInteger wrotePosition = new AtomicInteger(0); //当前文件的写指针AtomicInteger committedPosition = new AtomicInteger(0); //当前文件的提交指针AtomicInteger flushedPosition = new AtomicInteger(0); //刷写到磁盘指针int fileSize; //文件大小FileChannel fileChannel; //文件通道 ByteBuffer writeBuffer = null; //堆外内存ByteBufferTransientStorePool transientStorePool = null; //堆外内存池String fileName; //文件名称long fileFromOffset; //该文件的处理偏移量File file; //物理文件MappedByteBuffer mappedByteBuffer; //物理文件对应的内存映射Buffervolatile long storeTimestamp = 0; //文件最后一次内容写入时间boolean firstCreateInQueue = false; //是否是MappedFileQueue队列中第一个文件MappedFile初始化未开启transientStorePoolEnable。transientStorePoolEnable=true为true表示数据先存储到堆外内存，然后通过Commit线程将数据提交到内存映射Buffer中，再通过Flush线程将内存映射Buffer中数据持久化磁盘。123456789101112131415161718192021222324252627private void init(final String fileName, final int fileSize) throws IOException &#123; this.fileName = fileName; this.fileSize = fileSize; this.file = new File(fileName); this.fileFromOffset = Long.parseLong(this.file.getName()); boolean ok = false; ensureDirOK(this.file.getParent()); try &#123; this.fileChannel = new RandomAccessFile(this.file, \"rw\").getChannel(); this.mappedByteBuffer = this.fileChannel.map(MapMode.READ_WRITE, 0, fileSize); TOTAL_MAPPED_VIRTUAL_MEMORY.addAndGet(fileSize); TOTAL_MAPPED_FILES.incrementAndGet(); ok = true; &#125; catch (FileNotFoundException e) &#123; log.error(\"create file channel \" + this.fileName + \" Failed. \", e); throw e; &#125; catch (IOException e) &#123; log.error(\"map file \" + this.fileName + \" Failed. \", e); throw e; &#125; finally &#123; if (!ok &amp;&amp; this.fileChannel != null) &#123; this.fileChannel.close(); &#125; &#125;&#125;开启transientStorePoolEnable123456public void init(final String fileName, final int fileSize, final TransientStorePool transientStorePool) throws IOException &#123; init(fileName, fileSize); this.writeBuffer = transientStorePool.borrowBuffer(); //初始化writeBuffer this.transientStorePool = transientStorePool;&#125;MappedFile提交提交数据到FileChannel，commitLeastPages为本次提交最小的页数，如果待提交数据不满commitLeastPages，则不执行本次提交操作。如果writeBuffer如果为空，直接返回writePosition指针，无需执行commit操作，表名commit操作主体是writeBuffer。1234567891011121314151617181920212223public int commit(final int commitLeastPages) &#123; if (writeBuffer == null) &#123; //no need to commit data to file channel, so just regard wrotePosition as committedPosition. return this.wrotePosition.get(); &#125; //判断是否满足提交条件 if (this.isAbleToCommit(commitLeastPages)) &#123; if (this.hold()) &#123; commit0(commitLeastPages); this.release(); &#125; else &#123; log.warn(\"in commit, hold failed, commit offset = \" + this.committedPosition.get()); &#125; &#125; // 所有数据提交后,清空缓冲区 if (writeBuffer != null &amp;&amp; this.transientStorePool != null &amp;&amp; this.fileSize == this.committedPosition.get()) &#123; this.transientStorePool.returnBuffer(writeBuffer); this.writeBuffer = null; &#125; return this.committedPosition.get();&#125;MappedFile#isAbleToCommit判断是否执行commit操作，如果文件已满返回true；如果commitLeastpages大于0，则比较writePosition与上一次提交的指针commitPosition的差值，除以OS_PAGE_SIZE得到当前脏页的数量，如果大于commitLeastPages则返回true，如果commitLeastpages小于0表示只要存在脏页就提交。1234567891011121314151617protected boolean isAbleToCommit(final int commitLeastPages) &#123; //已经刷盘指针 int flush = this.committedPosition.get(); //文件写指针 int write = this.wrotePosition.get(); //写满刷盘 if (this.isFull()) &#123; return true; &#125; if (commitLeastPages &gt; 0) &#123; //文件内容达到commitLeastPages页数,则刷盘 return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) &gt;= commitLeastPages; &#125; return write &gt; flush;&#125;MappedFile#commit0具体提交的实现，首先创建WriteBuffer区共享缓存区，然后将新创建的position回退到上一次提交的位置（commitPosition），设置limit为wrotePosition（当前最大有效数据指针），然后把commitPosition到wrotePosition的数据写入到FileChannel中，然后更新committedPosition指针为wrotePosition。commit的作用就是将MappedFile的writeBuffer中数据提交到文件通道FileChannel中。12345678910111213141516171819202122232425protected void commit0(final int commitLeastPages) &#123; //写指针 int writePos = this.wrotePosition.get(); //上次提交指针 int lastCommittedPosition = this.committedPosition.get(); if (writePos - this.committedPosition.get() &gt; 0) &#123; try &#123; //复制共享内存区域 ByteBuffer byteBuffer = writeBuffer.slice(); //设置提交位置是上次提交位置 byteBuffer.position(lastCommittedPosition); //最大提交数量 byteBuffer.limit(writePos); //设置fileChannel位置为上次提交位置 this.fileChannel.position(lastCommittedPosition); //将lastCommittedPosition到writePos的数据复制到FileChannel中 this.fileChannel.write(byteBuffer); //重置提交位置 this.committedPosition.set(writePos); &#125; catch (Throwable e) &#123; log.error(\"Error occurred when commit data to FileChannel.\", e); &#125; &#125;&#125;MappedFile#flush刷写磁盘，直接调用MappedByteBuffer或fileChannel的force方法将内存中的数据持久化到磁盘，那么flushedPosition应该等于MappedByteBuffer中的写指针；如果writeBuffer不为空，则flushPosition应该等于上一次的commit指针；因为上一次提交的数据就是进入到MappedByteBuffer中的数据；如果writeBuffer为空，数据时直接进入到MappedByteBuffer，wrotePosition代表的是MappedByteBuffer中的指针，故设置flushPosition为wrotePosition。12345678910111213141516171819202122232425262728public int flush(final int flushLeastPages) &#123; //数据达到刷盘条件 if (this.isAbleToFlush(flushLeastPages)) &#123; //加锁，同步刷盘 if (this.hold()) &#123; //获得读指针 int value = getReadPosition(); try &#123; //数据从writeBuffer提交数据到fileChannel再刷新到磁盘 if (writeBuffer != null || this.fileChannel.position() != 0) &#123; this.fileChannel.force(false); &#125; else &#123; //从mmap刷新数据到磁盘 this.mappedByteBuffer.force(); &#125; &#125; catch (Throwable e) &#123; log.error(\"Error occurred when force data to disk.\", e); &#125; //更新刷盘位置 this.flushedPosition.set(value); this.release(); &#125; else &#123; log.warn(\"in flush, hold failed, flush offset = \" + this.flushedPosition.get()); this.flushedPosition.set(getReadPosition()); &#125; &#125; return this.getFlushedPosition();&#125;MappedFile#getReadPosition获取当前文件最大可读指针。如果writeBuffer为空，则直接返回当前的写指针；如果writeBuffer不为空，则返回上一次提交的指针。在MappedFile设置中,只有提交了的数据（写入到MappedByteBuffer或FileChannel中的数据）才是安全的数据1234public int getReadPosition() &#123; //如果writeBuffer为空,刷盘的位置就是应该等于上次commit的位置,如果为空则为mmap的写指针 return this.writeBuffer == null ? this.wrotePosition.get() : this.committedPosition.get();&#125;MappedFile#selectMappedBuffer查找pos到当前最大可读之间的数据，由于在整个写入期间都未曾改MappedByteBuffer的指针，如果mappedByteBuffer.slice()方法返回的共享缓存区空间为整个MappedFile，然后通过设置ByteBuffer的position为待查找的值，读取字节长度当前可读最大长度，最终返回的ByteBuffer的limit为size。整个共享缓存区的容量为（MappedFile#fileSize-pos）。故在操作SelectMappedBufferResult不能对包含在里面的ByteBuffer调用filp方法。123456789101112131415161718192021public SelectMappedBufferResult selectMappedBuffer(int pos) &#123; //获得最大可读指针 int readPosition = getReadPosition(); //pos小于最大可读指针,并且大于0 if (pos &lt; readPosition &amp;&amp; pos &gt;= 0) &#123; if (this.hold()) &#123; //复制mappedByteBuffer读共享区 ByteBuffer byteBuffer = this.mappedByteBuffer.slice(); //设置读指针位置 byteBuffer.position(pos); //获得可读范围 int size = readPosition - pos; //设置最大刻度范围 ByteBuffer byteBufferNew = byteBuffer.slice(); byteBufferNew.limit(size); return new SelectMappedBufferResult(this.fileFromOffset + pos, byteBufferNew, size, this); &#125; &#125; return null;&#125;MappedFile#shutdownMappedFile文件销毁的实现方法为public boolean destory(long intervalForcibly)，intervalForcibly表示拒绝被销毁的最大存活时间。123456789101112131415public void shutdown(final long intervalForcibly) &#123; if (this.available) &#123; //关闭MapedFile this.available = false; //设置当前关闭时间戳 this.firstShutdownTimestamp = System.currentTimeMillis(); //释放资源 this.release(); &#125; else if (this.getRefCount() &gt; 0) &#123; if ((System.currentTimeMillis() - this.firstShutdownTimestamp) &gt;= intervalForcibly) &#123; this.refCount.set(-1000 - this.getRefCount()); this.release(); &#125; &#125;&#125;TransientStorePool短暂的存储池。RocketMQ单独创建一个MappedByteBuffer内存缓存池，用来临时存储数据，数据先写入该内存映射中，然后由commit线程定时将数据从该内存复制到与目标物理文件对应的内存映射中。RocketMQ引入该机制主要的原因是提供一种内存锁定，将当前堆外内存一直锁定在内存中，避免被进程将内存交换到磁盘。123private final int poolSize; //availableBuffers个数private final int fileSize; //每隔ByteBuffer大小private final Deque&lt;ByteBuffer&gt; availableBuffers; //ByteBuffer容器。双端队列初始化123456789101112public void init() &#123; //创建poolSize个堆外内存 for (int i = 0; i &lt; poolSize; i++) &#123; ByteBuffer byteBuffer = ByteBuffer.allocateDirect(fileSize); final long address = ((DirectBuffer) byteBuffer).address(); Pointer pointer = new Pointer(address); //使用com.sun.jna.Library类库将该批内存锁定,避免被置换到交换区,提高存储性能 LibC.INSTANCE.mlock(pointer, new NativeLong(fileSize)); availableBuffers.offer(byteBuffer); &#125;&#125;实时更新消息消费队列与索引文件消息消费队文件、消息属性索引文件都是基于CommitLog文件构建的，当消息生产者提交的消息存储在CommitLog文件中，ConsumerQueue、IndexFile需要及时更新，否则消息无法及时被消费，根据消息属性查找消息也会出现较大延迟。RocketMQ通过开启一个线程ReputMessageService来准实时转发CommitLog文件更新事件，相应的任务处理器根据转发的消息及时更新ConsumerQueue、IndexFile文件。代码：DefaultMessageStore：start1234//设置CommitLog内存中最大偏移量this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);//启动this.reputMessageService.start();代码：DefaultMessageStore：run1234567891011121314public void run() &#123; DefaultMessageStore.log.info(this.getServiceName() + \" service started\"); //每隔1毫秒就继续尝试推送消息到消息消费队列和索引文件 while (!this.isStopped()) &#123; try &#123; Thread.sleep(1); this.doReput(); &#125; catch (Exception e) &#123; DefaultMessageStore.log.warn(this.getServiceName() + \" service has exception. \", e); &#125; &#125; DefaultMessageStore.log.info(this.getServiceName() + \" service end\");&#125;代码：DefaultMessageStore：deReput1234567891011//从result中循环遍历消息,一次读一条,创建DispatherRequest对象。for (int readSize = 0; readSize &lt; result.getSize() &amp;&amp; doNext; ) &#123; DispatchRequest dispatchRequest = DefaultMessageStore.this.commitLog.checkMessageAndReturnSize(result.getByteBuffer(), false, false); int size = dispatchRequest.getBufferSize() == -1 ? dispatchRequest.getMsgSize() : dispatchRequest.getBufferSize(); if (dispatchRequest.isSuccess()) &#123; if (size &gt; 0) &#123; DefaultMessageStore.this.doDispatch(dispatchRequest); &#125; &#125;&#125;DispatchRequest1234567891011121314String topic; //消息主题名称int queueId; //消息队列IDlong commitLogOffset; //消息物理偏移量int msgSize; //消息长度long tagsCode; //消息过滤tag hashCodelong storeTimestamp; //消息存储时间戳long consumeQueueOffset; //消息队列偏移量String keys; //消息索引keyboolean success; //是否成功解析到完整的消息String uniqKey; //消息唯一键int sysFlag; //消息系统标记long preparedTransactionOffset; //消息预处理事务偏移量Map&lt;String, String&gt; propertiesMap; //消息属性byte[] bitMap; //位图转发到ConsumerQueue12345678910111213141516class CommitLogDispatcherBuildConsumeQueue implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; final int tranType = MessageSysFlag.getTransactionValue(request.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: //消息分发 DefaultMessageStore.this.putMessagePositionInfo(request); break; case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: break; &#125; &#125;&#125;代码：DefaultMessageStore#putMessagePositionInfo123456public void putMessagePositionInfo(DispatchRequest dispatchRequest) &#123; //获得消费队列 ConsumeQueue cq = this.findConsumeQueue(dispatchRequest.getTopic(), dispatchRequest.getQueueId()); //消费队列分发消息 cq.putMessagePositionInfoWrapper(dispatchRequest);&#125;代码：DefaultMessageStore#putMessagePositionInfo123456789101112//依次将消息偏移量、消息长度、tag写入到ByteBuffer中this.byteBufferIndex.flip();this.byteBufferIndex.limit(CQ_STORE_UNIT_SIZE);this.byteBufferIndex.putLong(offset);this.byteBufferIndex.putInt(size);this.byteBufferIndex.putLong(tagsCode);//获得内存映射文件MappedFile mappedFile = this.mappedFileQueue.getLastMappedFile(expectLogicOffset);if (mappedFile != null) &#123; //将消息追加到内存映射文件,异步输盘 return mappedFile.appendMessage(this.byteBufferIndex.array());&#125;转发到Index123456789class CommitLogDispatcherBuildIndex implements CommitLogDispatcher &#123; @Override public void dispatch(DispatchRequest request) &#123; if (DefaultMessageStore.this.messageStoreConfig.isMessageIndexEnable()) &#123; DefaultMessageStore.this.indexService.buildIndex(request); &#125; &#125;&#125;代码：DefaultMessageStore#buildIndex12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void buildIndex(DispatchRequest req) &#123; //获得索引文件 IndexFile indexFile = retryGetAndCreateIndexFile(); if (indexFile != null) &#123; //获得文件最大物理偏移量 long endPhyOffset = indexFile.getEndPhyOffset(); DispatchRequest msg = req; String topic = msg.getTopic(); String keys = msg.getKeys(); //如果该消息的物理偏移量小于索引文件中的最大物理偏移量,则说明是重复数据,忽略本次索引构建 if (msg.getCommitLogOffset() &lt; endPhyOffset) &#123; return; &#125; final int tranType = MessageSysFlag.getTransactionValue(msg.getSysFlag()); switch (tranType) &#123; case MessageSysFlag.TRANSACTION_NOT_TYPE: case MessageSysFlag.TRANSACTION_PREPARED_TYPE: case MessageSysFlag.TRANSACTION_COMMIT_TYPE: break; case MessageSysFlag.TRANSACTION_ROLLBACK_TYPE: return; &#125; //如果消息ID不为空,则添加到Hash索引中 if (req.getUniqKey() != null) &#123; indexFile = putKey(indexFile, msg, buildKey(topic, req.getUniqKey())); if (indexFile == null) &#123; return; &#125; &#125; //构建索引key,RocketMQ支持为同一个消息建立多个索引,多个索引键空格隔开. if (keys != null &amp;&amp; keys.length() &gt; 0) &#123; String[] keyset = keys.split(MessageConst.KEY_SEPARATOR); for (int i = 0; i &lt; keyset.length; i++) &#123; String key = keyset[i]; if (key.length() &gt; 0) &#123; indexFile = putKey(indexFile, msg, buildKey(topic, key)); if (indexFile == null) &#123; return; &#125; &#125; &#125; &#125; &#125; else &#123; log.error(\"build index error, stop building index\"); &#125;&#125;消息队列和索引文件恢复由于RocketMQ存储首先将消息全量存储在CommitLog文件中，然后异步生成转发任务更新ConsumerQueue和Index文件。如果消息成功存储到CommitLog文件中，转发任务未成功执行，此时消息服务器Broker由于某个愿意宕机，导致CommitLog、ConsumerQueue、IndexFile文件数据不一致。如果不加以人工修复的话，会有一部分消息即便在CommitLog中文件中存在，但由于没有转发到ConsumerQueue，这部分消息将永远复发被消费者消费。存储文件加载代码：DefaultMessageStore#load判断上一次是否异常退出。实现机制是Broker在启动时创建abort文件，在退出时通过JVM钩子函数删除abort文件。如果下次启动时存在abort文件。说明Broker时异常退出的，CommitLog与ConsumerQueue数据有可能不一致，需要进行修复。123456789//判断临时文件是否存在boolean lastExitOK = !this.isTempFileExist();//根据临时文件判断当前Broker是否异常退出private boolean isTempFileExist() &#123; String fileName = StorePathConfigHelper .getAbortFile(this.messageStoreConfig.getStorePathRootDir()); File file = new File(fileName); return file.exists();&#125;代码：DefaultMessageStore#load12345678910111213141516171819//加载延时队列if (null != scheduleMessageService) &#123; result = result &amp;&amp; this.scheduleMessageService.load();&#125;// 加载CommitLog文件result = result &amp;&amp; this.commitLog.load();// 加载消费队列文件result = result &amp;&amp; this.loadConsumeQueue();if (result) &#123; //加载存储监测点,监测点主要记录CommitLog文件、ConsumerQueue文件、Index索引文件的刷盘点 this.storeCheckpoint =new StoreCheckpoint(StorePathConfigHelper.getStoreCheckpoint(this.messageStoreConfig.getStorePathRootDir())); //加载index文件 this.indexService.load(lastExitOK); //根据Broker是否异常退出,执行不同的恢复策略 this.recover(lastExitOK);&#125;代码：MappedFileQueue#load加载CommitLog到映射文件1234567891011121314151617181920212223242526272829303132//指向CommitLog文件目录File dir = new File(this.storePath);//获得文件数组File[] files = dir.listFiles();if (files != null) &#123; // 文件排序 Arrays.sort(files); //遍历文件 for (File file : files) &#123; //如果文件大小和配置文件不一致,退出 if (file.length() != this.mappedFileSize) &#123; return false; &#125; try &#123; //创建映射文件 MappedFile mappedFile = new MappedFile(file.getPath(), mappedFileSize); mappedFile.setWrotePosition(this.mappedFileSize); mappedFile.setFlushedPosition(this.mappedFileSize); mappedFile.setCommittedPosition(this.mappedFileSize); //将映射文件添加到队列 this.mappedFiles.add(mappedFile); log.info(\"load \" + file.getPath() + \" OK\"); &#125; catch (IOException e) &#123; log.error(\"load file \" + file + \" error\", e); return false; &#125; &#125;&#125;return true;代码：DefaultMessageStore#loadConsumeQueue加载消息消费队列12345678910111213141516171819202122232425262728293031323334353637383940//执行消费队列目录File dirLogic = new File(StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()));//遍历消费队列目录File[] fileTopicList = dirLogic.listFiles();if (fileTopicList != null) &#123; for (File fileTopic : fileTopicList) &#123; //获得子目录名称,即topic名称 String topic = fileTopic.getName(); //遍历子目录下的消费队列文件 File[] fileQueueIdList = fileTopic.listFiles(); if (fileQueueIdList != null) &#123; //遍历文件 for (File fileQueueId : fileQueueIdList) &#123; //文件名称即队列ID int queueId; try &#123; queueId = Integer.parseInt(fileQueueId.getName()); &#125; catch (NumberFormatException e) &#123; continue; &#125; //创建消费队列并加载到内存 ConsumeQueue logic = new ConsumeQueue( topic, queueId, StorePathConfigHelper.getStorePathConsumeQueue(this.messageStoreConfig.getStorePathRootDir()), this.getMessageStoreConfig().getMapedFileSizeConsumeQueue(), this); this.putConsumeQueue(topic, queueId, logic); if (!logic.load()) &#123; return false; &#125; &#125; &#125; &#125;&#125;log.info(\"load logics queue all over, OK\");return true;代码：IndexService#load加载索引文件12345678910111213141516171819202122232425262728293031323334353637public boolean load(final boolean lastExitOK) &#123; //索引文件目录 File dir = new File(this.storePath); //遍历索引文件 File[] files = dir.listFiles(); if (files != null) &#123; //文件排序 Arrays.sort(files); //遍历文件 for (File file : files) &#123; try &#123; //加载索引文件 IndexFile f = new IndexFile(file.getPath(), this.hashSlotNum, this.indexNum, 0, 0); f.load(); if (!lastExitOK) &#123; //索引文件上次的刷盘时间小于该索引文件的消息时间戳,该文件将立即删除 if (f.getEndTimestamp() &gt; this.defaultMessageStore.getStoreCheckpoint() .getIndexMsgTimestamp()) &#123; f.destroy(0); continue; &#125; &#125; //将索引文件添加到队列 log.info(\"load index file OK, \" + f.getFileName()); this.indexFileList.add(f); &#125; catch (IOException e) &#123; log.error(\"load file &#123;&#125; error\", file, e); return false; &#125; catch (NumberFormatException e) &#123; log.error(\"load file &#123;&#125; error\", file, e); &#125; &#125; &#125; return true;&#125;代码：DefaultMessageStore#recover文件恢复，根据Broker是否正常退出执行不同的恢复策略1234567891011121314private void recover(final boolean lastExitOK) &#123; //获得最大的物理便宜消费队列 long maxPhyOffsetOfConsumeQueue = this.recoverConsumeQueue(); if (lastExitOK) &#123; //正常恢复 this.commitLog.recoverNormally(maxPhyOffsetOfConsumeQueue); &#125; else &#123; //异常恢复 this.commitLog.recoverAbnormally(maxPhyOffsetOfConsumeQueue); &#125; //在CommitLog中保存每个消息消费队列当前的存储逻辑偏移量 this.recoverTopicQueueTable();&#125;代码：DefaultMessageStore#recoverTopicQueueTable恢复ConsumerQueue后，将在CommitLog实例中保存每隔消息队列当前的存储逻辑偏移量，这也是消息中不仅存储主题、消息队列ID、还存储了消息队列的关键所在。1234567891011121314public void recoverTopicQueueTable() &#123; HashMap&lt;String/* topic-queueid */, Long/* offset */&gt; table = new HashMap&lt;String, Long&gt;(1024); //CommitLog最小偏移量 long minPhyOffset = this.commitLog.getMinOffset(); //遍历消费队列,将消费队列保存在CommitLog中 for (ConcurrentMap&lt;Integer, ConsumeQueue&gt; maps : this.consumeQueueTable.values()) &#123; for (ConsumeQueue logic : maps.values()) &#123; String key = logic.getTopic() + \"-\" + logic.getQueueId(); table.put(key, logic.getMaxOffsetInQueue()); logic.correctMinOffset(minPhyOffset); &#125; &#125; this.commitLog.setTopicQueueTable(table);&#125;正常恢复代码：CommitLog#recoverNormally123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public void recoverNormally(long maxPhyOffsetOfConsumeQueue) &#123; final List&lt;MappedFile&gt; mappedFiles = this.mappedFileQueue.getMappedFiles(); if (!mappedFiles.isEmpty()) &#123; //Broker正常停止再重启时,从倒数第三个开始恢复,如果不足3个文件,则从第一个文件开始恢复。 int index = mappedFiles.size() - 3; if (index &lt; 0) index = 0; MappedFile mappedFile = mappedFiles.get(index); ByteBuffer byteBuffer = mappedFile.sliceByteBuffer(); long processOffset = mappedFile.getFileFromOffset(); //代表当前已校验通过的offset long mappedFileOffset = 0; while (true) &#123; //查找消息 DispatchRequest dispatchRequest = this.checkMessageAndReturnSize(byteBuffer, checkCRCOnRecover); //消息长度 int size = dispatchRequest.getMsgSize(); //查找结果为true,并且消息长度大于0,表示消息正确.mappedFileOffset向前移动本消息长度 if (dispatchRequest.isSuccess() &amp;&amp; size &gt; 0) &#123; mappedFileOffset += size; &#125; //如果查找结果为true且消息长度等于0,表示已到该文件末尾,如果还有下一个文件,则重置processOffset和MappedFileOffset重复查找下一个文件,否则跳出循环。 else if (dispatchRequest.isSuccess() &amp;&amp; size == 0) &#123; index++; if (index &gt;= mappedFiles.size()) &#123; // Current branch can not happen break; &#125; else &#123; //取出每个文件 mappedFile = mappedFiles.get(index); byteBuffer = mappedFile.sliceByteBuffer(); processOffset = mappedFile.getFileFromOffset(); mappedFileOffset = 0; &#125; &#125; // 查找结果为false，表明该文件未填满所有消息，跳出循环，结束循环 else if (!dispatchRequest.isSuccess()) &#123; log.info(\"recover physics file end, \" + mappedFile.getFileName()); break; &#125; &#125; //更新MappedFileQueue的flushedWhere和committedWhere指针 processOffset += mappedFileOffset; this.mappedFileQueue.setFlushedWhere(processOffset); this.mappedFileQueue.setCommittedWhere(processOffset); //删除offset之后的所有文件 this.mappedFileQueue.truncateDirtyFiles(processOffset); if (maxPhyOffsetOfConsumeQueue &gt;= processOffset) &#123; this.defaultMessageStore.truncateDirtyLogicFiles(processOffset); &#125; &#125; else &#123; this.mappedFileQueue.setFlushedWhere(0); this.mappedFileQueue.setCommittedWhere(0); this.defaultMessageStore.destroyLogics(); &#125;&#125;代码：MappedFileQueue#truncateDirtyFiles123456789101112131415161718192021222324public void truncateDirtyFiles(long offset) &#123; List&lt;MappedFile&gt; willRemoveFiles = new ArrayList&lt;MappedFile&gt;(); //遍历目录下文件 for (MappedFile file : this.mappedFiles) &#123; //文件尾部的偏移量 long fileTailOffset = file.getFileFromOffset() + this.mappedFileSize; //文件尾部的偏移量大于offset if (fileTailOffset &gt; offset) &#123; //offset大于文件的起始偏移量 if (offset &gt;= file.getFileFromOffset()) &#123; //更新wrotePosition、committedPosition、flushedPosistion file.setWrotePosition((int) (offset % this.mappedFileSize)); file.setCommittedPosition((int) (offset % this.mappedFileSize)); file.setFlushedPosition((int) (offset % this.mappedFileSize)); &#125; else &#123; //offset小于文件的起始偏移量,说明该文件是有效文件后面创建的,释放mappedFile占用内存,删除文件 file.destroy(1000); willRemoveFiles.add(file); &#125; &#125; &#125; this.deleteExpiredFile(willRemoveFiles);&#125;异常恢复Broker异常停止文件恢复的实现为CommitLog#recoverAbnormally。异常文件恢复步骤与正常停止文件恢复流程基本相同，其主要差别有两个。首先，正常停止默认从倒数第三个文件开始进行恢复，而异常停止则需要从最后一个文件往前走，找到第一个消息存储正常的文件。其次，如果CommitLog目录没有消息文件，如果消息消费队列目录下存在文件，则需要销毁。代码：CommitLog#recoverAbnormally12345678910111213141516171819202122232425if (!mappedFiles.isEmpty()) &#123; // Looking beginning to recover from which file int index = mappedFiles.size() - 1; MappedFile mappedFile = null; for (; index &gt;= 0; index--) &#123; mappedFile = mappedFiles.get(index); //判断消息文件是否是一个正确的文件 if (this.isMappedFileMatchedRecover(mappedFile)) &#123; log.info(\"recover from this mapped file \" + mappedFile.getFileName()); break; &#125; &#125; //根据索引取出mappedFile文件 if (index &lt; 0) &#123; index = 0; mappedFile = mappedFiles.get(index); &#125; //...验证消息的合法性,并将消息转发到消息消费队列和索引文件 &#125;else&#123; //未找到mappedFile,重置flushWhere、committedWhere都为0，销毁消息队列文件 this.mappedFileQueue.setFlushedWhere(0); this.mappedFileQueue.setCommittedWhere(0); this.defaultMessageStore.destroyLogics();&#125;刷盘机制RocketMQ的存储是基于JDK NIO的内存映射机制（MappedByteBuffer）的，消息存储首先将消息追加到内存，再根据配置的刷盘策略在不同时间进行刷写磁盘。同步刷盘消息追加到内存后，立即将数据刷写到磁盘文件代码：CommitLog#handleDiskFlush123456789101112//刷盘服务final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;if (messageExt.isWaitStoreMsgOK()) &#123; //封装刷盘请求 GroupCommitRequest request = new GroupCommitRequest(result.getWroteOffset() + result.getWroteBytes()); //提交刷盘请求 service.putRequest(request); //线程阻塞5秒，等待刷盘结束 boolean flushOK = request.waitForFlush(this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout()); if (!flushOK) &#123; putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH_DISK_TIMEOUT); &#125;GroupCommitRequest123long nextOffset; //刷盘点偏移量CountDownLatch countDownLatch = new CountDownLatch(1); //倒计树锁存器volatile boolean flushOK = false; //刷盘结果;默认为false代码：GroupCommitService#run123456789101112131415public void run() &#123; CommitLog.log.info(this.getServiceName() + \" service started\"); while (!this.isStopped()) &#123; try &#123; //线程等待10ms this.waitForRunning(10); //执行提交 this.doCommit(); &#125; catch (Exception e) &#123; CommitLog.log.warn(this.getServiceName() + \" service has exception. \", e); &#125; &#125; ...&#125;代码：GroupCommitService#doCommit123456789101112131415161718192021222324252627282930313233private void doCommit() &#123; //加锁 synchronized (this.requestsRead) &#123; if (!this.requestsRead.isEmpty()) &#123; //遍历requestsRead for (GroupCommitRequest req : this.requestsRead) &#123; // There may be a message in the next file, so a maximum of // two times the flush boolean flushOK = false; for (int i = 0; i &lt; 2 &amp;&amp; !flushOK; i++) &#123; flushOK = CommitLog.this.mappedFileQueue.getFlushedWhere() &gt;= req.getNextOffset(); //刷盘 if (!flushOK) &#123; CommitLog.this.mappedFileQueue.flush(0); &#125; &#125; //唤醒发送消息客户端 req.wakeupCustomer(flushOK); &#125; //更新刷盘监测点 long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp(); if (storeTimestamp &gt; 0) &#123; CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp); &#125; this.requestsRead.clear(); &#125; else &#123; // Because of individual messages is set to not sync flush, it // will come to this process CommitLog.this.mappedFileQueue.flush(0); &#125; &#125;&#125;异步刷盘在消息追加到内存后，立即返回给消息发送端。如果开启transientStorePoolEnable，RocketMQ会单独申请一个与目标物理文件（commitLog）同样大小的堆外内存，该堆外内存将使用内存锁定，确保不会被置换到虚拟内存中去，消息首先追加到堆外内存，然后提交到物理文件的内存映射中，然后刷写到磁盘。如果未开启transientStorePoolEnable，消息直接追加到物理文件直接映射文件中，然后刷写到磁盘中。开启transientStorePoolEnable后异步刷盘步骤:将消息直接追加到ByteBuffer（堆外内存）CommitRealTimeService线程每隔200ms将ByteBuffer新追加内容提交到MappedByteBuffer中MappedByteBuffer在内存中追加提交的内容，wrotePosition指针向后移动commit操作成功返回，将committedPosition位置恢复FlushRealTimeService线程默认每500ms将MappedByteBuffer中新追加的内存刷写到磁盘代码：CommitLog$CommitRealTimeService#run提交线程工作机制12345678910111213141516171819202122232425262728293031//间隔时间,默认200msint interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitIntervalCommitLog();//一次提交的至少页数int commitDataLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogLeastPages();//两次真实提交的最大间隔,默认200msint commitDataThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getCommitCommitLogThoroughInterval();//上次提交间隔超过commitDataThoroughInterval,则忽略提交commitDataThoroughInterval参数,直接提交long begin = System.currentTimeMillis();if (begin &gt;= (this.lastCommitTimestamp + commitDataThoroughInterval)) &#123; this.lastCommitTimestamp = begin; commitDataLeastPages = 0;&#125;//执行提交操作,将待提交数据提交到物理文件的内存映射区boolean result = CommitLog.this.mappedFileQueue.commit(commitDataLeastPages);long end = System.currentTimeMillis();if (!result) &#123; this.lastCommitTimestamp = end; // result = false means some data committed. //now wake up flush thread. //唤醒刷盘线程 flushCommitLogService.wakeup();&#125;if (end - begin &gt; 500) &#123; log.info(\"Commit data to file costs &#123;&#125; ms\", end - begin);&#125;this.waitForRunning(interval);代码：CommitLog$FlushRealTimeService#run刷盘线程工作机制1234567891011121314151617181920212223242526272829303132//表示await方法等待,默认falseboolean flushCommitLogTimed = CommitLog.this.defaultMessageStore.getMessageStoreConfig().isFlushCommitLogTimed();//线程执行时间间隔int interval = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushIntervalCommitLog();//一次刷写任务至少包含页数int flushPhysicQueueLeastPages = CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogLeastPages();//两次真实刷写任务最大间隔int flushPhysicQueueThoroughInterval =CommitLog.this.defaultMessageStore.getMessageStoreConfig().getFlushCommitLogThoroughInterval();...//距离上次提交间隔超过flushPhysicQueueThoroughInterval,则本次刷盘任务将忽略flushPhysicQueueLeastPages,直接提交long currentTimeMillis = System.currentTimeMillis();if (currentTimeMillis &gt;= (this.lastFlushTimestamp + flushPhysicQueueThoroughInterval)) &#123; this.lastFlushTimestamp = currentTimeMillis; flushPhysicQueueLeastPages = 0; printFlushProgress = (printTimes++ % 10) == 0;&#125;...//执行一次刷盘前,先等待指定时间间隔if (flushCommitLogTimed) &#123; Thread.sleep(interval);&#125; else &#123; this.waitForRunning(interval);&#125;...long begin = System.currentTimeMillis();//刷写磁盘CommitLog.this.mappedFileQueue.flush(flushPhysicQueueLeastPages);long storeTimestamp = CommitLog.this.mappedFileQueue.getStoreTimestamp();if (storeTimestamp &gt; 0) &#123;//更新存储监测点文件的时间戳CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);过期文件删除机制由于RocketMQ操作CommitLog、ConsumerQueue文件是基于内存映射机制并在启动的时候回加载CommitLog、ConsumerQueue目录下的所有文件，为了避免内存与磁盘的浪费，不可能将消息永久存储在消息服务器上，所以要引入一种机制来删除已过期的文件。RocketMQ顺序写CommitLog、ConsumerQueue文件，所有写操作全部落在最后一个CommitLog或者ConsumerQueue文件上，之前的文件在下一个文件创建后将不会再被更新。RocketMQ清除过期文件的方法时：如果当前文件在在一定时间间隔内没有再次被消费，则认为是过期文件，可以被删除，RocketMQ不会关注这个文件上的消息是否全部被消费。默认每个文件的过期时间为72小时，通过在Broker配置文件中设置fileReservedTime来改变过期时间，单位为小时。代码：DefaultMessageStore#addScheduleTask12345678910private void addScheduleTask() &#123; //每隔10s调度一次清除文件 this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; DefaultMessageStore.this.cleanFilesPeriodically(); &#125; &#125;, 1000 * 60, this.messageStoreConfig.getCleanResourceInterval(), TimeUnit.MILLISECONDS); ...&#125;代码：DefaultMessageStore#cleanFilesPeriodically123456private void cleanFilesPeriodically() &#123; //清除存储文件 this.cleanCommitLogService.run(); //清除消息消费队列文件 this.cleanConsumeQueueService.run();&#125;代码：DefaultMessageStore#deleteExpiredFiles123456789101112131415161718private void deleteExpiredFiles() &#123; //删除的数量 int deleteCount = 0; //文件保留的时间 long fileReservedTime = DefaultMessageStore.this.getMessageStoreConfig().getFileReservedTime(); //删除物理文件的间隔 int deletePhysicFilesInterval = DefaultMessageStore.this.getMessageStoreConfig().getDeleteCommitLogFilesInterval(); //线程被占用,第一次拒绝删除后能保留的最大时间,超过该时间,文件将被强制删除 int destroyMapedFileIntervalForcibly = DefaultMessageStore.this.getMessageStoreConfig().getDestroyMapedFileIntervalForcibly();boolean timeup = this.isTimeToDelete();boolean spacefull = this.isSpaceToDelete();boolean manualDelete = this.manualDeleteFileSeveralTimes &gt; 0;if (timeup || spacefull || manualDelete) &#123; ...执行删除逻辑&#125;else&#123; ...无作为&#125;删除文件操作的条件指定删除文件的时间点，RocketMQ通过deleteWhen设置一天的固定时间执行一次删除过期文件操作，默认4点磁盘空间如果不充足，删除过期文件预留，手工触发。代码：CleanCommitLogService#isSpaceToDelete当磁盘空间不足时执行删除过期文件1234567891011121314151617181920212223242526272829303132private boolean isSpaceToDelete() &#123; //磁盘分区的最大使用量 double ratio = DefaultMessageStore.this.getMessageStoreConfig().getDiskMaxUsedSpaceRatio() / 100.0; //是否需要立即执行删除过期文件操作 cleanImmediately = false; &#123; String storePathPhysic = DefaultMessageStore.this.getMessageStoreConfig().getStorePathCommitLog(); //当前CommitLog目录所在的磁盘分区的磁盘使用率 double physicRatio = UtilAll.getDiskPartitionSpaceUsedPercent(storePathPhysic); //diskSpaceWarningLevelRatio:磁盘使用率警告阈值,默认0.90 if (physicRatio &gt; diskSpaceWarningLevelRatio) &#123; boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskFull(); if (diskok) &#123; DefaultMessageStore.log.error(\"physic disk maybe full soon \" + physicRatio + \", so mark disk full\"); &#125; //diskSpaceCleanForciblyRatio:强制清除阈值,默认0.85 cleanImmediately = true; &#125; else if (physicRatio &gt; diskSpaceCleanForciblyRatio) &#123; cleanImmediately = true; &#125; else &#123; boolean diskok = DefaultMessageStore.this.runningFlags.getAndMakeDiskOK(); if (!diskok) &#123; DefaultMessageStore.log.info(\"physic disk space OK \" + physicRatio + \", so mark disk ok\"); &#125; &#125; if (physicRatio &lt; 0 || physicRatio &gt; ratio) &#123; DefaultMessageStore.log.info(\"physic disk maybe full soon, so reclaim space, \" + physicRatio); return true; &#125;&#125;代码：MappedFileQueue#deleteExpiredFileByTime执行文件销毁和删除1234567891011121314151617181920212223242526272829for (int i = 0; i &lt; mfsLength; i++) &#123; //遍历每隔文件 MappedFile mappedFile = (MappedFile) mfs[i]; //计算文件存活时间 long liveMaxTimestamp = mappedFile.getLastModifiedTimestamp() + expiredTime; //如果超过72小时,执行文件删除 if (System.currentTimeMillis() &gt;= liveMaxTimestamp || cleanImmediately) &#123; if (mappedFile.destroy(intervalForcibly)) &#123; files.add(mappedFile); deleteCount++; if (files.size() &gt;= DELETE_FILES_BATCH_MAX) &#123; break; &#125; if (deleteFilesInterval &gt; 0 &amp;&amp; (i + 1) &lt; mfsLength) &#123; try &#123; Thread.sleep(deleteFilesInterval); &#125; catch (InterruptedException e) &#123; &#125; &#125; &#125; else &#123; break; &#125; &#125; else &#123; //avoid deleting files in the middle break; &#125;&#125;小结RocketMQ的存储文件包括消息文件（Commitlog）、消息消费队列文件（ConsumerQueue）、Hash索引文件（IndexFile）、监测点文件（checkPoint）、abort（关闭异常文件）。单个消息存储文件、消息消费队列文件、Hash索引文件长度固定以便使用内存映射机制进行文件的读写操作。RocketMQ组织文件以文件的起始偏移量来命令文件，这样根据偏移量能快速定位到真实的物理文件。RocketMQ基于内存映射文件机制提供了同步刷盘和异步刷盘两种机制，异步刷盘是指在消息存储时先追加到内存映射文件，然后启动专门的刷盘线程定时将内存中的文件数据刷写到磁盘。CommitLog，消息存储文件，RocketMQ为了保证消息发送的高吞吐量，采用单一文件存储所有主题消息，保证消息存储是完全的顺序写，但这样给文件读取带来了不便，为此RocketMQ为了方便消息消费构建了消息消费队列文件，基于主题与队列进行组织，同时RocketMQ为消息实现了Hash索引，可以为消息设置索引键，根据所以能够快速从CommitLog文件中检索消息。当消息达到CommitLog后，会通过ReputMessageService线程接近实时地将消息转发给消息消费队列文件与索引文件。为了安全起见，RocketMQ引入abort文件，记录Broker的停机是否是正常关闭还是异常关闭，在重启Broker时为了保证CommitLog文件，消息消费队列文件与Hash索引文件的正确性，分别采用不同策略来恢复文件。RocketMQ不会永久存储消息文件、消息消费队列文件，而是启动文件过期机制并在磁盘空间不足或者默认凌晨4点删除过期文件，文件保存72小时并且在删除文件时并不会判断该消息文件上的消息是否被消费。Consumer消息消费概述消息消费以组的模式开展，一个消费组内可以包含多个消费者，每一个消费者组可订阅多个主题，消费组之间有ff式和广播模式两种消费模式。集群模式，主题下的同一条消息只允许被其中一个消费者消费。广播模式，主题下的同一条消息，将被集群内的所有消费者消费一次。消息服务器与消费者之间的消息传递也有两种模式：推模式、拉模式。所谓的拉模式，是消费端主动拉起拉消息请求，而推模式是消息达到消息服务器后，推送给消息消费者。RocketMQ消息推模式的实现基于拉模式，在拉模式上包装一层，一个拉取任务完成后开始下一个拉取任务。集群模式下，多个消费者如何对消息队列进行负载呢？消息队列负载机制遵循一个通用思想：一个消息队列同一个时间只允许被一个消费者消费，一个消费者可以消费多个消息队列。RocketMQ支持局部顺序消息消费，也就是保证同一个消息队列上的消息顺序消费。不支持消息全局顺序消费，如果要实现某一个主题的全局顺序消费，可以将该主题的队列数设置为1，牺牲高可用性。消息消费初探消息推送模式消息消费重要方法12345678void sendMessageBack(final MessageExt msg, final int delayLevel, final String brokerName)：发送消息确认Set&lt;MessageQueue&gt; fetchSubscribeMessageQueues(final String topic) :获取消费者对主题分配了那些消息队列void registerMessageListener(final MessageListenerConcurrently messageListener)：注册并发事件监听器void registerMessageListener(final MessageListenerOrderly messageListener)：注册顺序消息事件监听器void subscribe(final String topic, final String subExpression)：基于主题订阅消息，消息过滤使用表达式void subscribe(final String topic, final String fullClassName,final String filterClassSource)：基于主题订阅消息，消息过滤使用类模式void subscribe(final String topic, final MessageSelector selector) ：订阅消息，并指定队列选择器void unsubscribe(final String topic)：取消消息订阅DefaultMQPushConsumer12345678910111213141516171819202122232425262728293031323334//消费者组private String consumerGroup; //消息消费模式private MessageModel messageModel = MessageModel.CLUSTERING; //指定消费开始偏移量（最大偏移量、最小偏移量、启动时间戳）开始消费private ConsumeFromWhere consumeFromWhere = ConsumeFromWhere.CONSUME_FROM_LAST_OFFSET;//集群模式下的消息队列负载策略private AllocateMessageQueueStrategy allocateMessageQueueStrategy;//订阅信息private Map&lt;String /* topic */, String /* sub expression */&gt; subscription = new HashMap&lt;String, String&gt;();//消息业务监听器private MessageListener messageListener;//消息消费进度存储器private OffsetStore offsetStore;//消费者最小线程数量private int consumeThreadMin = 20;//消费者最大线程数量private int consumeThreadMax = 20;//并发消息消费时处理队列最大跨度private int consumeConcurrentlyMaxSpan = 2000;//每1000次流控后打印流控日志private int pullThresholdForQueue = 1000;//推模式下任务间隔时间private long pullInterval = 0;//推模式下任务拉取的条数,默认32条private int pullBatchSize = 32;//每次传入MessageListener#consumerMessage中消息的数量private int consumeMessageBatchMaxSize = 1;//是否每次拉取消息都订阅消息private boolean postSubscriptionWhenPull = false;//消息重试次数,-1代表16次private int maxReconsumeTimes = -1;//消息消费超时时间private long consumeTimeout = 15;消费者启动流程代码：DefaultMQPushConsumerImpl#start12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public synchronized void start() throws MQClientException &#123; switch (this.serviceState) &#123; case CREATE_JUST: this.defaultMQPushConsumer.getMessageModel(), this.defaultMQPushConsumer.isUnitMode()); this.serviceState = ServiceState.START_FAILED; //检查消息者是否合法 this.checkConfig(); //构建主题订阅信息 this.copySubscription(); //设置消费者客户端实例名称为进程ID if (this.defaultMQPushConsumer.getMessageModel() == MessageModel.CLUSTERING) &#123; this.defaultMQPushConsumer.changeInstanceNameToPID(); &#125; //创建MQClient实例 this.mQClientFactory = MQClientManager.getInstance().getAndCreateMQClientInstance(this.defaultMQPushConsumer, this.rpcHook); //构建rebalanceImpl this.rebalanceImpl.setConsumerGroup(this.defaultMQPushConsumer.getConsumerGroup()); this.rebalanceImpl.setMessageModel(this.defaultMQPushConsumer.getMessageModel()); this.rebalanceImpl.setAllocateMessageQueueStrategy(this.defaultMQPushConsumer.getAllocateMessageQueueStrategy()); this.rebalanceImpl.setmQClientFactory(this.mQClientFactor this.pullAPIWrapper = new PullAPIWrapper( mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup(), isUnitMode()); this.pullAPIWrapper.registerFilterMessageHook(filterMessageHookLis if (this.defaultMQPushConsumer.getOffsetStore() != null) &#123; this.offsetStore = this.defaultMQPushConsumer.getOffsetStore(); &#125; else &#123; switch (this.defaultMQPushConsumer.getMessageModel()) &#123; case BROADCASTING: //消息消费广播模式,将消费进度保存在本地 this.offsetStore = new LocalFileOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; case CLUSTERING: //消息消费集群模式,将消费进度保存在远端Broker this.offsetStore = new RemoteBrokerOffsetStore(this.mQClientFactory, this.defaultMQPushConsumer.getConsumerGroup()); break; default: break; &#125; this.defaultMQPushConsumer.setOffsetStore(this.offsetStore); &#125; this.offsetStore.load //创建顺序消息消费服务 if (this.getMessageListenerInner() instanceof MessageListenerOrderly) &#123; this.consumeOrderly = true; this.consumeMessageService = new ConsumeMessageOrderlyService(this, (MessageListenerOrderly) this.getMessageListenerInner()); //创建并发消息消费服务 &#125; else if (this.getMessageListenerInner() instanceof MessageListenerConcurrently) &#123; this.consumeOrderly = false; this.consumeMessageService = new ConsumeMessageConcurrentlyService(this, (MessageListenerConcurrently) this.getMessageListenerInner()); &#125; //消息消费服务启动 this.consumeMessageService.start(); //注册消费者实例 boolean registerOK = mQClientFactory.registerConsumer(this.defaultMQPushConsumer.getConsumerGroup(), this); if (!registerOK) &#123; this.serviceState = ServiceState.CREATE_JUST; this.consumeMessageService.shutdown(); throw new MQClientException(\"The consumer group[\" + this.defaultMQPushConsumer.getConsumerGroup() + \"] has been created before, specify another name please.\" + FAQUrl.suggestTodo(FAQUrl.GROUP_NAME_DUPLICATE_URL), null); //启动消费者客户端 mQClientFactory.start(); log.info(\"the consumer [&#123;&#125;] start OK.\", this.defaultMQPushConsumer.getConsumerGroup()); this.serviceState = ServiceState.RUNNING; break; case RUNNING: case START_FAILED: case SHUTDOWN_ALREADY: throw new MQClientException(\"The PushConsumer service state not OK, maybe started once, \" + this.serviceState + FAQUrl.suggestTodo(FAQUrl.CLIENT_SERVICE_NOT_OK), null); default: break; &#125; this.updateTopicSubscribeInfoWhenSubscriptionChanged(); this.mQClientFactory.checkClientInBroker(); this.mQClientFactory.sendHeartbeatToAllBrokerWithLock(); this.mQClientFactory.rebalanceImmediately();&#125;消息拉取消息消费模式有两种模式：广播模式与集群模式。广播模式比较简单，每一个消费者需要拉取订阅主题下所有队列的消息。本文重点讲解集群模式。在集群模式下，同一个消费者组内有多个消息消费者，同一个主题存在多个消费队列，消费者通过负载均衡的方式消费消息。消息队列负载均衡，通常的作法是一个消息队列在同一个时间只允许被一个消费消费者消费，一个消息消费者可以同时消费多个消息队列。PullMessageService实现机制从MQClientInstance的启动流程中可以看出，RocketMQ使用一个单独的线程PullMessageService来负责消息的拉取。代码：PullMessageService#run1234567891011121314151617public void run() &#123; log.info(this.getServiceName() + \" service started\"); //循环拉取消息 while (!this.isStopped()) &#123; try &#123; //从请求队列中获取拉取消息请求 PullRequest pullRequest = this.pullRequestQueue.take(); //拉取消息 this.pullMessage(pullRequest); &#125; catch (InterruptedException ignored) &#123; &#125; catch (Exception e) &#123; log.error(\"Pull Message Service Run Method exception\", e); &#125; &#125; log.info(this.getServiceName() + \" service end\");&#125;PullRequest12345private String consumerGroup; //消费者组private MessageQueue messageQueue; //待拉取消息队列private ProcessQueue processQueue; //消息处理队列private long nextOffset; //待拉取的MessageQueue偏移量private boolean lockedFirst = false; //是否被锁定代码：PullMessageService#pullMessage123456789101112private void pullMessage(final PullRequest pullRequest) &#123; //获得消费者实例 final MQConsumerInner consumer = this.mQClientFactory.selectConsumer(pullRequest.getConsumerGroup()); if (consumer != null) &#123; //强转为推送模式消费者 DefaultMQPushConsumerImpl impl = (DefaultMQPushConsumerImpl) consumer; //推送消息 impl.pullMessage(pullRequest); &#125; else &#123; log.warn(\"No matched consumer for the PullRequest &#123;&#125;, drop it\", pullRequest); &#125;&#125;####2）ProcessQueue实现机制ProcessQueue是MessageQueue在消费端的重现、快照。PullMessageService从消息服务器默认每次拉取32条消息，按照消息的队列偏移量顺序存放在ProcessQueue中，PullMessageService然后将消息提交到消费者消费线程池，消息成功消费后从ProcessQueue中移除。属性1234567891011121314//消息容器private final TreeMap&lt;Long, MessageExt&gt; msgTreeMap = new TreeMap&lt;Long, MessageExt&gt;();//读写锁private final ReadWriteLock lockTreeMap = new ReentrantReadWriteLock();//ProcessQueue总消息树private final AtomicLong msgCount = new AtomicLong();//ProcessQueue队列最大偏移量private volatile long queueOffsetMax = 0L;//当前ProcessQueue是否被丢弃private volatile boolean dropped = false;//上一次拉取时间戳private volatile long lastPullTimestamp = System.currentTimeMillis();//上一次消费时间戳private volatile long lastConsumeTimestamp = System.currentTimeMillis();方法12345678910111213141516//移除消费超时消息public void cleanExpiredMsg(DefaultMQPushConsumer pushConsumer)//添加消息public boolean putMessage(final List&lt;MessageExt&gt; msgs)//获取消息最大间隔public long getMaxSpan()//移除消息public long removeMessage(final List&lt;MessageExt&gt; msgs)//将consumingMsgOrderlyTreeMap中消息重新放在msgTreeMap,并清空consumingMsgOrderlyTreeMap public void rollback() //将consumingMsgOrderlyTreeMap消息清除,表示成功处理该批消息public long commit()//重新处理该批消息public void makeMessageToCosumeAgain(List&lt;MessageExt&gt; msgs) //从processQueue中取出batchSize条消息public List&lt;MessageExt&gt; takeMessags(final int batchSize)消息拉取基本流程客户端发起拉取请求代码：DefaultMQPushConsumerImpl#pullMessage1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071public void pullMessage(final PullRequest pullRequest) &#123; //从pullRequest获得ProcessQueue final ProcessQueue processQueue = pullRequest.getProcessQueue(); //如果处理队列被丢弃,直接返回 if (processQueue.isDropped()) &#123; log.info(\"the pull request[&#123;&#125;] is dropped.\", pullRequest.toString()); return; &#125; //如果处理队列未被丢弃,更新时间戳 pullRequest.getProcessQueue().setLastPullTimestamp(System.currentTimeMillis()); try &#123; this.makeSureStateOK(); &#125; catch (MQClientException e) &#123; log.warn(\"pullMessage exception, consumer state not ok\", e); this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION); return; &#125; //如果处理队列被挂起,延迟1s后再执行 if (this.isPause()) &#123; log.warn(\"consumer was paused, execute pull request later. instanceName=&#123;&#125;, group=&#123;&#125;\", this.defaultMQPushConsumer.getInstanceName(), this.defaultMQPushConsumer.getConsumerGroup()); this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_SUSPEND); return; &#125; //获得最大待处理消息数量 long cachedMessageCount = processQueue.getMsgCount().get(); //获得最大待处理消息大小 long cachedMessageSizeInMiB = processQueue.getMsgSize().get() / (1024 * 1024); //从数量进行流控 if (cachedMessageCount &gt; this.defaultMQPushConsumer.getPullThresholdForQueue()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); if ((queueFlowControlTimes++ % 1000) == 0) &#123; log.warn( \"the cached message count exceeds the threshold &#123;&#125;, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;\", this.defaultMQPushConsumer.getPullThresholdForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes); &#125; return; &#125; //从消息大小进行流控 if (cachedMessageSizeInMiB &gt; this.defaultMQPushConsumer.getPullThresholdSizeForQueue()) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_FLOW_CONTROL); if ((queueFlowControlTimes++ % 1000) == 0) &#123; log.warn( \"the cached message size exceeds the threshold &#123;&#125; MiB, so do flow control, minOffset=&#123;&#125;, maxOffset=&#123;&#125;, count=&#123;&#125;, size=&#123;&#125; MiB, pullRequest=&#123;&#125;, flowControlTimes=&#123;&#125;\", this.defaultMQPushConsumer.getPullThresholdSizeForQueue(), processQueue.getMsgTreeMap().firstKey(), processQueue.getMsgTreeMap().lastKey(), cachedMessageCount, cachedMessageSizeInMiB, pullRequest, queueFlowControlTimes); &#125; return; &#125; //获得订阅信息 final SubscriptionData subscriptionData = this.rebalanceImpl.getSubscriptionInner().get(pullRequest.getMessageQueue().getTopic()); if (null == subscriptionData) &#123; this.executePullRequestLater(pullRequest, PULL_TIME_DELAY_MILLS_WHEN_EXCEPTION); log.warn(\"find the consumer's subscription failed, &#123;&#125;\", pullRequest); return; //与服务端交互,获取消息 this.pullAPIWrapper.pullKernelImpl( pullRequest.getMessageQueue(), subExpression, subscriptionData.getExpressionType(), subscriptionData.getSubVersion(), pullRequest.getNextOffset(), this.defaultMQPushConsumer.getPullBatchSize(), sysFlag, commitOffsetValue, BROKER_SUSPEND_MAX_TIME_MILLIS, CONSUMER_TIMEOUT_MILLIS_WHEN_SUSPEND, CommunicationMode.ASYNC, pullCallback ); &#125;消息服务端Broker组装消息代码：PullMessageProcessor#processRequest12345678910111213141516171819//构建消息过滤器MessageFilter messageFilter;if (this.brokerController.getBrokerConfig().isFilterSupportRetry()) &#123; messageFilter = new ExpressionForRetryMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager());&#125; else &#123; messageFilter = new ExpressionMessageFilter(subscriptionData, consumerFilterData, this.brokerController.getConsumerFilterManager());&#125;//调用MessageStore.getMessage查找消息final GetMessageResult getMessageResult = this.brokerController.getMessageStore().getMessage( requestHeader.getConsumerGroup(), //消费组名称 requestHeader.getTopic(), //主题名称 requestHeader.getQueueId(), //队列ID requestHeader.getQueueOffset(), //待拉取偏移量 requestHeader.getMaxMsgNums(), //最大拉取消息条数 messageFilter //消息过滤器 );代码：DefaultMessageStore#getMessage123456789101112131415161718192021222324252627282930313233GetMessageStatus status = GetMessageStatus.NO_MESSAGE_IN_QUEUE;long nextBeginOffset = offset; //查找下一次队列偏移量long minOffset = 0; //当前消息队列最小偏移量long maxOffset = 0; //当前消息队列最大偏移量GetMessageResult getResult = new GetMessageResult();final long maxOffsetPy = this.commitLog.getMaxOffset(); //当前commitLog最大偏移量//根据主题名称和队列编号获取消息消费队列ConsumeQueue consumeQueue = findConsumeQueue(topic, queueId);...minOffset = consumeQueue.getMinOffsetInQueue();maxOffset = consumeQueue.getMaxOffsetInQueue();//消息偏移量异常情况校对下一次拉取偏移量if (maxOffset == 0) &#123; //表示当前消息队列中没有消息 status = GetMessageStatus.NO_MESSAGE_IN_QUEUE; nextBeginOffset = nextOffsetCorrection(offset, 0);&#125; else if (offset &lt; minOffset) &#123; //待拉取消息的偏移量小于队列的其实偏移量 status = GetMessageStatus.OFFSET_TOO_SMALL; nextBeginOffset = nextOffsetCorrection(offset, minOffset);&#125; else if (offset == maxOffset) &#123; //待拉取偏移量为队列最大偏移量 status = GetMessageStatus.OFFSET_OVERFLOW_ONE; nextBeginOffset = nextOffsetCorrection(offset, offset);&#125; else if (offset &gt; maxOffset) &#123; //偏移量越界 status = GetMessageStatus.OFFSET_OVERFLOW_BADLY; if (0 == minOffset) &#123; nextBeginOffset = nextOffsetCorrection(offset, minOffset); &#125; else &#123; nextBeginOffset = nextOffsetCorrection(offset, maxOffset); &#125;&#125;...//根据偏移量从CommitLog中拉取32条消息SelectMappedBufferResult selectResult = this.commitLog.getMessage(offsetPy, sizePy);代码：PullMessageProcessor#processRequest1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//根据拉取结果填充responseHeaderresponse.setRemark(getMessageResult.getStatus().name());responseHeader.setNextBeginOffset(getMessageResult.getNextBeginOffset());responseHeader.setMinOffset(getMessageResult.getMinOffset());responseHeader.setMaxOffset(getMessageResult.getMaxOffset());//判断如果存在主从同步慢,设置下一次拉取任务的ID为主节点switch (this.brokerController.getMessageStoreConfig().getBrokerRole()) &#123; case ASYNC_MASTER: case SYNC_MASTER: break; case SLAVE: if (!this.brokerController.getBrokerConfig().isSlaveReadEnable()) &#123; response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); responseHeader.setSuggestWhichBrokerId(MixAll.MASTER_ID); &#125; break;&#125;...//GetMessageResult与Response的Code转换switch (getMessageResult.getStatus()) &#123; case FOUND: //成功 response.setCode(ResponseCode.SUCCESS); break; case MESSAGE_WAS_REMOVING: //消息存放在下一个commitLog中 response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); //消息重试 break; case NO_MATCHED_LOGIC_QUEUE: //未找到队列 case NO_MESSAGE_IN_QUEUE: //队列中未包含消息 if (0 != requestHeader.getQueueOffset()) &#123; response.setCode(ResponseCode.PULL_OFFSET_MOVED); requestHeader.getQueueOffset(), getMessageResult.getNextBeginOffset(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getConsumerGroup() ); &#125; else &#123; response.setCode(ResponseCode.PULL_NOT_FOUND); &#125; break; case NO_MATCHED_MESSAGE: //未找到消息 response.setCode(ResponseCode.PULL_RETRY_IMMEDIATELY); break; case OFFSET_FOUND_NULL: //消息物理偏移量为空 response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_OVERFLOW_BADLY: //offset越界 response.setCode(ResponseCode.PULL_OFFSET_MOVED); // XXX: warn and notify me log.info(\"the request offset: &#123;&#125; over flow badly, broker max offset: &#123;&#125;, consumer: &#123;&#125;\", requestHeader.getQueueOffset(), getMessageResult.getMaxOffset(), channel.remoteAddress()); break; case OFFSET_OVERFLOW_ONE: //offset在队列中未找到 response.setCode(ResponseCode.PULL_NOT_FOUND); break; case OFFSET_TOO_SMALL: //offset未在队列中 response.setCode(ResponseCode.PULL_OFFSET_MOVED); requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueOffset(), getMessageResult.getMinOffset(), channel.remoteAddress()); break; default: assert false; break;&#125;...//如果CommitLog标记可用,并且当前Broker为主节点,则更新消息消费进度boolean storeOffsetEnable = brokerAllowSuspend;storeOffsetEnable = storeOffsetEnable &amp;&amp; hasCommitOffsetFlag;storeOffsetEnable = storeOffsetEnable &amp;&amp; this.brokerController.getMessageStoreConfig().getBrokerRole() != BrokerRole.SLAVE;if (storeOffsetEnable) &#123; this.brokerController.getConsumerOffsetManager().commitOffset(RemotingHelper.parseChannelRemoteAddr(channel), requestHeader.getConsumerGroup(), requestHeader.getTopic(), requestHeader.getQueueId(), requestHeader.getCommitOffset());&#125;消息拉取客户端处理消息代码：MQClientAPIImpl#processPullResponse12345678910111213141516171819202122232425262728private PullResult processPullResponse( final RemotingCommand response) throws MQBrokerException, RemotingCommandException &#123; PullStatus pullStatus = PullStatus.NO_NEW_MSG; //判断响应结果 switch (response.getCode()) &#123; case ResponseCode.SUCCESS: pullStatus = PullStatus.FOUND; break; case ResponseCode.PULL_NOT_FOUND: pullStatus = PullStatus.NO_NEW_MSG; break; case ResponseCode.PULL_RETRY_IMMEDIATELY: pullStatus = PullStatus.NO_MATCHED_MSG; break; case ResponseCode.PULL_OFFSET_MOVED: pullStatus = PullStatus.OFFSET_ILLEGAL; break; default: throw new MQBrokerException(response.getCode(), response.getRemark()); &#125; //解码响应头 PullMessageResponseHeader responseHeader = (PullMessageResponseHeader) response.decodeCommandCustomHeader(PullMessageResponseHeader.class); //封装PullResultExt返回 return new PullResultExt(pullStatus, responseHeader.getNextBeginOffset(), responseHeader.getMinOffset(), responseHeader.getMaxOffset(), null, responseHeader.getSuggestWhichBrokerId(), response.getBody());&#125;PullResult类12345private final PullStatus pullStatus; //拉取结果private final long nextBeginOffset; //下次拉取偏移量private final long minOffset; //消息队列最小偏移量private final long maxOffset; //消息队列最大偏移量private List&lt;MessageExt&gt; msgFoundList; //拉取的消息列表代码：DefaultMQPushConsumerImpl$PullCallback#OnSuccess123456789101112131415//将拉取到的消息存入processQueueboolean dispatchToConsume = processQueue.putMessage(pullResult.getMsgFoundList());//将processQueue提交到consumeMessageService中供消费者消费DefaultMQPushConsumerImpl.this.consumeMessageService.submitConsumeRequest( pullResult.getMsgFoundList(), processQueue, pullRequest.getMessageQueue(), dispatchToConsume);//如果pullInterval大于0,则等待pullInterval毫秒后将pullRequest对象放入到PullMessageService中的pullRequestQueue队列中if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval() &gt; 0) &#123; DefaultMQPushConsumerImpl.this.executePullRequestLater(pullRequest, DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getPullInterval());&#125; else &#123; DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);&#125;消息拉取总结消息拉取长轮询机制分析RocketMQ未真正实现消息推模式，而是消费者主动向消息服务器拉取消息，RocketMQ推模式是循环向消息服务端发起消息拉取请求，如果消息消费者向RocketMQ拉取消息时，消息未到达消费队列时，如果不启用长轮询机制，则会在服务端等待shortPollingTimeMills时间后（挂起）再去判断消息是否已经到达指定消息队列，如果消息仍未到达则提示拉取消息客户端PULL—NOT—FOUND（消息不存在）；如果开启长轮询模式，RocketMQ一方面会每隔5s轮询检查一次消息是否可达，同时一有消息达到后立马通知挂起线程再次验证消息是否是自己感兴趣的消息，如果是则从CommitLog文件中提取消息返回给消息拉取客户端，否则直到挂起超时，超时时间由消息拉取方在消息拉取是封装在请求参数中，PUSH模式为15s，PULL模式通过DefaultMQPullConsumer#setBrokerSuspendMaxTimeMillis设置。RocketMQ通过在Broker客户端配置longPollingEnable为true来开启长轮询模式。代码：PullMessageProcessor#processRequest12345678910111213141516171819//当没有拉取到消息时，通过长轮询方式继续拉取消息case ResponseCode.PULL_NOT_FOUND: if (brokerAllowSuspend &amp;&amp; hasSuspendFlag) &#123; long pollingTimeMills = suspendTimeoutMillisLong; if (!this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123; pollingTimeMills = this.brokerController.getBrokerConfig().getShortPollingTimeMills(); &#125; String topic = requestHeader.getTopic(); long offset = requestHeader.getQueueOffset(); int queueId = requestHeader.getQueueId(); //构建拉取请求对象 PullRequest pullRequest = new PullRequest(request, channel, pollingTimeMills, this.brokerController.getMessageStore().now(), offset, subscriptionData, messageFilter); //处理拉取请求 this.brokerController.getPullRequestHoldService().suspendPullRequest(topic, queueId, pullRequest); response = null; break; &#125;PullRequestHoldService方式实现长轮询代码：PullRequestHoldService#suspendPullRequest1234567891011121314//将拉取消息请求，放置在ManyPullRequest集合中public void suspendPullRequest(final String topic, final int queueId, final PullRequest pullRequest) &#123; String key = this.buildKey(topic, queueId); ManyPullRequest mpr = this.pullRequestTable.get(key); if (null == mpr) &#123; mpr = new ManyPullRequest(); ManyPullRequest prev = this.pullRequestTable.putIfAbsent(key, mpr); if (prev != null) &#123; mpr = prev; &#125; &#125; mpr.addPullRequest(pullRequest);&#125;代码：PullRequestHoldService#run12345678910111213141516171819202122232425public void run() &#123; log.info(\"&#123;&#125; service started\", this.getServiceName()); while (!this.isStopped()) &#123; try &#123; //如果开启长轮询每隔5秒判断消息是否到达 if (this.brokerController.getBrokerConfig().isLongPollingEnable()) &#123; this.waitForRunning(5 * 1000); &#125; else &#123; //没有开启长轮询,每隔1s再次尝试 this.waitForRunning(this.brokerController.getBrokerConfig().getShortPollingTimeMills()); &#125; long beginLockTimestamp = this.systemClock.now(); this.checkHoldRequest(); long costTime = this.systemClock.now() - beginLockTimestamp; if (costTime &gt; 5 * 1000) &#123; log.info(\"[NOTIFYME] check hold request cost &#123;&#125; ms.\", costTime); &#125; &#125; catch (Throwable e) &#123; log.warn(this.getServiceName() + \" service has exception. \", e); &#125; &#125; log.info(\"&#123;&#125; service end\", this.getServiceName());&#125;代码：PullRequestHoldService#checkHoldRequest123456789101112131415161718//遍历拉取任务private void checkHoldRequest() &#123; for (String key : this.pullRequestTable.keySet()) &#123; String[] kArray = key.split(TOPIC_QUEUEID_SEPARATOR); if (2 == kArray.length) &#123; String topic = kArray[0]; int queueId = Integer.parseInt(kArray[1]); //获得消息偏移量 final long offset = this.brokerController.getMessageStore().getMaxOffsetInQueue(topic, queueId); try &#123; //通知有消息达到 this.notifyMessageArriving(topic, queueId, offset); &#125; catch (Throwable e) &#123; log.error(\"check hold request failed. topic=&#123;&#125;, queueId=&#123;&#125;\", topic, queueId, e); &#125; &#125; &#125;&#125;代码：PullRequestHoldService#notifyMessageArriving1234567891011121314151617181920212223242526272829//如果拉取消息偏移大于请求偏移量,如果消息匹配调用executeRequestWhenWakeup处理消息if (newestOffset &gt; request.getPullFromThisOffset()) &#123; boolean match = request.getMessageFilter().isMatchedByConsumeQueue(tagsCode, new ConsumeQueueExt.CqExtUnit(tagsCode, msgStoreTime, filterBitMap)); // match by bit map, need eval again when properties is not null. if (match &amp;&amp; properties != null) &#123; match = request.getMessageFilter().isMatchedByCommitLog(null, properties); &#125; if (match) &#123; try &#123; this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; log.error(\"execute request when wakeup failed.\", e); &#125; continue; &#125;&#125;//如果过期时间超时,则不继续等待将直接返回给客户端消息未找到if (System.currentTimeMillis() &gt;= (request.getSuspendTimestamp() + request.getTimeoutMillis())) &#123; try &#123; this.brokerController.getPullMessageProcessor().executeRequestWhenWakeup(request.getClientChannel(), request.getRequestCommand()); &#125; catch (Throwable e) &#123; log.error(\"execute request when wakeup failed.\", e); &#125; continue;&#125;如果开启了长轮询机制，PullRequestHoldService会每隔5s被唤醒去尝试检测是否有新的消息的到来才给客户端响应，或者直到超时才给客户端进行响应，消息实时性比较差，为了避免这种情况，RocketMQ引入另外一种机制：当消息到达时唤醒挂起线程触发一次检查。DefaultMessageStore$ReputMessageService机制代码：DefaultMessageStore#start123//长轮询入口this.reputMessageService.setReputFromOffset(maxPhysicalPosInLogicQueue);this.reputMessageService.start();代码：DefaultMessageStore$ReputMessageService#run123456789101112131415public void run() &#123; DefaultMessageStore.log.info(this.getServiceName() + \" service started\"); while (!this.isStopped()) &#123; try &#123; Thread.sleep(1); //长轮询核心逻辑代码入口 this.doReput(); &#125; catch (Exception e) &#123; DefaultMessageStore.log.warn(this.getServiceName() + \" service has exception. \", e); &#125; &#125; DefaultMessageStore.log.info(this.getServiceName() + \" service end\");&#125;代码：DefaultMessageStore$ReputMessageService#deReput12345678//当新消息达到是,进行通知监听器进行处理if (BrokerRole.SLAVE != DefaultMessageStore.this.getMessageStoreConfig().getBrokerRole() &amp;&amp; DefaultMessageStore.this.brokerConfig.isLongPollingEnable()) &#123; DefaultMessageStore.this.messageArrivingListener.arriving(dispatchRequest.getTopic(), dispatchRequest.getQueueId(), dispatchRequest.getConsumeQueueOffset() + 1, dispatchRequest.getTagsCode(), dispatchRequest.getStoreTimestamp(), dispatchRequest.getBitMap(), dispatchRequest.getPropertiesMap());&#125;代码：NotifyMessageArrivingListener#arriving12345public void arriving(String topic, int queueId, long logicOffset, long tagsCode, long msgStoreTime, byte[] filterBitMap, Map&lt;String, String&gt; properties) &#123; this.pullRequestHoldService.notifyMessageArriving(topic, queueId, logicOffset, tagsCode, msgStoreTime, filterBitMap, properties);&#125;消息队列负载与重新分布机制RocketMQ消息队列重新分配是由RebalanceService线程来实现。一个MQClientInstance持有一个RebalanceService实现，并随着MQClientInstance的启动而启动。代码：RebalanceService#run12345678910public void run() &#123; log.info(this.getServiceName() + \" service started\"); //RebalanceService线程默认每隔20s执行一次mqClientFactory.doRebalance方法 while (!this.isStopped()) &#123; this.waitForRunning(waitInterval); this.mqClientFactory.doRebalance(); &#125; log.info(this.getServiceName() + \" service end\");&#125;代码：MQClientInstance#doRebalance12345678910111213public void doRebalance() &#123; //MQClientInstance遍历以注册的消费者,对消费者执行doRebalance()方法 for (Map.Entry&lt;String, MQConsumerInner&gt; entry : this.consumerTable.entrySet()) &#123; MQConsumerInner impl = entry.getValue(); if (impl != null) &#123; try &#123; impl.doRebalance(); &#125; catch (Throwable e) &#123; log.error(\"doRebalance exception\", e); &#125; &#125; &#125;&#125;代码：RebalanceImpl#doRebalance123456789101112131415161718//遍历订阅消息对每个主题的订阅的队列进行重新负载public void doRebalance(final boolean isOrder) &#123; Map&lt;String, SubscriptionData&gt; subTable = this.getSubscriptionInner(); if (subTable != null) &#123; for (final Map.Entry&lt;String, SubscriptionData&gt; entry : subTable.entrySet()) &#123; final String topic = entry.getKey(); try &#123; this.rebalanceByTopic(topic, isOrder); &#125; catch (Throwable e) &#123; if (!topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) &#123; log.warn(\"rebalanceByTopic Exception\", e); &#125; &#125; &#125; &#125; this.truncateMessageQueueNotMyTopic();&#125;代码：RebalanceImpl#rebalanceByTopic123456789101112131415161718192021222324252627//从主题订阅消息缓存表中获取主题的队列信息Set&lt;MessageQueue&gt; mqSet = this.topicSubscribeInfoTable.get(topic);//查找该主题订阅组所有的消费者IDList&lt;String&gt; cidAll = this.mQClientFactory.findConsumerIdList(topic, consumerGroup);//给消费者重新分配队列if (mqSet != null &amp;&amp; cidAll != null) &#123; List&lt;MessageQueue&gt; mqAll = new ArrayList&lt;MessageQueue&gt;(); mqAll.addAll(mqSet); Collections.sort(mqAll); Collections.sort(cidAll); AllocateMessageQueueStrategy strategy = this.allocateMessageQueueStrategy; List&lt;MessageQueue&gt; allocateResult = null; try &#123; allocateResult = strategy.allocate( this.consumerGroup, this.mQClientFactory.getClientId(), mqAll, cidAll); &#125; catch (Throwable e) &#123; log.error(\"AllocateMessageQueueStrategy.allocate Exception. allocateMessageQueueStrategyName=&#123;&#125;\", strategy.getName(), e); return; &#125;RocketMQ默认提供5中负载均衡分配算法123456789101112AllocateMessageQueueAveragely:平均分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q2,q3c2:q4,q5,a6c3:q7,q8AllocateMessageQueueAveragelyByCircle:平均轮询分配举例:8个队列q1,q2,q3,q4,q5,a6,q7,q8,消费者3个:c1,c2,c3分配如下:c1:q1,q4,q7c2:q2,q5,a8c3:q3,q6注意：消息队列的分配遵循一个消费者可以分配到多个队列，但同一个消息队列只会分配给一个消费者，故如果出现消费者个数大于消息队列数量，则有些消费者无法消费消息。消息消费过程PullMessageService负责对消息队列进行消息拉取，从远端服务器拉取消息后将消息存储ProcessQueue消息队列处理队列中，然后调用ConsumeMessageService#submitConsumeRequest方法进行消息消费，使用线程池来消费消息，确保了消息拉取与消息消费的解耦。ConsumeMessageService支持顺序消息和并发消息，核心类图如下：并发消息消费代码：ConsumeMessageConcurrentlyService#submitConsumeRequest1234567891011121314151617181920212223242526272829303132//消息批次单次final int consumeBatchSize = this.defaultMQPushConsumer.getConsumeMessageBatchMaxSize();//msgs.size()默认最多为32条。//如果msgs.size()小于consumeBatchSize,则直接将拉取到的消息放入到consumeRequest,然后将consumeRequest提交到消费者线程池中if (msgs.size() &lt;= consumeBatchSize) &#123; ConsumeRequest consumeRequest = new ConsumeRequest(msgs, processQueue, messageQueue); try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; this.submitConsumeRequestLater(consumeRequest); &#125;&#125;else&#123; //如果拉取的消息条数大于consumeBatchSize,则对拉取消息进行分页 for (int total = 0; total &lt; msgs.size(); ) &#123; List&lt;MessageExt&gt; msgThis = new ArrayList&lt;MessageExt&gt;(consumeBatchSize); for (int i = 0; i &lt; consumeBatchSize; i++, total++) &#123; if (total &lt; msgs.size()) &#123; msgThis.add(msgs.get(total)); &#125; else &#123; break; &#125; ConsumeRequest consumeRequest = new ConsumeRequest(msgThis, processQueue, messageQueue); try &#123; this.consumeExecutor.submit(consumeRequest); &#125; catch (RejectedExecutionException e) &#123; for (; total &lt; msgs.size(); total++) &#123; msgThis.add(msgs.get(total)); this.submitConsumeRequestLater(consumeRequest); &#125; &#125;&#125;代码：ConsumeMessageConcurrentlyService$ConsumeRequest#run12345678910111213141516171819202122232425262728//检查processQueue的dropped,如果为true,则停止该队列消费。if (this.processQueue.isDropped()) &#123; log.info(\"the message queue not be able to consume, because it's dropped. group=&#123;&#125; &#123;&#125;\", ConsumeMessageConcurrentlyService.this.consumerGroup, this.messageQueue); return;&#125;...//执行消息处理的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext = new ConsumeMessageContext(); consumeMessageContext.setNamespace(defaultMQPushConsumer.getNamespace()); consumeMessageContext.setConsumerGroup(defaultMQPushConsumer.getConsumerGroup()); consumeMessageContext.setProps(new HashMap&lt;String, String&gt;()); consumeMessageContext.setMq(messageQueue); consumeMessageContext.setMsgList(msgs); consumeMessageContext.setSuccess(false); ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookBefore(consumeMessageContext);&#125;...//调用应用程序消息监听器的consumeMessage方法,进入到具体的消息消费业务处理逻辑status = listener.consumeMessage(Collections.unmodifiableList(msgs), context);//执行消息处理后的钩子函数if (ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.hasHook()) &#123; consumeMessageContext.setStatus(status.toString()); consumeMessageContext.setSuccess(ConsumeConcurrentlyStatus.CONSUME_SUCCESS == status); ConsumeMessageConcurrentlyService.this.defaultMQPushConsumerImpl.executeHookAfter(consumeMessageContext);&#125;定时消息机制定时消息是消息发送到Broker后，并不立即被消费者消费而是要等到特定的时间后才能被消费，RocketMQ并不支持任意的时间精度，如果要支持任意时间精度定时调度，不可避免地需要在Broker层做消息排序，再加上持久化方面的考量，将不可避免的带来巨大的性能消耗，所以RocketMQ只支持特定级别的延迟消息。消息延迟级别在Broker端通过messageDelayLevel配置，默认为“1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h”，delayLevel=1表示延迟消息1s,delayLevel=2表示延迟5s,依次类推。RocketMQ定时消息实现类为ScheduleMessageService，该类在DefaultMessageStore中创建。通过在DefaultMessageStore中调用load方法加载该类并调用start方法启动。代码：ScheduleMessageService#load123456//加载延迟消息消费进度的加载与delayLevelTable的构造。延迟消息的进度默认存储路径为/store/config/delayOffset.jsonpublic boolean load() &#123; boolean result = super.load(); result = result &amp;&amp; this.parseDelayLevel(); return result;&#125;代码：ScheduleMessageService#start1234567891011121314151617181920212223242526//遍历延迟队列创建定时任务,遍历延迟级别，根据延迟级别level从offsetTable中获取消费队列的消费进度。如果不存在，则使用0for (Map.Entry&lt;Integer, Long&gt; entry : this.delayLevelTable.entrySet()) &#123; Integer level = entry.getKey(); Long timeDelay = entry.getValue(); Long offset = this.offsetTable.get(level); if (null == offset) &#123; offset = 0L; &#125; if (timeDelay != null) &#123; this.timer.schedule(new DeliverDelayedMessageTimerTask(level, offset), FIRST_DELAY_TIME); &#125;&#125;//每隔10s持久化一次延迟队列的消息消费进度this.timer.scheduleAtFixedRate(new TimerTask() &#123; @Override public void run() &#123; try &#123; if (started.get()) ScheduleMessageService.this.persist(); &#125; catch (Throwable e) &#123; log.error(\"scheduleAtFixedRate flush exception\", e); &#125; &#125;&#125;, 10000, this.defaultMessageStore.getMessageStoreConfig().getFlushDelayOffsetInterval());调度机制ScheduleMessageService的start方法启动后，会为每一个延迟级别创建一个调度任务，每一个延迟级别对应SCHEDULE_TOPIC_XXXX主题下的一个消息消费队列。定时调度任务的实现类为DeliverDelayedMessageTimerTask，核心实现方法为executeOnTimeup代码：ScheduleMessageService$DeliverDelayedMessageTimerTask#executeOnTimeup123456789101112131415161718192021222324252627282930313233343536//根据队列ID与延迟主题查找消息消费队列ConsumeQueue cq = ScheduleMessageService.this.defaultMessageStore.findConsumeQueue(SCHEDULE_TOPIC, delayLevel2QueueId(delayLevel));...//根据偏移量从消息消费队列中获取当前队列中所有有效的消息SelectMappedBufferResult bufferCQ = cq.getIndexBuffer(this.offset);...//遍历ConsumeQueue,解析消息队列中消息for (; i &lt; bufferCQ.getSize(); i += ConsumeQueue.CQ_STORE_UNIT_SIZE) &#123; long offsetPy = bufferCQ.getByteBuffer().getLong(); int sizePy = bufferCQ.getByteBuffer().getInt(); long tagsCode = bufferCQ.getByteBuffer().getLong(); if (cq.isExtAddr(tagsCode)) &#123; if (cq.getExt(tagsCode, cqExtUnit)) &#123; tagsCode = cqExtUnit.getTagsCode(); &#125; else &#123; //can't find ext content.So re compute tags code. log.error(\"[BUG] can't find consume queue extend file content!addr=&#123;&#125;, offsetPy=&#123;&#125;, sizePy=&#123;&#125;\", tagsCode, offsetPy, sizePy); long msgStoreTime = defaultMessageStore.getCommitLog().pickupStoreTimestamp(offsetPy, sizePy); tagsCode = computeDeliverTimestamp(delayLevel, msgStoreTime); &#125; &#125; long now = System.currentTimeMillis(); long deliverTimestamp = this.correctDeliverTimestamp(now, tagsCode); ... //根据消息偏移量与消息大小,从CommitLog中查找消息. MessageExt msgExt = ScheduleMessageService.this.defaultMessageStore.lookMessageByOffset( offsetPy, sizePy);&#125;顺序消息顺序消息实现类是org.apache.rocketmq.client.impl.consumer.ConsumeMessageOrderlyService代码：ConsumeMessageOrderlyService#start1234567891011public void start() &#123; //如果消息模式为集群模式，启动定时任务，默认每隔20s执行一次锁定分配给自己的消息消费队列 if (MessageModel.CLUSTERING.equals(ConsumeMessageOrderlyService.this.defaultMQPushConsumerImpl.messageModel())) &#123; this.scheduledExecutorService.scheduleAtFixedRate(new Runnable() &#123; @Override public void run() &#123; ConsumeMessageOrderlyService.this.lockMQPeriodically(); &#125; &#125;, 1000 * 1, ProcessQueue.REBALANCE_LOCK_INTERVAL, TimeUnit.MILLISECONDS); &#125;&#125;代码：ConsumeMessageOrderlyService#submitConsumeRequest1234567891011//构建消息任务,并提交消费线程池中public void submitConsumeRequest( final List&lt;MessageExt&gt; msgs, final ProcessQueue processQueue, final MessageQueue messageQueue, final boolean dispathToConsume) &#123; if (dispathToConsume) &#123; ConsumeRequest consumeRequest = new ConsumeRequest(processQueue, messageQueue); this.consumeExecutor.submit(consumeRequest); &#125;&#125;代码：ConsumeMessageOrderlyService$ConsumeRequest#run12345678910//如果消息队列为丢弃,则停止本次消费任务if (this.processQueue.isDropped()) &#123; log.warn(\"run, the message queue not be able to consume, because it's dropped. &#123;&#125;\", this.messageQueue); return;&#125;//从消息队列中获取一个对象。然后消费消息时先申请独占objLock锁。顺序消息一个消息消费队列同一时刻只会被一个消费线程池处理final Object objLock = messageQueueLock.fetchLockObject(this.messageQueue);synchronized (objLock) &#123; ...&#125;小结RocketMQ消息消费方式分别为集群模式、广播模式。消息队列负载由RebalanceService线程默认每隔20s进行一次消息队列负载，根据当前消费者组内消费者个数与主题队列数量按照某一种负载算法进行队列分配，分配原则为同一个消费者可以分配多个消息消费队列，同一个消息消费队列同一个时间只会分配给一个消费者。消息拉取由PullMessageService线程根据RebalanceService线程创建的拉取任务进行拉取，默认每次拉取32条消息，提交给消费者消费线程后继续下一次消息拉取。如果消息消费过慢产生消息堆积会触发消息消费拉取流控。并发消息消费指消费线程池中的线程可以并发对同一个消息队列的消息进行消费，消费成功后，取出消息队列中最小的消息偏移量作为消息消费进度偏移量存储在于消息消费进度存储文件中，集群模式消息消费进度存储在Broker（消息服务器），广播模式消息消费进度存储在消费者端。RocketMQ不支持任意精度的定时调度消息，只支持自定义的消息延迟级别，例如1s、2s、5s等，可通过在broker配置文件中设置messageDelayLevel。顺序消息一般使用集群模式，是指对消息消费者内的线程池中的线程对消息消费队列只能串行消费。并并发消息消费最本质的区别是消息消费时必须成功锁定消息消费队列，在Broker端会存储消息消费队列的锁占用情况。","categories":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://me.obey.fun/categories/MessageQueue/"},{"name":"RocketMQ","slug":"MessageQueue/RocketMQ","permalink":"https://me.obey.fun/categories/MessageQueue/RocketMQ/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://me.obey.fun/tags/中间件/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://me.obey.fun/tags/RocketMQ/"}],"keywords":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://me.obey.fun/categories/MessageQueue/"},{"name":"RocketMQ","slug":"MessageQueue/RocketMQ","permalink":"https://me.obey.fun/categories/MessageQueue/RocketMQ/"}]},{"title":"RocketMQ电商下单案例","slug":"RocketMQ电商下单案例","date":"2020-06-15T12:56:13.000Z","updated":"2020-06-17T02:13:46.000Z","comments":true,"path":"RocketMQ电商下单案例.html","link":"","permalink":"https://me.obey.fun/RocketMQ电商下单案例.html","excerpt":"","text":"案例介绍业务分析模拟电商网站购物场景中的【下单】和【支付】业务下单用户请求订单系统下单订单系统通过RPC调用订单服务下单订单服务调用优惠券服务，扣减优惠券订单服务调用调用库存服务，校验并扣减库存订单服务调用用户服务，扣减用户余额订单服务完成确认订单支付用户请求支付系统支付系统调用第三方支付平台API进行发起支付流程用户通过第三方支付平台支付成功后，第三方支付平台回调通知支付系统支付系统调用订单服务修改订单状态支付系统调用积分服务添加积分支付系统调用日志服务记录日志问题分析问题1用户提交订单后，扣减库存成功、扣减优惠券成功、使用余额成功，但是在确认订单操作失败，需要对库存、库存、余额进行回退。如何保证数据的完整性？使用MQ保证在下单失败后系统数据的完整性问题2用户通过第三方支付平台（支付宝、微信）支付成功后，第三方支付平台要通过回调API异步通知商家支付系统用户支付结果，支付系统根据支付结果修改订单状态、记录支付日志和给用户增加积分。商家支付系统如何保证在收到第三方支付平台的异步通知时，如何快速给第三方支付凭条做出回应？通过MQ进行数据分发，提高系统处理性能技术分析技术选型SpringBootDubboZookeeperRocketMQMysqlSpringBoot整合RocketMQ下载rocketmq-spring项目将rocketmq-spring安装到本地仓库1mvn install -Dmaven.skip.test=true消息生产者添加依赖12345678910111213141516171819202122232425262728&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;properties&gt; &lt;rocketmq-spring-boot-starter-version&gt;2.0.3&lt;/rocketmq-spring-boot-starter-version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;rocketmq-spring-boot-starter-version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt;配置文件123# application.propertiesrocketmq.name-server=192.168.25.135:9876;192.168.25.138:9876rocketmq.producer.group=my-group启动类123456@SpringBootApplicationpublic class MQProducerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MQSpringBootApplication.class); &#125;&#125;测试类123456789101112@RunWith(SpringRunner.class)@SpringBootTest(classes = &#123;MQSpringBootApplication.class&#125;)public class ProducerTest &#123; @Autowired private RocketMQTemplate rocketMQTemplate; @Test public void test1()&#123; rocketMQTemplate.convertAndSend(\"springboot-mq\",\"hello springboot rocketmq\"); &#125;&#125;消息消费者添加依赖同消息生产者配置文件同消息生产者启动类123456@SpringBootApplicationpublic class MQConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(MQSpringBootApplication.class); &#125;&#125;消息监听器12345678910@Slf4j@Component@RocketMQMessageListener(topic = \"springboot-mq\",consumerGroup = \"springboot-mq-consumer-1\")public class Consumer implements RocketMQListener&lt;String&gt; &#123; @Override public void onMessage(String message) &#123; log.info(\"Receive message：\"+message); &#125;&#125;SpringBoot整合Dubbo下载dubbo-spring-boot-starter依赖包将123```shellmvn install -Dmaven.skip.test=true搭建Zookeeper集群准备工作安装JDK将Zookeeper上传到服务器解压Zookeeper，并创建data目录，将conf下的zoo_sample.cfg文件改名为zoo.cfg建立1234```sh/usr/local/zookeeper-cluster/zookeeper-1/usr/local/zookeeper-cluster/zookeeper-2/usr/local/zookeeper-cluster/zookeeper-3配置每一个 Zookeeper 的 dataDir（zoo.cfg） clientPort 分别为 2181 2182 2183修改1234```shellclientPort=2181dataDir=/usr/local/zookeeper-cluster/zookeeper-1/data修改/usr/local/zookeeper-cluster/zookeeper-2/conf/zoo.cfg12clientPort=2182dataDir=/usr/local/zookeeper-cluster/zookeeper-2/data修改/usr/local/zookeeper-cluster/zookeeper-3/conf/zoo.cfg12clientPort=2183dataDir=/usr/local/zookeeper-cluster/zookeeper-3/data配置集群在每个 zookeeper 的 data 目录下创建一个 myid 文件，内容分别是 1、2、3 。这个文件就是记录每个服务器的 ID在每一个 zookeeper 的 zoo.cfg 配置客户端访问端口（clientPort）和集群服务器 IP 列表。集群服务器 IP 列表如下123server.1=192.168.25.140:2881:3881server.2=192.168.25.140:2882:3882server.3=192.168.25.140:2883:3883解释：server.服务器 ID=服务器 IP 地址：服务器之间通信端口：服务器之间投票选举端口启动集群启动集群就是分别启动每个实例。RPC服务接口123public interface IUserService &#123; public String sayHello(String name);&#125;服务提供者添加依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;!--dubbo--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;!--spring-boot-stater--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--zookeeper--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--API--&gt; &lt;dependency&gt; &lt;groupId&gt;com.itheima.demo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;配置文件12345678# application.propertiesspring.application.name=dubbo-demo-providerspring.dubbo.application.id=dubbo-demo-providerspring.dubbo.application.name=dubbo-demo-providerspring.dubbo.registry.address=zookeeper://192.168.25.140:2181;zookeeper://192.168.25.140:2182;zookeeper://192.168.25.140:2183spring.dubbo.server=truespring.dubbo.protocol.name=dubbospring.dubbo.protocol.port=20880启动类123456789@EnableDubboConfiguration@SpringBootApplicationpublic class ProviderBootstrap &#123; public static void main(String[] args) throws IOException &#123; SpringApplication.run(ProviderBootstrap.class,args); &#125;&#125;服务实现12345678@Component@Service(interfaceClass = IUserService.class)public class UserServiceImpl implements IUserService&#123; @Override public String sayHello(String name) &#123; return \"hello:\"+name; &#125;&#125;服务消费者添加依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--dubbo--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;log4j-to-slf4j&lt;/artifactId&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--zookeeper--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;!--API--&gt; &lt;dependency&gt; &lt;groupId&gt;com.itheima.demo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;配置文件12345# application.propertiesspring.application.name=dubbo-demo-consumerspring.dubbo.application.name=dubbo-demo-consumerspring.dubbo.application.id=dubbo-demo-consumer spring.dubbo.registry.address=zookeeper://192.168.25.140:2181;zookeeper://192.168.25.140:2182;zookeeper://192.168.25.140:2183启动类1234567@EnableDubboConfiguration@SpringBootApplicationpublic class ConsumerBootstrap &#123; public static void main(String[] args) &#123; SpringApplication.run(ConsumerBootstrap.class); &#125;&#125;Controller12345678910111213@RestController@RequestMapping(\"/user\")public class UserController &#123; @Reference private IUserService userService; @RequestMapping(\"/sayHello\") public String sayHello(String name)&#123; return userService.sayHello(name); &#125;&#125;环境搭建数据库优惠券表FieldTypeCommentcoupon_idbigint(50) NOT NULL优惠券IDcoupon_pricedecimal(10,2) NULL优惠券金额user_idbigint(50) NULL用户IDorder_idbigint(32) NULL订单IDis_usedint(1) NULL是否使用 0未使用 1已使用used_timetimestamp NULL使用时间商品表FieldTypeCommentgoods_idbigint(50) NOT NULL主键goods_namevarchar(255) NULL商品名称goods_numberint(11) NULL商品库存goods_pricedecimal(10,2) NULL商品价格goods_descvarchar(255) NULL商品描述add_timetimestamp NULL添加时间订单表FieldTypeCommentorder_idbigint(50) NOT NULL订单IDuser_idbigint(50) NULL用户IDorder_statusint(1) NULL订单状态 0未确认 1已确认 2已取消 3无效 4退款pay_statusint(1) NULL支付状态 0未支付 1支付中 2已支付shipping_statusint(1) NULL发货状态 0未发货 1已发货 2已退货addressvarchar(255) NULL收货地址consigneevarchar(255) NULL收货人goods_idbigint(50) NULL商品IDgoods_numberint(11) NULL商品数量goods_pricedecimal(10,2) NULL商品价格goods_amountdecimal(10,0) NULL商品总价shipping_feedecimal(10,2) NULL运费order_amountdecimal(10,2) NULL订单价格coupon_idbigint(50) NULL优惠券IDcoupon_paiddecimal(10,2) NULL优惠券money_paiddecimal(10,2) NULL已付金额pay_amountdecimal(10,2) NULL支付金额add_timetimestamp NULL创建时间confirm_timetimestamp NULL订单确认时间pay_timetimestamp NULL支付时间订单商品日志表FieldTypeCommentgoods_idint(11) NOT NULL商品IDorder_idvarchar(32) NOT NULL订单IDgoods_numberint(11) NULL库存数量log_timedatetime NULL记录时间用户表FieldTypeCommentuser_idbigint(50) NOT NULL用户IDuser_namevarchar(255) NULL用户姓名user_passwordvarchar(255) NULL用户密码user_mobilevarchar(255) NULL手机号user_scoreint(11) NULL积分user_reg_timetimestamp NULL注册时间user_moneydecimal(10,0) NULL用户余额用户余额日志表FieldTypeCommentuser_idbigint(50) NOT NULL用户IDorder_idbigint(50) NOT NULL订单IDmoney_log_typeint(1) NOT NULL日志类型 1订单付款 2 订单退款use_moneydecimal(10,2) NULL操作金额create_timetimestamp NULL日志时间订单支付表FieldTypeCommentpay_idbigint(50) NOT NULL支付编号order_idbigint(50) NULL订单编号pay_amountdecimal(10,2) NULL支付金额is_paidint(1) NULL是否已支付 1否 2是MQ消息生产表FieldTypeCommentidvarchar(100) NOT NULL主键group_namevarchar(100) NULL生产者组名msg_topicvarchar(100) NULL消息主题msg_tagvarchar(100) NULLTagmsg_keyvarchar(100) NULLKeymsg_bodyvarchar(500) NULL消息内容msg_statusint(1) NULL0:未处理;1:已经处理create_timetimestamp NOT NULL记录时间MQ消息消费表FieldTypeCommentmsg_idvarchar(50) NULL消息IDgroup_namevarchar(100) NOT NULL消费者组名msg_tagvarchar(100) NOT NULLTagmsg_keyvarchar(100) NOT NULLKeymsg_bodyvarchar(500) NULL消息体consumer_statusint(1) NULL0:正在处理;1:处理成功;2:处理失败consumer_timesint(1) NULL消费次数consumer_timestamptimestamp NULL消费时间remarkvarchar(500) NULL备注项目初始化shop系统基于Maven进行项目管理工程浏览父工程：shop-parent订单系统：shop-order-web支付系统：shop-pay-web优惠券服务：shop-coupon-service订单服务：shop-order-service支付服务：shop-pay-service商品服务：shop-goods-service用户服务：shop-user-service实体类：shop-pojo持久层：shop-dao接口层：shop-api工具工程：shop-common共12个系统工程关系Mybatis逆向工程使用代码生成使用Mybatis逆向工程针对数据表生成CURD持久层代码代码导入将实体类导入到shop-pojo工程在服务层工程中导入对应的Mapper类和对应配置文件公共类介绍ID生成器IDWorker：Twitter雪花算法异常处理类CustomerException：自定义异常类CastException：异常抛出类常量类ShopCode：系统状态类响应实体类Result：封装响应状态和响应信息下单业务下单基本流程接口定义IOrderService12345678public interface IOrderService &#123; /** * 确认订单 * @param order * @return Result */ Result confirmOrder(TradeOrder order);&#125;业务类实现123456789101112131415161718192021222324252627282930@Slf4j@Component@Service(interfaceClass = IOrderService.class)public class OrderServiceImpl implements IOrderService &#123; @Override public Result confirmOrder(TradeOrder order) &#123; //1.校验订单 //2.生成预订单 try &#123; //3.扣减库存 //4.扣减优惠券 //5.使用余额 //6.确认订单 //7.返回成功状态 &#125; catch (Exception e) &#123; //1.确认订单失败,发送消息 //2.返回失败状态 &#125; &#125;&#125;校验订单1234567891011121314151617181920212223242526private void checkOrder(TradeOrder order) &#123; //1.校验订单是否存在 if(order==null)&#123; CastException.cast(ShopCode.SHOP_ORDER_INVALID); &#125; //2.校验订单中的商品是否存在 TradeGoods goods = goodsService.findOne(order.getGoodsId()); if(goods==null)&#123; CastException.cast(ShopCode.SHOP_GOODS_NO_EXIST); &#125; //3.校验下单用户是否存在 TradeUser user = userService.findOne(order.getUserId()); if(user==null)&#123; CastException.cast(ShopCode.SHOP_USER_NO_EXIST); &#125; //4.校验商品单价是否合法 if(order.getGoodsPrice().compareTo(goods.getGoodsPrice())!=0)&#123; CastException.cast(ShopCode.SHOP_GOODS_PRICE_INVALID); &#125; //5.校验订单商品数量是否合法 if(order.getGoodsNumber()&gt;=goods.getGoodsNumber())&#123; CastException.cast(ShopCode.SHOP_GOODS_NUM_NOT_ENOUGH); &#125; log.info(\"校验订单通过\");&#125;生成预订单1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374private Long savePreOrder(TradeOrder order) &#123; //1.设置订单状态为不可见 order.setOrderStatus(ShopCode.SHOP_ORDER_NO_CONFIRM.getCode()); //2.订单ID order.setOrderId(idWorker.nextId()); //核算运费是否正确 BigDecimal shippingFee = calculateShippingFee(order.getOrderAmount()); if (order.getShippingFee().compareTo(shippingFee) != 0) &#123; CastException.cast(ShopCode.SHOP_ORDER_SHIPPINGFEE_INVALID); &#125; //3.计算订单总价格是否正确 BigDecimal orderAmount = order.getGoodsPrice().multiply(new BigDecimal(order.getGoodsNumber())); orderAmount.add(shippingFee); if (orderAmount.compareTo(order.getOrderAmount()) != 0) &#123; CastException.cast(ShopCode.SHOP_ORDERAMOUNT_INVALID); &#125; //4.判断优惠券信息是否合法 Long couponId = order.getCouponId(); if (couponId != null) &#123; TradeCoupon coupon = couponService.findOne(couponId); //优惠券不存在 if (coupon == null) &#123; CastException.cast(ShopCode.SHOP_COUPON_NO_EXIST); &#125; //优惠券已经使用 if ((ShopCode.SHOP_COUPON_ISUSED.getCode().toString()) .equals(coupon.getIsUsed().toString())) &#123; CastException.cast(ShopCode.SHOP_COUPON_INVALIED); &#125; order.setCouponPaid(coupon.getCouponPrice()); &#125; else &#123; order.setCouponPaid(BigDecimal.ZERO); &#125; //5.判断余额是否正确 BigDecimal moneyPaid = order.getMoneyPaid(); if (moneyPaid != null) &#123; //比较余额是否大于0 int r = order.getMoneyPaid().compareTo(BigDecimal.ZERO); //余额小于0 if (r == -1) &#123; CastException.cast(ShopCode.SHOP_MONEY_PAID_LESS_ZERO); &#125; //余额大于0 if (r == 1) &#123; //查询用户信息 TradeUser user = userService.findOne(order.getUserId()); if (user == null) &#123; CastException.cast(ShopCode.SHOP_USER_NO_EXIST); &#125; //比较余额是否大于用户账户余额 if (user.getUserMoney().compareTo(order.getMoneyPaid().longValue()) == -1) &#123; CastException.cast(ShopCode.SHOP_MONEY_PAID_INVALID); &#125; order.setMoneyPaid(order.getMoneyPaid()); &#125; &#125; else &#123; order.setMoneyPaid(BigDecimal.ZERO); &#125; //计算订单支付总价 order.setPayAmount(orderAmount.subtract(order.getCouponPaid()) .subtract(order.getMoneyPaid())); //设置订单添加时间 order.setAddTime(new Date()); //保存预订单 int r = orderMapper.insert(order); if (ShopCode.SHOP_SUCCESS.getCode() != r) &#123; CastException.cast(ShopCode.SHOP_ORDER_SAVE_ERROR); &#125; log.info(\"订单:[\"+order.getOrderId()+\"]预订单生成成功\"); return order.getOrderId();&#125;扣减库存通过dubbo调用商品服务完成扣减库存1234567891011private void reduceGoodsNum(TradeOrder order) &#123; TradeGoodsNumberLog goodsNumberLog = new TradeGoodsNumberLog(); goodsNumberLog.setGoodsId(order.getGoodsId()); goodsNumberLog.setOrderId(order.getOrderId()); goodsNumberLog.setGoodsNumber(order.getGoodsNumber()); Result result = goodsService.reduceGoodsNum(goodsNumberLog); if (result.getSuccess().equals(ShopCode.SHOP_FAIL.getSuccess())) &#123; CastException.cast(ShopCode.SHOP_REDUCE_GOODS_NUM_FAIL); &#125; log.info(\"订单:[\"+order.getOrderId()+\"]扣减库存[\"+order.getGoodsNumber()+\"个]成功\"); &#125;商品服务GoodsService扣减库存1234567891011121314151617181920212223242526@Overridepublic Result reduceGoodsNum(TradeGoodsNumberLog goodsNumberLog) &#123; if (goodsNumberLog == null || goodsNumberLog.getGoodsNumber() == null || goodsNumberLog.getOrderId() == null || goodsNumberLog.getGoodsNumber() == null || goodsNumberLog.getGoodsNumber().intValue() &lt;= 0) &#123; CastException.cast(ShopCode.SHOP_REQUEST_PARAMETER_VALID); &#125; TradeGoods goods = goodsMapper.selectByPrimaryKey(goodsNumberLog.getGoodsId()); if(goods.getGoodsNumber()&lt;goodsNumberLog.getGoodsNumber())&#123; //库存不足 CastException.cast(ShopCode.SHOP_GOODS_NUM_NOT_ENOUGH); &#125; //减库存 goods.setGoodsNumber(goods.getGoodsNumber()-goodsNumberLog.getGoodsNumber()); goodsMapper.updateByPrimaryKey(goods); //记录库存操作日志 goodsNumberLog.setGoodsNumber(-(goodsNumberLog.getGoodsNumber())); goodsNumberLog.setLogTime(new Date()); goodsNumberLogMapper.insert(goodsNumberLog); return new Result(ShopCode.SHOP_SUCCESS.getSuccess(),ShopCode.SHOP_SUCCESS.getMessage());&#125;扣减优惠券通过dubbo完成扣减优惠券123456789101112131415161718private void changeCoponStatus(TradeOrder order) &#123; //判断用户是否使用优惠券 if (!StringUtils.isEmpty(order.getCouponId())) &#123; //封装优惠券对象 TradeCoupon coupon = couponService.findOne(order.getCouponId()); coupon.setIsUsed(ShopCode.SHOP_COUPON_ISUSED.getCode()); coupon.setUsedTime(new Date()); coupon.setOrderId(order.getOrderId()); Result result = couponService.changeCouponStatus(coupon); //判断执行结果 if (result.getSuccess().equals(ShopCode.SHOP_FAIL.getSuccess())) &#123; //优惠券使用失败 CastException.cast(ShopCode.SHOP_COUPON_USE_FAIL); &#125; log.info(\"订单:[\"+order.getOrderId()+\"]使用扣减优惠券[\"+coupon.getCouponPrice()+\"元]成功\"); &#125;&#125;优惠券服务CouponService更改优惠券状态1234567891011121314@Overridepublic Result changeCouponStatus(TradeCoupon coupon) &#123; try &#123; //判断请求参数是否合法 if (coupon == null || StringUtils.isEmpty(coupon.getCouponId())) &#123; CastException.cast(ShopCode.SHOP_REQUEST_PARAMETER_VALID); &#125; //更新优惠券状态为已使用 couponMapper.updateByPrimaryKey(coupon); return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage()); &#125; catch (Exception e) &#123; return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage()); &#125;&#125;扣减用户余额通过用户服务完成扣减余额12345678910111213141516private void reduceMoneyPaid(TradeOrder order) &#123; //判断订单中使用的余额是否合法 if (order.getMoneyPaid() != null &amp;&amp; order.getMoneyPaid().compareTo(BigDecimal.ZERO) == 1) &#123; TradeUserMoneyLog userMoneyLog = new TradeUserMoneyLog(); userMoneyLog.setOrderId(order.getOrderId()); userMoneyLog.setUserId(order.getUserId()); userMoneyLog.setUseMoney(order.getMoneyPaid()); userMoneyLog.setMoneyLogType(ShopCode.SHOP_USER_MONEY_PAID.getCode()); //扣减余额 Result result = userService.changeUserMoney(userMoneyLog); if (result.getSuccess().equals(ShopCode.SHOP_FAIL.getSuccess())) &#123; CastException.cast(ShopCode.SHOP_USER_MONEY_REDUCE_FAIL); &#125; log.info(\"订单:[\"+order.getOrderId()+\"扣减余额[\"+order.getMoneyPaid()+\"元]成功]\"); &#125;&#125;用户服务UserService,更新余额&lt;img src=”https://tva2.sinaimg.cn/large/006MOU0zgy1gjo12dfbc1j30ek0ucwf3.jpg&quot; alt=”更改用户余额”referrerpolicy=”no-referrer”&gt;1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556@Overridepublic Result changeUserMoney(TradeUserMoneyLog userMoneyLog) &#123; //判断请求参数是否合法 if (userMoneyLog == null || userMoneyLog.getUserId() == null || userMoneyLog.getUseMoney() == null || userMoneyLog.getOrderId() == null || userMoneyLog.getUseMoney().compareTo(BigDecimal.ZERO) &lt;= 0) &#123; CastException.cast(ShopCode.SHOP_REQUEST_PARAMETER_VALID); &#125; //查询该订单是否存在付款记录 TradeUserMoneyLogExample userMoneyLogExample = new TradeUserMoneyLogExample(); userMoneyLogExample.createCriteria() .andUserIdEqualTo(userMoneyLog.getUserId()) .andOrderIdEqualTo(userMoneyLog.getOrderId()); int count = userMoneyLogMapper.countByExample(userMoneyLogExample); TradeUser tradeUser = new TradeUser(); tradeUser.setUserId(userMoneyLog.getUserId()); tradeUser.setUserMoney(userMoneyLog.getUseMoney().longValue()); //判断余额操作行为 //【付款操作】 if (userMoneyLog.getMoneyLogType().equals(ShopCode.SHOP_USER_MONEY_PAID.getCode())) &#123; //订单已经付款，则抛异常 if (count &gt; 0) &#123; CastException.cast(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY); &#125; //用户账户扣减余额 userMapper.reduceUserMoney(tradeUser); &#125; //【退款操作】 if (userMoneyLog.getMoneyLogType().equals(ShopCode.SHOP_USER_MONEY_REFUND.getCode())) &#123; //如果订单未付款,则不能退款,抛异常 if (count == 0) &#123; CastException.cast(ShopCode.SHOP_ORDER_PAY_STATUS_NO_PAY); &#125; //防止多次退款 userMoneyLogExample = new TradeUserMoneyLogExample(); userMoneyLogExample.createCriteria() .andUserIdEqualTo(userMoneyLog.getUserId()) .andOrderIdEqualTo(userMoneyLog.getOrderId()) .andMoneyLogTypeEqualTo(ShopCode.SHOP_USER_MONEY_REFUND.getCode()); count = userMoneyLogMapper.countByExample(userMoneyLogExample); if (count &gt; 0) &#123; CastException.cast(ShopCode.SHOP_USER_MONEY_REFUND_ALREADY); &#125; //用户账户添加余额 userMapper.addUserMoney(tradeUser); &#125; //记录用户使用余额日志 userMoneyLog.setCreateTime(new Date()); userMoneyLogMapper.insert(userMoneyLog); return new Result(ShopCode.SHOP_SUCCESS.getSuccess(),ShopCode.SHOP_SUCCESS.getMessage());&#125;确认订单12345678910private void updateOrderStatus(TradeOrder order) &#123; order.setOrderStatus(ShopCode.SHOP_ORDER_CONFIRM.getCode()); order.setPayStatus(ShopCode.SHOP_ORDER_PAY_STATUS_NO_PAY.getCode()); order.setConfirmTime(new Date()); int r = orderMapper.updateByPrimaryKey(order); if (r &lt;= 0) &#123; CastException.cast(ShopCode.SHOP_ORDER_CONFIRM_FAIL); &#125; log.info(\"订单:[\"+order.getOrderId()+\"]状态修改成功\");&#125;小结123456789101112131415161718192021222324@Overridepublic Result confirmOrder(TradeOrder order) &#123; //1.校验订单 checkOrder(order); //2.生成预订单 Long orderId = savePreOrder(order); order.setOrderId(orderId); try &#123; //3.扣减库存 reduceGoodsNum(order); //4.扣减优惠券 changeCoponStatus(order); //5.使用余额 reduceMoneyPaid(order); //6.确认订单 updateOrderStatus(order); log.info(\"订单:[\"+orderId+\"]确认成功\"); return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage()); &#125; catch (Exception e) &#123; //确认订单失败,发送消息 ... return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage()); &#125;&#125;失败补偿机制消息发送方配置RocketMQ属性值1234567rocketmq.name-server=192.168.25.135:9876;192.168.25.138:9876rocketmq.producer.group=orderProducerGroupmq.order.consumer.group.name=order_orderTopic_cancel_groupmq.order.topic=orderTopicmq.order.tag.confirm=order_confirmmq.order.tag.cancel=order_cancel注入模板类和属性值信息12345678@Autowiredprivate RocketMQTemplate rocketMQTemplate;@Value(\"$&#123;mq.order.topic&#125;\")private String topic;@Value(\"$&#123;mq.order.tag.cancel&#125;\")private String cancelTag;发送下单失败消息123456789101112131415161718192021222324252627282930@Overridepublic Result confirmOrder(TradeOrder order) &#123; //1.校验订单 //2.生成预订 try &#123; //3.扣减库存 //4.扣减优惠券 //5.使用余额 //6.确认订单 &#125; catch (Exception e) &#123; //确认订单失败,发送消息 CancelOrderMQ cancelOrderMQ = new CancelOrderMQ(); cancelOrderMQ.setOrderId(order.getOrderId()); cancelOrderMQ.setCouponId(order.getCouponId()); cancelOrderMQ.setGoodsId(order.getGoodsId()); cancelOrderMQ.setGoodsNumber(order.getGoodsNumber()); cancelOrderMQ.setUserId(order.getUserId()); cancelOrderMQ.setUserMoney(order.getMoneyPaid()); try &#123; sendMessage(topic, cancelTag, cancelOrderMQ.getOrderId().toString(), JSON.toJSONString(cancelOrderMQ)); &#125; catch (Exception e1) &#123; e1.printStackTrace(); CastException.cast(ShopCode.SHOP_MQ_SEND_MESSAGE_FAIL); &#125; return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage()); &#125;&#125;1234567891011121314private void sendMessage(String topic, String tags, String keys, String body) throws Exception &#123; //判断Topic是否为空 if (StringUtils.isEmpty(topic)) &#123; CastException.cast(ShopCode.SHOP_MQ_TOPIC_IS_EMPTY); &#125; //判断消息内容是否为空 if (StringUtils.isEmpty(body)) &#123; CastException.cast(ShopCode.SHOP_MQ_MESSAGE_BODY_IS_EMPTY); &#125; //消息体 Message message = new Message(topic, tags, keys, body.getBytes()); //发送消息 rocketMQTemplate.getProducer().send(message);&#125;4.2.2 消费接收方配置RocketMQ属性值123rocketmq.name-server=192.168.25.135:9876;192.168.25.138:9876mq.order.consumer.group.name=order_orderTopic_cancel_groupmq.order.topic=orderTopic创建监听类，消费消息123456789101112@Slf4j@Component@RocketMQMessageListener(topic = \"$&#123;mq.order.topic&#125;\", consumerGroup = \"$&#123;mq.order.consumer.group.name&#125;\", messageModel = MessageModel.BROADCASTING)public class CancelOrderConsumer implements RocketMQListener&lt;MessageExt&gt;&#123; @Override public void onMessage(MessageExt messageExt) &#123; ... &#125;&#125;回退库存流程分析消息消费者123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138@Slf4j@Component@RocketMQMessageListener(topic = \"$&#123;mq.order.topic&#125;\",consumerGroup = \"$&#123;mq.order.consumer.group.name&#125;\",messageModel = MessageModel.BROADCASTING )public class CancelMQListener implements RocketMQListener&lt;MessageExt&gt;&#123; @Value(\"$&#123;mq.order.consumer.group.name&#125;\") private String groupName; @Autowired private TradeGoodsMapper goodsMapper; @Autowired private TradeMqConsumerLogMapper mqConsumerLogMapper; @Autowired private TradeGoodsNumberLogMapper goodsNumberLogMapper; @Override public void onMessage(MessageExt messageExt) &#123; String msgId=null; String tags=null; String keys=null; String body=null; try &#123; //1. 解析消息内容 msgId = messageExt.getMsgId(); tags= messageExt.getTags(); keys= messageExt.getKeys(); body= new String(messageExt.getBody(),\"UTF-8\"); log.info(\"接受消息成功\"); //2. 查询消息消费记录 TradeMqConsumerLogKey primaryKey = new TradeMqConsumerLogKey(); primaryKey.setMsgTag(tags); primaryKey.setMsgKey(keys); primaryKey.setGroupName(groupName); TradeMqConsumerLog mqConsumerLog = mqConsumerLogMapper.selectByPrimaryKey(primaryKey); if(mqConsumerLog!=null)&#123; //3. 判断如果消费过... //3.1 获得消息处理状态 Integer status = mqConsumerLog.getConsumerStatus(); //处理过...返回 if(ShopCode.SHOP_MQ_MESSAGE_STATUS_SUCCESS.getCode().intValue()==status.intValue())&#123; log.info(\"消息:\"+msgId+\",已经处理过\"); return; &#125; //正在处理...返回 if(ShopCode.SHOP_MQ_MESSAGE_STATUS_PROCESSING.getCode().intValue()==status.intValue())&#123; log.info(\"消息:\"+msgId+\",正在处理\"); return; &#125; //处理失败 if(ShopCode.SHOP_MQ_MESSAGE_STATUS_FAIL.getCode().intValue()==status.intValue())&#123; //获得消息处理次数 Integer times = mqConsumerLog.getConsumerTimes(); if(times&gt;3)&#123; log.info(\"消息:\"+msgId+\",消息处理超过3次,不能再进行处理了\"); return; &#125; mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_PROCESSING.getCode()); //使用数据库乐观锁更新 TradeMqConsumerLogExample example = new TradeMqConsumerLogExample(); TradeMqConsumerLogExample.Criteria criteria = example.createCriteria(); criteria.andMsgTagEqualTo(mqConsumerLog.getMsgTag()); criteria.andMsgKeyEqualTo(mqConsumerLog.getMsgKey()); criteria.andGroupNameEqualTo(groupName); criteria.andConsumerTimesEqualTo(mqConsumerLog.getConsumerTimes()); int r = mqConsumerLogMapper.updateByExampleSelective(mqConsumerLog, example); if(r&lt;=0)&#123; //未修改成功,其他线程并发修改 log.info(\"并发修改,稍后处理\"); &#125; &#125; &#125;else&#123; //4. 判断如果没有消费过... mqConsumerLog = new TradeMqConsumerLog(); mqConsumerLog.setMsgTag(tags); mqConsumerLog.setMsgKey(keys); mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_PROCESSING.getCode()); mqConsumerLog.setMsgBody(body); mqConsumerLog.setMsgId(msgId); mqConsumerLog.setConsumerTimes(0); //将消息处理信息添加到数据库 mqConsumerLogMapper.insert(mqConsumerLog); &#125; //5. 回退库存 MQEntity mqEntity = JSON.parseObject(body, MQEntity.class); Long goodsId = mqEntity.getGoodsId(); TradeGoods goods = goodsMapper.selectByPrimaryKey(goodsId); goods.setGoodsNumber(goods.getGoodsNumber()+mqEntity.getGoodsNum()); goodsMapper.updateByPrimaryKey(goods); //记录库存操作日志 TradeGoodsNumberLog goodsNumberLog = new TradeGoodsNumberLog(); goodsNumberLog.setOrderId(mqEntity.getOrderId()); goodsNumberLog.setGoodsId(goodsId); goodsNumberLog.setGoodsNumber(mqEntity.getGoodsNum()); goodsNumberLog.setLogTime(new Date()); goodsNumberLogMapper.insert(goodsNumberLog); //6. 将消息的处理状态改为成功 mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_SUCCESS.getCode()); mqConsumerLog.setConsumerTimestamp(new Date()); mqConsumerLogMapper.updateByPrimaryKey(mqConsumerLog); log.info(\"回退库存成功\"); &#125; catch (Exception e) &#123; e.printStackTrace(); TradeMqConsumerLogKey primaryKey = new TradeMqConsumerLogKey(); primaryKey.setMsgTag(tags); primaryKey.setMsgKey(keys); primaryKey.setGroupName(groupName); TradeMqConsumerLog mqConsumerLog = mqConsumerLogMapper.selectByPrimaryKey(primaryKey); if(mqConsumerLog==null)&#123; //数据库未有记录 mqConsumerLog = new TradeMqConsumerLog(); mqConsumerLog.setMsgTag(tags); mqConsumerLog.setMsgKey(keys); mqConsumerLog.setConsumerStatus(ShopCode.SHOP_MQ_MESSAGE_STATUS_FAIL.getCode()); mqConsumerLog.setMsgBody(body); mqConsumerLog.setMsgId(msgId); mqConsumerLog.setConsumerTimes(1); mqConsumerLogMapper.insert(mqConsumerLog); &#125;else&#123; mqConsumerLog.setConsumerTimes(mqConsumerLog.getConsumerTimes()+1); mqConsumerLogMapper.updateByPrimaryKeySelective(mqConsumerLog); &#125; &#125; &#125;&#125;回退优惠券1234567891011121314151617181920212223242526272829303132@Slf4j@Component@RocketMQMessageListener(topic = \"$&#123;mq.order.topic&#125;\",consumerGroup = \"$&#123;mq.order.consumer.group.name&#125;\",messageModel = MessageModel.BROADCASTING )public class CancelMQListener implements RocketMQListener&lt;MessageExt&gt;&#123; @Autowired private TradeCouponMapper couponMapper; @Override public void onMessage(MessageExt message) &#123; try &#123; //1. 解析消息内容 String body = new String(message.getBody(), \"UTF-8\"); MQEntity mqEntity = JSON.parseObject(body, MQEntity.class); log.info(\"接收到消息\"); //2. 查询优惠券信息 TradeCoupon coupon = couponMapper.selectByPrimaryKey(mqEntity.getCouponId()); //3.更改优惠券状态 coupon.setUsedTime(null); coupon.setIsUsed(ShopCode.SHOP_COUPON_UNUSED.getCode()); coupon.setOrderId(null); couponMapper.updateByPrimaryKey(coupon); log.info(\"回退优惠券成功\"); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); log.error(\"回退优惠券失败\"); &#125; &#125;&#125;回退余额12345678910111213141516171819202122232425262728293031323334@Slf4j@Component@RocketMQMessageListener(topic = \"$&#123;mq.order.topic&#125;\",consumerGroup = \"$&#123;mq.order.consumer.group.name&#125;\",messageModel = MessageModel.BROADCASTING )public class CancelMQListener implements RocketMQListener&lt;MessageExt&gt;&#123; @Autowired private IUserService userService; @Override public void onMessage(MessageExt messageExt) &#123; try &#123; //1.解析消息 String body = new String(messageExt.getBody(), \"UTF-8\"); MQEntity mqEntity = JSON.parseObject(body, MQEntity.class); log.info(\"接收到消息\"); if(mqEntity.getUserMoney()!=null &amp;&amp; mqEntity.getUserMoney().compareTo(BigDecimal.ZERO)&gt;0)&#123; //2.调用业务层,进行余额修改 TradeUserMoneyLog userMoneyLog = new TradeUserMoneyLog(); userMoneyLog.setUseMoney(mqEntity.getUserMoney()); userMoneyLog.setMoneyLogType(ShopCode.SHOP_USER_MONEY_REFUND.getCode()); userMoneyLog.setUserId(mqEntity.getUserId()); userMoneyLog.setOrderId(mqEntity.getOrderId()); userService.updateMoneyPaid(userMoneyLog); log.info(\"余额回退成功\"); &#125; &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); log.error(\"余额回退失败\"); &#125; &#125;&#125;取消订单1234567891011121314@Override public void onMessage(MessageExt messageExt) &#123; String body = new String(messageExt.getBody(), \"UTF-8\"); String msgId = messageExt.getMsgId(); String tags = messageExt.getTags(); String keys = messageExt.getKeys(); log.info(\"CancelOrderProcessor receive message:\"+messageExt); CancelOrderMQ cancelOrderMQ = JSON.parseObject(body, CancelOrderMQ.class); TradeOrder order = orderService.findOne(cancelOrderMQ.getOrderId()); order.setOrderStatus(ShopCode.SHOP_ORDER_CANCEL.getCode()); orderService.changeOrderStatus(order); log.info(\"订单:[\"+order.getOrderId()+\"]状态设置为取消\"); return order; &#125;测试准备测试环境1234567@RunWith(SpringRunner.class)@SpringBootTest(classes = ShopOrderServiceApplication.class)public class OrderTest &#123; @Autowired private IOrderService orderService;&#125;准备测试数据用户数据商品数据优惠券数据测试下单成功流程123456789101112131415161718@Test public void add()&#123; Long goodsId=XXXL; Long userId=XXXL; Long couponId=XXXL; TradeOrder order = new TradeOrder(); order.setGoodsId(goodsId); order.setUserId(userId); order.setGoodsNumber(1); order.setAddress(\"北京\"); order.setGoodsPrice(new BigDecimal(\"5000\")); order.setOrderAmount(new BigDecimal(\"5000\")); order.setMoneyPaid(new BigDecimal(\"100\")); order.setCouponId(couponId); order.setShippingFee(new BigDecimal(0)); orderService.confirmOrder(order);&#125;执行完毕后,查看数据库中用户的余额、优惠券数据，及订单的状态数据测试下单失败流程代码同上。执行完毕后，查看用户的余额、优惠券数据是否发生更改，订单的状态是否为取消。支付业务创建支付订单12345678910111213141516171819202122public Result createPayment(TradePay tradePay) &#123; //查询订单支付状态 try &#123; TradePayExample payExample = new TradePayExample(); TradePayExample.Criteria criteria = payExample.createCriteria(); criteria.andOrderIdEqualTo(tradePay.getOrderId()); criteria.andIsPaidEqualTo(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode()); int count = tradePayMapper.countByExample(payExample); if (count &gt; 0) &#123; CastException.cast(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY); &#125; long payId = idWorker.nextId(); tradePay.setPayId(payId); tradePay.setIsPaid(ShopCode.SHOP_ORDER_PAY_STATUS_NO_PAY.getCode()); tradePayMapper.insert(tradePay); log.info(\"创建支付订单成功:\" + payId); &#125; catch (Exception e) &#123; return new Result(ShopCode.SHOP_FAIL.getSuccess(), ShopCode.SHOP_FAIL.getMessage()); &#125; return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage());&#125;支付回调流程分析代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344public Result callbackPayment(TradePay tradePay) &#123; if (tradePay.getIsPaid().equals(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode())) &#123; tradePay = tradePayMapper.selectByPrimaryKey(tradePay.getPayId()); if (tradePay == null) &#123; CastException.cast(ShopCode.SHOP_PAYMENT_NOT_FOUND); &#125; tradePay.setIsPaid(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode()); int i = tradePayMapper.updateByPrimaryKeySelective(tradePay); //更新成功代表支付成功 if (i == 1) &#123; TradeMqProducerTemp mqProducerTemp = new TradeMqProducerTemp(); mqProducerTemp.setId(String.valueOf(idWorker.nextId())); mqProducerTemp.setGroupName(\"payProducerGroup\"); mqProducerTemp.setMsgKey(String.valueOf(tradePay.getPayId())); mqProducerTemp.setMsgTag(topic); mqProducerTemp.setMsgBody(JSON.toJSONString(tradePay)); mqProducerTemp.setCreateTime(new Date()); mqProducerTempMapper.insert(mqProducerTemp); TradePay finalTradePay = tradePay; executorService.submit(new Runnable() &#123; @Override public void run() &#123; try &#123; SendResult sendResult = sendMessage(topic, tag, finalTradePay.getPayId(), JSON.toJSONString(finalTradePay)); log.info(JSON.toJSONString(sendResult)); if (SendStatus.SEND_OK.equals(sendResult.getSendStatus())) &#123; mqProducerTempMapper.deleteByPrimaryKey(mqProducerTemp.getId()); System.out.println(\"删除消息表成功\"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; &#125;); &#125; else &#123; CastException.cast(ShopCode.SHOP_PAYMENT_IS_PAID); &#125; &#125; return new Result(ShopCode.SHOP_SUCCESS.getSuccess(), ShopCode.SHOP_SUCCESS.getMessage());&#125;线程池优化消息发送逻辑创建线程池对象12345678910111213141516171819202122@Beanpublic ThreadPoolTaskExecutor getThreadPool() &#123; ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor(); executor.setCorePoolSize(4); executor.setMaxPoolSize(8); executor.setQueueCapacity(100); executor.setKeepAliveSeconds(60); executor.setThreadNamePrefix(\"Pool-A\"); executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy()); executor.initialize(); return executor;&#125;使用线程池123456789101112131415161718@Autowiredprivate ThreadPoolTaskExecutor executorService;executorService.submit(new Runnable() &#123; @Override public void run() &#123; try &#123; SendResult sendResult = sendMessage(topic, tag, finalTradePay.getPayId(), JSON.toJSONString(finalTradePay)); log.info(JSON.toJSONString(sendResult)); if (SendStatus.SEND_OK.equals(sendResult.getSendStatus())) &#123; mqProducerTempMapper.deleteByPrimaryKey(mqProducerTemp.getId()); System.out.println(\"删除消息表成功\"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;);处理消息支付成功后，支付服务payService发送MQ消息，订单服务、用户服务、日志服务需要订阅消息进行处理订单服务修改订单状态为已支付日志服务记录支付日志用户服务负责给用户增加积分以下用订单服务为例说明消息的处理情况配置RocketMQ属性值12mq.pay.topic=payTopicmq.pay.consumer.group.name=pay_payTopic_group消费消息在订单服务中，配置公共的消息处理类123456789101112131415161718192021222324252627public class BaseConsumer &#123; public TradeOrder handleMessage(IOrderService orderService, MessageExt messageExt,Integer code) throws Exception &#123; //解析消息内容 String body = new String(messageExt.getBody(), \"UTF-8\"); String msgId = messageExt.getMsgId(); String tags = messageExt.getTags(); String keys = messageExt.getKeys(); OrderMQ orderMq = JSON.parseObject(body, OrderMQ.class); //查询 TradeOrder order = orderService.findOne(orderMq.getOrderId()); if(ShopCode.SHOP_ORDER_MESSAGE_STATUS_CANCEL.getCode().equals(code))&#123; order.setOrderStatus(ShopCode.SHOP_ORDER_CANCEL.getCode()); &#125; if(ShopCode.SHOP_ORDER_MESSAGE_STATUS_ISPAID.getCode().equals(code))&#123; order.setPayStatus(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode()); &#125; orderService.changeOrderStatus(order); return order; &#125;&#125;接受订单支付成功消息1234567891011121314151617181920212223@Slf4j@Component@RocketMQMessageListener(topic = \"$&#123;mq.pay.topic&#125;\", consumerGroup = \"$&#123;mq.pay.consumer.group.name&#125;\")public class PayConsumer extends BaseConsumer implements RocketMQListener&lt;MessageExt&gt; &#123; @Autowired private IOrderService orderService; @Override public void onMessage(MessageExt messageExt) &#123; try &#123; log.info(\"CancelOrderProcessor receive message:\"+messageExt); TradeOrder order = handleMessage(orderService, messageExt, ShopCode.SHOP_ORDER_MESSAGE_STATUS_ISPAID.getCode()); log.info(\"订单:[\"+order.getOrderId()+\"]支付成功\"); &#125; catch (Exception e) &#123; e.printStackTrace(); log.error(\"订单支付失败\"); &#125; &#125;&#125;整体联调通过Rest客户端请求shop-order-web和shop-pay-web完成下单和支付操作准备工作配置RestTemplate类12345678910111213141516171819202122232425262728293031323334@Configurationpublic class RestTemplateConfig &#123; @Bean @ConditionalOnMissingBean(&#123; RestOperations.class, RestTemplate.class &#125;) public RestTemplate restTemplate(ClientHttpRequestFactory factory) &#123; RestTemplate restTemplate = new RestTemplate(factory); // 使用 utf-8 编码集的 conver 替换默认的 conver（默认的 string conver 的编码集为\"ISO-8859-1\"） List&lt;HttpMessageConverter&lt;?&gt;&gt; messageConverters = restTemplate.getMessageConverters(); Iterator&lt;HttpMessageConverter&lt;?&gt;&gt; iterator = messageConverters.iterator(); while (iterator.hasNext()) &#123; HttpMessageConverter&lt;?&gt; converter = iterator.next(); if (converter instanceof StringHttpMessageConverter) &#123; iterator.remove(); &#125; &#125; messageConverters.add(new StringHttpMessageConverter(Charset.forName(\"UTF-8\"))); return restTemplate; &#125; @Bean @ConditionalOnMissingBean(&#123;ClientHttpRequestFactory.class&#125;) public ClientHttpRequestFactory simpleClientHttpRequestFactory() &#123; SimpleClientHttpRequestFactory factory = new SimpleClientHttpRequestFactory(); // ms factory.setReadTimeout(15000); // ms factory.setConnectTimeout(15000); return factory; &#125;&#125;配置请求地址订单系统12345server.host=http://localhostserver.servlet.path=/order-webserver.port=8080shop.order.baseURI=$&#123;server.host&#125;:$&#123;server.port&#125;$&#123;server.servlet.path&#125;shop.order.confirm=/order/confirm支付系统123456server.host=http://localhostserver.servlet.path=/pay-webserver.port=9090shop.pay.baseURI=$&#123;server.host&#125;:$&#123;server.port&#125;$&#123;server.servlet.path&#125;shop.pay.createPayment=/pay/createPaymentshop.pay.callbackPayment=/pay/callbackPayment下单测试123456789101112131415161718192021222324252627282930313233343536373839404142@RunWith(SpringRunner.class)@ContextConfiguration(classes = ShopOrderWebApplication.class)@TestPropertySource(\"classpath:application.properties\")public class OrderTest &#123; @Autowired private RestTemplate restTemplate; @Value(\"$&#123;shop.order.baseURI&#125;\") private String baseURI; @Value(\"$&#123;shop.order.confirm&#125;\") private String confirmOrderPath; @Autowired private IDWorker idWorker; /** * 下单 */ @Test public void confirmOrder()&#123; Long goodsId=XXXL; Long userId=XXXL; Long couponId=XXXL; TradeOrder order = new TradeOrder(); order.setGoodsId(goodsId); order.setUserId(userId); order.setGoodsNumber(1); order.setAddress(\"北京\"); order.setGoodsPrice(new BigDecimal(\"5000\")); order.setOrderAmount(new BigDecimal(\"5000\")); order.setMoneyPaid(new BigDecimal(\"100\")); order.setCouponId(couponId); order.setShippingFee(new BigDecimal(0)); Result result = restTemplate.postForEntity(baseURI + confirmOrderPath, order, Result.class).getBody(); System.out.println(result); &#125;&#125;支付测试1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@RunWith(SpringRunner.class)@ContextConfiguration(classes = ShopPayWebApplication.class)@TestPropertySource(\"classpath:application.properties\")public class PayTest &#123; @Autowired private RestTemplate restTemplate; @Value(\"$&#123;shop.pay.baseURI&#125;\") private String baseURI; @Value(\"$&#123;shop.pay.createPayment&#125;\") private String createPaymentPath; @Value(\"$&#123;shop.pay.callbackPayment&#125;\") private String callbackPaymentPath; @Autowired private IDWorker idWorker; /** * 创建支付订单 */ @Test public void createPayment()&#123; Long orderId = 346321587315814400L; TradePay pay = new TradePay(); pay.setOrderId(orderId); pay.setPayAmount(new BigDecimal(4800)); Result result = restTemplate.postForEntity(baseURI + createPaymentPath, pay, Result.class).getBody(); System.out.println(result); &#125; /** * 支付回调 */ @Test public void callbackPayment()&#123; Long payId = 346321891507720192L; TradePay pay = new TradePay(); pay.setPayId(payId); pay.setIsPaid(ShopCode.SHOP_ORDER_PAY_STATUS_IS_PAY.getCode()); Result result = restTemplate.postForEntity(baseURI + callbackPaymentPath, pay, Result.class).getBody(); System.out.println(result); &#125;&#125;","categories":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://me.obey.fun/categories/MessageQueue/"},{"name":"RocketMQ","slug":"MessageQueue/RocketMQ","permalink":"https://me.obey.fun/categories/MessageQueue/RocketMQ/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://me.obey.fun/tags/中间件/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://me.obey.fun/tags/RocketMQ/"}],"keywords":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://me.obey.fun/categories/MessageQueue/"},{"name":"RocketMQ","slug":"MessageQueue/RocketMQ","permalink":"https://me.obey.fun/categories/MessageQueue/RocketMQ/"}]},{"title":"初探RocketMQ","slug":"初探RocketMQ","date":"2020-06-13T12:37:29.000Z","updated":"2020-06-15T02:21:32.000Z","comments":true,"path":"初探RocketMQ.html","link":"","permalink":"https://me.obey.fun/初探RocketMQ.html","excerpt":"","text":"MQ介绍为什么要用MQ消息队列是一种“先进先出”的数据结构其应用场景主要包含以下3个方面应用解耦系统的耦合性越高，容错性就越低。以电商应用为例，用户创建订单后，如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常，影响用户使用体验。使用消息队列解耦合，系统的耦合性就会提高了。比如物流系统发生故障，需要几分钟才能来修复，在这段时间内，物流系统要处理的数据被缓存到消息队列中，用户的下单操作正常完成。当物流系统回复后，补充处理存在消息队列中的订单消息即可，终端系统感知不到物流系统发生过几分钟故障。流量削峰应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了消息队列可以将大量请求缓存起来，分散到很长一段时间处理，这样可以大大提到系统的稳定性和用户体验。一般情况，为了保证系统的稳定性，如果系统负载超过阈值，就会阻止用户请求，这会影响用户体验，而如果使用消息队列将请求缓存起来，等待系统处理完毕后通知用户下单完毕，这样总不能下单体验要好。处于经济考量目的：业务系统正常时段的QPS如果是1000，流量最高峰是10000，为了应对流量高峰配置高性能的服务器显然不划算，这时可以使用消息队列对峰值流量削峰数据分发通过消息队列可以让数据在多个系统更加之间进行流通。数据的产生方不需要关心谁来使用数据，只需要将数据发送到消息队列，数据使用方直接在消息队列中直接获取数据即可MQ的优点和缺点优点：解耦、削峰、数据分发缺点包含以下几点：系统可用性降低系统引入的外部依赖越多，系统稳定性越差。一旦MQ宕机，就会对业务造成影响。如何保证MQ的高可用？系统复杂度提高MQ的加入大大增加了系统的复杂度，以前系统间是同步的远程调用，现在是通过MQ进行异步调用。如何保证消息没有被重复消费？怎么处理消息丢失情况？那么保证消息传递的顺序性？一致性问题A系统处理完业务，通过MQ给B、C、D三个系统发消息数据，如果B系统、C系统处理成功，D系统处理失败。如何保证消息数据处理的一致性？各种MQ产品的比较常见的MQ产品包括Kafka、ActiveMQ、RabbitMQ、RocketMQ。RocketMQ快速入门RocketMQ是阿里巴巴2016年MQ中间件，使用Java语言开发，在阿里内部，RocketMQ承接了例如“双11”等高并发场景的消息流转，能够处理万亿级别的消息。准备工作下载RocketMQRocketMQ最新版本：4.5.1下载地址环境要求Linux64位系统JDK1.8(64位)源码安装需要安装Maven 3.2.x安装RocketMQ安装步骤本教程以二进制包方式安装解压安装包进入安装目录目录介绍bin：启动脚本，包括shell脚本和CMD脚本conf：实例配置文件 ，包括broker配置文件、logback配置文件等lib：依赖jar包，包括Netty、commons-lang、FastJSON等启动RocketMQ启动NameServer1234# 1.启动NameServernohup sh bin/mqnamesrv &amp;# 2.查看启动日志tail -f ~/logs/rocketmqlogs/namesrv.log启动Broker1234# 1.启动Brokernohup sh bin/mqbroker -n localhost:9876 &amp;# 2.查看启动日志tail -f ~/logs/rocketmqlogs/broker.log问题描述：RocketMQ默认的虚拟机内存较大，启动Broker如果因为内存不足失败，需要编辑如下两个配置文件，修改JVM内存大小123# 编辑runbroker.sh和runserver.sh修改默认JVM大小vi runbroker.shvi runserver.sh参考设置：12345678910## 测试RocketMQ### 发送消息```sh# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.使用安装包的Demo发送消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Producer接收消息1234# 1.设置环境变量export NAMESRV_ADDR=localhost:9876# 2.接收消息sh bin/tools.sh org.apache.rocketmq.example.quickstart.Consumer关闭RocketMQ1234# 1.关闭NameServersh bin/mqshutdown namesrv# 2.关闭Brokersh bin/mqshutdown brokerRocketMQ集群搭建各角色介绍Producer：消息的发送者；举例：发信者Consumer：消息接收者；举例：收信者Broker：暂存和传输消息；举例：邮局NameServer：管理Broker；举例：各个邮局的管理机构Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者可以订阅一个或者多个Topic消息Message Queue：相当于是Topic的分区；用于并行发送和接收消息集群搭建方式集群特点NameServer是一个几乎无状态节点，可集群部署，节点之间无任何信息同步。Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。Producer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master建立长连接，且定时向Master发送心跳。Producer完全无状态，可集群部署。Consumer与NameServer集群中的其中一个节点（随机选择）建立长连接，定期从NameServer取Topic路由信息，并向提供Topic服务的Master、Slave建立长连接，且定时向Master、Slave发送心跳。Consumer既可以从Master订阅消息，也可以从Slave订阅消息，订阅规则由Broker配置决定。集群模式单Master模式这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用。不建议线上环境使用,可以用于本地测试。多Master模式一个集群无Slave，全是Master，例如2个Master或者3个Master，这种模式的优缺点如下：优点：配置简单，单个Master宕机或重启维护对应用无影响，在磁盘配置为RAID10时，即使机器宕机不可恢复情况下，由于RAID10磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢），性能最高；缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。多Master多Slave模式（异步）每个Master配置一个Slave，有多对Master-Slave，HA采用异步复制方式，主备有短暂消息延迟（毫秒级），这种模式的优缺点如下：优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，同时Master宕机后，消费者仍然可以从Slave消费，而且此过程对应用透明，不需要人工干预，性能同多Master模式几乎一样；缺点：Master宕机，磁盘损坏情况下会丢失少量消息。多Master多Slave模式（同步）每个Master配置一个Slave，有多对Master-Slave，HA采用同步双写方式，即只有主备都写成功，才向应用返回成功，这种模式的优缺点如下：优点：数据与服务都无单点故障，Master宕机情况下，消息无延迟，服务可用性与数据可用性都非常高；缺点：性能比异步复制模式略低（大约低10%左右），发送单个消息的RT会略高，且目前版本在主节点宕机后，备机不能自动切换为主机。双主双从集群搭建总体架构消息高可用采用2m-2s（同步双写）方式集群工作流程启动NameServer，NameServer起来后监听端口，等待Broker、Producer、Consumer连上来，相当于一个路由控制中心。Broker启动，跟所有的NameServer保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有Topic信息。注册成功后，NameServer集群中就有Topic跟Broker的映射关系。收发消息前，先创建Topic，创建Topic时需要指定该Topic要存储在哪些Broker上，也可以在发送消息时自动创建Topic。Producer发送消息，启动时先跟NameServer集群中的其中一台建立长连接，并从NameServer中获取当前发送的Topic存在哪些Broker上，轮询从队列列表中选择一个队列，然后与队列所在的Broker建立长连接从而向Broker发消息。Consumer跟Producer类似，跟其中一台NameServer建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。服务器环境序号IP角色架构模式1192.168.25.135nameserver、brokerserverMaster1、Slave22192.168.25.138nameserver、brokerserverMaster2、Slave1Host添加信息1vim /etc/hosts配置如下:12345678# nameserver192.168.25.135 rocketmq-nameserver1192.168.25.138 rocketmq-nameserver2# broker192.168.25.135 rocketmq-master1192.168.25.135 rocketmq-slave2192.168.25.138 rocketmq-master2192.168.25.138 rocketmq-slave1配置完成后, 重启网卡1systemctl restart network防火墙配置宿主机需要远程访问虚拟机的rocketmq服务和web服务，需要开放相关的端口号，简单粗暴的方式是直接关闭防火墙123456# 关闭防火墙systemctl stop firewalld.service # 查看防火墙的状态firewall-cmd --state # 禁止firewall开机启动systemctl disable firewalld.service或者为了安全，只开放特定的端口号，RocketMQ默认使用3个端口：9876 、10911 、11011 。如果防火墙没有关闭的话，那么防火墙就必须开放这些端口：nameserver 默认使用 9876 端口master 默认使用 10911 端口slave 默认使用11011 端口执行以下命令：12345678# 开放name server默认端口firewall-cmd --remove-port=9876/tcp --permanent# 开放master默认端口firewall-cmd --remove-port=10911/tcp --permanent# 开放slave默认端口 (当前集群模式可不开启)firewall-cmd --remove-port=11011/tcp --permanent # 重启防火墙firewall-cmd --reload环境变量配置1vim /etc/profile在profile文件的末尾加入如下命令1234#set rocketmqROCKETMQ_HOME=/usr/local/rocketmq/rocketmq-all-4.4.0-bin-releasePATH=$PATH:$ROCKETMQ_HOME/binexport ROCKETMQ_HOME PATH输入:wq! 保存并退出， 并使得配置立刻生效：1source /etc/profile创建消息存储路径1234mkdir /usr/local/rocketmq/storemkdir /usr/local/rocketmq/store/commitlogmkdir /usr/local/rocketmq/store/consumequeuemkdir /usr/local/rocketmq/store/indexbroker配置文件master1服务器：192.168.25.1351vi /usr/soft/rocketmq/conf/2m-2s-sync/broker-a.properties修改配置如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128slave2服务器：192.168.25.1351vi /usr/soft/rocketmq/conf/2m-2s-sync/broker-b-s.properties修改配置如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=1#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=11011#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SLAVE#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128master2服务器：192.168.25.1381vi /usr/soft/rocketmq/conf/2m-2s-sync/broker-b.properties修改配置如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-b#0 表示 Master，&gt;0 表示 SlavebrokerId=0#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=10911#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SYNC_MASTER#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=SYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128slave1服务器：192.168.25.1381vi /usr/soft/rocketmq/conf/2m-2s-sync/broker-a-s.properties修改配置如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960#所属集群名字brokerClusterName=rocketmq-cluster#broker名字，注意此处不同的配置文件填写的不一样brokerName=broker-a#0 表示 Master，&gt;0 表示 SlavebrokerId=1#nameServer地址，分号分割namesrvAddr=rocketmq-nameserver1:9876;rocketmq-nameserver2:9876#在发送消息时，自动创建服务器不存在的topic，默认创建的队列数defaultTopicQueueNums=4#是否允许 Broker 自动创建Topic，建议线下开启，线上关闭autoCreateTopicEnable=true#是否允许 Broker 自动创建订阅组，建议线下开启，线上关闭autoCreateSubscriptionGroup=true#Broker 对外服务的监听端口listenPort=11011#删除文件时间点，默认凌晨 4点deleteWhen=04#文件保留时间，默认 48 小时fileReservedTime=120#commitLog每个文件的大小默认1GmapedFileSizeCommitLog=1073741824#ConsumeQueue每个文件默认存30W条，根据业务情况调整mapedFileSizeConsumeQueue=300000#destroyMapedFileIntervalForcibly=120000#redeleteHangedFileInterval=120000#检测物理文件磁盘空间diskMaxUsedSpaceRatio=88#存储路径storePathRootDir=/usr/local/rocketmq/store#commitLog 存储路径storePathCommitLog=/usr/local/rocketmq/store/commitlog#消费队列存储路径存储路径storePathConsumeQueue=/usr/local/rocketmq/store/consumequeue#消息索引存储路径storePathIndex=/usr/local/rocketmq/store/index#checkpoint 文件存储路径storeCheckpoint=/usr/local/rocketmq/store/checkpoint#abort 文件存储路径abortFile=/usr/local/rocketmq/store/abort#限制的消息大小maxMessageSize=65536#flushCommitLogLeastPages=4#flushConsumeQueueLeastPages=2#flushCommitLogThoroughInterval=10000#flushConsumeQueueThoroughInterval=60000#Broker 的角色#- ASYNC_MASTER 异步复制Master#- SYNC_MASTER 同步双写Master#- SLAVEbrokerRole=SLAVE#刷盘方式#- ASYNC_FLUSH 异步刷盘#- SYNC_FLUSH 同步刷盘flushDiskType=ASYNC_FLUSH#checkTransactionMessageEnable=false#发消息线程池数量#sendMessageThreadPoolNums=128#拉消息线程池数量#pullMessageThreadPoolNums=128修改启动脚本文件runbroker.sh1vi /usr/local/rocketmq/bin/runbroker.sh需要根据内存大小进行适当的对JVM参数进行调整：123#===================================================# 开发环境配置 JVM ConfigurationJAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m\"runserver.sh1vim /usr/local/rocketmq/bin/runserver.sh1JAVA_OPT=\"$&#123;JAVA_OPT&#125; -server -Xms256m -Xmx256m -Xmn128m -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m\"服务启动启动NameServe集群分别在192.168.25.135和192.168.25.138启动NameServer12cd /usr/local/rocketmq/binnohup sh mqnamesrv &amp;启动Broker集群在192.168.25.135上启动master1和slave2master1：12cd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-syncbroker-a.properties &amp;slave2：12cd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-sync/broker-b-s.properties &amp;在192.168.25.138上启动master2和slave2master212cd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-sync/broker-b.properties &amp;slave112cd /usr/local/rocketmq/binnohup sh mqbroker -c /usr/local/rocketmq/conf/2m-2s-sync/broker-a-s.properties &amp;查看进程状态启动后通过JPS查看启动进程查看日志1234# 查看nameServer日志tail -500f ~/logs/rocketmqlogs/namesrv.log# 查看broker日志tail -500f ~/logs/rocketmqlogs/broker.logmqadmin管理工具使用方式进入RocketMQ安装位置，在bin目录下执行./mqadmin {command} {args}命令介绍Topic相关名称含义命令选项说明updateTopic创建更新Topic配置-bBroker 地址，表示 topic 所在Broker，只支持单台Broker，地址为ip:portupdateTopic创建更新Topic配置-ccluster 名称，表示 topic 所在集群（集群可通过clusterList 查询）updateTopic创建更新Topic配置-h打印帮助updateTopic创建更新Topic配置-nNameServer服务地址，格式 ip:portupdateTopic创建更新Topic配置-p指定新topic的读写权限( W=2,R=4,WR=6 )updateTopic创建更新Topic配置-r可读队列数（默认为 8）updateTopic创建更新Topic配置-w可写队列数（默认为 8）updateTopic创建更新Topic配置-ttopic 名称（名称只能使用字符^[a-zA-Z0-9_-]+$ ）deleteTopic删除Topic-ccluster 名称，表示 topic 所在集群（集群可通过clusterList 查询）deleteTopic删除Topic-h打印帮助deleteTopic删除Topic-nNameServer服务地址，格式 ip:portdeleteTopic删除Topic-p指定新topic的读写权限( W=2,R=4,WR=6 )topicList查看 Topic 列表信息-h打印帮助topicList查看 Topic 列表信息-c不配置-c只返回topic列表，增加-c返回clusterName,topic, consumerGroup信息，即topic的所属集群和订阅关系，没有参数topicList查看 Topic 列表信息-nNameServer服务地址，格式 ip:porttopicRoute查看 Topic 路由信息-ttopic 名称（名称只能使用字符^[a-zA-Z0-9_-]+$ ）topicRoute查看 Topic 路由信息-h打印帮助topicRoute查看 Topic 路由信息-nNameServer服务地址，格式 ip:porttopicStatus查看 Topic 消息队列offset-ttopic 名称（名称只能使用字符^[a-zA-Z0-9_-]+$ ）topicStatus查看 Topic 消息队列offset-h打印帮助topicStatus查看 Topic 消息队列offset-nNameServer服务地址，格式 ip:porttopicClusterList查看 Topic 所在集群列表-ttopic 名称（名称只能使用字符^[a-zA-Z0-9_-]+$ ）topicClusterList查看 Topic 所在集群列表-h打印帮助topicClusterList查看 Topic 所在集群列表-nNameServer服务地址，格式 ip:portupdateTopicPerm更新 Topic 读写权限-ttopic 名称（名称只能使用字符^[a-zA-Z0-9_-]+$ ）updateTopicPerm更新 Topic 读写权限-h打印帮助updateTopicPerm更新 Topic 读写权限-nNameServer服务地址，格式 ip:portupdateTopicPerm更新 Topic 读写权限-bBroker 地址，表示 topic 所在Broker，只支持单台Broker，地址为ip:portupdateTopicPerm更新 Topic 读写权限-ccluster 名称，表示 topic 所在集群（集群可通过clusterList 查询）updateTopicPerm更新 Topic 读写权限-p指定新topic的读写权限( W=2,R=4,WR=6 )updateOrderConf从NameServer上创建、删除、获取特定命名空间的kv配置，目前还未启用-ttopic 名称（名称只能使用字符^[a-zA-Z0-9_-]+$ ）updateOrderConf从NameServer上创建、删除、获取特定命名空间的kv配置，目前还未启用-h打印帮助updateOrderConf从NameServer上创建、删除、获取特定命名空间的kv配置，目前还未启用-nNameServer服务地址，格式 ip:portupdateOrderConf从NameServer上创建、删除、获取特定命名空间的kv配置，目前还未启用-vorderConf，值updateOrderConf从NameServer上创建、删除、获取特定命名空间的kv配置，目前还未启用-mmethod，可选get、put、deleteallocateMQ以平均负载算法计算消费者列表负载消息队列的负载结果-ttopic 名称（名称只能使用字符^[a-zA-Z0-9_-]+$ ）allocateMQ以平均负载算法计算消费者列表负载消息队列的负载结果-h打印帮助allocateMQ以平均负载算法计算消费者列表负载消息队列的负载结果-nNameServer服务地址，格式 ip:portallocateMQ以平均负载算法计算消费者列表负载消息队列的负载结果-iipList，用逗号分隔，计算这些ip去负载Topic的消息队列statsAll打印Topic订阅关系、TPS、积累量、24h读写总量等信息-h打印帮助statsAll打印Topic订阅关系、TPS、积累量、24h读写总量等信息-nNameServer服务地址，格式 ip:portstatsAll打印Topic订阅关系、TPS、积累量、24h读写总量等信息-a是否只打印活跃topicstatsAll打印Topic订阅关系、TPS、积累量、24h读写总量等信息-t指定topic集群相关名称含义命令选项说明clusterList查看集群信息，集群、BrokerName、BrokerId、TPS等信息-m打印更多信息 (增加打印出如下信息 #InTotalYest,#OutTotalYest, #InTotalToday ,#OutTotalToday)clusterList查看集群信息，集群、BrokerName、BrokerId、TPS等信息-h打印帮助clusterList查看集群信息，集群、BrokerName、BrokerId、TPS等信息-nNameServer服务地址，格式 ip:portclusterList查看集群信息，集群、BrokerName、BrokerId、TPS等信息-i打印间隔，单位秒clusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-aamount，每次探测的总数，RT = 总时间 /amountclusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-s消息大小，单位BclusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-c探测哪个集群clusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-p是否打印格式化日志，以丨分割，默认不打印clusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-h打印帮助clusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-m所属机房，打印使用clusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-i发送间隔，单位秒clusterRT发送消息检测集群各Broker RT。消息发往${BrokerName} Topic。-nNameServer 服务地址，格式 ip:portBroker相关名称含义命令选项说明updateBrokerConfig更新 Broker 配置文件，会修改Broker.conf-bBroker 地址，格式为ip:portupdateBrokerConfig更新 Broker 配置文件，会修改Broker.conf-ccluster 名称updateBrokerConfig更新 Broker 配置文件，会修改Broker.conf-kkey 值updateBrokerConfig更新 Broker 配置文件，会修改Broker.conf-vvalue 值updateBrokerConfig更新 Broker 配置文件，会修改Broker.conf-h打印帮助updateBrokerConfig更新 Broker 配置文件，会修改Broker.conf-nNameServer 服务地址，格式 ip:portbrokerStatus查看 Broker 统计信息、运行状态（你想要的信息几乎都在里面）-h打印帮助brokerStatus查看 Broker 统计信息、运行状态（你想要的信息几乎都在里面）-nNameServer 服务地址，格式 ip:portbrokerStatus查看 Broker 统计信息、运行状态（你想要的信息几乎都在里面）-bBroker 地址，格式为ip:portbrokerConsumeStatsBroker中各个消费者的消费情况，按Message Queue维度返回Consume Offset，Broker Offset，Diff，TImestamp等信息-h打印帮助brokerConsumeStatsBroker中各个消费者的消费情况，按Message Queue维度返回Consume Offset，Broker Offset，Diff，TImestamp等信息-nNameServer 服务地址，格式 ip:portbrokerConsumeStatsBroker中各个消费者的消费情况，按Message Queue维度返回Consume Offset，Broker Offset，Diff，TImestamp等信息-bBroker 地址，格式为ip:portbrokerConsumeStatsBroker中各个消费者的消费情况，按Message Queue维度返回Consume Offset，Broker Offset，Diff，TImestamp等信息-t请求超时时间brokerConsumeStatsBroker中各个消费者的消费情况，按Message Queue维度返回Consume Offset，Broker Offset，Diff，TImestamp等信息-ldiff阈值，超过阈值才打印brokerConsumeStatsBroker中各个消费者的消费情况，按Message Queue维度返回Consume Offset，Broker Offset，Diff，TImestamp等信息-o是否为顺序topic，一般为falsegetBrokerConfig获取Broker配置-nNameServer 服务地址，格式 ip:portgetBrokerConfig获取Broker配置-bBroker 地址，格式为ip:portwipeWritePerm从NameServer上清除 Broker写权限-h打印帮助wipeWritePerm从NameServer上清除 Broker写权限-nNameServer 服务地址，格式 ip:portwipeWritePerm从NameServer上清除 Broker写权限-bBroker 地址，格式为ip:portcleanExpiredCQ清理Broker上过期的Consume Queue，如果手动减少对列数可能产生过期队列-h打印帮助cleanExpiredCQ清理Broker上过期的Consume Queue，如果手动减少对列数可能产生过期队列-nNameServer 服务地址，格式 ip:portcleanExpiredCQ清理Broker上过期的Consume Queue，如果手动减少对列数可能产生过期队列-bBroker 地址，格式为ip:portcleanExpiredCQ清理Broker上过期的Consume Queue，如果手动减少对列数可能产生过期队列-ccluster 名称cleanUnusedTopic清理Broker上不使用的Topic，从内存中释放Topic的Consume Queue，如果手动删除Topic会产生不使用的Topic-h打印帮助cleanUnusedTopic清理Broker上不使用的Topic，从内存中释放Topic的Consume Queue，如果手动删除Topic会产生不使用的Topic-nNameServer 服务地址，格式 ip:portcleanUnusedTopic清理Broker上不使用的Topic，从内存中释放Topic的Consume Queue，如果手动删除Topic会产生不使用的Topic-bBroker 地址，格式为ip:portcleanUnusedTopic清理Broker上不使用的Topic，从内存中释放Topic的Consume Queue，如果手动删除Topic会产生不使用的Topic-ccluster 名称sendMsgStatus向Broker发消息，返回发送状态和RT-h打印帮助sendMsgStatus向Broker发消息，返回发送状态和RT-nNameServer 服务地址，格式 ip:portsendMsgStatus向Broker发消息，返回发送状态和RT-bBroker 地址，格式为ip:portsendMsgStatus向Broker发消息，返回发送状态和RT-ccluster 名称sendMsgStatus向Broker发消息，返回发送状态和RT-s消息大小，单位B消息相关名称含义命令选项说明queryMsgById根据offsetMsgId查询msg，如果使用开源控制台，应使用offsetMsgId，此命令还有其他参数，具体作用请阅读QueryMsgByIdSubCommand。-h打印帮助queryMsgById根据offsetMsgId查询msg，如果使用开源控制台，应使用offsetMsgId，此命令还有其他参数，具体作用请阅读QueryMsgByIdSubCommand。-nNameServer 服务地址，格式 ip:portqueryMsgById根据offsetMsgId查询msg，如果使用开源控制台，应使用offsetMsgId，此命令还有其他参数，具体作用请阅读QueryMsgByIdSubCommand。-iqueueIdqueryMsgByKey根据消息 Key 查询消息-h打印帮助queryMsgByKey根据消息 Key 查询消息-nNameServer 服务地址，格式 ip:portqueryMsgByKey根据消息 Key 查询消息-kmsgKeyqueryMsgByKey根据消息 Key 查询消息-ttopic名称queryMsgByOffset根据 Offset 查询消息-h打印帮助queryMsgByOffset根据 Offset 查询消息-nNameServer 服务地址，格式 ip:portqueryMsgByOffset根据 Offset 查询消息-ooffset 值queryMsgByOffset根据 Offset 查询消息-iqueueIdqueryMsgByOffset根据 Offset 查询消息-b开始时间戳，格式参见-hqueryMsgByUniqueKey根据msgId查询，msgId不同于offsetMsgId，区别详见常见运维问题。-g，-d配合使用，查到消息后尝试让特定的消费者消费消息并返回消费结果-h打印帮助queryMsgByUniqueKey根据msgId查询，msgId不同于offsetMsgId，区别详见常见运维问题。-g，-d配合使用，查到消息后尝试让特定的消费者消费消息并返回消费结果-nNameServer 服务地址，格式 ip:portqueryMsgByUniqueKey根据msgId查询，msgId不同于offsetMsgId，区别详见常见运维问题。-g，-d配合使用，查到消息后尝试让特定的消费者消费消息并返回消费结果-gconsumerGroupqueryMsgByUniqueKey根据msgId查询，msgId不同于offsetMsgId，区别详见常见运维问题。-g，-d配合使用，查到消息后尝试让特定的消费者消费消息并返回消费结果-d是否打印消息体queryMsgByUniqueKey根据msgId查询，msgId不同于offsetMsgId，区别详见常见运维问题。-g，-d配合使用，查到消息后尝试让特定的消费者消费消息并返回消费结果-iuniqe msg idqueryMsgByUniqueKey根据msgId查询，msgId不同于offsetMsgId，区别详见常见运维问题。-g，-d配合使用，查到消息后尝试让特定的消费者消费消息并返回消费结果-ttopic名称checkMsgSendRT检测向topic发消息的RT，功能类似clusterRT-h打印帮助checkMsgSendRT检测向topic发消息的RT，功能类似clusterRT-nNameServer 服务地址，格式 ip:portcheckMsgSendRT检测向topic发消息的RT，功能类似clusterRT-ttopic名称checkMsgSendRT检测向topic发消息的RT，功能类似clusterRT-aBrokerNamecheckMsgSendRT检测向topic发消息的RT，功能类似clusterRT-ssubExpress，过滤表达式sendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-h打印帮助sendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-nNameServer 服务地址，格式 ip:portsendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-ttopic名称sendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-p是否打印消息sendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-kmsgKeysendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-c字符集，例如UTF-8sendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-b开始时间戳，格式参见-hsendMessage发送一条消息，可以根据配置发往特定Message Queue，或普通发送。-iqueueIdconsumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-h打印帮助consumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-nNameServer 服务地址，格式 ip:portconsumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-ttopic名称consumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-b开始时间戳，格式参见-hconsumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-ooffset 值consumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-iqueueIdconsumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-gconsumerGroupconsumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-ssubExpress，过滤表达式consumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-d是否打印消息体consumeMessage消费消息。可以根据offset、开始&amp;结束时间戳、消息队列消费消息，配置不同执行不同消费逻辑，详见ConsumeMessageCommand。-c字符集，例如UTF-8printMsg从Broker消费消息并打印，可选时间段-h打印帮助printMsg从Broker消费消息并打印，可选时间段-nNameServer 服务地址，格式 ip:portprintMsg从Broker消费消息并打印，可选时间段-ttopic名称printMsg从Broker消费消息并打印，可选时间段-ssubExpress，过滤表达式printMsg从Broker消费消息并打印，可选时间段-b开始时间戳，格式参见-hprintMsg从Broker消费消息并打印，可选时间段-e结束时间戳printMsg从Broker消费消息并打印，可选时间段-d是否打印消息体printMsgByQueue类似printMsg，但指定Message Queue-h打印帮助printMsgByQueue类似printMsg，但指定Message Queue-nNameServer 服务地址，格式 ip:portprintMsgByQueue类似printMsg，但指定Message Queue-ttopic名称printMsgByQueue类似printMsg，但指定Message Queue-iqueueIdprintMsgByQueue类似printMsg，但指定Message Queue-aBrokerNameprintMsgByQueue类似printMsg，但指定Message Queue-c字符集，例如UTF-8printMsgByQueue类似printMsg，但指定Message Queue-ssubExpress，过滤表达式printMsgByQueue类似printMsg，但指定Message Queue-b开始时间戳，格式参见-hprintMsgByQueue类似printMsg，但指定Message Queue-e结束时间戳printMsgByQueue类似printMsg，但指定Message Queue-p是否打印消息printMsgByQueue类似printMsg，但指定Message Queue-d是否打印消息体printMsgByQueue类似printMsg，但指定Message Queue-f是否统计tag数量并打印resetOffsetByTime按时间戳重置offset，Broker和consumer都会重置-h打印帮助resetOffsetByTime按时间戳重置offset，Broker和consumer都会重置-nNameServer 服务地址，格式 ip:portresetOffsetByTime按时间戳重置offset，Broker和consumer都会重置-gconsumerGroupresetOffsetByTime按时间戳重置offset，Broker和consumer都会重置-ttopic名称resetOffsetByTime按时间戳重置offset，Broker和consumer都会重置-ssubExpress，过滤表达式resetOffsetByTime按时间戳重置offset，Broker和consumer都会重置-f是否统计tag数量并打印resetOffsetByTime按时间戳重置offset，Broker和consumer都会重置-c字符集，例如UTF-8消费者、消费组相关名称含义命令选项说明consumerProgress查看订阅组消费状态，可以查看具体的client IP的消息积累量-h打印帮助consumerProgress查看订阅组消费状态，可以查看具体的client IP的消息积累量-nNameServer 服务地址，格式 ip:portconsumerProgress查看订阅组消费状态，可以查看具体的client IP的消息积累量-g消费者所属组名consumerProgress查看订阅组消费状态，可以查看具体的client IP的消息积累量-s是否打印client IPconsumerStatus查看消费者状态，包括同一个分组中是否都是相同的订阅，分析Process Queue是否堆积，返回消费者jstack结果，内容较多，使用者参见ConsumerStatusSubCommand-h打印帮助consumerStatus查看消费者状态，包括同一个分组中是否都是相同的订阅，分析Process Queue是否堆积，返回消费者jstack结果，内容较多，使用者参见ConsumerStatusSubCommand-nNameServer 服务地址，格式 ip:portconsumerStatus查看消费者状态，包括同一个分组中是否都是相同的订阅，分析Process Queue是否堆积，返回消费者jstack结果，内容较多，使用者参见ConsumerStatusSubCommand-g消费者所属组名consumerStatus查看消费者状态，包括同一个分组中是否都是相同的订阅，分析Process Queue是否堆积，返回消费者jstack结果，内容较多，使用者参见ConsumerStatusSubCommand-iclientIdconsumerStatus查看消费者状态，包括同一个分组中是否都是相同的订阅，分析Process Queue是否堆积，返回消费者jstack结果，内容较多，使用者参见ConsumerStatusSubCommand-s是否执行jstackgetConsumerStatus获取 Consumer 消费进度-h打印帮助getConsumerStatus获取 Consumer 消费进度-nNameServer 服务地址，格式 ip:portgetConsumerStatus获取 Consumer 消费进度-g消费者所属组名getConsumerStatus获取 Consumer 消费进度-iclientIdgetConsumerStatus获取 Consumer 消费进度-t查询主题updateSubGroup更新或创建订阅关系-nNameServer 服务地址，格式 ip:portupdateSubGroup更新或创建订阅关系-h打印帮助updateSubGroup更新或创建订阅关系-bBroker地址updateSubGroup更新或创建订阅关系-c集群名称updateSubGroup更新或创建订阅关系-g消费者分组名称updateSubGroup更新或创建订阅关系-s分组是否允许消费updateSubGroup更新或创建订阅关系-m是否从最小offset开始消费updateSubGroup更新或创建订阅关系-d是否是广播模式updateSubGroup更新或创建订阅关系-q重试队列数量updateSubGroup更新或创建订阅关系-r最大重试次数updateSubGroup更新或创建订阅关系-i当slaveReadEnable开启时有效，且还未达到从slave消费时建议从哪个BrokerId消费，可以配置备机id，主动从备机消费updateSubGroup更新或创建订阅关系-w如果Broker建议从slave消费，配置决定从哪个slave消费，配置BrokerId，例如1updateSubGroup更新或创建订阅关系-a当消费者数量变化时是否通知其他消费者负载均衡deleteSubGroup从Broker删除订阅关系-nNameServer 服务地址，格式 ip:portdeleteSubGroup从Broker删除订阅关系-h打印帮助deleteSubGroup从Broker删除订阅关系-bBroker地址deleteSubGroup从Broker删除订阅关系-c集群名称deleteSubGroup从Broker删除订阅关系-g消费者分组名称cloneGroupOffset在目标群组中使用源群组的offset-nNameServer 服务地址，格式 ip:portcloneGroupOffset在目标群组中使用源群组的offset-h打印帮助cloneGroupOffset在目标群组中使用源群组的offset-s源消费者组cloneGroupOffset在目标群组中使用源群组的offset-d目标消费者组cloneGroupOffset在目标群组中使用源群组的offset-ttopic名称连接相关名称含义命令选项说明consumerConnec tion查询 Consumer 的网络连接-nNameServer 服务地址，格式 ip:portconsumerConnec tion查询 Consumer 的网络连接-h打印帮助consumerConnec tion查询 Consumer 的网络连接-g消费者组名称producerConnec tion查询 Producer 的网络连接-g消费者组名称producerConnec tion查询 Producer 的网络连接ttopic名称producerConnec tion查询 Producer 的网络连接-nNameServer 服务地址，格式 ip:portproducerConnec tion查询 Producer 的网络连接-h打印帮助NameServer相关名称含义命令选项说明updateKvConfig更新NameServer的kv配置，目前还未使用-s命名空间updateKvConfig更新NameServer的kv配置，目前还未使用-kkeyupdateKvConfig更新NameServer的kv配置，目前还未使用-vvalueupdateKvConfig更新NameServer的kv配置，目前还未使用-nNameServer 服务地址，格式 ip:portupdateKvConfig更新NameServer的kv配置，目前还未使用-h打印帮助deleteKvConfig删除NameServer的kv配置-s命名空间deleteKvConfig删除NameServer的kv配置-kkeydeleteKvConfig删除NameServer的kv配置-nNameServer 服务地址，格式 ip:portdeleteKvConfig删除NameServer的kv配置-h打印帮助getNamesrvConfig获取NameServer配置-nNameServer 服务地址，格式 ip:portgetNamesrvConfig获取NameServer配置-h打印帮助updateNamesrvConfig修改NameServer配置-kkeyupdateNamesrvConfig修改NameServer配置-vvalueupdateNamesrvConfig修改NameServer配置-nNameServer 服务地址，格式 ip:portupdateNamesrvConfig修改NameServer配置-h打印帮助其他名称含义命令选项说明startMonitoring开启监控进程，监控消息误删、重试队列消息数等-nNameServer 服务地址，格式 ip:portstartMonitoring开启监控进程，监控消息误删、重试队列消息数等-h打印帮助注意事项几乎所有命令都需要配置-n表示NameServer地址，格式为ip:port几乎所有命令都可以通过-h获取帮助如果既有Broker地址（-b）配置项又有clusterName（-c）配置项，则优先以Broker地址执行命令；如果不配置Broker地址，则对集群中所有主机执行命令集群监控平台搭建概述RocketMQ有一个对其扩展的开源项目incubator-rocketmq-externals，这个项目中有一个子模块叫rocketmq-console，这个便是管理控制台项目了，先将incubator-rocketmq-externals拉到本地，因为我们需要自己对rocketmq-console进行编译打包运行。下载并编译打包123git clone https://github.com/apache/rocketmq-externalscd rocketmq-consolemvn clean package -Dmaven.test.skip=true注意：打包前在rocketmq-console中配置namesrv集群地址：1rocketmq.config.namesrvAddr=192.168.25.135:9876;192.168.25.138:9876启动rocketmq-console：1java -jar rocketmq-console-ng-1.0.0.jar启动成功后，我们就可以通过浏览器访问http://localhost:8080进入控制台界面了，如下图：集群状态：消息发送样例导入MQ客户端依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.rocketmq&lt;/groupId&gt; &lt;artifactId&gt;rocketmq-client&lt;/artifactId&gt; &lt;version&gt;4.4.0&lt;/version&gt;&lt;/dependency&gt;消息发送者步骤分析r1234561.创建消息生产者producer，并制定生产者组名2.指定Nameserver地址3.启动producer4.创建消息对象，指定主题Topic、Tag和消息体5.发送消息6.关闭生产者producer消息消费者步骤分析123451.创建消费者Consumer，制定消费者组名2.指定Nameserver地址3.订阅主题Topic和Tag4.设置回调函数，处理消息5.启动消费者consumer基本样例消息发送发送同步消息这种可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。1234567891011121314151617181920212223public class SyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送消息到一个Broker SendResult sendResult = producer.send(msg); // 通过sendResult返回消息是否成功送达 System.out.printf(\"%s%n\", sendResult); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125;发送异步消息异步消息通常用在对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。12345678910111213141516171819202122232425262728293031323334public class AsyncProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); producer.setRetryTimesWhenSendAsyncFailed(0); for (int i = 0; i &lt; 100; i++) &#123; final int index = i; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\", \"TagA\", \"OrderID188\", \"Hello world\".getBytes(RemotingHelper.DEFAULT_CHARSET)); // SendCallback接收异步返回结果的回调 producer.send(msg, new SendCallback() &#123; @Override public void onSuccess(SendResult sendResult) &#123; System.out.printf(\"%-10d OK %s %n\", index, sendResult.getMsgId()); &#125; @Override public void onException(Throwable e) &#123; System.out.printf(\"%-10d Exception %s %n\", index, e); e.printStackTrace(); &#125; &#125;); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125;单向发送消息这种方式主要用在不特别关心发送结果的场景，例如日志发送。12345678910111213141516171819202122public class OnewayProducer &#123; public static void main(String[] args) throws Exception&#123; // 实例化消息生产者Producer DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); // 设置NameServer的地址 producer.setNamesrvAddr(\"localhost:9876\"); // 启动Producer实例 producer.start(); for (int i = 0; i &lt; 100; i++) &#123; // 创建消息，并指定Topic，Tag和消息体 Message msg = new Message(\"TopicTest\" /* Topic */, \"TagA\" /* Tag */, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET) /* Message body */ ); // 发送单向消息，没有任何返回结果 producer.sendOneway(msg); &#125; // 如果不再发送消息，关闭Producer实例。 producer.shutdown(); &#125;&#125;消费消息负载均衡模式消费者采用负载均衡方式消费消息，多个消费者共同消费队列消息，每个消费者处理的消息不同1234567891011121314151617181920212223public static void main(String[] args) throws Exception &#123; // 实例化消息生产者,指定组名 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group1\"); // 指定Namesrv地址信息. consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅Topic consumer.subscribe(\"Test\", \"*\"); //负载均衡模式消费 consumer.setMessageModel(MessageModel.CLUSTERING); // 注册回调函数，处理消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); //启动消息者 consumer.start(); System.out.printf(\"Consumer Started.%n\");&#125;广播模式消费者采用广播的方式消费消息，每个消费者消费的消息都是相同的1234567891011121314151617181920212223public static void main(String[] args) throws Exception &#123; // 实例化消息生产者,指定组名 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"group1\"); // 指定Namesrv地址信息. consumer.setNamesrvAddr(\"localhost:9876\"); // 订阅Topic consumer.subscribe(\"Test\", \"*\"); //广播模式消费 consumer.setMessageModel(MessageModel.BROADCASTING); // 注册回调函数，处理消息 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; System.out.printf(\"%s Receive New Messages: %s %n\", Thread.currentThread().getName(), msgs); return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); //启动消息者 consumer.start(); System.out.printf(\"Consumer Started.%n\");&#125;顺序消息消息有序指的是可以按照消息的发送顺序来消费(FIFO)。RocketMQ可以严格的保证消息有序，可以分为分区有序或者全局有序。顺序消费的原理解析，在默认的情况下消息发送会采取Round Robin轮询方式把消息发送到不同的queue(分区队列)；而消费消息的时候从多个queue上拉取消息，这种情况发送和消费是不能保证顺序。但是如果控制发送的顺序消息只依次发送到同一个queue中，消费的时候只从这个queue上依次拉取，则就保证了顺序。当发送和消费参与的queue只有一个，则是全局有序；如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的。下面用订单进行分区有序的示例。一个订单的顺序流程是：创建、付款、推送、完成。订单号相同的消息会被先后发送到同一个队列中，消费时，同一个OrderId获取到的肯定是同一个队列。顺序消息生产123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134/*** Producer，发送顺序消息*/public class Producer &#123; public static void main(String[] args) throws Exception &#123; DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\"); producer.setNamesrvAddr(\"127.0.0.1:9876\"); producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagC\", \"TagD\"&#125;; // 订单列表 List&lt;OrderStep&gt; orderList = new Producer().buildOrders(); Date date = new Date(); SimpleDateFormat sdf = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\"); String dateStr = sdf.format(date); for (int i = 0; i &lt; 10; i++) &#123; // 加个时间前缀 String body = dateStr + \" Hello RocketMQ \" + orderList.get(i); Message msg = new Message(\"TopicTest\", tags[i % tags.length], \"KEY\" + i, body.getBytes()); SendResult sendResult = producer.send(msg, new MessageQueueSelector() &#123; @Override public MessageQueue select(List&lt;MessageQueue&gt; mqs, Message msg, Object arg) &#123; Long id = (Long) arg; //根据订单id选择发送queue long index = id % mqs.size(); return mqs.get((int) index); &#125; &#125;, orderList.get(i).getOrderId());//订单id System.out.println(String.format(\"SendResult status:%s, queueId:%d, body:%s\", sendResult.getSendStatus(), sendResult.getMessageQueue().getQueueId(), body)); &#125; producer.shutdown(); &#125; /** * 订单的步骤 */ private static class OrderStep &#123; private long orderId; private String desc; public long getOrderId() &#123; return orderId; &#125; public void setOrderId(long orderId) &#123; this.orderId = orderId; &#125; public String getDesc() &#123; return desc; &#125; public void setDesc(String desc) &#123; this.desc = desc; &#125; @Override public String toString() &#123; return \"OrderStep&#123;\" + \"orderId=\" + orderId + \", desc='\" + desc + '\\'' + '&#125;'; &#125; &#125; /** * 生成模拟订单数据 */ private List&lt;OrderStep&gt; buildOrders() &#123; List&lt;OrderStep&gt; orderList = new ArrayList&lt;OrderStep&gt;(); OrderStep orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"创建\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"付款\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111065L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"推送\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103117235L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); orderDemo = new OrderStep(); orderDemo.setOrderId(15103111039L); orderDemo.setDesc(\"完成\"); orderList.add(orderDemo); return orderList; &#125;&#125;顺序消费消息1234567891011121314151617181920212223242526272829303132333435363738394041424344/*** 顺序消息消费，带事务方式（应用可控制Offset什么时候提交）*/public class ConsumerInOrder &#123; public static void main(String[] args) throws Exception &#123; DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_3\"); consumer.setNamesrvAddr(\"127.0.0.1:9876\"); /** * 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费&lt;br&gt; * 如果非第一次启动，那么按照上次消费的位置继续消费 */ consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET); consumer.subscribe(\"TopicTest\", \"TagA || TagC || TagD\"); consumer.registerMessageListener(new MessageListenerOrderly() &#123; Random random = new Random(); @Override public ConsumeOrderlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeOrderlyContext context) &#123; context.setAutoCommit(true); for (MessageExt msg : msgs) &#123; // 可以看到每个queue有唯一的consume线程来消费, 订单对每个queue(分区)有序 System.out.println(\"consumeThread=\" + Thread.currentThread().getName() + \"queueId=\" + msg.getQueueId() + \", content:\" + new String(msg.getBody())); &#125; try &#123; //模拟业务逻辑处理中... TimeUnit.SECONDS.sleep(random.nextInt(10)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return ConsumeOrderlyStatus.SUCCESS; &#125; &#125;); consumer.start(); System.out.println(\"Consumer Started.\"); &#125;&#125;延时消息比如电商里，提交了一个订单就可以发送一个延时消息，1h后去检查这个订单的状态，如果还是未付款就取消订单释放库存。启动消息消费者123456789101112131415161718192021public class ScheduledMessageConsumer &#123; public static void main(String[] args) throws Exception &#123; // 实例化消费者 DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"ExampleConsumer\"); // 订阅Topics consumer.subscribe(\"TestTopic\", \"*\"); // 注册消息监听者 consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; messages, ConsumeConcurrentlyContext context) &#123; for (MessageExt message : messages) &#123; // Print approximate delay time period System.out.println(\"Receive message[msgId=\" + message.getMsgId() + \"] \" + (System.currentTimeMillis() - message.getStoreTimestamp()) + \"ms later\"); &#125; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125; &#125;); // 启动消费者 consumer.start(); &#125;&#125;发送延时消息123456789101112131415161718public class ScheduledMessageProducer &#123; public static void main(String[] args) throws Exception &#123; // 实例化一个生产者来产生延时消息 DefaultMQProducer producer = new DefaultMQProducer(\"ExampleProducerGroup\"); // 启动生产者 producer.start(); int totalMessagesToSend = 100; for (int i = 0; i &lt; totalMessagesToSend; i++) &#123; Message message = new Message(\"TestTopic\", (\"Hello scheduled message \" + i).getBytes()); // 设置延时等级3,这个消息将在10s之后发送(现在只支持固定的几个时间,详看delayTimeLevel) message.setDelayTimeLevel(3); // 发送消息 producer.send(message); &#125; // 关闭生产者 producer.shutdown(); &#125;&#125;验证您将会看到消息的消费比存储时间晚10秒使用限制12// org/apache/rocketmq/store/config/MessageStoreConfig.javaprivate String messageDelayLevel = \"1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h\";现在RocketMq并不支持任意时间的延时，需要设置几个固定的延时等级，从1s到2h分别对应着等级1到18批量消息批量发送消息能显著提高传递小消息的性能。限制是这些批量消息应该有相同的topic，相同的waitStoreMsgOK，而且不能是延时消息。此外，这一批消息的总大小不应超过4MB。发送批量消息如果您每次只发送不超过4MB的消息，则很容易使用批处理，样例如下：1234567891011String topic = \"BatchTest\";List&lt;Message&gt; messages = new ArrayList&lt;&gt;();messages.add(new Message(topic, \"TagA\", \"OrderID001\", \"Hello world 0\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID002\", \"Hello world 1\".getBytes()));messages.add(new Message(topic, \"TagA\", \"OrderID003\", \"Hello world 2\".getBytes()));try &#123; producer.send(messages);&#125; catch (Exception e) &#123; e.printStackTrace(); //处理error&#125;如果消息的总长度可能大于4MB时，这时候最好把消息进行分割12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ListSplitter implements Iterator&lt;List&lt;Message&gt;&gt; &#123; private final int SIZE_LIMIT = 1024 * 1024 * 4; private final List&lt;Message&gt; messages; private int currIndex; public ListSplitter(List&lt;Message&gt; messages) &#123; this.messages = messages; &#125; @Override public boolean hasNext() &#123; return currIndex &lt; messages.size(); &#125; @Override public List&lt;Message&gt; next() &#123; int nextIndex = currIndex; int totalSize = 0; for (; nextIndex &lt; messages.size(); nextIndex++) &#123; Message message = messages.get(nextIndex); int tmpSize = message.getTopic().length() + message.getBody().length; Map&lt;String, String&gt; properties = message.getProperties(); for (Map.Entry&lt;String, String&gt; entry : properties.entrySet()) &#123; tmpSize += entry.getKey().length() + entry.getValue().length(); &#125; tmpSize = tmpSize + 20; // 增加日志的开销20字节 if (tmpSize &gt; SIZE_LIMIT) &#123; //单个消息超过了最大的限制 //忽略,否则会阻塞分裂的进程 if (nextIndex - currIndex == 0) &#123; //假如下一个子列表没有元素,则添加这个子列表然后退出循环,否则只是退出循环 nextIndex++; &#125; break; &#125; if (tmpSize + totalSize &gt; SIZE_LIMIT) &#123; break; &#125; else &#123; totalSize += tmpSize; &#125; &#125; List&lt;Message&gt; subList = messages.subList(currIndex, nextIndex); currIndex = nextIndex; return subList; &#125;&#125;//把大的消息分裂成若干个小的消息ListSplitter splitter = new ListSplitter(messages);while (splitter.hasNext()) &#123; try &#123; List&lt;Message&gt; listItem = splitter.next(); producer.send(listItem); &#125; catch (Exception e) &#123; e.printStackTrace(); //处理error &#125;&#125;过滤消息在大多数情况下，TAG是一个简单而有用的设计，其可以来选择您想要的消息。例如：12DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"CID_EXAMPLE\");consumer.subscribe(\"TOPIC\", \"TAGA || TAGB || TAGC\");消费者将接收包含TAGA或TAGB或TAGC的消息。但是限制是一个消息只能有一个标签，这对于复杂的场景可能不起作用。在这种情况下，可以使用SQL表达式筛选消息。SQL特性可以通过发送消息时的属性来进行计算。在RocketMQ定义的语法下，可以实现一些简单的逻辑。下面是一个例子：1234567891011121314------------| message ||----------| a &gt; 5 AND b = &apos;abc&apos;| a = 10 | --------------------&gt; Gotten| b = &apos;abc&apos;|| c = true |------------------------| message ||----------| a &gt; 5 AND b = &apos;abc&apos;| a = 1 | --------------------&gt; Missed| b = &apos;abc&apos;|| c = true |------------SQL基本语法RocketMQ只定义了一些基本语法来支持这个特性。你也可以很容易地扩展它。数值比较，比如：&gt;，&gt;=，&lt;，&lt;=，BETWEEN，=；字符比较，比如：=，&lt;&gt;，IN；IS NULL 或者 IS NOT NULL；逻辑符号 AND，OR，NOT；常量支持类型为：数值，比如：123，3.1415；字符，比如：‘abc’，必须用单引号包裹起来；NULL，特殊的常量布尔值，TRUE 或 FALSE只有使用push模式的消费者才能用使用SQL92标准的sql语句，接口如下：1public void subscribe(finalString topic, final MessageSelector messageSelector)消息生产者发送消息时，你能通过putUserProperty来设置消息的属性1234567891011DefaultMQProducer producer = new DefaultMQProducer(\"please_rename_unique_group_name\");producer.start();Message msg = new Message(\"TopicTest\", tag, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET));// 设置一些属性msg.putUserProperty(\"a\", String.valueOf(i));SendResult sendResult = producer.send(msg);producer.shutdown();消息消费者用MessageSelector.bySql来使用sql筛选消息12345678910DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(\"please_rename_unique_group_name_4\");// 只有订阅的消息有这个属性a, a &gt;=0 and a &lt;= 3consumer.subscribe(\"TopicTest\", MessageSelector.bySql(\"a between 0 and 3\");consumer.registerMessageListener(new MessageListenerConcurrently() &#123; @Override public ConsumeConcurrentlyStatus consumeMessage(List&lt;MessageExt&gt; msgs, ConsumeConcurrentlyContext context) &#123; return ConsumeConcurrentlyStatus.CONSUME_SUCCESS; &#125;&#125;);consumer.start();事务消息流程分析上图说明了事务消息的大致方案，其中分为两个流程：正常事务消息的发送及提交、事务消息的补偿流程。事务消息发送及提交(1) 发送消息（half消息）。(2) 服务端响应消息写入结果。(3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。(4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）事务补偿(1) 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”(2) Producer收到回查消息，检查回查消息对应的本地事务的状态(3) 根据本地事务状态，重新Commit或者Rollback其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。事务消息状态事务消息共有三种状态，提交状态、回滚状态、中间状态：TransactionStatus.CommitTransaction: 提交事务，它允许消费者消费此消息。TransactionStatus.RollbackTransaction: 回滚事务，它代表该消息将被删除，不允许被消费。TransactionStatus.Unknown: 中间状态，它代表需要检查消息队列来确定状态。发送事务消息创建事务性生产者使用 TransactionMQProducer类创建生产者，并指定唯一的 ProducerGroup，就可以设置自定义线程池来处理这些检查请求。执行本地事务后、需要根据执行结果对消息队列进行回复。回传的事务状态在请参考前一节。1234567891011121314151617181920212223242526public class Producer &#123; public static void main(String[] args) throws MQClientException, InterruptedException &#123; //创建事务监听器 TransactionListener transactionListener = new TransactionListenerImpl(); //创建消息生产者 TransactionMQProducer producer = new TransactionMQProducer(\"group6\"); producer.setNamesrvAddr(\"192.168.25.135:9876;192.168.25.138:9876\"); //生产者这是监听器 producer.setTransactionListener(transactionListener); //启动消息生产者 producer.start(); String[] tags = new String[]&#123;\"TagA\", \"TagB\", \"TagC\"&#125;; for (int i = 0; i &lt; 3; i++) &#123; try &#123; Message msg = new Message(\"TransactionTopic\", tags[i % tags.length], \"KEY\" + i, (\"Hello RocketMQ \" + i).getBytes(RemotingHelper.DEFAULT_CHARSET)); SendResult sendResult = producer.sendMessageInTransaction(msg, null); System.out.printf(\"%s%n\", sendResult); TimeUnit.SECONDS.sleep(1); &#125; catch (MQClientException | UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; &#125; //producer.shutdown(); &#125;&#125;实现事务的监听接口当发送半消息成功时，我们使用 executeLocalTransaction 方法来执行本地事务。它返回前一节中提到的三个事务状态之一。checkLocalTranscation 方法用于检查本地事务状态，并回应消息队列的检查请求。它也是返回前一节中提到的三个事务状态之一。123456789101112131415161718192021public class TransactionListenerImpl implements TransactionListener &#123; @Override public LocalTransactionState executeLocalTransaction(Message msg, Object arg) &#123; System.out.println(\"执行本地事务\"); if (StringUtils.equals(\"TagA\", msg.getTags())) &#123; return LocalTransactionState.COMMIT_MESSAGE; &#125; else if (StringUtils.equals(\"TagB\", msg.getTags())) &#123; return LocalTransactionState.ROLLBACK_MESSAGE; &#125; else &#123; return LocalTransactionState.UNKNOW; &#125; &#125; @Override public LocalTransactionState checkLocalTransaction(MessageExt msg) &#123; System.out.println(\"MQ检查消息Tag【\"+msg.getTags()+\"】的本地事务执行结果\"); return LocalTransactionState.COMMIT_MESSAGE; &#125;&#125;使用限制事务消息不支持延时消息和批量消息。为了避免单个消息被检查太多次而导致半队列消息累积，我们默认将单个消息的检查次数限制为 15 次，但是用户可以通过 Broker 配置文件的 transactionCheckMax参数来修改此限制。如果已经检查某条消息超过 N 次的话（ N = transactionCheckMax ） 则 Broker 将丢弃此消息，并在默认情况下同时打印错误日志。用户可以通过重写 AbstractTransactionCheckListener 类来修改这个行为。事务消息将在 Broker 配置文件中的参数 transactionMsgTimeout 这样的特定时间长度之后被检查。当发送事务消息时，用户还可以通过设置用户属性 CHECK_IMMUNITY_TIME_IN_SECONDS 来改变这个限制，该参数优先于 transactionMsgTimeout 参数。事务性消息可能不止一次被检查或消费。提交给用户的目标主题消息可能会失败，目前这依日志的记录而定。它的高可用性通过 RocketMQ 本身的高可用性机制来保证，如果希望确保事务消息不丢失、并且事务完整性得到保证，建议使用同步的双重写入机制。事务消息的生产者 ID 不能与其他类型消息的生产者 ID 共享。与其他类型的消息不同，事务消息允许反向查询、MQ服务器能通过它们的生产者 ID 查询到消费者。","categories":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://me.obey.fun/categories/MessageQueue/"},{"name":"RocketMQ","slug":"MessageQueue/RocketMQ","permalink":"https://me.obey.fun/categories/MessageQueue/RocketMQ/"}],"tags":[{"name":"中间件","slug":"中间件","permalink":"https://me.obey.fun/tags/中间件/"},{"name":"RocketMQ","slug":"RocketMQ","permalink":"https://me.obey.fun/tags/RocketMQ/"}],"keywords":[{"name":"MessageQueue","slug":"MessageQueue","permalink":"https://me.obey.fun/categories/MessageQueue/"},{"name":"RocketMQ","slug":"MessageQueue/RocketMQ","permalink":"https://me.obey.fun/categories/MessageQueue/RocketMQ/"}]},{"title":"Mybatis-Plus必知必会","slug":"Mybatis-Plus必知必会","date":"2020-05-03T12:54:29.000Z","updated":"2020-05-30T02:24:41.000Z","comments":true,"path":"Mybatis-Plus必知必会.html","link":"","permalink":"https://me.obey.fun/Mybatis-Plus必知必会.html","excerpt":"","text":"mybatis-plus简介：Mybatis-Plus（简称MP）是一个 Mybatis 的增强工具，在 Mybatis 的基础上只做增强不做改变，为简化开发、提高效率而生。这是官方给的定义，关于mybatis-plus的更多介绍及特性，可以参考mybatis-plus官网。那么它是怎么增强的呢？其实就是它已经封装好了一些crud方法，我们不需要再写xml了，直接调用这些方法就行，就类似于JPA。spring整合mybatis-plus:正如官方所说，mybatis-plus在mybatis的基础上只做增强不做改变，因此其与spring的整合亦非常简单。只需把mybatis的依赖换成mybatis-plus的依赖，再把sqlSessionFactory换成mybatis-plus的即可。接下来看具体操作：1、pom.xml:核心依赖如下：1234567891011121314151617181920212223&lt;!-- spring --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.14.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;4.3.14.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;4.3.14.RELEASE&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- mp 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt;&lt;/dependency&gt;注意：这些是核心依赖，本项目还用到了mysql驱动、c3p0、日志（slf4j-api，slf4j-log4j2）、lombok。集成mybatis-plus要把mybatis、mybatis-spring去掉，避免冲突；lombok是一个工具，添加了这个依赖，开发工具再安装Lombok插件，就可以使用它了，最常用的用法就是在实体类中使用它的@Data注解，这样实体类就不用写set、get、toString等方法了。关于Lombok的更多用法，请自行百度。2、log4j.xml:123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE log4j:configuration SYSTEM \"log4j.dtd\"&gt;&lt;log4j:configuration xmlns:log4j=\"http://jakarta.apache.org/log4j/\"&gt; &lt;appender name=\"STDOUT\" class=\"org.apache.log4j.ConsoleAppender\"&gt; &lt;param name=\"Encoding\" value=\"UTF-8\" /&gt; &lt;layout class=\"org.apache.log4j.PatternLayout\"&gt; &lt;param name=\"ConversionPattern\" value=\"%-5p %d&#123;MM-ddHH:mm:ss,SSS&#125; %m (%F:%L) \\n\" /&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;logger name=\"java.sql\"&gt; &lt;level value=\"debug\" /&gt; &lt;/logger&gt; &lt;logger name=\"org.apache.ibatis\"&gt; &lt;level value=\"info\" /&gt; &lt;/logger&gt; &lt;root&gt; &lt;level value=\"debug\" /&gt; &lt;appender-ref ref=\"STDOUT\" /&gt; &lt;/root&gt;&lt;/log4j:configuration&gt;3、jdbc.properties:1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql:///数据库名?useUnicode=true&amp;characterEncoding=utf8jdbc.username=#jdbc.password=#4、mybatis-config.xml:123456&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt;&lt;/configuration&gt;注：因为是与spring整合，所有mybatis-plus的大部分都写在spring的配置文件中，这里定义一个空的mybatis-config.xml即可。5、spring-dao.xml:1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt; &lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:jee=\"http://www.springframework.org/schema/jee\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xsi:schemaLocation=\" http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd\"&gt; &lt;!-- 配置整合mybatis-plus过程 --&gt; &lt;!-- 1、配置数据库相关参数properties的属性：$&#123;url&#125; --&gt; &lt;context:property-placeholder location=\"classpath:jdbc.properties\" /&gt; &lt;!-- 2、配置数据库连接池 --&gt; &lt;bean id=\"dataSource\" class=\"com.mchange.v2.c3p0.ComboPooledDataSource\"&gt; &lt;property name=\"driverClass\" value=\"$&#123;jdbc.driver&#125;\"/&gt; &lt;property name=\"jdbcUrl\" value=\"$&#123;jdbc.url&#125;\"/&gt; &lt;property name=\"user\" value=\"$&#123;jdbc.username&#125;\"/&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\"/&gt; &lt;/bean&gt; &lt;!-- mybatis的sqlsessionFactorybean：org.mybatis.spring.SqlSessionFactoryBean--&gt; &lt;!-- 3、配置mybatis-plus的sqlSessionFactory --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.zhu.mybatisplus.entity\"/&gt; &lt;/bean&gt; &lt;!-- 4、DAO接口所在包名，Spring会自动查找其下的类 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;property name=\"basePackage\" value=\"com.zhu.mybatisplus.dao\" /&gt; &lt;property name=\"sqlSessionFactoryBeanName\" value=\"sqlSessionFactory\"/&gt; &lt;/bean&gt; &lt;/beans&gt;6、entity:12345678910111213@Data@TableName(value = \"tb_employee\")//指定表名public class Employee &#123; //value与数据库主键列名一致，若实体类属性名与表主键列名一致可省略value @TableId(value = \"id\",type = IdType.AUTO)//指定自增策略 private Integer id; //若没有开启驼峰命名，或者表中列名不符合驼峰规则，可通过该注解指定数据库表中的列名，exist标明数据表中有没有对应列 @TableField(value = \"last_name\",exist = true) private String lastName; private String email; private Integer gender; private Integer age;&#125;7、mapper:12public interface EmplopyeeDao extends BaseMapper&lt;Employee&gt; &#123;&#125;这样就完成了mybatis-plus与spring的整合。首先是把mybatis和mybatis-spring依赖换成mybatis-plus的依赖，然后把sqlsessionfactory换成mybatis-plus的，然后实体类中添加@TableName、@TableId等注解，最后mapper继承BaseMapper即可。8、测试：12345678910@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;\"classpath:spring/spring-dao.xml\"&#125;)public class test &#123; @Autowired private DataSource dataSource; @Test public void testDataSource() throws SQLException &#123; System.out.println(dataSource.getConnection()); &#125;&#125;运行该junit，可输出获取到的连接，说明整合没问题：本文所有代码本人均亲自测试过，本文涉及代码又较多，为了不影响篇幅，故非必要处不再截图。接下来的所有操作都是基于此整合好的项目。mp的通用crud:需求：存在一张 tb_employee 表，且已有对应的实体类 Employee，实现tb_employee 表的 CRUD 操作我们需要做什么呢？基于 Mybatis：需要编写 EmployeeMapper 接口，并在 EmployeeMapper.xml 映射文件中手动编写 CRUD 方法对应的sql语句。基于 MP：只需要创建 EmployeeMapper 接口, 并继承 BaseMapper 接口。我们已经有了Employee、tb_employee了，并且EmployeeDao也继承了BaseMapper了，接下来就使用crud方法。1、insert操作：1234567891011121314151617@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;\"classpath:spring/spring-dao.xml\"&#125;)public class test &#123; @Autowired private EmplopyeeDao emplopyeeDao; @Test public void testInsert()&#123; Employee employee = new Employee(); employee.setLastName(\"东方不败\"); employee.setEmail(\"dfbb@163.com\"); employee.setGender(1); employee.setAge(20); emplopyeeDao.insert(employee); //mybatisplus会自动把当前插入对象在数据库中的id写回到该实体中 System.out.println(employee.getId()); &#125;&#125;执行添加操作，直接调用insert方法传入实体即可。2、update操作：12345678@Testpublic void testUpdate()&#123; Employee employee = new Employee(); employee.setId(1); employee.setLastName(\"更新测试\"); //emplopyeeDao.updateById(employee);//根据id进行更新，没有传值的属性就不会更新 emplopyeeDao.updateAllColumnById(employee);//根据id进行更新，没传值的属性就更新为null&#125;注：注意这两个update操作的区别，updateById方法，没有传值的字段不会进行更新，比如只传入了lastName，那么age、gender等属性就会保留原来的值；updateAllColumnById方法，顾名思义，会更新所有的列，没有传值的列会更新为null。3、select操作：(1)、根据id查询：1Employee employee = emplopyeeDao.selectById(1);(2)、根据条件查询一条数据：12345Employee employeeCondition = new Employee();employeeCondition.setId(1);employeeCondition.setLastName(\"更新测试\");//若是数据库中符合传入的条件的记录有多条，那就不能用这个方法，会报错Employee employee = emplopyeeDao.selectOne(employeeCondition);注：这个方法的sql语句就是where id = 1 and last_name = 更新测试，若是符合这个条件的记录不止一条，那么就会报错。(3)、根据查询条件返回多条数据：当符合指定条件的记录数有多条时，上面那个方法就会报错，就应该用这个方法。12345Map&lt;String,Object&gt; columnMap = new HashMap&lt;&gt;();columnMap.put(\"last_name\",\"东方不败\");//写表中的列名columnMap.put(\"gender\",\"1\");List&lt;Employee&gt; employees = emplopyeeDao.selectByMap(columnMap);System.out.println(employees.size());注：查询条件用map集合封装，columnMap，写的是数据表中的列名，而非实体类的属性名。比如属性名为lastName，数据表中字段为last_name，这里应该写的是last_name。selectByMap方法返回值用list集合接收。(4)、通过id批量查询：123456List&lt;Integer&gt; idList = new ArrayList&lt;&gt;();idList.add(1);idList.add(2);idList.add(3);List&lt;Employee&gt; employees = emplopyeeDao.selectBatchIds(idList);System.out.println(employees);注：把需要查询的id都add到list集合中，然后调用selectBatchIds方法，传入该list集合即可，该方法返回的是对应id的所有记录，所有返回值也是用list接收。(5)、分页查询：12List&lt;Employee&gt; employees = emplopyeeDao.selectPage(new Page&lt;&gt;(1,2),null);System.out.println(employees);注：selectPage方法就是分页查询，在page中传入分页信息，后者为null的分页条件，这里先让其为null，讲了条件构造器再说其用法。这个分页其实并不是物理分页，而是内存分页。也就是说，查询的时候并没有limit语句。等配置了分页插件后才可以实现真正的分页。4、delete操作：(1)、根据id删除：1emplopyeeDao.deleteById(1);(2)、根据条件删除：1234Map&lt;String,Object&gt; columnMap = new HashMap&lt;&gt;();columnMap.put(\"gender\",0);columnMap.put(\"age\",18);emplopyeeDao.deleteByMap(columnMap);注：该方法与selectByMap类似，将条件封装在columnMap中，然后调用deleteByMap方法，传入columnMap即可，返回值是Integer类型，表示影响的行数。(3)、根据id批量删除：1234List&lt;Integer&gt; idList = new ArrayList&lt;&gt;();idList.add(1);idList.add(2);emplopyeeDao.deleteBatchIds(idList);注：该方法和selectBatchIds类似，把需要删除的记录的id装进idList，然后调用deleteBatchIds，传入idList即可。全局策略配置：通过上面的小案例我们可以发现，实体类需要加@TableName注解指定数据库表名，通过@TableId注解指定id的增长策略。实体类少倒也无所谓，实体类一多的话也麻烦。所以可以在spring-dao.xml的文件中进行全局策略配置。123456789&lt;!-- 5、mybatisplus的全局策略配置 --&gt;&lt;bean id=\"globalConfiguration\" class=\"com.baomidou.mybatisplus.entity.GlobalConfiguration\"&gt; &lt;!-- 2.3版本后，驼峰命名默认值就是true，所以可不配置 --&gt; &lt;!--&lt;property name=\"dbColumnUnderline\" value=\"true\"/&gt;--&gt; &lt;!-- 全局主键自增策略，0表示auto --&gt; &lt;property name=\"idType\" value=\"0\"/&gt; &lt;!-- 全局表前缀配置 --&gt; &lt;property name=\"tablePrefix\" value=\"tb_\"/&gt;&lt;/bean&gt;这里配置了还没用，还需要在sqlSessionFactory中注入配置才会生效。如下：12345678&lt;!-- 3、配置mybatisplus的sqlSessionFactory --&gt;&lt;bean id=\"sqlSessionFactory\" class=\"com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.zhu.mybatisplus.entity\"/&gt; &lt;!-- 注入全局配置 --&gt; &lt;property name=\"globalConfig\" ref=\"globalConfiguration\"/&gt;&lt;/bean&gt;如此一来，实体类中的@TableName注解和@TableId注解就可以去掉了。条件构造器(EntityWrapper)：以上基本的 CRUD 操作，我们仅仅需要继承一个 BaseMapper 即可实现大部分单表 CRUD 操作。BaseMapper 提供了多达 17 个方法供使用, 可以极其方便的实现单一、批量、分页等操作，极大的减少开发负担。但是mybatis-plus的强大不限于此，请看如下需求该如何处理：需求：我们需要分页查询 tb_employee 表中，年龄在 18~50 之间性别为男且姓名为 xx 的所有用户，这时候我们该如何实现上述需求呢？使用MyBatis : 需要在 SQL 映射文件中编写带条件查询的 SQL,并用PageHelper 插件完成分页. 实现以上一个简单的需求，往往需要我们做很多重复单调的工作。使用MP: 依旧不用编写 SQL 语句，MP 提供了功能强大的条件构造器 —— EntityWrapper。接下来就直接看几个案例体会EntityWrapper的使用。1、分页查询年龄在18 - 50且gender为0、姓名为tom的用户：123456List&lt;Employee&gt; employees = emplopyeeDao.selectPage(new Page&lt;Employee&gt;(1,3), new EntityWrapper&lt;Employee&gt;() .between(\"age\",18,50) .eq(\"gender\",0) .eq(\"last_name\",\"tom\"));注：由此案例可知，分页查询和之前一样，new 一个page对象传入分页信息即可。至于分页条件，new 一个EntityWrapper对象，调用该对象的相关方法即可。between方法三个参数，分别是column、value1、value2，该方法表示column的值要在value1和value2之间；eq是equals的简写，该方法两个参数，column和value，表示column的值和value要相等。注意column是数据表对应的字段，而非实体类属性字段。2、查询gender为0且名字中带有老师、或者邮箱中带有a的用户：12345678List&lt;Employee&gt; employees = emplopyeeDao.selectList( new EntityWrapper&lt;Employee&gt;() .eq(\"gender\",0) .like(\"last_name\",\"老师\") //.or()//和or new 区别不大 .orNew() .like(\"email\",\"a\"));注：未说分页查询，所以用selectList即可，用EntityWrapper的like方法进行模糊查询，like方法就是指column的值包含value值，此处like方法就是查询last_name中包含“老师”字样的记录；“或者”用or或者orNew方法表示，这两个方法区别不大，用哪个都可以，可以通过控制台的sql语句自行感受其区别。3、查询gender为0，根据age排序，简单分页：123456List&lt;Employee&gt; employees = emplopyeeDao.selectList( new EntityWrapper&lt;Employee&gt;() .eq(\"gender\",0) .orderBy(\"age\")//直接orderby 是升序，asc .last(\"desc limit 1,3\")//在sql语句后面追加last里面的内容(改为降序，同时分页));注：简单分页是指不用page对象进行分页。orderBy方法就是根据传入的column进行升序排序，若要降序，可以使用orderByDesc方法，也可以如案例中所示用last方法；last方法就是将last方法里面的value值追加到sql语句的后面，在该案例中，最后的sql语句就变为select ······ order by desc limit 1, 3，追加了desc limit 1,3所以可以进行降序排序和分页。4、分页查询年龄在18 - 50且gender为0、姓名为tom的用户：条件构造器除了EntityWrapper，还有Condition。用Condition来处理一下这个需求：123456List&lt;Employee&gt; employees = emplopyeeDao.selectPage( new Page&lt;Employee&gt;(1,2), Condition.create() .between(\"age\",18,50) .eq(\"gender\",\"0\"));注：Condition和EntityWrapper的区别就是，创建条件构造器时，EntityWrapper是new出来的，而Condition是调create方法创建出来。5、根据条件更新：123456789101112@Testpublic void testEntityWrapperUpdate()&#123; Employee employee = new Employee(); employee.setLastName(\"苍老师\"); employee.setEmail(\"cjk@sina.com\"); employee.setGender(0); emplopyeeDao.update(employee, new EntityWrapper&lt;Employee&gt;() .eq(\"last_name\",\"tom\") .eq(\"age\",25) );&#125;注：该案例表示把last_name为tom，age为25的所有用户的信息更新为employee中设置的信息。6、根据条件删除：12345emplopyeeDao.delete( new EntityWrapper&lt;Employee&gt;() .eq(\"last_name\",\"tom\") .eq(\"age\",16));注：该案例表示把last_name为tom、age为16的所有用户删除。odel类，重写pkVal方法。2、mapper:12public interface UserDao extends BaseMapper&lt;User&gt; &#123;&#125;注：虽然AR模式用不到该接口，但是一定要定义，否则使用AR时会报空指针异常。ActiveRecord:Active Record(活动记录)，是一种领域模型模式，特点是一个模型类对应关系型数据库中的一个表，而模型类的一个实例对应表中的一行记录。ActiveRecord 一直广受动态语言（ PHP 、 Ruby 等）的喜爱，而 Java 作为准静态语言，对于 ActiveRecord 往往只能感叹其优雅，所以 MP 也在 AR 道路上进行了一定的探索，仅仅需要让实体类继承 Model 类且实现主键指定方法，即可开启 AR 之旅。接下来看具体代码：1、entity:123456789101112@Datapublic class User extends Model&lt;User&gt; &#123; private Integer id; private String name; private Integer age; private Integer gender; //重写这个方法，return当前类的主键 @Override protected Serializable pkVal() &#123; return id; &#125;&#125;注：实体类继承Model类，重写pkVal方法。2、mapper:12public interface UserDao extends BaseMapper&lt;User&gt; &#123;&#125;注：虽然AR模式用不到该接口，但是一定要定义，否则使用AR时会报空指针异常。3、使用AR:(1)、AR插入操作：12345678910111213@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(&#123;\"classpath:spring/spring-dao.xml\"&#125;)public class TestAR &#123; @Test public void testArInsert()&#123; User user = new User(); user.setName(\"林青霞\"); user.setAge(22); user.setGender(1); boolean result = user.insert(); System.out.println(result); &#125;&#125;image.png注：可以看到我们并不需要注入mapper接口，不过正如刚才所说，不使用但还是要定义，否则会报错。AR操作是通过对象本身调用相关方法，比如要insert一个user，那就用这个user调用insert方法即可。返回值为布尔类型，由上图可看到返回了true，是操作成功的。(2)、AR更新操作：12345678@Testpublic void testArUpdate()&#123; User user = new User(); user.setId(1); user.setName(\"刘亦菲\"); boolean result = user.updateById(); System.out.println(result);&#125;注：user调用updateById方法，将id为1的用户进行更新。(3)、AR查询操作：12345678910111213141516171819@Testpublic void testArSelect()&#123; User user = new User(); //1、根据id查询 //user = user.selectById(1); //或者这样用 //user.setId(1); //user = user.selectById(); //2、查询所有 //List&lt;User&gt; users = user.selectAll(); //3、根据条件查询 //List&lt;User&gt; users = user.selectList(new EntityWrapper&lt;User&gt;().like(\"name\",\"刘\")); //4、查询符合条件的总数 int result = user.selectCount(new EntityWrapper&lt;User&gt;().eq(\"gender\",1)); System.out.println(result);&#125;注：上面的代码涉及到了四个不同的查询操作，其实用法与MP的BaseMapper提供的方法的用法差不多，只不过这里是实体对象调用。(4)、AR删除操作：1234567891011121314@Test public void testArDelete()&#123; User user = new User(); //删除数据库中不存在的数据也是返回true //1、根据id删除数据 //boolean result = user.deleteById(1); //或者这样写 //user.setId(1); //boolean result = user.deleteById(); //2、根据条件删除 boolean result = user.delete(new EntityWrapper&lt;User&gt;().like(\"name\",\"玲\")); System.out.println(result); &#125;注：这里介绍了两个删除方法，代码中已有注释说明。需要注意的是，删除数据库中不存在的数据，结果也是true。(5)、AR分页操作：123456789@Test public void testArPage()&#123; User user = new User(); Page&lt;User&gt; page = user.selectPage(new Page&lt;&gt;(1,4), new EntityWrapper&lt;User&gt;().like(\"name\",\"刘\")); List&lt;User&gt; users = page.getRecords(); System.out.println(users); &#125;注：这个分页方法和BaseMapper提供的分页一样都是内存分页，并非物理分页，因为sql语句中没用limit，和BaseMapper的selectPage方法一样，配置了分页插件后就可以实现真正的物理分页。AR的分页方法与BaseMapper提供的分页方法不同的是，BaseMapper的selectPage方法返回值是查询到的记录的list集合，而AR的selectPage方法返回的是page对象，该page对象封装了查询到的信息，可以通过getRecords方法获取信息。插件的配置：MP提供了很多好用的插件，而且配置简单，使用方便。接下来一起看看MP的插件如何使用。1、分页插件：之前就有说到，BaseMapper的selectPage方法和AR提供的selectPage方法都不是物理分页，需要配置分页插件后才是物理分页，那么现在就来看看如何配置这个插件。12345678910111213141516&lt;!-- 3、配置mybatisplus的sqlSessionFactory --&gt; &lt;bean id=\"sqlSessionFactory\" class= \"com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis-config.xml\"/&gt; &lt;property name=\"typeAliasesPackage\" value=\"com.zhu.mybatisplus.entity\"/&gt; &lt;!-- 注入全局配置 --&gt; &lt;property name=\"globalConfig\" ref=\"globalConfiguration\"/&gt; &lt;!-- 配置插件 --&gt; &lt;property name=\"plugins\"&gt; &lt;list&gt; &lt;!-- 分页插件 --&gt; &lt;bean class=\"com.baomidou.mybatisplus.plugins.PaginationInterceptor\"/&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;注：在sqlSessionFactory这个bean中，通过&lt;property name=&quot;plugins&quot;&gt;配置插件，接下来的所有插件都配置在这个list中。123456789101112131415161718@Test public void testPage() &#123; //配置了分页插件后，还是和以前一样的使用selectpage方法， //但是现在就是真正的物理分页了，sql语句中有limit了 Page&lt;Employee&gt; page = new Page&lt;&gt;(1, 2); List&lt;Employee&gt; employeeList = emplopyeeDao.selectPage(page, null); System.out.println(employeeList); System.out.println(\"================= 相关的分页信息 ==================\"); System.out.println(\"总条数:\" + page.getTotal()); System.out.println(\"当前页码:\" + page.getCurrent()); System.out.println(\"总页数:\" + page.getPages()); System.out.println(\"每页显示条数:\" + page.getSize()); System.out.println(\"是否有上一页:\" + page.hasPrevious()); System.out.println(\"是否有下一页:\" + page.hasNext()); //还可以将查询到的结果set进page对象中 page.setRecords(employeeList); &#125;由图可知，sql语句中已经有了limit，是物理分页了。也可以通过page调用相关方法获取到相关的分页信息，而且还可以把查询到的结果set回page对象中，方便前端使用。2、性能分析插件：在plugin的list中添加如下bean即可开启性能分析插件：123456&lt;!-- 输出每条SQL语句及其执行时间，生产环境不建议使用该插件 --&gt;&lt;bean class=\"com.baomidou.mybatisplus.plugins.PerformanceInterceptor\"&gt; &lt;property name=\"format\" value=\"true\"/&gt;&lt;!-- 格式化SQL语句 --&gt; &lt;property name=\"maxTime\" value=\"1000\"/&gt;&lt;!-- sql执行时间超过value值就会停止执行， 单位是毫秒 --&gt;&lt;/bean&gt;注：这个性能分析插件配置了两个属性，第一个是格式化sql语句，设置为true后，sql语句格式就像上面的截图中的一样；第二个属性是sql语句执行的最大时间，超过value值就会报错，这里表示超过1000毫秒就会停止执行sql语句。3、执行分析插件：1234&lt;!-- 如果是对全表的删除或更新操作，就会终止该操作 --&gt;&lt;bean class=\"com.baomidou.mybatisplus.plugins.SqlExplainInterceptor\"&gt; &lt;property name=\"stopProceed\" value=\"true\"/&gt;&lt;/bean&gt;注：这个插件配置了一个属性，stopProceed设置为true后，如果执行的是删除表中全部内容，那就会抛出异常，终止该操作。该插件主要是防止手抖误删数据。12345@Testpublic void testSqlExplain()&#123; //条件为null，就是删除全表，执行分析插件会终止该操作 emplopyeeDao.delete(null);&#125;运行该junit测试，可以看到报如下错误，说明该插件生效了。MP的逆向工程：MyBatis 的代码生成器基于xml文件进行生成，可生成: 实体类、Mapper 接口、Mapper 映射文件。MP 的代码生成器基于Java代码进行生成，可生成: 实体类(可以选择是否支持 AR)、Mapper 接口、Mapper 映射文件、 Service 层、Controller 层。1、添加依赖：1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.37&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mp 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;2.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- mybatisplus逆向工程需要模板引擎，用freemaker也行 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.velocity&lt;/groupId&gt; &lt;artifactId&gt;velocity-engine-core&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt;&lt;/dependency&gt;注：上面是必须的三个依赖，为了可以在控制台直观的看到生成情况，可以添加日志包(slf4j-api和slf4j-log4j2)，为了让生成的代码不会报错，还可以根据情况添加spring相关的依赖、lombok依赖等。2、生成器示例代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class test &#123; @Test public void testGenerator()&#123; //1、全局配置 GlobalConfig config = new GlobalConfig(); config.setActiveRecord(true)//开启AR模式 .setAuthor(\"huiprogramer\")//设置作者 //生成路径(一般都是生成在此项目的src/main/java下面) .setOutputDir(\"E:\\\\develop\\\\Java\\\\workspace\\\\ideaworkspace\\\\mpg\\\\src\\\\main\\\\java\") .setFileOverride(true)//第二次生成会把第一次生成的覆盖掉 .setIdType(IdType.AUTO)//主键策略 .setServiceName(\"%sService\")//生成的service接口名字首字母是否为I，这样设置就没有I .setBaseResultMap(true)//生成resultMap .setBaseColumnList(true);//在xml中生成基础列 //2、数据源配置 DataSourceConfig dataSourceConfig = new DataSourceConfig(); dataSourceConfig.setDbType(DbType.MYSQL)//数据库类型 .setDriverName(\"com.mysql.jdbc.Driver\") .setUrl(\"jdbc:mysql:///数据库名\") .setUsername(\"数据库用户名\") .setPassword(\"数据库密码\"); //3、策略配置 StrategyConfig strategyConfig = new StrategyConfig(); strategyConfig.setCapitalMode(true)//开启全局大写命名 .setDbColumnUnderline(true)//表名字段名使用下划线 .setNaming(NamingStrategy.underline_to_camel)//下划线到驼峰的命名方式 .setTablePrefix(\"tb_\")//表名前缀 .setEntityLombokModel(true)//使用lombok .setInclude(\"表1\",\"表2\");//逆向工程使用的表 //4、包名策略配置 PackageConfig packageConfig = new PackageConfig(); packageConfig.setParent(\"com.zhu.mpg\")//设置包名的parent .setMapper(\"mapper\") .setService(\"service\") .setController(\"controller\") .setEntity(\"entity\") .setXml(\"mapper\");//设置xml文件的目录 //5、整合配置 AutoGenerator autoGenerator = new AutoGenerator(); autoGenerator.setGlobalConfig(config) .setDataSource(dataSourceConfig) .setStrategy(strategyConfig) .setPackageInfo(packageConfig); //6、执行 autoGenerator.execute(); &#125;&#125;注：以上便是示例代码，只要运行该junit测试，就会生成entity、mapper接口、mapper的xml文件、service、serviceImpl、controller代码。每一个设置代码中均有详细注释，此处不再赘述。自定义全局操作：AutoSqlInjector ：BaseMapper提供了17个常用方法，但是有些需求这些方法还是不能很好的实现，那么怎么办呢？大家肯定会想到是在xml文件中写sql语句解决。这样确实可以，因为MP是只做增强不做改变，我们完全可以按照mybatis的原来的方式来解决。不过MP也提供了另一种解决办法，那就是自定义全局操作。所谓自定义全局操作，也就是我们可以在mapper中自定义一些方法，然后通过某些操作，让自定义的这个方法也能像BaseMapper的内置方法，供全局调用。接下来就看看如何实现(以deleteAll方法为例)。1、在mapper接口中定义方法：123public interface EmplopyeeDao extends BaseMapper&lt;Employee&gt; &#123; int deleteAll();&#125;123public interface UserDao extends BaseMapper&lt;User&gt; &#123; int deleteAll();&#125;在这两个mapper接口中都定义了deleteAll方法。2、编写自定义注入类：123456789101112131415161718public class MySqlInjector extends AutoSqlInjector &#123; @Override public void inject(Configuration configuration, MapperBuilderAssistant builderAssistant, Class&lt;?&gt; mapperClass, Class&lt;?&gt; modelClass, TableInfo table) &#123; /* 添加一个自定义方法 */ deleteAllUser(mapperClass, modelClass, table); System.out.println(table.getTableName()); &#125; public void deleteAllUser(Class&lt;?&gt; mapperClass, Class&lt;?&gt; modelClass, TableInfo table) &#123; /* 执行 SQL ，动态 SQL 参考类 SqlMethod */ String sql = \"delete from \" + table.getTableName(); /* mapper 接口方法名一致 */ String method = \"deleteAll\"; SqlSource sqlSource = languageDriver.createSqlSource(configuration, sql, modelClass); this.addDeleteMappedStatement(mapperClass, method, sqlSource); &#125;&#125;注：该类继承AutoSqlInjector，重写inject方法。然后编写sql语句，指定mapper接口中的方法，最后调用addDeleteMappedStatement方法即可。3、在spring配置文件中配置：12&lt;!-- 定义自定义注入器 --&gt;&lt;bean class=\"com.zhu.mybatisplus.injector.MySqlInjector\" id=\"mySqlInjector\"/&gt;1234567&lt;!-- 5、mybatisplus的全局策略配置 --&gt; &lt;bean id=\"globalConfiguration\" class=\"com.baomidou.mybatisplus.entity.GlobalConfiguration\"&gt; &lt;property name=\"idType\" value=\"0\"/&gt; &lt;property name=\"tablePrefix\" value=\"tb_\"/&gt; &lt;!-- 注入自定义全局操作 --&gt; &lt;property name=\"sqlInjector\" ref=\"mySqlInjector\"/&gt; &lt;/bean&gt;注：先把刚才自定义的类注册成bean，然后在全局策略配置的bean中引用自定义类的bean即可。4、测试：1234567891011@Testpublic void testMySqlInjector()&#123; Integer result = userDao.deleteAll(); System.out.println(result);&#125;@Testpublic void testMySqlInjector2()&#123; Integer result = emplopyeeDao.deleteAll(); System.out.println(result);&#125;注：经测试，当userDao调用deleteAll方法时，会删除tb_user表的所有数据，employeeDao调用deleteAll方法时，会删除tb_employee表的所有数据。说明deleteAll方法是有效的。不过在运行这两个测试时，由于是全表删除操作，所有要先把执行分析插件关了。逻辑删除：其实数据并不会轻易的删除掉，毕竟数据收集不易，所以就有了逻辑删除。逻辑删除: 并不会真正的从数据库中将数据删除掉，而是将当前被删除的这条数据中的一个逻辑删除字段置为删除状态，比如该数据有一个字段logic_flag，当其值为1表示未删除，值为-1表示删除，那么逻辑删除就是将1变成-1。1、数据表：在数据表中需要添加逻辑删除字段(logic_flag)。2、实体类：123456789@Datapublic class User&#123; private Integer id; private String name; private Integer age; private Integer gender; @TableLogic //标记逻辑删除属性 private Integer logicFlag;&#125;注：数据库中逻辑删除字段是logic_flag，所以实体类中的logicFlag需要用@TableLogic注解标记。3、mapper:12public interface UserDao extends BaseMapper&lt;User&gt; &#123;&#125;4、配置逻辑删除：需要在spring-dao.xml中做如下配置：首先定义逻辑删除的bean：12&lt;!-- 逻辑删除 --&gt;&lt;bean class=\"com.baomidou.mybatisplus.mapper.LogicSqlInjector\" id=\"logicSqlInjector\"/&gt;再在全局配置的bean中注入逻辑删除以及逻辑删除值：1234567891011&lt;!-- 5、mybatisplus的全局策略配置 --&gt; &lt;bean id=\"globalConfiguration\" class=\"com.baomidou.mybatisplus.entity.GlobalConfiguration\"&gt; &lt;!-- 此处省略其他全局配置 --&gt; &lt;!-- 注入自定义全局操作，做逻辑删除时需要先注释掉 --&gt; &lt;!--&lt;property name=\"sqlInjector\" ref=\"mySqlInjector\"/&gt;--&gt; &lt;!-- 注入逻辑删除，先要把自定义的注释掉 --&gt; &lt;property name=\"sqlInjector\" ref=\"logicSqlInjector\"/&gt; &lt;!-- 注入逻辑删除值 --&gt; &lt;property name=\"logicDeleteValue\" value=\"-1\"/&gt;&lt;!-- -1是删除状态 --&gt; &lt;property name=\"logicNotDeleteValue\" value=\"1\"/&gt;&lt;!-- 1是未删除状态 --&gt; &lt;/bean&gt;注：因为逻辑删除实际上也是一个sqlInjector，所以先要把刚才做自定义全局操作时注入的自定义全局操作注释掉，上面代码中已有详细注释说明。6、测试：1234567@Test public void testLogicDelete()&#123; Integer result = userDao.deleteById(1); System.out.println(result); //User user = userDao.selectById(1); //System.out.println(user); &#125;注：运行该测试，执行删除操作的时候，真正执行的sql语句是UPDATE tb_user SET logic_flag=-1 WHERE id=?，就是把逻辑删除字段的值设置为-1；当逻辑删除字段的值是-1时再执行查询操作，sql是SELECT ... FROM tb_user WHERE id=? AND logic_flag=1，所以查询结果是null。公共字段自动填充：我们知道，当我们进行插入或者更新操作时，没有设置值的属性，那么在数据表中要么是为null，要么是保留原来的值。有的时候我们我们没有赋值但是却不想让其为空，比如name属性，我们插入时会默认赋上“林志玲”，更新时会默认赋值上“朱茵”，那么就可以用公共字段自动填充。1、使用@TableField注解标记填充字段12@TableField(fill = FieldFill.INSERT_UPDATE)//插入和更新时填充 private String name;2、编写公共字段填充处理器类：1234567891011121314151617public class MyMetaObjectHandler extends MetaObjectHandler &#123; @Override public void insertFill(MetaObject metaObject) &#123; Object fieldValue = getFieldValByName(\"name\",metaObject); //获取需要填充的字段 if(fieldValue == null)&#123; //如果该字段没有设置值 setFieldValByName(\"name\",\"林志玲\",metaObject); //那就将其设置为\"林志玲\" &#125; &#125; @Override public void updateFill(MetaObject metaObject) &#123; Object fieldValue = getFieldValByName(\"name\",metaObject);//获取需要填充的字段 if(fieldValue == null)&#123; //如果该字段没有设置值 setFieldValByName(\"name\",\"朱茵\",metaObject); //那就将其设置为\"朱茵\" &#125; &#125;&#125;注：该类继承了MetaObjectHandler类，重写了insertFill和updateFill方法，在这两个方法获取需要填充的字段以及默认填充的值。3、在spring-dao.xml中配置：12&lt;!-- 公共字段填充处理器 --&gt;&lt;bean class=\"com.zhu.mybatisplus.handler.MyMetaObjectHandler\" id=\"myMetaObjectHandler\"/&gt;123456&lt;!-- 5、mybatisplus的全局策略配置 --&gt; &lt;bean id=\"globalConfiguration\" class=\"com.baomidou.mybatisplus.entity.GlobalConfiguration\"&gt; &lt;!-- 此处省略其他配置 --&gt; &lt;!-- 注入公共字段填充处理器 --&gt; &lt;property name=\"metaObjectHandler\" ref=\"myMetaObjectHandler\"/&gt; &lt;/bean&gt;注：和配置逻辑删除一样，都是先将自定义的类注册成bean，再在全局策略配置中引用这个bean即可。4、测试：12345678@Testpublic void testHandlerInsert() &#123; User user = new User(); user.setGender(1); user.setAge(22); user.setLogicFlag(1); userDao.insert(user);&#125;注：可以看到，虽然我们并没有给name赋值，但是已经自动把“林志玲”传进去了。更新时也一样有效，此处就不将测试代码贴出来了。","categories":[{"name":"Mybatis-Plus","slug":"Mybatis-Plus","permalink":"https://me.obey.fun/categories/Mybatis-Plus/"},{"name":"ORM","slug":"Mybatis-Plus/ORM","permalink":"https://me.obey.fun/categories/Mybatis-Plus/ORM/"}],"tags":[{"name":"Mybatis","slug":"Mybatis","permalink":"https://me.obey.fun/tags/Mybatis/"},{"name":"Mybatis-Plus","slug":"Mybatis-Plus","permalink":"https://me.obey.fun/tags/Mybatis-Plus/"}],"keywords":[{"name":"Mybatis-Plus","slug":"Mybatis-Plus","permalink":"https://me.obey.fun/categories/Mybatis-Plus/"},{"name":"ORM","slug":"Mybatis-Plus/ORM","permalink":"https://me.obey.fun/categories/Mybatis-Plus/ORM/"}]},{"title":"SpringCloud简单入门","slug":"SpringCloud简单入门","date":"2020-05-02T13:05:38.000Z","updated":"2020-05-25T04:16:42.000Z","comments":true,"path":"SpringCloud简单入门.html","link":"","permalink":"https://me.obey.fun/SpringCloud简单入门.html","excerpt":"","text":"什么是SpringCloud？SpringCloud，基于SpringBoot提供了一套微服务解决方案，包括服务注册与发现，配置中心，全链路监控，服务网关，负载均衡，熔断器等组件，除了基于NetFlix的开源组件做高度抽象封装之外，还有一些选型中立的开源组件。SpringCloud利用springboot的开发便利性，巧妙的简化了分布式系统基础设施的开发，SpringCloud为开发人员提供了快速构建分布式系统的一些工具，包括配置管理，服务发现，断路器，路由，微代理，事件总线，全局锁，决策竞选，分布式会话等等，他们都可以用springboot的开发风格做到一键启动和部署。SpringCloud和SpringBoot的关系SpringBoot专注于快速方便的开发单个个体微服务SpringCloud是关注全局的微服务协调整理治理框架，它将SpringBoot开的一个个单体服务整合并管理起来，为各个服务之间提供：配置管理，服务发现，断路器，路由，微代理，时间总线，全局锁，决策竞选，分布式会话等等集成服务。SpringBoot可以离开SpringCloud独立使用，开发项目，SpringCloud关注全度的服务治理框架Dubbo和Spring Cloud对比解决的问题域不一样：Dubbo的定位是一款RPC框架，Spring Cloud的目的是微服务架构下的一站式解决方案SpringCloud初体验创建父工程创建普通maven项目，因为是父项目，所以把src目录删除掉pom文件导入所需依赖12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;artifactId&gt;ksspringcloud&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;modules&gt; &lt;module&gt;springcloud-api&lt;/module&gt; &lt;module&gt;springcloud-provider-dept-8001&lt;/module&gt; &lt;module&gt;springcloud-consumer-dept-80&lt;/module&gt; &lt;module&gt;springcloud-eureka-7001&lt;/module&gt; &lt;/modules&gt; &lt;!--打包方式 pom--&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;!--提取版本--&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;lombok.version&gt;1.18.12&lt;/lombok.version&gt; &lt;log4j.version&gt;1.2.17&lt;/log4j.version&gt; &lt;logback.version&gt;1.2.3&lt;/logback.version&gt; &lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt; &lt;druid.version&gt;1.1.14&lt;/druid.version&gt; &lt;/properties&gt; &lt;!--总的依赖管理--&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--SpringCloud的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Hoxton.SR3&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--SpringBoot的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-dependencies&lt;/artifactId&gt; &lt;version&gt;2.2.6.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;!--数据库--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--数据源--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;$&#123;druid.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!--SpringBoot启动器--&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--日志和测试--&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;$&#123;logback.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt;创建公共实体类api​ (管理pojo)，创建普通maven模块添加子工程所需依赖1234567&lt;!--当前的module自己需要的依赖，如果父依赖种已经配置了版本，这里就不用写版本号--&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;创建数据库右键root@localhost—&gt;创建数据库数据库：XXXXXX基字符集：utf8数据库排序规则：utf8_general_ci创建表格​ -Database-&gt;选中数据库–右键–new–Table往数据库插入数据创建实体类(所有实体类务必实现序列化)12345678910111213141516171819202122/** * 所有实体类务必实现序列化 */@Data@NoArgsConstructor@Accessors(chain = true) //链式写法public class Dept implements Serializable &#123; private Long deptno; //主键 private String deptname;//部门名称 //这个数据是存在哪个数据库的字段，微服务，一个服务对应一个数据库，同一个信息可能存在不同的数据库中 private String db_source; public Dept(String deptname) &#123; this.deptname = deptname; &#125; /** * 链式写法：可以连续写 * Dept dept = new Dept(); * dept.setDeptno(11).setDeptname(\"开发部\").set…… */&#125;这个微服务到此结束，此微服务只负责pojo创建服务的提供者模块springcloud-provider-dept-8001添加子服务依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;springcloud&lt;/artifactId&gt; &lt;groupId&gt;com.kuang&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-provider-dept-8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--我们需要拿到实体类，所以要配置咱们的api module--&gt; &lt;dependency&gt; &lt;groupId&gt;com.kuang&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--测试--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--数据库--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--数据源--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jetty--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;application.yml配置文件1234567891011121314151617server: port: 8001spring: application: name: springcloud-provider-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver #org.gjt.mm.mysql.Driver或者com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/scdb01?useSSL=false&amp;characterEncoding=utf8&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true username: root password: 123456mybatis: type-aliases-package: cn.kgc.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xmlmybatis-config.xml配置123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!--开启二级缓存--&gt; &lt;setting name=\"cacheEnabled\" value=\"true\"/&gt; &lt;/settings&gt;&lt;/configuration&gt;创建部门的dao接口：DeptDao123456789101112131415161718192021222324252627package cn.kgc.dao;import cn.kgc.pojo.Dept;import org.apache.ibatis.annotations.Mapper;import org.springframework.stereotype.Repository;import java.util.List;@Mapper@Repositorypublic interface DeptDao &#123; /** * 增加一个部门 */ public boolean addDept(Dept dept); /** * id查询部门 */ public Dept queryById(Integer id); /** * 查询所有部门 */ public List&lt;Dept&gt; queryAll();&#125;对应mapper文件(DeptMapper.xml)12345678910111213141516&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"cn.kgc.dao.DeptDao\"&gt; &lt;insert id=\"addDept\" parameterType=\"Dept\"&gt; insert into dept(deptName,db_source) values (#&#123;deptName&#125;,DATABASE()); &lt;/insert&gt; &lt;select id=\"queryById\" resultType=\"Dept\" parameterType=\"Integer\"&gt; select * from dept where deptNo = #&#123;deptNo&#125;; &lt;/select&gt; &lt;select id=\"queryAll\" resultType=\"Dept\"&gt; select * from dept; &lt;/select&gt;&lt;/mapper&gt;service层代码1234567891011121314151617181920212223package cn.kgc.service;import cn.kgc.pojo.Dept;import java.util.List;public interface DeptService &#123; /** * 增加一个部门 */ public boolean addDept(Dept dept); /** * id查询部门 */ public Dept queryById(Integer id); /** * 查询所有部门 */ public List&lt;Dept&gt; queryAll();&#125;123456789101112131415161718192021222324252627282930package cn.kgc.service;import cn.kgc.dao.DeptDao;import cn.kgc.pojo.Dept;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import java.util.List;@Servicepublic class DeptServiceImpl implements DeptService &#123; @Autowired private DeptDao deptDao; @Override public boolean addDept(Dept dept) &#123; return deptDao.addDept(dept); &#125; @Override public Dept queryById(Integer id) &#123; return deptDao.queryById(id); &#125; @Override public List&lt;Dept&gt; queryAll() &#123; return deptDao.queryAll(); &#125;&#125;控制器1234567891011121314151617181920212223/** * //提供RestFul服务 */@RestControllerpublic class DeptController &#123; @Autowired private DeptService deptService; @PostMapping(\"/dept/add\") public boolean addDept(@RequestBody Dept dept)&#123; return deptService.addDept(dept); &#125; @GetMapping(\"/dept/get/&#123;id&#125;\") public Dept get(@PathVariable(\"id\") Integer id)&#123; return deptService.queryById(id); &#125; @GetMapping(\"/dept/list\") public List&lt;Dept&gt; queryAll()&#123; return deptService.queryAll(); &#125;&#125;创建启动器123456789/** * 启动类 */@SpringBootApplicationpublic class DeptProvider8001Main &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider8001Main.class,args); &#125;&#125;启动项目测试12http://localhost:8001/dept/get/11http://localhost:8001/dept/list创建服务的消费者模块​ springcloud-consumer-dept-80pom依赖1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;ksspringcloud&lt;/artifactId&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-consumer-dept-80&lt;/artifactId&gt; &lt;!--实体类+web--&gt; &lt;dependencies&gt; &lt;!--我们需要拿到实体类，所以要配置咱们的api module--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;application.yml配置12server: port: 80注册RestTemplate(config目录内创建类ConfigBean)12345678@Configurationpublic class ConfigBean &#123; @Bean public RestTemplate getRestTemplate()&#123; return new RestTemplate(); &#125;&#125;控制器1234567891011121314151617181920212223242526272829303132333435package cn.kgc.controller;import cn.kgc.pojo.Dept;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.client.RestTemplate;import java.util.List;@RestControllerpublic class DeptConsumerController &#123; @Autowired private RestTemplate restTemplate; //提供多种便捷访问远程HTTP服务的方法，简单的RestFul服务模板 private static final String REST_URL_PREFIX = \"http://localhost:8001\"; @RequestMapping(\"/consumer/dept/add\") public Boolean add(Dept dept)&#123; return restTemplate.postForObject(REST_URL_PREFIX+\"/dept/add\",dept,boolean.class); &#125; @RequestMapping(\"/consumer/dept/get/&#123;id&#125;\") public Dept get(@PathVariable(\"id\") Integer id)&#123; return restTemplate.getForObject(REST_URL_PREFIX+\"/dept/get/\"+id,Dept.class); &#125; @RequestMapping(\"/consumer/dept/list\") public List&lt;Dept&gt; list()&#123; return restTemplate.getForObject(REST_URL_PREFIX+\"/dept/list\",List.class); &#125;&#125;启动类123456@SpringBootApplicationpublic class DeptConsumer80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer80.class,args); &#125;&#125;启动两个子项目测试123http://localhost/consumer/dept/get/12http://localhost/consumer/dept/listhttp://localhost/consumer/dept/add?deptName=225Eureka注册中心的使用什么是EurekaNetflix在涉及Eureka时，遵循的就是API原则.Eureka是Netflix的一个子模块，也是核心模块之一。Eureka是基于REST的服务，用于定位服务，以实现云端中间件层服务发现和故障转移，服务注册与发现对于微服务来说是非常重要的，有了服务注册与发现，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务调用的配置文件了，功能类似于Dubbo的注册中心，比如Zookeeper.原理理解Eureka基本的架构Springcloud 封装了Netflix公司开发的Eureka模块来实现服务注册与发现 (对比Zookeeper).Eureka采用了C-S的架构设计，EurekaServer作为服务注册功能的服务器，他是服务注册中心.而系统中的其他微服务，使用Eureka的客户端连接到EurekaServer并维持心跳连接。这样系统的维护人员就可以通过EurekaServer来监控系统中各个微服务是否正常运行，Springcloud 的一些其他模块 (比如Zuul) 就可以通过EurekaServer来发现系统中的其他微服务，并执行相关的逻辑.Eureka 包含两个组件：Eureka Server 和 Eureka Client.Eureka Server 提供服务注册，各个节点启动后，回在EurekaServer中进行注册，这样Eureka Server中的服务注册表中将会储存所有课用服务节点的信息，服务节点的信息可以在界面中直观的看到.Eureka Client 是一个Java客户端，用于简化EurekaServer的交互，客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向EurekaServer发送心跳 (默认周期为30秒) 。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，EurekaServer将会从服务注册表中把这个服务节点移除掉 (默认周期为90s).三大角色Eureka Server：提供服务的注册与发现Service Provider：服务生产方，将自身服务注册到Eureka中，从而使服务消费方能狗找到Service Consumer：服务消费方，从Eureka中获取注册服务列表，从而找到服务方创建module，springcloud-eureka-7001导入依赖123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;ksspringcloud&lt;/artifactId&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-eureka-7001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--eureka-server--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;配置application.yml123456789101112server: port: 7001eureka: instance: hostname: localhost # Eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向注册中心注册自己 fetch-registry: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: # 设置与 Eureka Server 交互的地址查询服务和注册服务都需要依赖这个地址 defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/写启动类1234567@SpringBootApplication@EnableEurekaServer //注解：服务端的启动类，可以接受其他服务注册进来public class EurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServer_7001.class,args); &#125;&#125;启动项目测试1http://localhost:7001将服务提供者8001注册进Eureka中8001的pom加入Eureka依赖1234567891011&lt;!--Eureka--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt; &lt;!--完善监控信息--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;application.yml添加Eureka配置信息123456789101112#Eureka的配置，服务注册到哪里eureka: client: service-url: defaultZone: http://localhost:7001/eureka/ instance: instance-id: springboot-provader-dept8001 #修改Eureka上的默认描述信息 #info配置,监控里点击项目名可查看项目详情，开发公司，开发人等等自定义添加info: app-name: kuangshen-springcloud company.name: blog.kuangstudy.com启动类开启注解支持@EnableEurekaClient1234567@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到eureka中public class DeptProvider8001Main &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider8001Main.class,args); &#125;&#125;启动7001和8001进行测试1234http://localhost:7001/成功发现服务点击 UP (1) - springboot-provader-dept8001会返回 &#123;\"app-name\":\"kuangshen-springcloud\",\"company\":&#123;\"name\":\"blog.kuangstudy.com\"&#125;&#125;Eureka自我保护机制，好死不如赖活着一句话总结就是：某时刻某一个微服务不可用，eureka不会立即清理，依旧会对该微服务的信息进行保存！默认情况下，当eureka server在一定时间内没有收到实例的心跳，便会把该实例从注册表中删除（默认是90秒），但是，如果短时间内丢失大量的实例心跳，便会触发eureka server的自我保护机制，比如在开发测试时，需要频繁地重启微服务实例，但是我们很少会把eureka server一起重启（因为在开发过程中不会修改eureka注册中心），当一分钟内收到的心跳数大量减少时，会触发该保护机制。可以在eureka管理界面看到Renews threshold和Renews(last min)，当后者（最后一分钟收到的心跳数）小于前者（心跳阈值）的时候，触发保护机制，会出现红色的警告：EMERGENCY!EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY’RE NOT.RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEGING EXPIRED JUST TO BE SAFE.从警告中可以看到，eureka认为虽然收不到实例的心跳，但它认为实例还是健康的，eureka会保护这些实例，不会把它们从注册表中删掉。该保护机制的目的是避免网络连接故障，在发生网络故障时，微服务和注册中心之间无法正常通信，但服务本身是健康的，不应该注销该服务，如果eureka因网络故障而把微服务误删了，那即使网络恢复了，该微服务也不会重新注册到eureka server了，因为只有在微服务启动的时候才会发起注册请求，后面只会发送心跳和服务列表请求，这样的话，该实例虽然是运行着，但永远不会被其它服务所感知。所以，eureka server在短时间内丢失过多的客户端心跳时，会进入自我保护模式，该模式下，eureka会保护注册表中的信息，不在注销任何微服务，当网络故障恢复后，eureka会自动退出保护模式。自我保护模式可以让集群更加健壮。但是我们在开发测试阶段，需要频繁地重启发布，如果触发了保护机制，则旧的服务实例没有被删除，这时请求有可能跑到旧的实例中，而该实例已经关闭了，这就导致请求错误，影响开发测试。所以，在开发测试阶段，我们可以把自我保护模式关闭，只需在eureka server配置文件中加上如下配置即可：eureka.server.enable-self-preservation=falseEureka集群配置新建两个module分别为springcloud-eureka-7002、springcloud-eureka-7003，并把eureka依赖和热部署依赖导进pom文件，配置主启动类配置系统中的localsC:\\Windows\\System32\\drivers\\etc\\hosts最底部添加123127.0.0.1 eureka7001.com127.0.0.1 eureka7002.com127.0.0.1 eureka7003.com关联三个注册中心(每个这侧中心挂载其他两个)1234567891011121314server: port: 7001eureka: instance: hostname: eureka7001.com # Eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向注册中心注册自己 fetch-registry: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: # 单击-设置与 Eureka Server 交互的地址查询服务和注册服务都需要依赖这个地址 #defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群-关联，挂载7002和7003 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/1234567891011121314server: port: 7002eureka: instance: hostname: eureka7002.com # Eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向注册中心注册自己 fetch-registry: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: # 设置与 Eureka Server 交互的地址查询服务和注册服务都需要依赖这个地址 # defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群-关联，挂载7001和7003 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7003.com:7003/eureka/1234567891011121314server: port: 7003eureka: instance: hostname: eureka7003.com # Eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向注册中心注册自己 fetch-registry: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: # 设置与 Eureka Server 交互的地址查询服务和注册服务都需要依赖这个地址 # defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群-关联，挂载7001和7002 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/启动三个eureka服务中心和8001服务，可以看到成功挂载其他两个中心以及可发现8001服务12345678910111213141516171819访问http://eureka7002.com:7001 DS Replicas eureka7003.com eureka7002.com Application AMIs Availability Zones StatusSPRINGCLOUD-PROVIDER-DEPT n/a (1) (1) UP (1) - springboot-provader-dept8001访问http://eureka7002.com:7002 DS Replicas eureka7003.com eureka7001.com Application AMIs Availability Zones StatusSPRINGCLOUD-PROVIDER-DEPT n/a (1) (1) UP (1) - springboot-provader-dept8001访问http://eureka7002.com:7003 DS Replicas eureka7002.com eureka7001.com Application AMIs Availability Zones StatusSPRINGCLOUD-PROVIDER-DEPT n/a (1) (1) UP (1) - springboot-provader-dept8001如果其中一个崩了，其他两个还正常运行，这时服务不会 停止Eureka对比ZookeeperACID是什么？A (Atomicity) 原子性C (Consistency) 一致性I (Isolation) 隔离性D (Durability) 持久性CAP是什么?C (Consistency) 强一致性A (Availability) 可用性P (Partition tolerance) 分区容错性CAP的三进二：CA、AP、CPCAP理论的核心一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求根据CAP原理，将NoSQL数据库分成了满足CA原则，满足CP原则和满足AP原则三大类CA：单点集群，满足一致性，可用性的系统，通常可扩展性较差CP：满足一致性，分区容错的系统，通常性能不是特别高AP：满足可用性，分区容错的系统，通常可能对一致性要求低一些作为分布式服务注册中心，Eureka比Zookeeper好在哪里？著名的CAP理论指出，一个分布式系统不可能同时满足C (一致性) 、A (可用性) 、P (容错性)，由于分区容错性P再分布式系统中是必须要保证的，因此我们只能再A和C之间进行权衡。Zookeeper保证的是CP当向注册中心查询服务列表时，我们可以容忍注册中心返回的是几分钟以前的注册信息，但不能接收服务直接down掉不可用。也就是说，服务注册功能对可用性的要求要高于一致性。但zookeeper会出现这样一种情况，当master节点因为网络故障与其他节点失去联系时，剩余节点会重新进行leader选举。问题在于，选举leader的时间太长，30-120s，且选举期间整个zookeeper集群是不可用的，这就导致在选举期间注册服务瘫痪。在云部署的环境下，因为网络问题使得zookeeper集群失去master节点是较大概率发生的事件，虽然服务最终能够恢复，但是，漫长的选举时间导致注册长期不可用，是不可容忍的。Eureka保证的是APEureka看明白了这一点，因此在设计时就优先保证可用性。Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和查询服务。而Eureka的客户端在向某个Eureka注册时，如果发现连接失败，则会自动切换至其他节点，只要有一台Eureka还在，就能保住注册服务的可用性，只不过查到的信息可能不是最新的，除此之外，Eureka还有之中自我保护机制，如果在15分钟内超过85%的节点都没有正常的心跳，那么Eureka就认为客户端与注册中心出现了网络故障，此时会出现以下几种情况：Eureka不在从注册列表中移除因为长时间没收到心跳而应该过期的服务Eureka仍然能够接受新服务的注册和查询请求，但是不会被同步到其他节点上 (即保证当前节点依然可用)当网络稳定时，当前实例新的注册信息会被同步到其他节点中因此，Eureka可以很好的应对因网络故障导致部分节点失去联系的情况，而不会像zookeeper那样使整个注册服务瘫痪Eureka 注册中心刚开始看到Eureka这个单词的时候真心不会念，查了后发现他有一个好听的名字，来，大家一起念 [jʊ’rikə]简介Eureka本身是Netflix开源的一款提供服务注册和发现的产品，并且提供了相应的Java封装。在它的实现中，节点之间相互平等，部分注册中心的节点挂掉也不会对集群造成影响，即使集群只剩一个节点存活，也可以正常提供发现服务。哪怕是所有的服务注册节点都挂了，Eureka Clients（客户端）上也会缓存服务调用的信息。这就保证了我们微服务之间的互相调用足够健壮。Zookeeper主要为大型分布式计算提供开源的分布式配置服务、同步服务和命名注册。曾经是Hadoop项目中的一个子项目，用来控制集群中的数据，目前已升级为独立的顶级项目。很多场景下也用它作为Service发现服务解决方案。对比在分布式系统中有个著名的CAP定理（C-数据一致性；A-服务可用性；P-服务对网络分区故障的容错性，这三个特性在任何分布式系统中不能同时满足，最多同时满足两个）；ZookeeperZookeeper是基于CP来设计的，即任何时刻对Zookeeper的访问请求能得到一致的数据结果，同时系统对网络分割具备容错性，但是它不能保证每次服务请求的可用性。从实际情况来分析，在使用Zookeeper获取服务列表时，如果zookeeper正在选主，或者Zookeeper集群中半数以上机器不可用，那么将无法获得数据。所以说，Zookeeper不能保证服务可用性。诚然，在大多数分布式环境中，尤其是涉及到数据存储的场景，数据一致性应该是首先被保证的，这也是zookeeper设计成CP的原因。但是对于服务发现场景来说，情况就不太一样了：针对同一个服务，即使注册中心的不同节点保存的服务提供者信息不尽相同，也并不会造成灾难性的后果。因为对于服务消费者来说，能消费才是最重要的——拿到可能不正确的服务实例信息后尝试消费一下，也好过因为无法获取实例信息而不去消费。（尝试一下可以快速失败，之后可以更新配置并重试）所以，对于服务发现而言，可用性比数据一致性更加重要——AP胜过CP。Eureka而Spring Cloud Netflix在设计Eureka时遵守的就是AP原则。Eureka Server也可以运行多个实例来构建集群，解决单点问题，但不同于ZooKeeper的选举leader的过程，Eureka Server采用的是Peer to Peer对等通信。这是一种去中心化的架构，无master/slave区分，每一个Peer都是对等的。在这种架构中，节点通过彼此互相注册来提高可用性，每个节点需要添加一个或多个有效的serviceUrl指向其他节点。每个节点都可被视为其他节点的副本。如果某台Eureka Server宕机，Eureka Client的请求会自动切换到新的Eureka Server节点，当宕机的服务器重新恢复后，Eureka会再次将其纳入到服务器集群管理之中。当节点开始接受客户端请求时，所有的操作都会进行replicateToPeer（节点间复制）操作，将请求复制到其他Eureka Server当前所知的所有节点中。一个新的Eureka Server节点启动后，会首先尝试从邻近节点获取所有实例注册表信息，完成初始化。Eureka Server通过getEurekaServiceUrls()方法获取所有的节点，并且会通过心跳续约的方式定期更新。默认配置下，如果Eureka Server在一定时间内没有接收到某个服务实例的心跳，Eureka Server将会注销该实例（默认为90秒，通过eureka.instance.lease-expiration-duration-in-seconds配置）。当Eureka Server节点在短时间内丢失过多的心跳时（比如发生了网络分区故障），那么这个节点就会进入自我保护模式。什么是自我保护模式？默认配置下，如果Eureka Server每分钟收到心跳续约的数量低于一个阈值（instance的数量(60/每个instance的心跳间隔秒数)自我保护系数），并且持续15分钟，就会触发自我保护。在自我保护模式中，Eureka Server会保护服务注册表中的信息，不再注销任何服务实例。当它收到的心跳数重新恢复到阈值以上时，该Eureka Server节点就会自动退出自我保护模式。它的设计哲学前面提到过，那就是宁可保留错误的服务注册信息，也不盲目注销任何可能健康的服务实例。该模式可以通过eureka.server.enable-self-preservation = false来禁用，同时eureka.instance.lease-renewal-interval-in-seconds可以用来更改心跳间隔，eureka.server.renewal-percent-threshold可以用来修改自我保护系数（默认0.85）。总结ZooKeeper基于CP，不保证高可用，如果zookeeper正在选主，或者Zookeeper集群中半数以上机器不可用，那么将无法获得数据。Eureka基于AP，能保证高可用，即使所有机器都挂了，也能拿到本地缓存的数据。作为注册中心，其实配置是不经常变动的，只有发版和机器出故障时会变。对于不经常变动的配置来说，CP是不合适的，而AP在遇到问题时可以用牺牲一致性来保证可用性，既返回旧数据，缓存数据。所以理论上Eureka是更适合作注册中心。而现实环境中大部分项目可能会使用ZooKeeper，那是因为集群不够大，并且基本不会遇到用做注册中心的机器一半以上都挂了的情况。所以实际上也没什么大问题。Ribbon：负载均衡(基于客户端)负载均衡以及RibbonRibbon是什么？Spring Cloud Ribbon 是基于Netflix Ribbon 实现的一套客户端负载均衡的工具。简单的说，Ribbon 是 Netflix 发布的开源项目，主要功能是提供客户端的软件负载均衡算法，将 Netflix 的中间层服务连接在一起。Ribbon 的客户端组件提供一系列完整的配置项，如：连接超时、重试等。简单的说，就是在配置文件中列出 LoadBalancer (简称LB：负载均衡) 后面所有的及其，Ribbon 会自动的帮助你基于某种规则 (如简单轮询，随机连接等等) 去连接这些机器。我们也容易使用 Ribbon 实现自定义的负载均衡算法！Ribbon能干嘛？LB，即负载均衡 (LoadBalancer) ，在微服务或分布式集群中经常用的一种应用。负载均衡简单的说就是将用户的请求平摊的分配到多个服务上，从而达到系统的HA (高用)。常见的负载均衡软件有 Nginx、Lvs 等等。Dubbo、SpringCloud 中均给我们提供了负载均衡，SpringCloud 的负载均衡算法可以自定义。负载均衡简单分类：集中式LB即在服务的提供方和消费方之间使用独立的LB设施，如Nginx，由该设施负责把访问请求通过某种策略转发至服务的提供方！进程式LB将LB逻辑集成到消费方，消费方从服务注册中心获知有哪些地址可用，然后自己再从这些地址中选出一个合适的服务器。Ribbon 就属于进程内LB，它只是一个类库，集成于消费方进程，消费方通过它来获取到服务提供方的地址！集成Ribbon1、springcloud-consumer-dept-80**向pom.xml中添加Ribbon和Eureka依赖123456789101112&lt;!--Ribbon--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;!--Eureka: Ribbon需要从Eureka服务中心获取要拿什么--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;2、在application.yml文件中配置Eureka123456# Eureka配置eureka: client: register-with-eureka: false # 不向 Eureka注册自己 service-url: # 从三个注册中心中随机取一个去访问 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/3、主启动类加上@EnableEurekaClient注解，开启Eureka1234567@SpringBootApplication@EnableEurekaClientpublic class DeptConsumer80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer80.class,args); &#125;&#125;4、自定义Spring配置类：ConfigBean.java 配置负载均衡实现RestTemplate123456789@Configurationpublic class ConfigBean &#123;//@Configuration -- spring applicationContext.xml @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125;&#125;5、修改conroller：DeptConsumerController.java123//Ribbon:我们这里的地址，应该是一个变量，通过服务名来访问//private static final String REST_URL_PREFIX = \"http://localhost:8001\";private static final String REST_URL_PREFIX = \"http://SPRINGCLOUD-PROVIDER-DEPT\";6、测试123启动所有服务访问 http://localhost/consumer/dept/get/1 http://localhost/consumer/dept/list使用Ribbon实现负载均衡1、创建两个数据库scdb02、scdb03,表内容一直db_source为各自的数据库名2、新建两个服务提供者Moudle：springcloud-provider-dept-8003、springcloud-provider-dept-80023、将8001的依赖和resource目录粘贴入8002、8003项目中，将application.yml文件中更改相应的名称1234567891011121314151617181920212223242526272829303132server: port: 8003spring: application: name: springcloud-provider-dept #三个名称一致为前提，我们时通过名称连接的 datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver #org.gjt.mm.mysql.Driver或者com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/scdb03?useSSL=false&amp;characterEncoding=utf8&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true username: root password: 123456#mybatis配置mybatis: type-aliases-package: cn.kgc.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xml#Eureka的配置，服务注册到哪里eureka: client: service-url: # 发布到集群，三个eureka注册中心 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springboot-provader-dept8003#info配置info: app-name: kuangshen-springcloud company.name: blog.kuangstudy.com4、将8001的所有java代码拷贝粘贴入8002、8003，更改各自的启动类5、启动所有项目进行测试123456789http://eureka7001.com:7001/EMERGENCY! EUREKA MAY BE INCORRECTLY CLAIMING INSTANCES ARE UP WHEN THEY'RE NOT. RENEWALS ARE LESSER THAN THRESHOLD AND HENCE THE INSTANCES ARE NOT BEING EXPIRED JUST TO BE SAFE.DS Replicaseureka7003.comeureka7002.comInstances currently registered with EurekaApplication AMIs Availability Zones StatusSPRINGCLOUD-PROVIDER-DEPT n/a (3) (3) UP (3) - springboot-provader-dept8001 , springboot-provader-dept8002 , springboot-provader-dept8003可以看到三个实例12345访问http://localhost/consumer/dept/get/4会从三个服务中轮询（默认算法）查询：&#123;\"deptNo\":4,\"deptName\":\"市场部\",\"db_source\":\"scdb03\"&#125;&#123;\"deptNo\":4,\"deptName\":\"市场部\",\"db_source\":\"scdb02\"&#125;&#123;\"deptNo\":4,\"deptName\":\"市场部\",\"db_source\":\"scdb01\"&#125;以上这种每次访问http://localhost/consumer/dept/list随机访问集群中某个服务提供者，这种情况叫做轮询，轮询算法在SpringCloud中可以自定义。6、如何切换或者自定义规则呢？在springcloud-provider-dept-80模块下的ConfigBean中进行配置，切换使用不同的规则123456789101112131415161718192021@Configurationpublic class ConfigBean &#123;//@Configuration -- spring applicationContext.xml /** * IRule: * RoundRobinRule 轮询 * RandomRule 随机 * AvailabilityFilteringRule ： 会先过滤掉，跳闸，访问故障的服务~，对剩下的进行轮询~ * RetryRule ： 会先按照轮询获取服务~，如果服务获取失败，则会在指定的时间内进行，重试 */ @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate() &#123; return new RestTemplate(); &#125; @Bean public IRule myRule()&#123; return new RandomRule();//使用随机规则 &#125;&#125;也可以自定义规则，在myRule包下自定义一个配置类MyRule.java，注意：该包不要和主启动类所在的包同级，要跟启动类所在包同级：12345678910111213/** * @Auther: huiprogramer * @Date: 2020/05/19/11:58 * @Description: 自定义规则 */@Configurationpublic class MyRule &#123; @Bean public IRule myRule()&#123; return new MyRandomRule();//默认是轮询RandomRule,现在自定义为自己的 &#125;&#125;主启动类开启负载均衡并指定自定义的MyRule配置类12345678910//Ribbon 和 Eureka 整合以后，客户端可以直接调用，不用关心IP地址和端口号@SpringBootApplication@EnableEurekaClient//在微服务启动的时候就能加载自定义的Ribbon类(自定义的规则会覆盖原有默认的规则)@RibbonClient(name = \"SPRINGCLOUD-PROVIDER-DEPT\",configuration = MyRule.class)//开启负载均衡,并指定自定义的规则public class DeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumer_80.class, args); &#125;&#125;自定义的规则(这里我们参考Ribbon中默认的规则代码自己稍微改动)：MyRandomRule.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class MyRandomRule extends AbstractLoadBalancerRule &#123; /** * 每个服务访问5次则换下一个服务(总共3个服务) * &lt;p&gt; * total=0,默认=0,如果=5,指向下一个服务节点 * index=0,默认=0,如果total=5,index+1 */ private int total = 0;//被调用的次数 private int currentIndex = 0;//当前是谁在提供服务 //@edu.umd.cs.findbugs.annotations.SuppressWarnings(value = \"RCN_REDUNDANT_NULLCHECK_OF_NULL_VALUE\") public Server choose(ILoadBalancer lb, Object key) &#123; if (lb == null) &#123; return null; &#125; Server server = null; while (server == null) &#123; if (Thread.interrupted()) &#123; return null; &#125; List&lt;Server&gt; upList = lb.getReachableServers();//获得当前活着的服务 List&lt;Server&gt; allList = lb.getAllServers();//获取所有的服务 int serverCount = allList.size(); if (serverCount == 0) &#123; /* * No servers. End regardless of pass, because subsequent passes * only get more restrictive. */ return null; &#125; //int index = chooseRandomInt(serverCount);//生成区间随机数 //server = upList.get(index);//从或活着的服务中,随机获取一个 //=====================自定义代码========================= if (total &lt; 5) &#123; server = upList.get(currentIndex); total++; &#125; else &#123; total = 0; currentIndex++; if (currentIndex &gt; upList.size()) &#123; currentIndex = 0; &#125; server = upList.get(currentIndex);//从活着的服务中,获取指定的服务来进行操作 &#125; //====================================================== if (server == null) &#123; /* * The only time this should happen is if the server list were * somehow trimmed. This is a transient condition. Retry after * yielding. */ Thread.yield(); continue; &#125; if (server.isAlive()) &#123; return (server); &#125; // Shouldn't actually happen.. but must be transient or a bug. server = null; Thread.yield(); &#125; return server; &#125; protected int chooseRandomInt(int serverCount) &#123; return ThreadLocalRandom.current().nextInt(serverCount); &#125; @Override public Server choose(Object key) &#123; return choose(getLoadBalancer(), key); &#125; @Override public void initWithNiwsConfig(IClientConfig clientConfig) &#123; // TODO Auto-generated method stub &#125;&#125;Feign：负载均衡(基于服务端)Feign简介Feign是声明式Web Service客户端，它让微服务之间的调用变得更简单，类似controller调用service。SpringCloud集成了Ribbon和Eureka，可以使用Feigin提供负载均衡的http客户端只需要创建一个接口，然后添加注解即可~Feign，主要是社区版，大家都习惯面向接口编程。这个是很多开发人员的规范。调用微服务访问两种方法微服务名字 【ribbon】接口和注解 【feign】Feign能干什么？Feign旨在使编写Java Http客户端变得更容易前面在使用Ribbon + RestTemplate时，利用RestTemplate对Http请求的封装处理，形成了一套模板化的调用方法。但是在实际开发中，由于对服务依赖的调用可能不止一处，往往一个接口会被多处调用，所以通常都会针对每个微服务自行封装一个客户端类来包装这些依赖服务的调用。所以，Feign在此基础上做了进一步的封装，由他来帮助我们定义和实现依赖服务接口的定义，在Feign的实现下，我们只需要创建一个接口并使用注解的方式来配置它 (类似以前Dao接口上标注Mapper注解，现在是一个微服务接口上面标注一个Feign注解)，即可完成对服务提供方的接口绑定，简化了使用Spring Cloud Ribbon 时，自动封装服务调用客户端的开发量。Feign默认集成了Ribbon利用Ribbon维护了MicroServiceCloud-Dept的服务列表信息，并且通过轮询实现了客户端的负载均衡，而与Ribbon不同的是，通过Feign只需要定义服务绑定接口且以声明式的方法，优雅而简单的实现了服务调用。Feign的使用步骤1、创建springcloud-consumer-fdept-feign模块拷贝springcloud-consumer-dept-80模块下的pom.xml，resource，以及java代码到springcloud-consumer-feign模块，并添加feign依赖。123456&lt;!--Feign的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;2、springcloud-api的pom.xml中也添加openfeign依赖123456&lt;!--Feign的依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;3、springcloud-api项目中创建service包创建DeptFeignService接口12345678910111213@Component@FeignClient(value = \"SPRINGCLOUD-PROVIDER-DEPT\")public interface DeptFeignService &#123; @GetMapping(\"/dept/get/&#123;id&#125;\") public Dept queryById(@PathVariable(\"id\") Integer id); @GetMapping(\"/dept/list\") public List&lt;Dept&gt; queryAll(); @PostMapping(\"/dept/add\") public Boolean addDept(Dept dept);&#125;4、修改springcloud-consumer-fdept-feign项目中的Controller去引用feign接口123456789101112131415161718192021@RestControllerpublic class DeptConsumerController &#123; @Autowired private DeptFeignService deptFeignService; @RequestMapping(\"/consumer/dept/add\") public Boolean add(Dept dept)&#123; return deptFeignService.addDept(dept); &#125; @RequestMapping(\"/consumer/dept/get/&#123;id&#125;\") public Dept get(@PathVariable(\"id\") Integer id)&#123; return deptFeignService.queryById(id); &#125; @RequestMapping(\"/consumer/dept/list\") public List&lt;Dept&gt; list()&#123; return deptFeignService.queryAll(); &#125;&#125;5、启动类1234567@SpringBootApplication@EnableFeignClientspublic class FeignDeptConsumer_80 &#123; public static void main(String[] args) &#123; SpringApplication.run(FeignDeptConsumer_80.class,args); &#125;&#125;6、启动全部项目除了原有80消费端123http://localhost/consumer/dept/get/2http://localhost/consumer/dept/list可以看到随机切换数据库，达到负载均衡7、切换轮询与随机负载均衡123456789101112131415161718192021@Configurationpublic class ConfigBean &#123; /** * IRule: * RoundRobinRule 轮询 * RandomRule 随机 * AvailabilityFilteringRule ： 会先过滤掉，跳闸，访问故障的服务~，对剩下的进行轮询~ * RetryRule ： 会先按照轮询获取服务~，如果服务获取失败，则会在指定的时间内进行，重试 */ @LoadBalanced //配置负载均衡实现RestTemplate @Bean public RestTemplate getRestTemplate()&#123; return new RestTemplate();//使用轮询规则 &#125; @Bean public IRule myRule()&#123; return new RandomRule();//使用随机规则 &#125;&#125;Hystrix：服务熔断分布式系统面临的问题复杂分布式体系结构中的应用程序有数十个依赖关系，每个依赖关系在某些时候将不可避免失败！服务雪崩多个微服务之间调用的时候，假设微服务A调用微服务B和微服务C，微服务B和微服务C又调用其他的微服务，这就是所谓的“扇出”，如果扇出的链路上某个微服务的调用响应时间过长，或者不可用，对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，所谓的“雪崩效应”。对于高流量的应用来说，单一的后端依赖可能会导致所有服务器上的所有资源都在几十秒内饱和。比失败更糟糕的是，这些应用程序还可能导致服务之间的延迟增加，备份队列，线程和其他系统资源紧张，导致整个系统发生更多的级联故障，这些都表示需要对故障和延迟进行隔离和管理，以便单个依赖关系的失败，不能取消整个应用程序或系统。我们需要，弃车保帅什么是Hystrix？Hystrix是一个应用于处理分布式系统的延迟和容错的开源库，在分布式系统里，许多依赖不可避免的会调用失败，比如超时，异常等，Hystrix能够保证在一个依赖出问题的情况下，不会导致整个体系服务失败，避免级联故障，以提高分布式系统的弹性。“断路器”本身是一种开关装置，当某个服务单元发生故障之后，通过断路器的故障监控 (类似熔断保险丝) ，向调用方方茴一个服务预期的，可处理的备选响应 (FallBack) ，而不是长时间的等待或者抛出调用方法无法处理的异常，这样就可以保证了服务调用方的线程不会被长时间，不必要的占用，从而避免了故障在分布式系统中的蔓延，乃至雪崩。Hystrix能干嘛？服务降级服务熔断服务限流接近实时的监控…服务熔断什么是服务熔断?熔断机制是赌赢雪崩效应的一种微服务链路保护机制。在微服务架构中，微服务之间的数据交互通过远程调用完成，微服务A调用微服务B和微服务C，微服务B和微服务C又调用其它的微服务，此时如果链路上某个微服务的调用响应时间过长或者不可用，那么对微服务A的调用就会占用越来越多的系统资源，进而引起系统崩溃，导致“雪崩效应”。服务熔断是应对雪崩效应的一种微服务链路保护机制。例如在高压电路中，如果某个地方的电压过高，熔断器就会熔断，对电路进行保护。同样，在微服务架构中，熔断机制也是起着类似的作用。当调用链路的某个微服务不可用或者响应时间太长时，会进行服务熔断，不再有该节点微服务的调用，快速返回错误的响应信息。当检测到该节点微服务调用响应正常后，恢复调用链路。当扇出链路的某个微服务不可用或者响应时间太长时，会进行服务的降级，进而熔断该节点微服务的调用，快速返回错误的响应信息。检测到该节点微服务调用响应正常后恢复调用链路。在SpringCloud框架里熔断机制通过Hystrix实现。Hystrix会监控微服务间调用的状况，当失败的调用到一定阀值缺省是5秒内20次调用失败，就会启动熔断机制。熔断机制的注解是：@HystrixCommand。服务熔断解决如下问题：当所依赖的对象不稳定时，能够起到快速失败的目的；快速失败后，能够根据一定的算法动态试探所依赖对象是否恢复。入门案例1、新建springcloud-provider-dept-hystrix-8001模块并拷贝springcloud-provider-dept–8001内的pom.xml、resource和Java代码进行初始化并调整。2、导入hystrix依赖123456&lt;!--导入Hystrix依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-hystrix&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt;&lt;/dependency&gt;3、调整yml配置文件123456789101112131415161718192021222324252627282930313233343536373839server: port: 8001# mybatis配置mybatis: # springcloud-api 模块下的pojo包 type-aliases-package: com.haust.springcloud.pojo # 本模块下的mybatis-config.xml核心配置文件类路径 config-location: classpath:mybatis/mybatis-config.xml # 本模块下的mapper配置文件类路径 mapper-locations: classpath:mybatis/mapper/*.xml# spring配置spring: application: #项目名 name: springcloud-provider-dept datasource: # 德鲁伊数据源 type: com.alibaba.druid.pool.DruidDataSource driver-class-name: com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/db01?useUnicode=true&amp;characterEncoding=utf-8 username: root password: root# Eureka配置：配置服务注册中心地址eureka: client: service-url: # 注册中心地址7001-7003 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springcloud-provider-dept-hystrix-8001 #修改Eureka上的默认描述信息 prefer-ip-address: true #改为true后默认显示的是ip地址而不再是localhost#info配置info: app.name: haust-springcloud #项目的名称 company.name: com.haust #公司的名称4、修改controller1234567891011121314151617181920212223242526//提供Restful服务@RestControllerpublic class DeptController &#123; @Autowired private DeptService deptService; @HystrixCommand(fallbackMethod = \"hystrixGet\")//如果根据id查询出现异常,走这段代码 @GetMapping(\"/dept/get/&#123;id&#125;\")//根据id查询 public Dept get(@PathVariable(\"id\") Long id)&#123; Dept dept = deptService.queryById(id); if (dept==null)&#123; throw new RuntimeException(\"这个id=&gt;\"+id+\",不存在该用户，或信息无法找到~\"); &#125; return dept; &#125; //根据id查询备选方案(熔断) public Dept hystrixGet(@PathVariable(\"id\") Long id)&#123; return new Dept().setDeptno(id) .setDname(\"这个id=&gt;\"+id+\",没有对应的信息,null---@Hystrix~\") .setDb_source(\"在MySQL中没有这个数据库\"); &#125;&#125;5、为主启动类添加对熔断的支持注解@EnableCircuitBreaker12345678@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到eureka中@EnableCircuitBreakerpublic class DeptHystrixProvider8001Main &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptHystrixProvider8001Main.class,args); &#125;&#125;6、测试不适用熔断,页面报错抛异常信息1\"java.lang.RuntimeException: 这个id=&gt;6,不存在该部门，或信息无法找到~\\r\\n\\tat cn.kgc... (5318 bytes)]使用熔断后，当访问一个不存在的id时，前台页展示数据如下1&#123;\"deptNo\":6,\"deptName\":\"这个id=&gt;6,没有对应的信息,null---@Hystrix~\",\"db_source\":\"在MySQL中没有这个数据库\"&#125;因此，为了避免因某个微服务后台出现异常或错误而导致整个应用或网页报错，使用熔断是必要的服务降级什么是服务降级?服务降级是指 当服务器压力剧增的情况下，根据实际业务情况及流量，对一些服务和页面有策略的不处理或换种简单的方式处理，从而释放服务器资源以保证核心业务正常运作或高效运作。说白了，就是尽可能的把系统资源让给优先级高的服务。资源有限，而请求是无限的。如果在并发高峰期，不做服务降级处理，一方面肯定会影响整体服务的性能，严重的话可能会导致宕机某些重要的服务不可用。所以，一般在高峰期，为了保证核心功能服务的可用性，都要对某些服务降级处理。比如当双11活动时，把交易无关的服务统统降级，如查看蚂蚁深林，查看历史订单等等。服务降级主要用于什么场景呢？当整个微服务架构整体的负载超出了预设的上限阈值或即将到来的流量预计将会超过预设的阈值时，为了保证重要或基本的服务能正常运行，可以将一些 不重要 或 不紧急 的服务或任务进行服务的 延迟使用 或 暂停使用。降级的方式可以根据业务来，可以延迟服务，比如延迟给用户增加积分，只是放到一个缓存中，等服务平稳之后再执行 ；或者在粒度范围内关闭服务，比如关闭相关文章的推荐当某一时间内服务A的访问量暴增，而B和C的访问量较少，为了缓解A服务的压力，这时候需要B和C暂时关闭一些服务功能，去承担A的部分服务，从而为A分担压力，叫做服务降级。服务降级需要考虑的问题那些服务是核心服务，哪些服务是非核心服务那些服务可以支持降级，那些服务不能支持降级，降级策略是什么除服务降级之外是否存在更复杂的业务放通场景，策略是什么？自动降级分类超时降级：主要配置好超时时间和超时重试次数和机制，并使用异步机制探测回复情况失败次数降级：主要是一些不稳定的api，当失败调用次数达到一定阀值自动降级，同样要使用异步机制探测回复情况故障降级：比如要调用的远程服务挂掉了（网络故障、DNS故障、http服务返回错误的状态码、rpc服务抛出异常），则可以直接降级。降级后的处理方案有：默认值（比如库存服务挂了，返回默认现货）、兜底数据（比如广告挂了，返回提前准备好的一些静态页面）、缓存（之前暂存的一些缓存数据）限流降级：秒杀或者抢购一些限购商品时，此时可能会因为访问量太大而导致系统崩溃，此时会使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级；降级后的处理方案可以是：排队页面（将用户导流到排队页面等一会重试）、无货（直接告知用户没货了）、错误页（如活动太火爆了，稍后重试）。入门案例1、在springcloud-api模块下的service包中新建降级配置类DeptClientServiceFallBackFactory.java1234567891011121314151617181920212223242526@Componentpublic class DeptClientServiceFallBackFactory implements FallbackFactory &#123; @Override public DeptFeignService create(Throwable throwable) &#123; return new DeptFeignService() &#123; @Override public Dept queryById(Integer id) &#123; return new Dept() .setDeptNo(id) .setDeptName(\"id=&gt;\" + id + \"没有对应的信息，客户端提供了降级的信息，这个服务现在已经被关闭\") .setDb_source(\"没有数据~\"); &#125; @Override public List&lt;Dept&gt; queryAll() &#123; return null; &#125; @Override public Boolean addDept(Dept dept) &#123; return false; &#125; &#125;; &#125;&#125;2、在DeptFeignService中指定降级配置类DeptFeiGnServiceFallBackFactory1234567891011121314@Component //注册到spring容器中//@FeignClient:微服务客户端注解,value:指定微服务的名字,这样就可以使Feign客户端直接找到对应的微服务@FeignClient(value = \"SPRINGCLOUD-PROVIDER-DEPT\",fallbackFactory = DeptClientServiceFallBackFactory.class)//fallbackFactory指定降级配置类public interface DeptFeignService &#123; @GetMapping(\"/dept/get/&#123;id&#125;\") public Dept queryById(@PathVariable(\"id\") Long id); @GetMapping(\"/dept/list\") public List&lt;Dept&gt; queryAll(); @GetMapping(\"/dept/add\") public Boolean addDept(Dept dept);&#125;3、在springcloud-consumer-dept-feign模块中开启降级1234567891011121314server: port: 80# Eureka配置eureka: client: register-with-eureka: false # 不向 Eureka注册自己 service-url: # 从三个注册中心中随机取一个去访问 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/# 开启降级feign.hystrixfeign: hystrix: enabled: true4、测试(启动7001服务，feigen80服务和8001提供服务)1234如果项目正常启动中，那么浏览http://localhost/consumer/dept/get/1得到：&#123;\"deptNo\":1,\"deptName\":\"开发部\",\"db_source\":\"scdb01\"&#125;如果人为的去停掉8001服务，那么浏览http://localhost/consumer/dept/get/1得到：&#123;\"deptNo\":1,\"deptName\":\"id=&gt;1没有对应的信息，客户端提供了降级的信息，这个服务现在已经被关闭\",\"db_source\":\"没有数据~\"&#125;服务熔断和降级的区别​服务熔断—&gt;服务端：某个服务超时或异常，引起熔断~，类似于保险丝(自我熔断)服务降级—&gt;客户端：从整体网站请求负载考虑，当某个服务熔断或者关闭之后，服务将不再被调用，此时在客户端，我们可以准备一个 FallBackFactory ，返回一个默认的值(缺省值)。会导致整体的服务下降，但是好歹能用，比直接挂掉强。​触发原因不太一样，服务熔断一般是某个服务（下游服务）故障引起，而服务降级一般是从整体负荷考虑；​管理目标的层次不太一样，熔断其实是一个框架级的处理，每个微服务都需要（无层级之分），而降级一般需要对业务有层级之分（比如降级一般是从最外围服务开始）​实现方式不太一样，服务降级具有代码侵入性(由控制器完成/或自动降级)，熔断一般称为自我熔断。限流：限制并发的请求访问量，超过阈值则拒绝；降级：服务分优先级，牺牲非核心服务（不可用），保证核心服务稳定；从整体负荷考虑；熔断：依赖的下游服务故障触发熔断，避免引发本系统崩溃；系统自动执行和恢复Dashboard 流监控1、新建springcloud-consumer-hystrix-dashboard模块2、添加依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;dependencies&gt; &lt;!--导入Hystrix依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--dashboard依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Feign的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Ribbon--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--实体类+web--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;3、配置端口application.yml1234567891011121314server: port: 9001# Eureka配置eureka: client: register-with-eureka: false # 不向 Eureka注册自己 service-url: # 从三个注册中心中随机取一个去访问 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/# 开启降级feign.hystrixfeign: hystrix: enabled: true4、主启动类123456789@SpringBootApplication//开启Dashboard@EnableHystrixDashboard@EnableFeignClientspublic class DeptConsumerDashboard_9001 &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptConsumerDashboard_9001.class,args); &#125;&#125;5、给springcloud-provider-dept-hystrix-8001模块下的主启动类添加如下代码,添加监控导入依赖hystrix123456&lt;!--导入Hystrix依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;12345678910111213141516171819@SpringBootApplication@EnableEurekaClient //EnableEurekaClient 客户端的启动类，在服务启动后自动向注册中心注册服务@EnableDiscoveryClient //服务发现@EnableCircuitBreakerpublic class DeptHystrixProvider8001Main &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptHystrixProvider8001Main.class,args); &#125; //增加一个 Servlet @Bean public ServletRegistrationBean hystrixMetricsStreamServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new HystrixMetricsStreamServlet()); //访问该页面就是监控页面 registrationBean.addUrlMappings(\"/actuator/hystrix.stream\"); return registrationBean; &#125;&#125;5、测试12345浏览：http://localhost:8001/actuator/hystrix.stream 看是否能ping到数据监控仪表盘页面：http://localhost:9001/hystrix 输入http://localhost:8001/actuator/hystrix.stream网址 点击Monitor Stream --显示项目监控仪表盘 浏览：http://localhost:8001/dept/get/5--看是否有变化--不断刷新可看到仪表盘中圆变大，心跳加快Zuul路由网关什么是zuul?Zull包含了对请求的路由(用来跳转的)和过滤两个最主要功能：其中路由功能负责将外部请求转发到具体的微服务实例上，是实现外部访问统一入口的基础，而过滤器功能则负责对请求的处理过程进行干预，是实现请求校验，服务聚合等功能的基础。Zuul和Eureka进行整合，将Zuul自身注册为Eureka服务治理下的应用，同时从Eureka中获得其他服务的消息，也即以后的访问微服务都是通过Zuul跳转后获得。​注意：Zuul服务最终还是会注册进Eureka​提供：代理+路由+过滤 三大功能！​Zuul能干嘛？验证与安全保障: 识别面向各类资源的验证要求并拒绝那些与要求不符的请求。审查与监控: 在边缘位置追踪有意义数据及统计结果，从而为我们带来准确的生产状态结论。动态路由: 以动态方式根据需要将请求路由至不同后端集群处。压力测试: 逐渐增加指向集群的负载流量，从而计算性能水平。负载分配: 为每一种负载类型分配对应容量，并弃用超出限定值的请求。静态响应处理: 在边缘位置直接建立部分响应，从而避免其流入内部集群。多区域弹性: 跨越AWS区域进行请求路由，旨在实现ELB使用多样化并保证边缘位置与使用者尽可能接近。入门案例1、新建springcloud-zuul模块，并导入依赖1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;dependencies&gt; &lt;!--导入zuul依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;version&gt;1.4.6.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--导入Hystrix依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--dashboard依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Ribbon--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-ribbon&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Eureka: Ribbon需要从Eureka服务中心获取要拿什么--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--实体类+web--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;2、application.yml1234567891011121314151617181920212223242526server: port: 9527spring: application: name: springcloud-zuul #微服务名称eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: #实例的id instance-id: zuul9527.com prefer-ip-address: true # 显示ipinfo: app.name: haust.springcloud #项目名称 company.name: haust #公司名称zuul: prefix: /king # 设置公共的前缀,实现隐藏原有路由 routes: mydept: path: /mydept/** service-id: springcloud-provider-dept ignored-services: \"*\" # 不向外界暴露出你配置的隐射之外的服务~,项目名访问不到数据king/springcloud-provider-dept/dept/get/2，必须用mydept3、添加网址信息（可选）12c:windows/system32/drivers/etc/hosts末尾添加172.0.0.1 www.kingqing.com4、主启动类1234567@SpringBootApplication@EnableZuulProxy //开启Zuulpublic class ZuulApplication_9527 &#123; public static void main(String[] args) &#123; SpringApplication.run(ZuulApplication_9527.class,args); &#125;&#125;5、测试1234启动7001注册服务中心，启动dept-hystrix-8001待熔断的服务，启动网关zuul服务1、访问http://eureka7001.com:7001/可以看到有两个服务注册进eureka中；2、访问http://localhost:8001/dept/get/3，可以拿到数据信息3、访问http://www.kingqing.com:9527/king/mydept/dept/get/3，也可以拿到数据，避免了暴露真实的微服务名称及端口，而http://www.kingqing.com:9527/king/springcloud-provider-dept/dept/get/2用服务名查询不到数据Spring Cloud Config 分布式配置Dalston.RELEASE​Spring Cloud Config为分布式系统中的外部配置提供服务器和客户端支持。使用Config Server，您可以在所有环境中管理应用程序的外部属性。客户端和服务器上的概念映射与Spring Environment和PropertySource抽象相同，因此它们与Spring应用程序非常契合，但可以与任何以任何语言运行的应用程序一起使用。随着应用程序通过从开发人员到测试和生产的部署流程，您可以管理这些环境之间的配置，并确定应用程序具有迁移时需要运行的一切。服务器存储后端的默认实现使用git，因此它轻松支持标签版本的配置环境，以及可以访问用于管理内容的各种工具。很容易添加替代实现，并使用Spring配置将其插入。概述分布式系统面临的–配置文件问题​微服务意味着要将单体应用中的业务拆分成一个个子服务，每个服务的粒度相对较小，因此系统中会出现大量的服务，由于每个服务都需要必要的配置信息才能运行，所以一套集中式的，动态的配置管理设施是必不可少的。spring cloud提供了configServer来解决这个问题，我们每一个微服务自己带着一个application.yml，那上百个的配置文件修改起来，令人头疼！什么是SpringCloud config分布式配置中心？spring cloud config 为微服务架构中的微服务提供集中化的外部支持，配置服务器为各个不同微服务应用的所有环节提供了一个中心化的外部配置。spring cloud config 分为服务端和客户端两部分。服务端也称为 分布式配置中心，它是一个独立的微服务应用，用来连接配置服务器并为客户端提供获取配置信息，加密，解密信息等访问接口。客户端则是通过指定的配置中心来管理应用资源，以及与业务相关的配置内容，并在启动的时候从配置中心获取和加载配置信息。配置服务器默认采用git来存储配置信息，这样就有助于对环境配置进行版本管理。并且可用通过git客户端工具来方便的管理和访问配置内容。spring cloud config 分布式配置中心能干嘛？集中式管理配置文件不同环境，不同配置，动态化的配置更新，分环境部署，比如 /dev /test /prod /beta /release运行期间动态调整配置，不再需要在每个服务部署的机器上编写配置文件，服务会向配置中心统一拉取配置自己的信息.当配置发生变动时，服务不需要重启，即可感知到配置的变化，并应用新的配置将配置信息以REST接口的形式暴露.spring cloud config 分布式配置中心与GitHub整合由于spring cloud config 默认使用git来存储配置文件 (也有其他方式，比如自持SVN 和本地文件)，但是最推荐的还是git ，而且使用的是 http / https 访问的形式。gitee的使用(码云)1、访问https://gitee.com/，注册账户2、创建远程仓库登入Gitee后，点击头像旁边的”+”加号–&gt;新建仓库；创库名称：springcloud-config仓库介绍：随意是否公开：公开语言：java添加.gitignore:java添加开源许可证：GPL-3.0勾选-使用Readme文件初始化这个仓库选择分支模型：但分支模型(只创建master分支)点击创建3、获取SSHKey首先要在本地创建一个ssh key 这个的目的就是你现在需要在你电脑上获得一个密匙。按如下命令来生成sshkey:1234$ ssh-keygen -t rsa -C \"417496479@qq.com\" # Generating public/private rsa key pair...# 三次回车即可生成 ssh key查看你的public key：12$ cat ~/.ssh/id_rsa.pub# ssh-rsa AAAAB3NzaC1yc2E... youremail@youremail.com并把他添加到Gitee123设置--安全设置子项SSh公钥标题：随意公钥：粘贴上一步得到的，ssh-rsa……代码，添加后，在终端中输入12345#Gitee$ ssh -T git@gitee.com#GitHub$ ssh -T git@github.com第一次绑定的时候输入上边的代码之后会提示是否continue,输入yes后程序会自动连接，如果要求登录，直接输入登录信息即可。再次执行上面的命令，检查是否成功连接，如果返回一下信息，则表示添加成功1Hi 冰糖葫芦娃! You've successfully authenticated, but GITEE.COM does not provide shell access.4、设置基本信息12$ git config --global user.name \"yourname\"$ git config --global user.email \"youremail@youremail.com\"name尽量和码云或GitHub保持一致，但email必须是码云或GitHub注册时使用的邮箱。命令不分前后，没有顺序。查看设计的信息12$ git config --list #可以查看用户名以及邮箱信息5、初始化本地库然后就是将你的远程仓库克隆到本地，或者你可以在本地初始化一个项目后再进行云端绑定。12345678#Gitee$ git clone https://gitee.com/yourname/repository#Github$ git clone https://github.com/yourname/repository.git#yourname 您在码云或github注册的用户名#repository 您创建的远程仓库名称成功将把gitee上的仓库下载到本机6、测试本机配置修改上传到gitee上在下载好的项目里创建文件application.yml123456789101112131415spring: profiles: active: dev ---spring: profiles: dev application: name: springcloud-config-dev ---spring: profiles: test application: name: springcloud-config-test将添加的application.yml提交到gittee上1234567891、将文件添加到暂存区$ git add . # .代表所有2、查看状态$ git status # 显示 new file: application.yml3、本地提交$ git commit -m \"第一次提交\"4、push到远程$ git push origin master成功将文件同步到gitee上入门案例服务端1、新建springcloud-config-server-3344模块导入pom.xml依赖123456789101112131415161718 &lt;dependencies&gt; &lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--完善监控信息--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;3、resource下创建application.yml配置文件，Spring Cloud Config服务器从git存储库（必须提供）为远程客户端提供配置：1234567891011121314server: port: 3344spring: application: name: springcloud-config-server # 连接码云远程仓库 cloud: config: server: git: #注意是https的而不是ssh uri: https://gitee.com/cao_shi_peng/springcloud-config.git # 通过 config-server可以连接到git，访问其中的资源以及配置~4、主启动类1234567@EnableConfigServer //开启spring cloud config server服务@SpringBootApplicationpublic class Config_server_3344 &#123; public static void main(String[] args) &#123; SpringApplication.run(Config_server_3344.class,args); &#125;&#125;5、测试1234567891011121314访问http://localhost:3344/application-dev.yml获取信息为： spring: application: name: springcloud-config-dev profiles: active: dev访问http://localhost:3344/application-test.yml获取信息为： spring: application: name: springcloud-config-test profiles: active: dev服务端搞定了客户端1、将本地git仓库springcloud-config文件夹下新建的configclient.yml提交到码云仓库：123456789101112131415161718192021222324252627282930313233spring: profiles: active: dev---server: port: 8201spring: profiles: dev application: name: springcloud-provider-dept#Eureka的配置，服务注册到哪里eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/ ---server: port: 8202spring: profiles: test application: name: springcloud-provider-dept#Eureka的配置，服务注册到哪里eureka: client: service-url: defaultZone: http://eureka7001.com:7001/eureka/push到远程1234$ git add .$ gir status #查看状态$ git commit -m \"抵四次提交\" #提交到本地仓库$ git push origin master #提交到远程库2、新建一个springcloud-config-client-3355模块，并导入依赖12345678910111213141516&lt;dependencies&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt;3、resources下创建application.yml和bootstrap.yml配置文件bootstrap.yml是系统级别的配置12345678# 系统级别的配置（服务连接远程仓库那东西）spring: cloud: config: name: configclient # 需要从git上读取的资源名称，不要后缀 profile: dev #需要哪个环境 label: master #从哪个分支拿 uri: http://localhost:3344application.yml是用户级别的配置1234# 用户级别的配置（客户端连接服务器拿东西）spring: application: name: springcloud-config-client4、启动类123456@SpringBootApplicationpublic class ConfigClient &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigClient.class,args); &#125;&#125;5、创建controller包下的ConfigClientController.java用于测试12345678910111213141516@RestControllerpublic class ConfigClientController &#123; @Value(\"$&#123;spring.application.name&#125;\") private String applicationName; @Value(\"$&#123;eureka.client.service-url.defaultZone&#125;\") private String eurekaServer; @Value(\"$&#123;server.port&#125;\") private String port; @RequestMapping(\"/config\") public String getConfig()&#123; return \"applicationName:\"+applicationName+ \",eurekaServer\"+eurekaServer+ \",port\"+port; &#125;&#125;6、测试启动 config-server-3344项目，启动config-client-3355项目首先http://localhost:3344/master/configclient-dev.yml这个可以拿到数据；其次http://localhost:8201/config；可以拿到数据1234applicationName:springcloud-config- dev,eurekaServer:http://eureka7001.com:7001/eureka/,port:8201``` 将本地系统级别配置bootstrap.yml中的profile设置为test--》此时`http://localhost:8201/config`将访问不到任何数据，而`http://localhost:8202/config`可以读取到数据：applicationName:springcloud-config-test,eurekaServer:http://eureka7001.com:7001/eureka/,port:820212345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273**7、小案例**1、本地新建config-dept.yml和config-eureka.yml并提交到码云仓库config-eureka.yml```ymlspring: profiles: active: dev---server: port: 7001 spring: profiles: dev application: name: springcloud-provider-eureka eureka: instance: hostname: eureka7001.com # Eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向注册中心注册自己 fetch-registry: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: # 单击-设置与 Eureka Server 交互的地址查询服务和注册服务都需要依赖这个地址 #defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群-关联，挂载7002和7003 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ ---server: port: 7001 spring: profiles: pro application: name: springcloud-provider-depteureka: instance: hostname: eureka7001.com # Eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向注册中心注册自己 fetch-registry: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: # 单击-设置与 Eureka Server 交互的地址查询服务和注册服务都需要依赖这个地址 #defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群-关联，挂载7002和7003 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/---server: port: 7001 spring: profiles: test application: name: springcloud-provider-eureka eureka: instance: hostname: eureka7001.com # Eureka 服务端的实例名称 client: register-with-eureka: false # false 表示不向注册中心注册自己 fetch-registry: false # false 表示自己端就是注册中心，职责就是维护服务实例，并不需要去检索服务 service-url: # 单击-设置与 Eureka Server 交互的地址查询服务和注册服务都需要依赖这个地址 #defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ # 集群-关联，挂载7002和7003 defaultZone: http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/push到远程1234$ git add .$ gir status #查看状态$ git commit -m \"抵四次提交\" #提交到本地仓库$ git push origin master #提交到远程库2、新建springcloud-config-eureka-7001模块，并将原来的springcloud-eureka-7001模块下的内容拷贝的该模块。新建bootstrap.yml连接远程配置1234567spring: cloud: config: name: config-eureka # 仓库中的配置文件名称 label: master profile: dev uri: http://localhost:3344application.yml配置123spring: application: name: config-eureka在pom.xml中添加spring cloud config依赖123456&lt;!--config--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt;&lt;/dependency&gt;3、主启动类1234567@SpringBootApplication@EnableEurekaServer //EnableEurekaServer 服务端的启动类，可以接受别人注册进来~public class ConfigEurekaServer_7001 &#123; public static void main(String[] args) &#123; SpringApplication.run(ConfigEurekaServer_7001.class,args); &#125;&#125;4、测试第一步：启动 Config_Server_3344，并访问 http://localhost:3344/master/config-eureka-dev.yml 测试第二部：启动ConfigEurekaServer_7001，访问 http://localhost:7001/ 测试5、新建springcloud-config-dept-8001模块并拷贝springcloud-provider-dept-8001的内容同理导入spring cloud config依赖、清空application.yml 、新建bootstrap.yml配置文件并配置pom.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;parent&gt; &lt;artifactId&gt;ksspringcloud&lt;/artifactId&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;artifactId&gt;springcloud-config-dept-8001&lt;/artifactId&gt; &lt;dependencies&gt; &lt;!--config--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--导入Hystrix依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--dashboard依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--Eureka--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;version&gt;2.2.2.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!--完善监控信息--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--我们需要拿到实体类，所以要配置咱们的api module--&gt; &lt;dependency&gt; &lt;groupId&gt;cn.kgc&lt;/groupId&gt; &lt;artifactId&gt;springcloud-api&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;!--测试--&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--数据库--&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--数据源--&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--jetty--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--热部署工具--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;新建config-dept-yml并上传到git上123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475spring: profiles: active: dev---server: port: 8001spring: profiles: dev application: name: springcloud-config-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver #org.gjt.mm.mysql.Driver或者com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/scdb03?useSSL=false&amp;characterEncoding=utf8&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true username: root password: 123456#mybatis配置mybatis: type-aliases-package: cn.kgc.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xml#Eureka的配置，服务注册到哪里eureka: client: service-url: # 发布到集群，三个eureka注册中心 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springboot-provader-dept8001#info配置info: app-name: kuangshen-springcloud company.name: blog.kuangstudy.com --- server: port: 8001spring: profiles: test application: name: springcloud-config-dept datasource: type: com.alibaba.druid.pool.DruidDataSource driver-class-name: org.gjt.mm.mysql.Driver #org.gjt.mm.mysql.Driver或者com.mysql.jdbc.Driver url: jdbc:mysql://localhost:3306/scdb02?useSSL=false&amp;characterEncoding=utf8&amp;serverTimezone=GMT%2B8&amp;allowPublicKeyRetrieval=true username: root password: 123456#mybatis配置mybatis: type-aliases-package: cn.kgc.pojo config-location: classpath:mybatis/mybatis-config.xml mapper-locations: classpath:mybatis/mapper/*.xml#Eureka的配置，服务注册到哪里eureka: client: service-url: # 发布到集群，三个eureka注册中心 defaultZone: http://eureka7001.com:7001/eureka/,http://eureka7002.com:7002/eureka/,http://eureka7003.com:7003/eureka/ instance: instance-id: springboot-provader-dept8001#info配置info: app-name: kuangshen-springcloud company.name: blog.kuangstudy.combootstrap.yml1234567spring: cloud: config: name: config-dept # 仓库中的配置文件名称 label: master profile: dev uri: http://localhost:3344application.yml123spring: application: name: springcloud-config-dept-80016、主启动123456789@SpringBootApplication@EnableEurekaClient //在服务启动后自动注册到eureka中@EnableDiscoveryClient //服务发现@EnableCircuitBreakerpublic class DeptProvider8001Main &#123; public static void main(String[] args) &#123; SpringApplication.run(DeptProvider8001Main.class,args); &#125;&#125;7、启动项目测试12345678910111213http://localhost:3344/config-dept-dev.yml，http://localhost:3344/config-dept-test.yml分别能读取到配置的两个环境 http://localhost:7001/ 读取到客户端以启动：Application AMIs Availability Zones StatusSPRINGCLOUD-CONFIG-DEPT n/a (1) (1) UP (1) - springboot-provader-dept8001http://localhost:8001/dept/get/4 能读取到配置中的test环境&#123;\"deptNo\":4,\"deptName\":\"市场部\",\"db_source\":\"scdb02\"&#125;--&gt;从数据库scdb02获取的信息如果把客户端的bootstrap.yml中的profile：改成dev并重新启动客户端（或者热部署--&gt;启动类--Build--build module ******）http://localhost:8001/dept/get/4 能读取到配置中的dev环境 &#123;\"deptNo\":4,\"deptName\":\"市场部\",\"db_source\":\"scdb03\"&#125;--&gt;从数据库scdb03获取的信息","categories":[{"name":"Spring","slug":"Spring","permalink":"https://me.obey.fun/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://me.obey.fun/categories/Spring/SpringCloud/"},{"name":"REST API","slug":"Spring/SpringCloud/REST-API","permalink":"https://me.obey.fun/categories/Spring/SpringCloud/REST-API/"}],"tags":[{"name":"微服务","slug":"微服务","permalink":"https://me.obey.fun/tags/微服务/"},{"name":"REST","slug":"REST","permalink":"https://me.obey.fun/tags/REST/"}],"keywords":[{"name":"Spring","slug":"Spring","permalink":"https://me.obey.fun/categories/Spring/"},{"name":"SpringCloud","slug":"Spring/SpringCloud","permalink":"https://me.obey.fun/categories/Spring/SpringCloud/"},{"name":"REST API","slug":"Spring/SpringCloud/REST-API","permalink":"https://me.obey.fun/categories/Spring/SpringCloud/REST-API/"}]},{"title":"ElasticSearch7.x简单使用","slug":"ElasticSearch7-x简单使用","date":"2020-04-18T01:39:44.000Z","updated":"2020-04-21T07:43:16.000Z","comments":true,"path":"ElasticSearch7-x简单使用.html","link":"","permalink":"https://me.obey.fun/ElasticSearch7-x简单使用.html","excerpt":"","text":"ElasticSearch7.6.x什么是ElasticSearch？Elasticsearch是一个基于Lucene的搜索服务器。它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。Elasticsearch是用Java语言开发的，并作为Apache许可条款下的开放源码发布，是一种流行的企业级搜索引擎。ES的基本概念对比于现有的关系型数据库去学习Relational DBElasticsearch数据库（database）索引（indices）表（tables）类型（types）行（rows）文档(document)字段（columns）字段（fields）Restful风格：methodurl地址描述PUTlocalhost:9200/indices/types/document_ID创建文档（指定ID）POSTlocalhost:9200/indices/types创建文档（随机ID）POSTlocalhost:9200/indices/types/document_ID/_update修改文档DELETElocalhost:9200/indices/types/document_ID删除文档GETlocalhost:9200/indices/types/document_ID通过ID查询文档POSTlocalhost:9200/indices/types/_search查询所有的文档indices：n. 指数；目录（index的复数）基础测试：12PUT /test01/_doc/2&#123; &#125;请求头+请求体关于索引的操作创建索引1234PUT /indices/types/document_ID&#123;&#125;数据类型：FieldType字符串类型text 、 keyword数值类型long, integer, short, byte, double,float,half_float, scaled_float日期类型date布尔值类型boolean二进制类型binary指定字段的类型12345678910111213141516PUT /test01&#123; \"mappings\": &#123; \"properties\": &#123; \"name\":&#123; \"type\": \"text\" &#125;, \"age\":&#123; \"type\": \"integer\" &#125;, \"birthday\":&#123; \"type\": \"date\" &#125; &#125; &#125;&#125;可以通过 GET 请求获取具体的信息！1GET indicesget _cat/ 可以获得es的当前的很多信息1GET _cat/indices?v更新数据put1234put /indices/types/document_ID&#123; \"name\":\"summer\"&#125;POST _update123456POST /indices/types/document_ID/_update&#123; \"doc\":&#123; \"name\":\"summer\" &#125;&#125;put 的方法只是简单的覆盖而已，后面加_update只会修改修改的数据。删除索引123DELETE /indicesDELETE /indices/_doc/DELETE /indices/_doc/document_ID关于文档的基本操作基本操作：添加数据1234567PUT /summer/user/1&#123; \"name\":\"summer\", \"age\":\"22\", \"desc\":\"学java很开心\", \"tags\":[\"帅哥\",\"暖男\",\"666\"]&#125;修改内容put1234put /indices/types/document_ID&#123; \"name\":\"summer\"&#125;POST _update123456POST /indices/types/document_ID/_update&#123; \"doc\":&#123; \"name\":\"summer\" &#125;&#125;简单地搜索！1GET /summer/user/_search?q=name:summer条件：1q=name:summer复杂操作搜索查找12345678GET /summer/user/_search&#123; \"query\": &#123; \"match\": &#123; \"name\": \"summer\" &#125; &#125;&#125;查出来的结果：我们发现我们的结果在hits中，想要的信息在hits中的hits中n. 击打；网页点击数；采样数（hit的复数）限制只显示哪个字段select name,age from user ;123456789GET /summer/user/_search&#123; \"query\": &#123; \"match\": &#123; \"desc\":\"学java很开心\" &#125; &#125;, \"_source\": [\"name\",\"age\"]&#125;排序select * from user ORDER BY age;123456789101112131415GET /summer/user/_search&#123; \"query\": &#123; \"match\": &#123; \"desc\":\"学java很开心\" &#125; &#125;, \"sort\": [ &#123; \"age\": &#123; \"order\": \"desc\" &#125; &#125; ]&#125;分页 from sizeselect * from user limit from ,size ;1234567891011GET /summer/user/_search&#123; \"query\": &#123; \"match\": &#123; \"desc\":\"学java很开心\" &#125; &#125;, \"_source\": [\"name\",\"age\"], \"from\": 0, \"size\": 2&#125;布尔值查询bool 就是SQL语句中的wheremust:select * from user where name = ‘summer’ and desc = ‘学java很开心’12345678910111213141516171819GET /summer/user/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"match\": &#123; \"name\":\"summer\" &#125; &#125;, &#123; \"match\": &#123; \"desc\":\"学java很开心\" &#125; &#125; ] &#125; &#125;&#125;should:select * from user where name = ‘summer’ or desc = ‘学java很开心’12345678910111213141516171819GET /summer/user/_search&#123; \"query\": &#123; \"bool\": &#123; \"should\": [ &#123; \"match\": &#123; \"name\":\"summer\" &#125; &#125;, &#123; \"match\": &#123; \"desc\":\"学java很开心\" &#125; &#125; ] &#125; &#125;&#125;must_notselect * from user where not name = ‘summer’1234567891011121314GET /summer/user/_search&#123; \"query\": &#123; \"bool\": &#123; \"must_not\": [ &#123; \"match\": &#123; \"name\":\"summer\" &#125; &#125; ] &#125; &#125;&#125;过滤器 filter12345678910111213141516171819GET /summer/user/_search&#123; \"query\": &#123; \"bool\": &#123; \"must\": [ &#123; \"name\":\"summer\" &#125; ] , \"filter\": &#123; \"range\": &#123; \"age\": &#123; \"gte\": 10, \"lte\": 20 &#125; &#125; &#125; &#125;&#125;匹配多个条件12345678GET /summer/user/_search&#123; \"query\": &#123; \"match\": &#123; \"tags\": \"暖男 高中生\" &#125; &#125;&#125;精确查询关于分词：term ：直接查询精确的match：会使用分词器解析！（先分析文档，然后在通过分析的文档进行查询！）12345678GET /summer/user/_search&#123; \"query\": &#123; \"term\": &#123; \"name\":\"summer\" &#125; &#125;&#125;高亮查询12345678910111213GET /summer/user/_search&#123; \"query\": &#123; \"match\": &#123; \"name\":\"summer\" &#125; &#125; , \"highlight\": &#123; \"fields\": &#123; \"name\":&#123;&#125; &#125; &#125;&#125;集成springboot原生依赖导入12345&lt;dependency&gt; &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt; &lt;artifactId&gt;elasticsearch-rest-high-level-client&lt;/artifactId&gt; &lt;version&gt;7.6.2&lt;/version&gt;&lt;/dependency&gt;注：如果在创建springboot时直接选择了elasticsearch，就需要去springboot中去修改版本，因为springboot中默认的是6.X12345&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;!--自定义版本--&gt; &lt;elasticsearch.version&gt;7.6.1&lt;/elasticsearch.version&gt;&lt;/properties&gt;自定义一下版本。将elasticsearch核心类配置进入springboot中123456789@Configurationpublic class ElasticSearchConfig &#123; @Bean public RestHighLevelClient restHighLevelClient()&#123; return new RestHighLevelClient(RestClient.builder(new HttpHost(\"127.0.01\",9200,\"http\"))); &#125;&#125;测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127package com.summer;@SpringBootTestclass SpringbootEsApiApplicationTests &#123; @Autowired @Qualifier(\"restHighLevelClient\") private RestHighLevelClient client; @Test void contextLoads() throws IOException &#123; CreateIndexRequest request = new CreateIndexRequest(\"summer_002\"); CreateIndexResponse response = client.indices().create(request, RequestOptions.DEFAULT); System.out.println(response); &#125; // 测试获取索引,判断其是否存在 @Test void TestExistIndex() throws IOException &#123; GetIndexRequest request = new GetIndexRequest(\"summer_001\"); boolean exists = client.indices().exists(request, RequestOptions.DEFAULT); System.out.println(exists); &#125; // 测试删除索引 @Test void TestDeleteIndex() throws IOException &#123; DeleteIndexRequest request = new DeleteIndexRequest(\"summer_001\"); AcknowledgedResponse delete = client.indices().delete(request, RequestOptions.DEFAULT); System.out.println(delete); &#125; // 测试添加文档 @Test void TestAddDocument() throws IOException &#123; //创建对象 User user = new User(\"summer\",20); //创建请求 IndexRequest request = new IndexRequest(\"summer_002\"); //规则 /summer_02/_doc/1 request.id(\"1\"); request.timeout(\"1s\"); // 将数据放入请求中 request.source(JSON.toJSONString(user), XContentType.JSON); //客户端发送请求 IndexResponse index = client.index(request, RequestOptions.DEFAULT); //查看结果 System.out.println(index.toString()); System.out.println(index.status()); &#125; // 获得文档的信息 @Test void testGetDocument() throws IOException &#123; //创建get请求 GetRequest getRequest = new GetRequest(\"summer_002\",\"1\"); //执行命令 客户端发送，获得结果 GetResponse documentFields = client.get(getRequest, RequestOptions.DEFAULT); //打印结果 System.out.println(documentFields); System.out.println(documentFields.getSourceAsString()); &#125; // 更新文档的信息 @Test void testUpdateDocument() throws IOException &#123; //创建请求 UpdateRequest updateRequest = new UpdateRequest(\"summer_002\",\"1\"); User user = new User(\"pppnut\",22); UpdateRequest doc = updateRequest.doc(JSON.toJSONString(user), XContentType.JSON); UpdateResponse update = client.update(doc, RequestOptions.DEFAULT); System.out.println(update); System.out.println(update.status()); &#125; // 删除文档记录 @Test void testDeleteDocument() throws IOException &#123; DeleteRequest deleteRequest = new DeleteRequest(\"summer_002\",\"1\"); DeleteResponse delete = client.delete(deleteRequest, RequestOptions.DEFAULT); System.out.println(delete); System.out.println(delete.status()); &#125; // 特殊的，真的项目一般都会批量插入数据！ @Test void testBulkRequest() throws IOException &#123; BulkRequest bulkRequest = new BulkRequest(); ArrayList&lt;User&gt; users = new ArrayList&lt;&gt;(); for (int i = 10; i &lt; 22; i++) &#123; users.add(new User(\"summer\"+i,i)); &#125; for (int i = 0; i &lt; users.size(); i++) &#123; bulkRequest.add( new IndexRequest(\"summer_002\") .source(JSON.toJSONString(users.get(i)),XContentType.JSON)); &#125; bulkRequest.timeout(\"10S\"); BulkResponse bulk = client.bulk(bulkRequest, RequestOptions.DEFAULT); System.out.println(bulk); System.out.println(bulk.status()); &#125; // 查询 // SearchRequest 搜索请求 // SearchSourceBuilder 条件构造 // HighlightBuilder 构建高亮 // TermQueryBuilder 精确查询 // MatchAllQueryBuilder // xxx QueryBuilder 对应我们刚才看到的命令！ @Test void SearchRequest() throws IOException &#123; SearchRequest searchRequest = new SearchRequest(\"summer_002\"); SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"name\", \"summer\"); // MatchAllQueryBuilder matchAllQueryBuilder = QueryBuilders.matchAllQuery(); SearchSourceBuilder query = sourceBuilder.query(termQueryBuilder); SearchRequest source = searchRequest.source(query); SearchResponse searchResponse = client.search(source, RequestOptions.DEFAULT); System.out.println(searchResponse); System.out.println(JSON.toJSONString(searchResponse.getHits())); System.out.println(searchResponse.getHits()); &#125;&#125;总结java对ElasticSearch进行操作请求头请求体请求体的具体操作执行请求体报错：发现索引必须都是小写12[summer_001Spring] ElasticsearchStatusException[Elasticsearch exception [type=invalid_index_name_exception, reason=Invalid index name [summer_001Spring], must be lowercase]]坑点: 这里必须要new IndexRequest,不然值会重复12345678users.forEach(System.out::println); System.out.println(\"====================================================================\"); for (int i = 0; i &lt; users.size(); i++) &#123; bulkRequest.add( new IndexRequest(\"summer_002\") .source(JSON.toJSONString(users.get(i)),XContentType.JSON)); System.out.println(users.get(i)); &#125;","categories":[{"name":"Lucene","slug":"Lucene","permalink":"https://me.obey.fun/categories/Lucene/"},{"name":"ElasticSearch","slug":"Lucene/ElasticSearch","permalink":"https://me.obey.fun/categories/Lucene/ElasticSearch/"}],"tags":[{"name":"ES","slug":"ES","permalink":"https://me.obey.fun/tags/ES/"},{"name":"倒排索引","slug":"倒排索引","permalink":"https://me.obey.fun/tags/倒排索引/"}],"keywords":[{"name":"Lucene","slug":"Lucene","permalink":"https://me.obey.fun/categories/Lucene/"},{"name":"ElasticSearch","slug":"Lucene/ElasticSearch","permalink":"https://me.obey.fun/categories/Lucene/ElasticSearch/"}]},{"title":"Spring Security认证授权","slug":"Spring-Security认证授权","date":"2020-04-16T04:24:24.000Z","updated":"2020-05-03T02:20:16.000Z","comments":true,"path":"Spring-Security认证授权.html","link":"","permalink":"https://me.obey.fun/Spring-Security认证授权.html","excerpt":"","text":"Spring Security 快速上手Spring Security介绍Spring Security是一个能够为基于Spring的企业应用系统提供声明式的安全访问控制解决方案的安全框架。由于它是Spring生态系统中的一员，因此它伴随着整个Spring生态系统不断修正、升级，spring boot项目中加入spring security更是十分简单，使用Spring Security 减少了为企业系统安全控制编写大量重复代码的工作。创建工程创建maven工程1）创建maven工程 security-spring-security，工程结构如下：2）引入以下依赖：在security-springmvc的基础上增加spring-security的依赖：12345678910 &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring‐security‐web&lt;/artifactId&gt; &lt;version&gt;5.1.4.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.security&lt;/groupId&gt; &lt;artifactId&gt;spring‐security‐config&lt;/artifactId&gt; &lt;version&gt;5.1.4.RELEASE&lt;/version&gt; &lt;/dependency&gt;Spring容器配置在config包下定义ApplicationConfig.java，它对应web.xml中ContextLoaderListener的配置1234567@Configuration@ComponentScan(basePackages = \"com.itheima.security.springmvc\" ,excludeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION,value =Controller.class)&#125;)public class ApplicationConfig &#123; //在此配置除了Controller的其它bean，比如：数据库链接池、事务管理器、业务bean等。&#125;Servlet Context配置本案例采用Servlet3.0无web.xml方式，的config包下定义WebConfig.java，它对应于DispatcherServlet配置。123456789101112131415@Configuration@EnableWebMvc@ComponentScan(basePackages = \"com.itheima.security.springmvc\" ,includeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION,value =Controller.class)&#125;)public class WebConfig implements WebMvcConfigurer &#123; //视图解析器 @Bean public InternalResourceViewResolver viewResolver()&#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(\"/WEB‐INF/views/\"); viewResolver.setSuffix(\".jsp\"); return viewResolver; &#125; &#125;加载 Spring容器在init包下定义Spring容器初始化类SpringApplicationInitializer，此类实现WebApplicationInitializer接口，Spring容器启动时加载WebApplicationInitializer接口的所有实现类。123456789101112131415public class SpringApplicationInitializer extendsAbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class&lt;?&gt;[] &#123; ApplicationConfig.class &#125;;//指定rootContext的配置类 &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class&lt;?&gt;[] &#123; WebConfig.class &#125;; //指定servletContext的配置类 &#125; @Override protected String[] getServletMappings() &#123; return new String [] &#123;\"/\"&#125;; &#125;&#125;认证认证页面springSecurity默认提供认证页面，不需要额外开发。安全配置spring security提供了用户名密码登录、退出、会话管理等认证功能，只需要配置即可使用。1) 在config包下定义WebSecurityConfig，安全配置的内容包括：用户信息、密码编码器、安全拦截机制。1234567891011121314151617181920212223242526@EnableWebSecuritypublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123;//配置用户信息服务 @Bean public UserDetailsService userDetailsService() &#123; InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(\"zhangsan\").password(\"123\").authorities(\"p1\").build()); manager.createUser(User.withUsername(\"lisi\").password(\"456\").authorities(\"p2\").build()); return manager;&#125;@Beanpublic PasswordEncoder passwordEncoder() &#123;return NoOpPasswordEncoder.getInstance(); &#125;//配置安全拦截机制@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/r/**\").authenticated() （1） .anyRequest().permitAll() （2） .and() .formLogin().successForwardUrl(\"/login‐success\"); （3）&#125;&#125;在 userDetailsService()方法中，我们返回了一个UserDetailsService给spring容器，Spring Security会使用它来获取用户信息。我们暂时使用InMemoryUserDetailsManager实现类，并在其中分别创建了zhangsan、lisi两个用户，并设置密码和权限。而在configure()中，我们通过HttpSecurity设置了安全拦截规则，其中包含了以下内容：（1）url匹配/r/**的资源，经过认证后才能访问。（2）其他url完全开放。（3）支持form表单认证，认证成功后转向/login-success。关于HttpSecurity的配置清单请参考附录 HttpSecurity。2) 加载 WebSecurityConfig修改SpringApplicationInitializer的getRootConfigClasses()方法，添加WebSecurityConfig.class：1234@Overrideprotected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class&lt;?&gt;[] &#123; ApplicationConfig.class, WebSecurityConfig.class&#125;;&#125;Spring Security初始化Spring Security 初始化，这里有两种情况若当前环境没有使用 Spring或Spring MVC，则需要将 WebSecurityConfig(Spring Security配置类) 传入超类，以确保获取配置，并创建spring context。相反，若当前环境已经使用 spring，我们应该在现有的springContext中注册Spring Security(上一步已经做将WebSecurityConfig加载至rootcontext)，此方法可以什么都不做。在init包下定义SpringSecurityApplicationInitializer：123456public class SpringSecurityApplicationInitializer extends AbstractSecurityWebApplicationInitializer &#123; public SpringSecurityApplicationInitializer() &#123; //super(WebSecurityConfig.class); &#125;&#125;默认根路径请求在WebConfig.java中添加默认请求根路径跳转到/login，此url为spring security提供：12345// 默认Url根路径跳转到/login，此url为spring security提供@Overridepublic void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"redirect:/login\");&#125;spring security默认提供的登录页面。认证成功页面在安全配置中，认证成功将跳转到/login-success，代码如下：12345678910// 配置安全拦截机制@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/r/**\").authenticated() （1） .anyRequest().permitAll() （2） .and() .formLogin().successForwardUrl(\"/login‐success\"); （3）&#125;spring security支持form表单认证，认证成功后转向/login-success。在LoginController中定义/login-success:1234@RequestMapping(value = \"/login‐success\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;) public String loginSuccess()&#123; return \" 登录成功\";&#125;测试（1）启动项目，访问http://localhost:8080/security-spring-security/路径地址页面会根据WebConfig中addViewControllers配置规则，跳转至/login，/login是Spring Security提供的登录页面。（2）登录1、输入错误的用户名、密码2、输入正确的用户名、密码，登录成功（3）退出1、请求/logout退出2、退出 后再访问资源自动跳转到登录页面授权实现授权需要对用户的访问进行拦截校验，校验用户的权限是否可以操作指定的资源，Spring Security默认提供授权实现方法。在LoginController添加/r/r1或/r/r212345678910111213141516/** * 测试资源1 * @return */@GetMapping(value = \"/r/r1\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;)public String r1()&#123; return \" 访问资源1\";&#125;/** * 测试资源2 * @return */@GetMapping(value = \"/r/r2\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;)public String r2()&#123; return \" 访问资源2\";&#125;在安全配置类 WebSecurityConfig.java中配置授权规则：12.antMatchers(\"/r/r1\").hasAuthority(\"p1\") .antMatchers(\"/r/r2\").hasAuthority(\"p2\").antMatchers(&quot;/r/r1&quot;).hasAuthority(&quot;p1&quot;)表示：访问/r/r1资源的 url 需要拥有p1权限。.antMatchers(&quot;/r/r2&quot;).hasAuthority(&quot;p2&quot;)表示：访问/r/r2资源的 url 需要拥有p2权限。完整的WebSecurityConfig方法如下：1234567891011@Override protected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/r/r1\").hasAuthority(\"p1\") .antMatchers(\"/r/r2\").hasAuthority(\"p2\") .antMatchers(\"/r/**\").authenticated() .anyRequest().permitAll() .and() .formLogin().successForwardUrl(\"/login‐success\");&#125;测试：1、登录成功2、访问/r/r1和/r/r2，有权限时则正常访问，否则返回403（拒绝访问）小结通过快速上手，咱们使用Spring Security实现了认证和授权，Spring Security提供了基于账号和密码的认证方式，通过安全配置即可实现请求拦截，授权功能，Spring Security能完成的不仅仅是这些。Spring Security 应用详解集成SpringBootSpring Boot 介绍Spring Boot是一套Spring的快速开发框架，基于Spring 4.0设计，使用Spring Boot开发可以避免一些繁琐的工程搭建和配置，同时它集成了大量的常用框架，快速导入依赖包，避免依赖包的冲突。基本上常用的开发框架都支持Spring Boot开发，例如：MyBatis、Dubbo等，Spring家族更是如此，例如：Spring cloud、Spring mvc、Spring security等，使用Spring Boot开发可以大大得高生产率，所以Spring Boot的使用率非常高。本章节讲解如何通过 Spring Boot开发Spring Security应用，Spring Boot提供spring-boot-starter-security用于开发Spring Security应用。创建maven工程1）创建maven工程 security-spring-boot，工程结构如下：2）引入以下依赖：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101&lt;?xml version=\"1.0\" encoding=\"UTF‐8\"?&gt; &lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema‐instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven‐4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima.security&lt;/groupId&gt; &lt;artifactId&gt;security‐springboot&lt;/artifactId&gt; &lt;version&gt;1.0‐SNAPSHOT&lt;/version&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐parent&lt;/artifactId&gt; &lt;version&gt;2.1.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF‐8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!‐‐ 以下是&gt;spring boot依赖‐‐&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!‐‐ 以下是&gt;spring security依赖‐‐&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!‐‐ 以下是jsp依赖‐‐&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet‐api&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!‐‐jsp页面使用jstl标签 ‐‐&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐tomcat&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!‐‐用于编译jsp ‐‐&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat‐embed‐jasper&lt;/artifactId&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;security‐springboot&lt;/finalName&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7‐maven‐plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven‐compiler‐plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven‐resources‐plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;utf‐8&lt;/encoding&gt; &lt;useDefaultDelimiters&gt;true&lt;/useDefaultDelimiters&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt;spring 容器配置SpringBoot工程启动会自动扫描启动类所在包下的所有Bean，加载到spring容器。1）Spring Boot配置文件在resources下添加application.properties，内容如下：123server.port=8080server.servlet.context‐path=/security‐springbootspring.application.name = security‐springboot2 ）Spring Boot 启动类123456@SpringBootApplicationpublic class SecuritySpringBootApp &#123; public static void main(String[] args) &#123; SpringApplication.run(SecuritySpringBootApp.class, args); &#125;&#125;Servlet Context配置由于Spring boot starter自动装配机制，这里无需使用@EnableWebMvc与@ComponentScan，WebConfig如下:12345678@Configurationpublic class WebConfig implements WebMvcConfigurer &#123; //默认Url根路径跳转到/login，此url为spring security提供 @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"redirect:/login\"); &#125;&#125;视图解析器配置在application.properties中12spring.mvc.view.prefix=/WEB‐INF/views/ spring.mvc.view.suffix=.jsp安全配置由于Spring boot starter自动装配机制，这里无需使用@EnableWebSecurity，WebSecurityConfig内容如下:1234@Configurationpublic class WebSecurityConfig extends WebSecurityConfigurerAdapter &#123; //内容跟Spring security入门程序一致&#125;测试LoginController的内容同同Spring security入门程序。1234@RestControllerpublic class LoginController &#123; //内容略..跟Spring security入门程序保持一致&#125;测试过程：1、测试认证2、测试退出3、测试授权工作原理结构总览Spring Security所解决的问题就是安全访问控制，而安全访问控制功能其实就是对所有进入系统的请求进行拦截，校验每个请求是否能够访问它所期望的资源。根据前边知识的学习，可以通过Filter或AOP等技术来实现，Spring Security对Web资源的保护是靠Filter实现的，所以从这个Filter来入手，逐步深入Spring Security原理。当初始化Spring Security时，会创建一个名为 SpringSecurityFilterChain 的Servlet过滤器，类型为org.springframework.security.web.FilterChainProxy，它实现了javax.servlet.Filter，因此外部的请求会经过此类，下图是Spring Security过滤器链结构图：FilterChainProxy 是一个代理，真正起作用的是FilterChainProxy中SecurityFilterChain所包含的各个Filter，同时这些Filter作为Bean被Spring管理，它们是Spring Security核心，各有各的职责，但他们并不直接处理用户的认证，也不直接处理用户的授权，而是把它们交给了认证管理器（AuthenticationManager）和决策管理器（AccessDecisionManager）进行处理，下图是FilterChainProxy相关类的UML图示。spring Security功能的实现主要是由一系列过滤器链相互配合完成。下面介绍过滤器链中主要的几个过滤器及其作用：SecurityContextPersistenceFilter 这个Filter是整个拦截过程的入口和出口（也就是第一个和最后一个拦截器），会在请求开始时从配置好的 SecurityContextRepository 中获取 SecurityContext，然后把它设置给SecurityContextHolder。在请求完成后将SecurityContextHolder 持有的 SecurityContext 再保存到配置好的 SecurityContextRepository，同时清除 securityContextHolder 所持有的 SecurityContext；UsernamePasswordAuthenticationFilter 用于处理来自表单提交的认证。该表单必须提供对应的用户名和密码，其内部还有登录成功或失败后进行处理的 AuthenticationSuccessHandler 和AuthenticationFailureHandler，这些都可以根据需求做相关改变；FilterSecurityInterceptor 是用于保护web资源的，使用AccessDecisionManager对当前用户进行授权访问，前面已经详细介绍过了；ExceptionTranslationFilter 能够捕获来自 FilterChain 所有的异常，并进行处理。但是它只会处理两类异常：AuthenticationException 和 AccessDeniedException，其它的异常它会继续抛出。认证流程认证流程让我们仔细分析认证过程：用户提交用户名、密码被SecurityFilterChain中的 UsernamePasswordAuthenticationFilter 过滤器获取到，封装为请求Authentication，通常情况下是UsernamePasswordAuthenticationToken这个实现类。然后过滤器将Authentication提交至认证管理器（AuthenticationManager）进行认证认证成功后，AuthenticationManager 身份管理器返回一个被填充满了信息的（包括上面提到的权限信息，身份信息，细节信息，但密码通常会被移除） Authentication 实例。SecurityContextHolder 安全上下文容器将第3步填充了信息的 Authentication ，通过SecurityContextHolder.getContext().setAuthentication(…)方法，设置到其中。可以看出AuthenticationManager接口（认证管理器）是认证相关的核心接口，也是发起认证的出发点，它的实现类为ProviderManager。而Spring Security支持多种认证方式，因此ProviderManager维护着一个List&lt;AuthenticationProvider&gt; 列表，存放多种认证方式，最终实际的认证工作是由AuthenticationProvider完成的。咱们知道web表单的对应的AuthenticationProvider实现类为DaoAuthenticationProvider，它的内部又维护着一个UserDetailsService负责UserDetails的获取。最终AuthenticationProvider将UserDetails填充至Authentication。认证核心组件的大体关系如下：AuthenticationProvider通过前面的Spring Security认证流程我们得知，认证管理器（AuthenticationManager）委托AuthenticationProvider完成认证工作。AuthenticationProvider是一个接口，定义如下：1234public interface AuthenticationProvider &#123; Authentication authenticate(Authentication authentication) throws AuthenticationException; boolean supports(Class&lt;?&gt; var1);&#125;authenticate()方法定义了认证的实现过程，它的参数是一个Authentication，里面包含了登录用户所提交的用户、密码等。而返回值也是一个Authentication，这个Authentication则是在认证成功后，将用户的权限及其他信息重新组装后生成。Spring Security中维护着一个 List&lt;AuthenticationProvider&gt; 列表，存放多种认证方式，不同的认证方式使用不同的AuthenticationProvider。如使用用户名密码登录时，使用AuthenticationProvider1，短信登录时使用AuthenticationProvider2等等这样的例子很多。每个AuthenticationProvider需要实现supports（）方法来表明自己支持的认证方式，如我们使用表单方式认证，在提交请求时Spring Security会生成UsernamePasswordAuthenticationToken，它是一个Authentication，里面封装着用户提交的用户名、密码信息。而对应的，哪个AuthenticationProvider来处理它？我们在DaoAuthenticationProvider的基类AbstractUserDetailsAuthenticationProvider发现以下代码：123public boolean supports(Class&lt;?&gt; authentication) &#123; return UsernamePasswordAuthenticationToken.class.isAssignableFrom(authentication);&#125;也就是说当web表单提交用户名密码时，Spring Security由DaoAuthenticationProvider处理。最后，我们来看一下 Authentication(认证信息)的结构，它是一个接口，我们之前提到的UsernamePasswordAuthenticationToken就是它的实现之一：123456789public interface Authentication extends Principal, Serializable &#123; （1） Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); （2） Object getCredentials(); （3） Object getDetails(); （4） Object getPrincipal(); （5） boolean isAuthenticated(); void setAuthenticated(boolean var1) throws IllegalArgumentException;&#125;（1）Authentication是spring security包中的接口，直接继承自Principal类，而Principal是位于 java.security包中的。它是表示着一个抽象主体身份，任何主体都有一个名称，因此包含一个getName()方法。（2）getAuthorities()，权限信息列表，默认是GrantedAuthority接口的一些实现类，通常是代表权限信息的一系列字符串。（3）getCredentials()，凭证信息，用户输入的密码字符串，在认证过后通常会被移除，用于保障安全。（4）getDetails()，细节信息，web应用中的实现接口通常为 WebAuthenticationDetails，它记录了访问者的ip地址和sessionId的值。（5）getPrincipal()，身份信息，大部分情况下返回的是UserDetails接口的实现类，UserDetails代表用户的详细信息，那从Authentication中取出来的UserDetails就是当前登录用户信息，它也是框架中的常用接口之一。UserDetailsService1）认识UserDetailsService现在咱们现在知道DaoAuthenticationProvider处理了 web 表单的认证逻辑，认证成功后既得到一个Authentication(UsernamePasswordAuthenticationToken实现)，里面包含了身份信息（Principal）。这个身份信息就是一个 Object ，大多数情况下它可以被强转为UserDetails对象。DaoAuthenticationProvider中包含了一个UserDetailsService实例，它负责根据用户名提取用户信息UserDetails(包含密码)，而后DaoAuthenticationProvider会去对比UserDetailsService提取的用户密码与用户提交的密码是否匹配作为认证成功的关键依据，因此可以通过将自定义的 UserDetailsService 公开为spring bean来定义自定义身份验证。123public interface UserDetailsService &#123; UserDetails loadUserByUsername(String username) throws UsernameNotFoundException; &#125;很多人把 DaoAuthenticationProvider和UserDetailsService的职责搞混淆，其实UserDetailsService只负责从特定的地方（通常是数据库）加载用户信息，仅此而已。而DaoAuthenticationProvider的职责更大，它完成完整的认证流程，同时会把UserDetails填充至Authentication。上面一直提到UserDetails是用户信息，咱们看一下它的真面目：123456789public interface UserDetails extends Serializable &#123; Collection&lt;? extends GrantedAuthority&gt; getAuthorities(); String getPassword(); String getUsername(); boolean isAccountNonExpired(); boolean isAccountNonLocked(); boolean isCredentialsNonExpired(); boolean isEnabled();&#125;它和Authentication接口很类似，比如它们都拥有username，authorities。Authentication的getCredentials()与UserDetails中的getPassword()需要被区分对待，前者是用户提交的密码凭证，后者是用户实际存储的密码，认证其实就是对这两者的比对。Authentication中的getAuthorities()实际是由UserDetails的getAuthorities()传递而形成的。还记得Authentication接口中的getDetails()方法吗？其中的UserDetails用户详细信息便是经过了AuthenticationProvider认证之后被填充的。通过实现UserDetailsService和UserDetails，我们可以完成对用户信息获取方式以及用户信息字段的扩展。Spring Security提供的InMemoryUserDetailsManager(内存认证)，JdbcUserDetailsManager(jdbc认证)就是UserDetailsService的实现类，主要区别无非就是从内存还是从数据库加载用户。2）测试自定义UserDetailsService12345678910111213@Service public class SpringDataUserDetailsService implements UserDetailsService &#123; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //登录账号 System.out.println(\"username=\"+username); //根据账号去数据库查询... //这里暂时使用静态数据 UserDetails userDetails =User.withUsername(username).password(\"123\").authorities(\"p1\").build(); return userDetails; &#125;&#125;屏蔽安全配置类中 UserDetailsService 的定义12345678/* @Bean public UserDetailsService userDetailsService() &#123; InMemoryUserDetailsManager manager = new InMemoryUserDetailsManager(); manager.createUser(User.withUsername(\"zhangsan\").password(\"123\").authorities(\"p1\").build()); manager.createUser(User.withUsername(\"lisi\").password(\"456\").authorities(\"p2\").build()); return manager; &#125;*/重启工程，请求认证，SpringDataUserDetailsService的loadUserByUsername方法被调用 ，查询用户信息。PasswordEncoder1）认识PasswordEncoderDaoAuthenticationProvider认证处理器通过UserDetailsService获取到UserDetails后，它是如何与请求Authentication中的密码做对比呢？在这里Spring Security为了适应多种多样的加密类型，又做了抽象，DaoAuthenticationProvider通过PasswordEncoder接口的matches方法进行密码的对比，而具体的密码对比细节取决于实现：1234567public interface PasswordEncoder &#123; String encode(CharSequence var1); boolean matches(CharSequence var1, String var2); default boolean upgradeEncoding(String encodedPassword) &#123; return false; &#125;&#125;而Spring Security提供很多内置的PasswordEncoder，能够开箱即用，使用某种PasswordEncoder只需要进行如下声明即可，如下：1234@Bean public PasswordEncoder passwordEncoder() &#123; return NoOpPasswordEncoder.getInstance();&#125;NoOpPasswordEncoder采用字符串匹配方法，不对密码进行加密比较处理，密码比较流程如下：用户输入密码（明文 ）DaoAuthenticationProvider获取UserDetails（其中存储了用户的正确密码）DaoAuthenticationProvider使用PasswordEncoder对输入的密码和正确的密码进行校验，密码一致则校验通过，否则校验失败。NoOpPasswordEncoder 的校验规则拿 输入的密码和UserDetails中的正确密码进行字符串比较，字符串内容一致则校验通过，否则 校验失败。实际项目中推荐使用BCryptPasswordEncoder, Pbkdf2PasswordEncoder, SCryptPasswordEncoder等，感兴趣的大家可以看看这些PasswordEncoder的具体实现。2）使用CryptPasswordEncoder1、配置BCryptPasswordEncoder在安全配置类中定义：1234@Bean public PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder();&#125;测试发现认证失败，提示：Encoded password does not look like BCrypt。原因：由于UserDetails中存储的是原始密码（比如：123），它不是BCrypt格式。跟踪 DaoAuthenticationProvider第 33 行代码查看 userDetails中的内容 ，跟踪第 38 行代码查看PasswordEncoder的类型。2、测试BCrypt通过下边的代码测试BCrypt加密及校验的方法添加依赖：12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;编写测试方法：12345678910111213@RunWith(SpringRunner.class) public class TestBCrypt &#123; @Test public void test1()&#123; //对原始密码加密 String hashpw = BCrypt.hashpw(\"123\",BCrypt.gensalt()); System.out.println(hashpw); //校验原始密码和BCrypt密码是否一致 boolean checkpw = BCrypt.checkpw(\"123\",\"$2a$10$NlBC84MVb7F95EXYTXwLneXgCca6/GipyWR5NHm8K0203bSQMLpvm\"); System.out.println(checkpw); &#125;&#125;3、修改安全配置类将UserDetails中的原始密码修改为BCrypt格式12manager.createUser(User.withUsername(\"zhangsan\").password(\"$2a$10$1b5mIkehqv5c4KRrX9bUj.A4Y2hug3IGCnMCL5i4RpQrYV12xNKye\").authorities(\"p1\").build());实际项目中存储在数据库中的密码并不是原始密码，都是经过加密处理的密码。授权流程授权流程通过快速上手我们知道，Spring Security可以通过 http.authorizeRequests()对web请求进行授权保护。Spring Security使用标准Filter建立了对web请求的拦截，最终实现对资源的授权访问。Spring Security的授权流程如下：分析授权流程：拦截请求，已认证用户访问受保护的web资源将被SecurityFilterChain中的 FilterSecurityInterceptor 的子类拦截。获取资源访问策略，FilterSecurityInterceptor会从 SecurityMetadataSource 的子类DefaultFilterInvocationSecurityMetadataSource 获取要访问当前资源所需要的权限Collection&lt;ConfigAttribute&gt; 。SecurityMetadataSource其实就是读取访问策略的抽象，而读取的内容，其实就是我们配置的访问规则， 读取访问策略如：12345 http.authorizeRequests() .antMatchers(\"/r/r1\").hasAuthority(\"p1\") .antMatchers(\"/r/r2\").hasAuthority(\"p2\") ...最后，FilterSecurityInterceptor会调用 AccessDecisionManager 进行授权决策，若决策通过，则允许访问资源，否则将禁止访问。AccessDecisionManager（访问决策管理器）的核心接口如下:12345678public interface AccessDecisionManager &#123; /** * 通过传递的参数来决定用户是否有访问对应受保护资源的权限 */ void decide(Authentication authentication , Object object, Collection&lt;ConfigAttribute&gt;configAttributes ) throws AccessDeniedException, InsufficientAuthenticationException; //略.. &#125;这里着重说明一下decide的参数：authentication：要访问资源的访问者的身份object：要访问的受保护资源，web请求对应FilterInvocationconfigAttributes：是受保护资源的访问策略，通过SecurityMetadataSource获取。decide接口就是用来鉴定当前用户是否有访问对应受保护资源的权限。授权决策AccessDecisionManager采用投票的方式来确定是否能够访问受保护资源。通过上图可以看出，AccessDecisionManager中包含的一系列AccessDecisionVoter将会被用来对Authentication是否有权访问受保护对象进行投票，AccessDecisionManager根据投票结果，做出最终决策。AccessDecisionVoter是一个接口，其中定义有三个方法，具体结构如下所示。12345678public interface AccessDecisionVoter&lt;S&gt; &#123; int ACCESS_GRANTED = 1; int ACCESS_ABSTAIN = 0; int ACCESS_DENIED = ‐1; boolean supports(ConfigAttribute var1); boolean supports(Class&lt;?&gt; var1); int vote(Authentication var1, S var2, Collection&lt;ConfigAttribute&gt; var3);&#125;vote()方法的返回结果会是AccessDecisionVoter中定义的三个常量之一。ACCESS_GRANTED表示同意，ACCESS_DENIED表示拒绝，ACCESS_ABSTAIN表示弃权。如果一个AccessDecisionVoter不能判定当前Authentication是否拥有访问对应受保护对象的权限，则其vote()方法的返回值应当为弃权ACCESS_ABSTAIN。Spring Security内置了三个基于投票的AccessDecisionManager实现类如下，它们分别是AffirmativeBased、ConsensusBased和UnanimousBased。AffirmativeBased的逻辑是：只要有AccessDecisionVoter的投票为ACCESS_GRANTED则同意用户进行访问；如果全部弃权也表示通过；如果没有一个人投赞成票，但是有人投反对票，则将抛出AccessDeniedException。Spring security默认使用的是AffirmativeBased。ConsensusBased的逻辑是：如果赞成票多于反对票则表示通过。反过来，如果反对票多于赞成票则将抛出AccessDeniedException。如果赞成票与反对票相同且不等于0，并且属性allowIfEqualGrantedDeniedDecisions的值为true，则表示通过，否则将抛出异常AccessDeniedException。参数allowIfEqualGrantedDeniedDecisions的值默认为true。如果所有的AccessDecisionVoter都弃权了，则将视参数allowIfAllAbstainDecisions的值而定，如果该值为true则表示通过，否则将抛出异常AccessDeniedException。参数allowIfAllAbstainDecisions的值默认为false。UnanimousBased的逻辑与另外两种实现有点不一样，另外两种会一次性把受保护对象的配置属性全部传递给AccessDecisionVoter进行投票，而UnanimousBased会一次只传递一个ConfigAttribute给AccessDecisionVoter进行投票。这也就意味着如果我们的AccessDecisionVoter的逻辑是只要传递进来的ConfigAttribute中有一个能够匹配则投赞成票，但是放到UnanimousBased中其投票结果就不一定是赞成了。UnanimousBased的逻辑具体来说是这样的：如果受保护对象配置的某一个ConfigAttribute被任意的AccessDecisionVoter反对了，则将抛出AccessDeniedException。如果没有反对票，但是有赞成票，则表示通过。如果全部弃权了，则将视参数allowIfAllAbstainDecisions的值而定，true则通过，false则抛出AccessDeniedException。Spring Security也内置一些投票者实现类如RoleVoter、AuthenticatedVoter和WebExpressionVoter等，可以自行查阅资料进行学习。自定义认证Spring Security提供了非常好的认证扩展方法，比如：快速上手中将用户信息存储到内存中，实际开发中用户信息通常在数据库，Spring security可以实现从数据库读取用户信息，Spring security还支持多种授权方法。自定义登录页面在快速上手中，你可能会想知道登录页面从哪里来的？因为我们并没有提供任何的HTML或JSP文件。Spring Security的默认配置没有明确设定一个登录页面的URL，因此Spring Security会根据启用的功能自动生成一个登录页面URL，并使用默认URL处理登录的提交内容，登录后跳转的到默认URL等等。尽管自动生成的登录页面很方便快速启动和运行，但大多数应用程序都希望定义自己的登录页面。认证页面将security-springmvc工程的login.jsp拷贝到security-springboot下，目录保持一致。配置认证页面在WebConfig.java中配置认证页面地址：123456// 默认Url根路径跳转到/login，此url为spring security提供@Overridepublic void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"redirect:/login‐view\"); registry.addViewController(\"/login‐view\").setViewName(\"login\");&#125;安全配置在WebSecurityConfig中配置表章登录信息：1234567891011121314 // 配置安全拦截机制@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() .antMatchers(\"/r/**\").authenticated() .anyRequest().permitAll() .and() .formLogin() (1) .loginPage(\"/login‐view\") (2) .loginProcessingUrl(\"/login\") (3) .successForwardUrl(\"/login‐success\") (4) .permitAll();&#125;（1）允许表单登录（2）指定我们自己的登录页,spring security以重定向方式跳转到/login-view（3）指定登录处理的URL，也就是用户名、密码表单提交的目的路径（4）指定登录成功后的跳转URL（5）我们必须允许所有用户访问我们的登录页（例如为验证的用户），这个 formLogin().permitAll() 方法允许任意用户访问基于表单登录的所有的URL。测试当用户没有认证时访问系统的资源会重定向到login-view页面输入账号和密码，点击登录,报错：Whitelabel Error PageType=Forbidden，Status=403问题解决：spring security为防止CSRF（Cross-site request forgery跨站请求伪造）的发生，限制了除了get以外的大多数方法。解决方法1：屏蔽CSRF控制，即spring security不再限制CSRF。配置WebSecurityConfig12345@Override protected void configure(HttpSecurity http) throws Exception &#123; http.csrf().disable() //屏蔽CSRF控制，即spring security不再限制CSRF ...&#125;本案例采用方法1解决方法2：在login.jsp页面添加一个token，spring security会验证token，如果token合法则可以继续请求。修改login.jsp1234&lt;form action=\"login\" method=\"post\"&gt; &lt;input type=\"hidden\" name=\"$&#123;_csrf.parameterName&#125;\" value=\"$&#123;_csrf.token&#125;\"/&gt; ...&lt;/form&gt;连接数据库认证前边的例子我们是将用户信息存储在内存中，实际项目中用户信息存储在数据库中，本节实现从数据库读取用户信息。根据前边对认证流程研究，只需要重新定义UserDetailService即可实现根据用户账号查询数据库。创建数据库创建user_db数据库1CREATE DATABASE `user_db` CHARACTER SET 'utf8' COLLATE 'utf8_general_ci';创建t_user表12345678CREATE TABLE `t_user` ( `id` bigint(20) NOT NULL COMMENT '用户id', `username` varchar(64) NOT NULL, `password` varchar(64) NOT NULL, `fullname` varchar(255) NOT NULL COMMENT '用户姓名', `mobile` varchar(11) DEFAULT NULL COMMENT '手机号', PRIMARY KEY (`id`) USING BTREE) ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC代码实现1）定义dataSource在application.properties配置1234spring.datasource.url=jdbc:mysql://localhost:3306/user_db spring.datasource.username=rootspring.datasource.password=mysqlspring.datasource.driver‐class‐name=com.mysql.jdbc.Driver2）添加依赖1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring‐boot‐starter‐jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql‐connector‐java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt;&lt;/dependency&gt;3）定义Dao定义模型类型，在 model包定义UserDto：12345678@Data public class UserDto &#123; private String id; private String username; private String password; private String fullname; private String mobile;&#125;在Dao包定义UserDao：1234567891011121314@Repository public class UserDao &#123; @Autowired JdbcTemplate jdbcTemplate; public UserDto getUserByUsername(String username)&#123; String sql =\"select id,username,password,fullname from t_user where username = ?\"; List&lt;UserDto&gt; list = jdbcTemplate.query(sql, new Object[]&#123;username&#125;, newBeanPropertyRowMapper&lt;&gt;(UserDto.class)); if(list == null &amp;&amp; list.size() &lt;= 0)&#123; return null; &#125; return list.get(0); &#125;&#125;定义UserDetailService在service包下定义SpringDataUserDetailsService：123456789101112131415161718@Service public class SpringDataUserDetailsService implements UserDetailsService &#123; @Autowired UserDao userDao; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //登录账号 System.out.println(\"username=\"+username); //根据账号去数据库查询... UserDto user = userDao.getUserByUsername(username); if(user == null)&#123; return null; &#125; // 这里暂时使用静态数据 UserDetails userDetails =User.withUsername(user.getFullname()).password(user.getPassword()).authorities(\"p1\").build(); return userDetails; &#125;&#125;测试输入账号和密码请求认证，跟踪代码。使用BCryptPasswordEncoder按照我们前边讲的PasswordEncoder的使用方法，使用BCryptPasswordEncoder需要完成如下工作：1、在安全配置类中定义BCryptPasswordEncoder1234@Bean public PasswordEncoder passwordEncoder() &#123; return new BCryptPasswordEncoder();&#125;2、UserDetails中的密码存储BCrypt格式前边实现了从数据库查询用户信息，所以数据库中的密码应该存储BCrypt格式会话用户认证通过后，为了避免用户的每次操作都进行认证可将用户的信息保存在会话中。spring security提供会话管理，认证通过后将身份信息放入SecurityContextHolder上下文，SecurityContext与当前线程进行绑定，方便获取用户身份。获取用户身份编写LoginController，实现/r/r1、/r/r2的测试资源，并修改loginSuccess方法，注意getUsername方法，SpringSecurity获取当前登录用户信息的方法为SecurityContextHolder.getContext().getAuthentication()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849@RestControllerpublic class LoginController &#123; /** * 用户登录成功 * @return */ @RequestMapping(value = \"/login‐success\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;) public String loginSuccess()&#123; String username = getUsername(); return username + \" 登录成功\"; &#125; /** * 获取当前登录用户名 * @return */ private String getUsername()&#123; Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if(!authentication.isAuthenticated())&#123; return null; &#125; Object principal = authentication.getPrincipal(); String username = null; if (principal instanceof org.springframework.security.core.userdetails.UserDetails) &#123; username =((org.springframework.security.core.userdetails.UserDetails)principal).getUsername(); &#125; else &#123; username = principal.toString(); &#125; return username; &#125; /** * 测试资源1 * @return */ @GetMapping(value = \"/r/r1\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;) public String r1()&#123; String username = getUsername(); return username + \" 访问资源1\"; &#125; /** * 测试资源2 * @return */ @GetMapping(value = \"/r/r2\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;) public String r2()&#123; String username = getUsername(); return username + \" 访问资源2\"; &#125;&#125;测试登录前访问资源被重定向至登录页面。登录后访问资源成功访问资源，如下：zhangsan 访问资源1会话控制我们可以通过以下选项准确控制会话何时创建以及Spring Security如何与之交互：机制描述always总是创建一个sessionifRequired如果需要就创建一个Session（默认）登录时neverSpringSecurity 将不会创建Session，但是如果应用中其他地方创建了Session，那么SpringSecurity将会使用它。statelessSpringSecurity将绝对不会创建Session，也不使用Session通过以下配置方式对该选项进行配置：12345@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http.sessionManagement() .sessionCreationPolicy(SessionCreationPolicy.IF_REQUIRED)&#125;默认情况下，Spring Security会为每个登录成功的用户会新建一个Session，就是ifRequired 。若选用never，则指示Spring Security对登录成功的用户不创建Session了，但若你的应用程序在某地方新建了session，那么Spring Security会用它的。若使用stateless，则说明Spring Security对登录成功的用户不会创建Session了，你的应用程序也不会允许新建session。并且它会暗示不使用cookie，所以每个请求都需要重新进行身份验证。这种无状态架构适用于REST API及其无状态认证机制。会话超时可以再sevlet容器中设置Session的超时时间，如下设置Session有效期为3600s；spring boot 配置文件：1server.servlet.session.timeout=3600ssession超时之后，可以通过Spring Security 设置跳转的路径。123http.sessionManagement() .expiredUrl(\"/login‐view?error=EXPIRED_SESSION\") .invalidSessionUrl(\"/login‐view?error=INVALID_SESSION\");expired指session过期，invalidSession指传入的sessionid无效。安全会话cookie我们可以使用httpOnly和secure标签来保护我们的会话cookie：httpOnly ：如果为true，那么浏览器脚本将无法访问cookiesecure ：如果为true，则cookie将仅通过HTTPS连接发送spring boot 配置文件：12server.servlet.session.cookie.http‐only=trueserver.servlet.session.cookie.secure=true4.6 退出Spring security默认实现了logout退出，访问/logout，果然不出所料，退出功能Spring也替我们做好了。点击“Log Out”退出 成功。退出 后访问其它url判断是否成功退出。这里也可以自定义退出成功的页面：在WebSecurityConfig的protected void configure(HttpSecurity http)中配置：1234.and() .logout().logoutUrl(\"/logout\").logoutSuccessUrl(\"/login‐view?logout\");当退出操作出发时，将发生：使 HTTP Session 无效清除 SecurityContextHolder跳转到 /login -view?logout但是，类似于配置登录功能，咱们可以进一步自定义退出功能：1234567891011121314@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() //... .and() .logout() (1) .logoutUrl(\"/logout\") (2) .logoutSuccessUrl(\"/login‐view?logout\") (3) .logoutSuccessHandler(logoutSuccessHandler) (4) .addLogoutHandler(logoutHandler) (5) .invalidateHttpSession(true); (6) &#125;（1）提供系统退出支持，使用 WebSecurityConfigurerAdapter 会自动被应用（2）设置触发退出操作的URL (默认是 /logout ).（3）退出之后跳转的URL。默认是 /login?logout 。（4）定制的 LogoutSuccessHandler ，用于实现用户退出成功时的处理。如果指定了这个选项那么logoutSuccessUrl() 的设置会被忽略。（5）添加一个 LogoutHandler ，用于实现用户退出时的清理工作.默认 SecurityContextLogoutHandler 会被添加为最后一个 LogoutHandler 。（6）指定是否在退出时让 HttpSession 无效。 默认设置为 true。注意：如果让logout在GET请求下生效，必须关闭防止CSRF攻击csrf().disable()。如果开启了CSRF，必须使用post方式请求/logoutlogoutHandler：一般来说， LogoutHandler 的实现类被用来执行必要的清理，因而他们不应该抛出异常。下面是Spring Security提供的一些实现：PersistentTokenBasedRememberMeServices 基于持久化token的RememberMe功能的相关清理TokenBasedRememberMeService 基于token的RememberMe功能的相关清理CookieClearingLogoutHandler 退出时Cookie的相关清理CsrfLogoutHandler 负责在退出时移除csrfTokenSecurityContextLogoutHandler 退出时SecurityContext的相关清理链式API提供了调用相应的 LogoutHandler 实现的快捷方式，比如deleteCookies()。授权概述授权的方式包括 web授权和方法授权，web授权是通过 url拦截进行授权，方法授权是通过 方法拦截进行授权。他们都会调用accessDecisionManager进行授权决策，若为web授权则拦截器为FilterSecurityInterceptor；若为方法授权则拦截器为MethodSecurityInterceptor。如果同时通过web授权和方法授权则先执行web授权，再执行方法授权，最后决策通过，则允许访问资源，否则将禁止访问。类关系如下：准备环境数据库环境在t_user数据库创建如下表：角色表：123456789101112CREATE TABLE `t_role` ( `id` varchar(32) NOT NULL, `role_name` varchar(255) DEFAULT NULL, `description` varchar(255) DEFAULT NULL, `create_time` datetime DEFAULT NULL, `update_time` datetime DEFAULT NULL, `status` char(1) NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `unique_role_name` (`role_name`)) ENGINE=InnoDB DEFAULT CHARSET=utf8insert into `t_role`(`id`,`role_name`,`description`,`create_time`,`update_time`,`status`) values('1','管理员',NULL,NULL,NULL,'');用户角色关系表：123456789CREATE TABLE `t_user_role` ( `user_id` varchar(32) NOT NULL, `role_id` varchar(32) NOT NULL, `create_time` datetime DEFAULT NULL, `creator` varchar(255) DEFAULT NULL, PRIMARY KEY (`user_id`,`role_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8insert into `t_user_role`(`user_id`,`role_id`,`create_time`,`creator`) values('1','1',NULL,NULL);权限表：123456789CREATE TABLE `t_permission` ( `id` varchar(32) NOT NULL, `code` varchar(32) NOT NULL COMMENT '权限标识符', `description` varchar(64) DEFAULT NULL COMMENT '描述', `url` varchar(128) DEFAULT NULL COMMENT '请求地址', PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8insert into `t_permission`(`id`,`code`,`description`,`url`) values ('1','p1','测试资源1','/r/r1'),('2','p3','测试资源2','/r/r2');角色权限关系表：123456CREATE TABLE `t_role_permission` ( `role_id` varchar(32) NOT NULL, `permission_id` varchar(32) NOT NULL, PRIMARY KEY (`role_id`,`permission_id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8insert into `t_role_permission`(`role_id`,`permission_id`) values ('1','1'),('1','2');修改UserDetailService1、修改dao接口在UserDao中添加：12345678910111213// 根据用户id查询用户权限public List&lt;String&gt; findPermissionsByUserId(String userId)&#123; String sql=\"SELECT * FROM t_permission WHERE id IN(\\n\" + \"SELECT permission_id FROM t_role_permission WHERE role_id IN(\\n\" + \"\\tSELECT role_id FROM t_user_role WHERE user_id = ? \\n\" + \")\\n\" + \")\"; List&lt;PermissionDto&gt; list = jdbcTemplate.query(sql, new Object[]&#123;userId&#125;, newBeanPropertyRowMapper&lt;&gt;(PermissionDto.class)); List&lt;String&gt; permissions = new ArrayList&lt;&gt;(); list.iterator().forEachRemaining(c‐&gt;permissions.add(c.getCode())); return permissions;&#125;2、修改UserDetailService实现从数据库读取权限123456789101112131415161718@Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException &#123; //登录账号 System.out.println(\"username=\"+username); //根据账号去数据库查询... UserDto user = userDao.getUserByUsername(username); if(user == null)&#123; return null; &#125; //查询用户权限 List&lt;String&gt; permissions = userDao.findPermissionsByUserId(user.getId()); String[] perarray = new String[permissions.size()]; permissions.toArray(perarray); //创建userDetails UserDetails userDetails =User.withUsername(user.getFullname()).password(user.getPassword()).authorities(perarray).build(); return userDetails;&#125;web授权在上面例子中我们完成了认证拦截，并对/r/**下的某些资源进行简单的授权保护，但是我们想进行灵活的授权控制该怎么做呢？通过给 http.authorizeRequests() 添加多个子节点来定制需求到我们的URL，如下代码：12345678910111213@Overrideprotected void configure(HttpSecurity http) throws Exception &#123; http .authorizeRequests() (1) .antMatchers(\"/r/r1\").hasAuthority(\"p1\") (2) .antMatchers(\"/r/r2\").hasAuthority(\"p2\") (3) .antMatchers(\"/r/r3\").access(\"hasAuthority('p1') and hasAuthority('p2')\") (4) .antMatchers(\"/r/**\").authenticated() (5) .anyRequest().permitAll() (6) .and() .formLogin() // ... &#125;（1） http.authorizeRequests() 方法有多个子节点，每个macher按照他们的声明顺序执行。（2）指定”/r/r1”URL，拥有p1权限能够访问（3）指定”/r/r2”URL，拥有p2权限能够访问（4）指定了”/r/r3”URL，同时拥有p1和p2权限才能够访问（5）指定了除了r1、r2、r3之外”/r/**”资源，同时通过身份认证就能够访问，这里使用SpEL（Spring Expression Language）表达式。。（6）剩余的尚未匹配的资源，不做保护。注意：规则的顺序是重要的,更具体的规则应该先写.现在以/admin开始的所有内容都需要具有ADMIN角色的身份验证用户,即使是/admin/login路径(因为/admin/login已经被/admin/**规则匹配,因此第二个规则被忽略).12.antMatchers(\"/admin/**\").hasRole(\"ADMIN\") .antMatchers(\"/admin/login\").permitAll()因此,登录页面的规则应该在/admin/**规则之前.例如.12.antMatchers(\"/admin/login\").permitAll() .antMatchers(\"/admin/**\").hasRole(\"ADMIN\")保护URL常用的方法有：authenticated() 保护URL，需要用户登录permitAll() 指定URL无需保护，一般应用与静态资源文件hasRole(String role) 限制单个角色访问，角色将被增加 “ROLE_” .所以”ADMIN” 将和 “ROLE_ADMIN”进行比较.hasAuthority(String authority) 限制单个权限访问hasAnyRole(String… roles)允许多个角色访问.hasAnyAuthority(String… authorities) 允许多个权限访问.access(String attribute) 该方法使用 SpEL表达式, 所以可以创建复杂的限制.hasIpAddress(String ipaddressExpression) 限制IP地址或子网方法授权现在我们已经掌握了使用如何使用 http.authorizeRequests() 对web资源进行授权保护，从Spring Security2.0版本开始，它支持服务层方法的安全性的支持。本节学习@PreAuthorize,@PostAuthorize, @Secured三类注解。我们可以在任何 @Configuration 实例上使用 @EnableGlobalMethodSecurity 注释来启用基于注解的安全性。以下内容将启用Spring Security的 @Secured 注释。12@EnableGlobalMethodSecurity(securedEnabled = true) public class MethodSecurityConfig &#123;// ...&#125;然后向方法（在类或接口上）添加注解就会限制对该方法的访问。 Spring Security的原生注释支持为该方法定义了一组属性。 这些将被传递给AccessDecisionManager以供它作出实际的决定：12345678public interface BankService &#123;@Secured(\"IS_AUTHENTICATED_ANONYMOUSLY\")public Account readAccount(Long id);@Secured(\"IS_AUTHENTICATED_ANONYMOUSLY\")public Account[] findAccounts();@Secured(\"ROLE_TELLER\")public Account post(Account account, double amount);&#125;以上配置标明readAccount、findAccounts方法可匿名访问，底层使用WebExpressionVoter投票器，可从AffirmativeBased第23行代码跟踪。。post方法需要有TELLER角色才能访问，底层使用RoleVoter投票器。使用如下代码可启用prePost注解的支持1234@EnableGlobalMethodSecurity(prePostEnabled = true) public class MethodSecurityConfig &#123;// ...&#125;相应Java代码如下：12345678public interface BankService &#123;@PreAuthorize(\"isAnonymous()\")public Account readAccount(Long id);@PreAuthorize(\"isAnonymous()\")public Account[] findAccounts();@PreAuthorize(\"hasAuthority('p_transfer') and hasAuthority('p_read_account')\")public Account post(Account account, double amount);&#125;以上配置标明readAccount、findAccounts方法可匿名访问，post方法需要同时拥有p_transfer和p_read_account权限才能访问，底层使用WebExpressionVoter投票器，可从AffirmativeBased第23行代码跟踪。","categories":[{"name":"Filter","slug":"Filter","permalink":"https://me.obey.fun/categories/Filter/"},{"name":"Spring Security","slug":"Filter/Spring-Security","permalink":"https://me.obey.fun/categories/Filter/Spring-Security/"}],"tags":[{"name":"Web认证","slug":"Web认证","permalink":"https://me.obey.fun/tags/Web认证/"},{"name":"Web授权","slug":"Web授权","permalink":"https://me.obey.fun/tags/Web授权/"}],"keywords":[{"name":"Filter","slug":"Filter","permalink":"https://me.obey.fun/categories/Filter/"},{"name":"Spring Security","slug":"Filter/Spring-Security","permalink":"https://me.obey.fun/categories/Filter/Spring-Security/"}]},{"title":"Centos7系统的配置","slug":"centos7系统的配置","date":"2019-12-08T12:25:28.000Z","updated":"2020-02-03T14:45:40.919Z","comments":true,"path":"centos7系统的配置.html","link":"","permalink":"https://me.obey.fun/centos7系统的配置.html","excerpt":"","text":"Centos的配置静态IP的配置NAT适配器的配置首先，打开控制面板-网络和Internet-网络连接找到VMware Network Adapter VMnet8点击右键属性。然后，选择Internet协议版本4，再次点击属性。最后，选择使用下面的IP地址、使用下面的DNS服务器地址，自己设立ip地址、子网编码、默认网关等。虚拟机的虚拟网络编辑打开虚拟机，导航栏点击编辑-虚拟网络编辑器，进入到虚拟网络编辑器中，参考下图配置。记住NAT设置中的子网IP、子网掩码、网关IP三项，接下来配置文件主要是这三项。Centos的配置文件1、编辑网络配置文件。1vi /etc/sysconfig/network-scripts/ifcfg-ens33注：我的是ens33，不同的人或许会有不同。打开配置文件后，按 i 进行编辑。按ESC后输入:wq，意思是保存后退出。2、重启网络1service network restart3、测试网络1ping www.baidu.com测试是否能连接网络。4、查看IP地址输入ifconfig,看看是否地址为你配置的ip地址。防火墙的配置Centos7防火墙常用配置及说明Centos7和Centos6 防火墙的区别：使用的工具不一样了。Centos6 使用的是iptables ，Centos7 使用的是filewalliptables 用于过滤数据包，属于网络层防火墙。firewall 能够允许哪些服务可用，那些端口可用…属于更高一层的防火墙。常用命令：12345678910111213141516171819vi /usr/lib/firewalld/services/ssh.xmlvi /usr/lib/firewalld/services/html.xmlsystemctl enable firewalld.servicesystemctl restart firewalld.servicefirewall-cmd --statefirewall-cmd --list-allfirewall-cmd --zone=public --permanent --add-port=8502/tcp vi /etc/firewalld/zones/public.xml&lt;port protocol=&quot;tcp&quot; port=&quot;8502&quot;/&gt;systemctl restart firewalld.servicefirewall 配置The configuration for firewalld is stored in various XML filesin /usr/lib/firewalld and /etc/firewalld注意：以下firewalld 的操作只有重启之后才有效：service firewalld restart1、系统配置目录1/usr/lib/firewalld/services目录中存放定义好的网络服务和端口参数，系统参数，不能修改。2、用户配置目录1/etc/firewalld/3、如何自定义添加端口用户可以通过修改配置文件的方式添加端口，也可以通过命令的方式添加端口，注意：修改的内容会在/etc/firewalld/目录下的配置文件中体现。3.1、 命令的方式添加端口：1firwall-cmd --permanent --add-port=9527/tcp参数介绍：firwall-cmd：是Linux提供的操作firewall的一个工具；–permanent：表示设置为持久；–add-port：标识添加的端口；另外，firewall中有Zone的概念，可以将具体的端口制定到具体的zone配置文件中。例如：添加8010端口1firewall-cmd --zone=public --permanent --add-port=8010/tcp--zone=public：指定的zone为public；如果–zone=dmz 这样设置的话，会在dmz.xml文件中新增一条。3.2、修改配置文件的方式添加端口12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;zone&gt; &lt;short&gt;Public&lt;/short&gt; &lt;description&gt;For use in public areas.&lt;/description&gt; &lt;br&gt;&lt;rule family=\"ipv4\"&gt; &lt;br&gt; &lt;source address=\"122.10.70.234\"/&gt; &lt;br&gt; &lt;port protocol=\"udp\" port=\"514\"/&gt; &lt;br&gt; &lt;accept/&gt; &lt;br&gt;&lt;/rule&gt;&lt;rule family=\"ipv4\"&gt; &lt;source address=\"123.60.255.14\"/&gt; &lt;port protocol=\"tcp\" port=\"10050-10051\"/&gt; &lt;accept/&gt; &lt;/rule&gt; &lt;rule family=\"ipv4\"&gt; &lt;source address=\"192.249.87.114\"/&gt; 放通指定ip，指定端口、协议 &lt;port protocol=\"tcp\" port=\"80\"/&gt; &lt;accept/&gt; &lt;/rule&gt;&lt;rule family=\"ipv4\"&gt; 放通任意ip访问服务器的9527端口 &lt;port protocol=\"tcp\" port=\"9527\"/&gt; &lt;accept/&gt; &lt;/rule&gt;&lt;/zone&gt;上述的一个配置文件可以很好的看出：添加需要的规则，开放通源ip为122.10.70.234，端口514，协议tcp；开放通源ip为123.60.255.14，端口10050-10051，协议tcp；开放通源ip为任意，端口9527，协议tcp；4、firewall常用命令重启、关闭、开启、firewalld.serverice 服务123456789101112131415Service firewalld restart 重启Service firewalld start 开启Service firewalld stop 关闭systemctl status firewalldsystemctl stop firewalld 关闭systemctl start firewalld 开启systemctl restart firewalld 重启systemctl disable firewalld 关闭开机启动查看状态1firewall-cmd --state查看防火墙规则1firewall-cmd --list-all5、Centos 切换为iptables防火墙切换到iptables首先应该关掉默认的firewalld，然后安装iptables服务。关闭firewall：1service firewalld stop systemctl disable firewalld.service #禁止firewall开机启动安装iptables防火墙1yum install iptables-services #安装编辑iptables防火墙配置1vi /etc/sysconfig/iptables #编辑防火墙配置文件下边是一个完整的配置文件：12345678910Firewall configuration written by system-config-firewall Manual customization of this file is not recommended. *filter :INPUT ACCEPT [0:0] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [0:0] -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT -A INPUT -p icmp -j ACCEPT -A INPUT -i lo -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 80 -j ACCEPT -A INPUT -m state --state NEW -m tcp -p tcp --dport 3306 -j ACCEPT -A INPUT -j REJECT --reject-with icmp-host-prohibited -A FORWARD -j REJECT --reject-with icmp-host-prohibited COMMIT:wq! #保存退出12service iptables start #开启systemctl enable iptables.service #设置防火墙开机启动","categories":[{"name":"Linux","slug":"Linux","permalink":"https://me.obey.fun/categories/Linux/"},{"name":"Centos","slug":"Linux/Centos","permalink":"https://me.obey.fun/categories/Linux/Centos/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"https://me.obey.fun/tags/Linux/"},{"name":"Centos7","slug":"Centos7","permalink":"https://me.obey.fun/tags/Centos7/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://me.obey.fun/categories/Linux/"},{"name":"Centos","slug":"Linux/Centos","permalink":"https://me.obey.fun/categories/Linux/Centos/"}]},{"title":"Linux入门","slug":"Linux入门","date":"2019-12-04T12:57:28.000Z","updated":"2019-12-05T13:36:46.243Z","comments":true,"path":"Linux入门.html","link":"","permalink":"https://me.obey.fun/Linux入门.html","excerpt":"","text":"Linux 入门Linux 概述Unix 介绍UNIX操作系统（尤尼斯），是一个强大的多用户、多任务操作系统，支持多种处理器架构，按照操作系统的分类，属于分时操作系统，最早由KenThompson、Dennis Ritchie和Douglas McIlroy于1969年在AT&amp;T的贝尔实验室开发。目前它的商标权由国际开放标准组织所拥有，只有符合单一UNIX规范的UNIX系统才能使用UNIX这个名称，否则只能称为类UNIX（UNIX-like）。Linux 介绍Linux是一套免费使用和自由传播的类Unix操作系统，是一个基于POSIX和Unix的多用户、多任务、支持多线程和多CPU的操作系统。伴随着互联网的发展，Linux得到了来自全世界软件爱好者、组织、公司的支持。它除了在服务器操作系统方面保持着强劲的发展势头以外，在个人电脑、嵌入式系统上都有着长足的进步。使用者不仅可以直观地获取该操作系统的实现机制，而且可以根据自身的需要来修改完善这个操作系统，使其最大化地适应用户的需要。Linux不仅系统性能稳定，而且是开源软件。其核心防火墙组件性能高效、配置简单，保证了系统的安全。在很多企业网络中，为了追求速度和安全，Linux操作系统不仅仅是被网络运维人员当作服务器使用，Linux既可以当作服务器，又可以当作网络防火墙是Linux的 一大亮点。Linux与其他操作系统相比 ，具有开放源码、没有版权、技术社区用户多等特点 ，开放源码使得用户可以自由裁剪，灵活性高，功能强大，成本低。尤其系统中内嵌网络协议栈 ，经过适当的配置就可实现路由器的功能。这些特点使得Linux成为开发路由交换设备的理想开发平台Linux 的历史Linux操作系统的诞生、发展和成长过程始终依赖着五个重要支柱：Unix操作系统、MINIX操作系统、GNU计划、POSIX标准和Internet网络。20世纪80年代，计算机硬件的性能不断提高，PC的市场不断扩大，当时可供计算机选用的操作系统主要有Unix、DOS和MacOS这几种。Unix价格昂贵，不能运行于PC；DOS显得简陋，且源代码被软件厂商严格保密；MacOS是一种专门用于苹果计算机的操作系统。此时，计算机科学领域迫切需要一个更加完善、强大、廉价和完全开放的操作系统。由于供教学使用的典型操作系统很少，因此当时在荷兰当教授的美国人AndrewS.Tanenbaum编写了一个操作系统，名为MINIX，为了向学生讲述操作系统内部工作原理。MINIX虽然很好，但只是一个用于教学目的的简单操作系统，而不是一个强有力的实用操作系统，然而最大的好处就是公开源代码。全世界学计算机的学生都通过钻研MINIX源代码来了解电脑里运行的MINIX操作系统，芬兰赫尔辛基大学大学二年级的学生Linus Torvalds就是其中一个，在吸收了MINIX精华的基础上，Linus于1991年写出了属于自己的Linux操作系统，版本为Linux0.01，是Linux时代开始的标志。他利用Unix的核心，去除繁杂的核心程序，改写成适用于一般计算机的x86系统，并放在网络上供大家下载，1994年推出完整的核心Version1.0，至此，Linux逐渐成为功能完善、稳定的操作系统，并被广泛使用。Linux 系统的应用服务器系统：Web应用服务器、数据库服务器、接口服务器、DNS、FTP等等；嵌入式系统：路由器、防火墙、手机PDA、IP分享器、交换器、家电用品的微电脑控制器等等，高性能运算、计算密集型应用；Linux有强大的运算能力。桌面应用系统移动手持系统Linux 的版本Linux的版本分为两种：内核版本和发行版本。内核版本是指在linus领导下的内核小组开发维护的系统内核的版本号。发行版本是一些组织和公司根据自己发行版的不同而自定的。Linux 的主流版本Linux MintLinux Mint是一个基于Ubuntu的发行版，最早于2006年由居住在爱尔兰的法国出生的IT专家Clement Lefebvre发布。最初维护一个专门为新Linux用户提供帮助，技巧和文档的Linux网站，笔者看到了开发Linux发行版的必要性，该发行版致力于解决那些技术性较强的产品的使用问题，让它们更易于使用。在他的网站上向访问者征求反馈意见之后，他继续把许多人提到的“改进的Ubuntu”或“Ubuntu完善版”的东西建立起来。注：Ubuntu就是以易用，对新手友好著称的。可想而知Mint的目标更进一步，让Linux更加的贴近了普通用户。但是，Linux Mint不仅仅是一个具有新的应用程序和更新的桌面主题的Ubuntu。自开始以来，开发人员一直在增加各种Mint下的图形工具以提高可用性;这包括mintDesktop – 用于配置桌面环境的实用程序，mintMenu – 一个新的，优雅的菜单结构，以方便导航，mintInstall – 一个易于使用的软件安装程序，mintUpdate – 一个软件更新程序，提供了一些更突出的几个工具和数百个额外的改进。该项目还开发了很多替代的专有程序以避免一些潜在的法律版权问题，其中包括专利和专利设计的多媒体编解码器，这些编解码器在很多发行版中通常是不存在的。因此，Mint在易用性方面的声誉得到了进一步的加强，也许Linux Mint的最佳特性之一就是开发人员倾听用户的意见，并总是快速地实施好的建议。因为Linux Mint是可以免费下载，因此该项目通过捐赠，广告和专业支持服务获得收入。它没有固定的发布时间表或者计划的功能列表，但是在每个Ubuntu长期支持版本发布几周后，可以预期Linux Mint的新版本。除Mint的MATE和Cinnamon桌面两个主要版本之外，该项目还使用包括KDE和Xfce在内的其他桌面版本构建版本。这些版本通常在两个“主要”版本几周后完成，有时可能会缺少一些主要分支中中的一些“Mint”工具和其他功能。 Mint系列的另一个版本是基于Debian稳定版分支的“Debian版”。 Linux Mint的Debian版本提供了非常稳定的基础，而桌面软件包的更新速度比Mint的“主要分支”版本更快。 Linux Mint不适用软件自由原则，也不会发布安全公告。优点：精心整理的内部开发的“Mint”工具，数百个用户友好的增强功能，包含多媒体编解码器缺点：“社区”版本，因此可能并不总是包含最新的功能。另外，项目不会发布安全建议软件包管理： mintInstall包管理器,使用DEB包（与Ubuntu兼容）可用的版本：“主”版本（MATE和Cinnamon桌面），“社区”版本（KDE和Xfce桌面），Linux Mint“Debian”版本（MATE或Cinnamon桌面）UbuntuUbuntu的推出是在2004年9月首次宣布的。尽管这个项目在Linux发行版中是一个相对较新的，但是它的邮件列表很快就被热情的用户和开发人员所占领。随后的几年中，Ubuntu发展成为最受欢迎的桌面Linux发行版，并为开发易于使用和免费的桌面操作系统做出了巨大贡献，该操作系统成为市场上专有桌面操作系统强有力的竞争者。Ubuntu成功的原因是什么？首先，这个项目是由南非千万富翁，前Debian开发人员和全球第二位太空游客Mark Shuttleworth共同创建的，该公司是位于马恩岛的Canonical Ltd公司，目前正在为该项目提供资金。其次，Ubuntu从其他类似项目的错误中吸取教训，并从一开始就避免了这些错误 – 它创建了一个优秀的基于Web的基础架构，其中包含Wiki风格的文档，创造性的bug报告功能以及专业的管理方法。第三，由于其富有的创始人，Ubuntu能够向所有感兴趣的用户免费发送CD，从而有助于分发的快速普及。在技术方面，Ubuntu基于Debian“Sid”（不稳定分支），但是使用的是GNOME，Firefox和LibreOffice等一些著名软件包的最新版本。它使用称为“Unity”独创的用户界面。它具有可预测的6个月发布时间表，外加一个长期支持（LTS）版本，支持5年的安全更新，具体取决于版本（非LTS版本支持9个月）。 Ubuntu的其他特殊功能包括可安装的Live DVD，独占应用和桌面主题，Windows用户的迁移助理，支持3D桌面效果等最新技术，为ATI和NVIDIA图形卡以及无线网络轻松安装专有设备驱动程序，并为非免费或专利设计的媒体编解码器提供按需支持。优点：固定发布周期和支持期; 具有5年安全更新的长期支持（LTS）变体;新手友好; 丰富的文档，官方和用户无私贡献缺点：与Debian有一定的兼容性问题; 频繁的重大更新可能流失一些用户，Unity用户界面被批评为更适合移动设备，而不是电脑; 非LTS版本只有9个月的安全支持软件包管理：使用DEB包的高级包工具（APT）其他衍生版：Ubuntu，Kubuntu，Xubuntu，Lubuntu，Ubuntu GNOME，Ubuntu MATE，Ubuntu Budgie，Ubuntu Kylin，适用于64位（x86_64）处理器的Ubuntu Studio;基于Ubuntu的发行版： Linux Mint (桌面版本), elementary OS (桌面版本), Zorin OS (桌面版本), Pinguy OS (桌面版本),Trisquel GNU/Linux (自由软件), Bodhi Linux (Enlightenment桌面)Debian GNU/LinuxDebian GNU / Linux于1993年首次公布。它的创始人Ian Murdock的初始想法是在空闲时间创建一个由数百名志愿者开发的完全非商业项目。当时怀疑论者远远超过乐观主义者，似乎注定要夭折收尾，但实际情况却恰恰相反。 Debian不仅幸存下来，而且还在不到十年的时间里成为了最大的Linux发行版，也是有史以来创建的最大的协作软件项目！Debian GNU / Linux的成功可以用下面的数字来说明。它由1000多名志愿者开发，它的软件库包含近50,000个二进制包（编译为8个处理器架构），有120个基于Debian的发行版和live CD。这些数字是任何其他基于Linux的操作系统无法比拟的。 Debian主要有三个主要分支（或四个，如果包括增加稳定性的“实验”分支）：“unstable”（也称为“sid”），“testing”和“stable ”。软件包和功能的逐步整合和稳定性，以及项目完善的质量控制机制，使得Debian获得了今天可用的最佳测试和无缺陷发行版之一的声誉。然而，这种冗长而复杂的开发风格也有一些缺点：Debian的稳定版本并不是特别新，特别是因为新的稳定版本每1 – 3年才会发布一次。那些喜欢最新软件包和技术的用户被迫使用Debian testing(测试)或unstable(不稳定)分支。 Debian高度民主的结构导致了有争议的决定，并引发了开发者之间的分歧。这导致了项目的停滞不前，没有能将项目快速推进。优点：非常稳定;卓越的质量控制;包括超过30,000个软件包;支持比任何其他Linux发行版更多的处理器体系结构缺点：保守 – 由于支持许多处理器架构，并不总是包含更新的技术;缓释周期（每1 – 3年稳定释放一次）;对开发者邮件列表和博客的讨论有时是不可能的软件包管理：使用DEB包的高级包工具（APT）可用的版本：12个处理器架构的安装CD/DVD和live CD映像，包括来自Intel，AMD，Power和其他所有32位和64位处理器基于Debian的替代方案：Ubuntu, SparkyLinux(Enlightenment, JWM, LXDE, MATE, Openbox, Razor-qt, Xfce桌面), SolydXK (Xfce或KDE), KNOPPIX (LXDE), Tanglu(GNOME, KDE), siduction (LXQt)MageiaMageia可能是这个列表中的最新发行版，但它的来源可以追溯到1998年7月，当时GalDuval发布了Mandrake Linux。当时它只是一个红帽Linux的分支，KDE作为默认的桌面，更完善的硬件支持和一些用户友好的功能，加上媒体的积极评论，它获得了一定的知名度。Mandrake Linux后来变成了一个商业版本，并在2010年几乎破产之前更名为Mandriva（为了避免一些与商标有关的麻烦，并纪念与巴西的Conectiva合并），最终由一家俄罗斯风险投资公司拯救了，新管理层因为巨大的开支而决定在该公司巴黎总部裁减大部分的Mandriva开发人员。在没有工作的情况下，他们决定组建一个Mageia，这个社区项目是Mandrake和Mandriva的核心延续，或许比Mandriva本身更为合理。Mageia主要是一个桌面版本。其最受欢迎的功能是最优秀的软件应用，精良的系统管理套件（Mageia控制中心），吸引了大量志愿者贡献者以及广泛的国际化支持。它具有最简单但功能强大的系统安装程序之一，同时还可以使用KDE或GNOME桌面和全面的语言支持。而且可以来直接从桌面安装系统，无需刻录到U盘。该发行版具有良好的软件包管理功能，具有强大的命令行选项和图形化软件管理模块，可以轻松访问数千个软件包。独特的Mageia控制中心随着每个版本的不断改进，为Linux的新手提供了一个强大的工具来配置他们的计算机的任何方面，而无需使用终端命令行。尽管Mageia自2010年9月成立以来一直处于起步阶段，但仍有人担心其是否有能力维持长期开发的工作，毕竟大部分工作是由志愿者在完成的。此外，它缺乏一些更大的Linux发行版的完善的基础架构。项目的文档也需要做一些改进，而9个月的发布周期在引起新闻和媒体兴趣方面也可以被视为一个缺点，特别是与其他使用6个月的短期开发过程的主要发行版相比。优点：适合初学者;优秀的中央配置工具;支持数十种语言的开箱即用支持;可安装的Live镜像缺点：与Mandriva分开之后，缺乏声誉和资源，有人担心开发者没有能力长期维持开发软件包管理：使用RPM软件包，Rpmdrake（URPMI的图形前端）的URPMI包管理器可用版本：用于32位（i586）和64位（x86_64）处理器的安装DVD;可安装32位（i586）处理器的live CDFedora虽然Fedora仅在2004年9月才正式发布，但它的起源可追溯到1995年，当时它是由Bob Young和Marc Ewing以Red Hat Linux的名义发布的。该公司的第一款产品Red Hat Linux 1.0“母亲节”在同一年发布，之后很快又进行了一些错误修复更新。 1997年，红帽公司推出了革命性的RPM软件包管理系统，具有依赖解决方案和其他先进功能，极大地促进了分发的迅速普及并超越Slackware Linux成为世界上使用最广泛的Linux发行版。在以后的几年中，红帽将按照正常的6个月发布时间表进行开发。在2003年刚发布Red Hat Linux 9之后，该公司对其产品系列进行了一些根本性的改变。它保留了红帽商业产品的商标，特别是红帽企业Linux，并引入了Fedora Core（后来改名为Fedora），这是一个红帽赞助的，但面向社区的发行版，专为“Linux爱好者”设计。从刚开始的批评后，Linux社区接受了“新的”发行版作为Red Hat Linux的核心延续版本。 Fedora重新成为一个高质量的版本，成为市场上最受欢迎的操作系统之一。与此同时，红帽公司迅速成为全球规模最大，盈利能力最强的Linux公司，拥有创新的产品阵容，出色的客户支持以及红帽认证工程师（RHCE）认证计划等其他受欢迎的计划。尽管Fedora的方向仍然由Red Hat，Inc.主要控制，并且该产品有时被看作是对红帽企业Linux的测试平台(小白鼠)，无论是正确的还是错误的，无可否认，Fedora是最具创新性的分发版之一。它对Linux内核，glibc和GCC的贡献是众所周知的，它最近集成了SELinux功能，虚拟化技术，系统服务管理器，先进的日志文件系统以及其他企业级功能， 。不利的一面是，Fedora仍然缺乏明确的面向桌面的策略，以使产品更容易用于“Linux爱好者”目标以外的用户。优点：高度创新;突出的安全功能;大量支持的软件包;严格遵守自由软件的理念;具有许多流行桌面环境的Live CD的可用性缺点：Fedora的优先级倾向于倾向于企业功能，而不是桌面可用性;一些出色的边缘功能，比如早期切换到KDE 4和GNOME 3，偶尔会疏远一些桌面用户软件包管理：使用RPM软件包的YUM图形和命令行工具可用的版本：用于32位（i386）和64位（x86_64）处理器的Fedora;还有GNOME，KDE，LXDE，MATE和Xfce桌面的CD版本CentOSCentOS于2003年底推出，是一个社区项目，目标是将红帽企业Linux（RHEL）的源代码重建为可安装的Linux发行版，并为所有包含的软件包提供及时的安全更新。更直白地说，CentOS是一个RHEL克隆版。这两个发行版之间唯一的技术差异就是品牌 – CentOS用自己的所有代码取代了所有的红帽商标和标识。尽管如此，红帽与CentOS之间的关系仍然保持友好，许多CentOS开发者与Red Hat保持着紧密的联系，甚至直接受雇于Red Hat。CentOS经常被看作是一个可靠的服务器发行版。它配备了经过良好测试和稳定的Linux内核和软件包，构成了其母公司Red Hat Enterprise Linux的基础。尽管是志愿者维护的一个社区项目，但它已经赢得了市场上更高端服务器产品（尤其是经验丰富的Linux系统管理员）的稳定，免费替代品的声誉。 CentOS也适合作为企业桌面解决方案，特别是在稳定性，可靠性和长期支持优于最新软件和功能的地方。像RHEL一样，CentOS支持大约7 – 10年的安全更新。尽管有其优势，CentOS可能不是所有部署方案中的最佳解决方案。那些喜欢使用最新的Linux技术和最新的软件包进行发布的用户应该到别处去看看。主要的CentOS版本是在RHEL版本的基础上发布的，每2 – 3年才会发布一次，而小版本（例如5.1）则以6到9个月为间隔。小发行通常不包含任何主要功能（虽然有时包括支持更新的硬件），只有少数软件包可能会更新到新版本。 Linux内核，基本系统和大多数应用程序版本保持不变，但偶尔也可以在试验的基础上提供重要软件包（例如LibreOffice或Firefox）的新版本。当然也有一个分支项目，CentOS也为其发行版的用户构建了更新的软件包，但是包含它们的软件库默认是不启用的，因为它们可能会破坏上游的兼容性。优点：非常稳定和可靠;免费下载和使用;有7年以上的免费安全更新;缺点：缺乏最新的Linux技术;有时该项目未能履行其及时提供安全更新和新稳定版本的承诺软件包管理：使用RPM软件包的YUM图形和命令行工具可用版本：用于i386和x86_64处理器的安装DVD和可安装的Live CD（GNOME）;旧版本（3.x和4.x）也可用于Alpha，IA64和IBM z系列（s390，s390x）处理器。其他RHEL克隆和基于CentOS的发行版：Scientific Linux，Springdale Linux，SME服务器，Rocks Cluster Distribution，Oracle Enterprise LinuxPCLinuxOSPCLinuxOS于2003年由比尔·雷诺兹（Bill Reynolds）首先宣布，被称为“Texstar”。在创建自己的发行版之前，Texstar已经是Mandrake Linux社区用户的知名开发人员构建的最新的RPM包，并提供免费下载。 2003年，他决定建立一个新的发行版，最初基于Mandrake Linux，但有几个显著的可用性改进。理念是应该对初学者是友好的，具有专有内核模块，浏览器插件和媒体编解码器的开箱即用的支持，并应作为一个简单直观的图形安装程序的Live CD。几年后的发展，PCLinuxOS正在迅速接近其预期的状态。就可用性而言，该项目为大多数Windows到Linux移民希望从他们的新操作系统中获得的许多技术提供了开箱即用的支持。在软件方面，PCLinuxOS是一个面向KDE的发行版，具有定制且始终最新版本的流行桌面环境。不断增长的软件存储库包含其他桌面，并为许多常见任务提供各种各样的桌面软件包。对于系统配置，PCLinuxOS保留了很多Mandriva优秀的控制中心，但是用APT和Synaptic（一个图形化的包管理前端）取代了它的包管理系统。不利的一面是，PCLinuxOS缺乏任何形式的路线图或发布目标。尽管越来越多的社区参与这个项目，大多数的发展和决策仍然掌握在Texstar的手中，他们在判断发布的稳定性时倾向于保守的一面。因此，PCLinuxOS的开发过程往往是艰巨的。例如，尽管频繁要求64位版本，但开发者直到最近才开始生产64位版本。此外，该项目不提供任何安全建议，而是依靠用户通过所包括的管理工具保持系统最新的状态。优点：对图形驱动程序，浏览器插件和媒体编解码器的开箱即用支持;滚动更新机制;最新的软件缺点：对非英语语言没有开箱即用的支持;缺乏发布计划和安全建议软件包管理：使用RPM包的高级包工具（APT）可用的版本：KDE，完整的Monty，KDE Minime，LXDE，LXDE Mini，Openbox，Openbox盆景，用于64位（x86_64）处理器体系结构的KDELinux 目录结构/root — 启动Linux时使用的一些核心文件。如操作系统内核、引导程序Grub等。home — 存储普通用户的个人文件ftp — 用户所有服务httpdsambauser1user2bin — 系统启动时需要的执行文件（二进制）sbin — 可执行程序的目录，但大多存放涉及系统管理的命令。只有root权限才能执行proc — 虚拟，存在linux内核镜像；保存所有内核参数以及系统配置信息1 — 进程编号usr — 用户目录，存放用户级的文件bin — 几乎所有用户所用命令，另外存在与/bin，/usr/local/binsbin — 系统管理员命令，与用户相关，例如，大部分服务器程序include — 存放C/C++头文件的目录lib — 固定的程序数据local — 本地安装软件保存位置man — 手工生成的目录info — 信息文档doc — 不同包文档信息tmpX11R6 — 该目录用于保存运行X-Window所需的所有文件。该目录中还包含用于运行GUI要的配置文件和二进制文件。X386 — 功能同X11R6，X11 发行版5 的系统文件boot — 引导加载器所需文件，系统所需图片保存于此lib — 根文件系统目录下程序和核心模块的公共库modules — 可加载模块，系统崩溃后重启所需模块dev — 设备文件目录etc — 配置文件skel — home目录建立，该目录初始化sysconfig — 网络，时间，键盘等配置目录varfilelib — 该目录下的文件在系统运行时，会改变local — 安装在/usr/local的程序数据，变化的lock — 文件使用特定外设或文件，为其上锁，其他文件暂时不能访问log — 记录日志run — 系统运行合法信息spool — 打印机、邮件、代理服务器等假脱机目录tmpcatman — 缓存目录mnt — 临时用于挂载文件系统的地方。一般情况下这个目录是空的，而在我们将要挂载分区时在这个目录下建立目录，再将我们将要访问的设备挂载在这个目录上，这样我们就可访问文件了。tmp — 临时文件目录，系统启动后的临时文件存放在/var/tmplost+found — 在文件系统修复时恢复的文件/：根目录，一般根目录下只存放目录，不要存放文件，/etc、/bin、/dev、/lib、/sbin应该和根目录放置在一个分区中/bin:/usr/bin:可执行二进制文件的目录，如常用的命令ls、tar、mv、cat等。/boot：放置linux系统启动时用到的一些文件。/boot/vmlinuz为linux的内核文件，以及/boot/gurb。建议单独分区，分区大小100M即可/dev：存放linux系统下的设备文件，访问该目录下某个文件，相当于访问某个设备，常用的是挂载光驱mount /dev/cdrom /mnt。/etc：系统配置文件存放的目录，不建议在此目录下存放可执行文件，重要的配置文件有/etc/inittab、/etc/fstab、/etc/init.d、/etc/X11、/etc/sysconfig、/etc/xinetd.d修改配置文件之前记得备份。注：/etc/X11存放与x windows有关的设置。/home：系统默认的用户家目录，新增用户账号时，用户的家目录都存放在此目录下，~表示当前用户的家目录，~test表示用户test的家目录。建议单独分区，并设置较大的磁盘空间，方便用户存放数据/lib:/usr/lib:/usr/local/lib：系统使用的函数库的目录，程序在执行过程中，需要调用一些额外的参数时需要函数库的协助，比较重要的目录为/lib/modules。/lost+fount：系统异常产生错误时，会将一些遗失的片段放置于此目录下，通常这个目录会自动出现在装置目录下。如加载硬盘于/disk 中，此目录下就会自动产生目录/disk/lost+found/mnt:/media：光盘默认挂载点，通常光盘挂载于/mnt/cdrom下，也不一定，可以选择任意位置进行挂载。/opt：给主机额外安装软件所摆放的目录。如：FC4使用的Fedora 社群开发软件，如果想要自行安装新的KDE 桌面软件，可以将该软件安装在该目录下。以前的 Linux 系统中，习惯放置在 /usr/local 目录下/proc：此目录的数据都在内存中，如系统核心，外部设备，网络状态，由于数据都存放于内存中，所以不占用磁盘空间，比较重要的目录有/proc/cpuinfo、/proc/interrupts、/proc/dma、/proc/ioports、/proc/net/*等/root：系统管理员root的家目录，系统第一个启动的分区为/，所以最好将/root和/放置在一个分区下。/sbin:/usr/sbin:/usr/local/sbin：放置系统管理员使用的可执行命令，如fdisk、shutdown、mount等。与/bin不同的是，这几个目录是给系统管理员root使用的命令，一般用户只能”查看”而不能设置和使用。/tmp：一般用户或正在执行的程序临时存放文件的目录,任何人都可以访问,重要数据不可放置在此目录下/srv：服务启动之后需要访问的数据目录，如www服务需要访问的网页数据存放在/srv/www内/usr：应用程序存放目录，/usr/bin存放应用程序，/usr/share存放共享数据，/usr/lib存放不能直接运行的，却是许多程序运行所必需的一些函数库文件。/usr/local:存放软件升级包。/usr/share/doc:系统说明文件存放目录。/usr/share/man: 程序说明文件存放目录，使用 man ls时会查询/usr/share/man/man1/ls.1.gz的内容建议单独分区，设置较大的磁盘空间/var：放置系统执行过程中经常变化的文件，如随时更改的日志文件/var/log，/var/log/message：所有的登录文件存放目录，/var/spool/mail：邮件存放的目录，/var/run:程序或服务启动后，其PID存放在该目录下。建议单独分区，设置较大的磁盘空间Linux 的常用命名磁盘管理ls 命令ls（list）功能：列出目录内容格式：ls [参数] [文件或目录]-a或–all &emsp; 显示所有文件和目录。注意隐藏文件、特殊目录、. 和 .. 。-l &emsp; 使用详细格式列表，ls -l 可简化成 ll 。-t &emsp; 用文件和目录的更改时间排序。-r &emsp; 反向排序–help &emsp; 在线帮助cd 命令cd（change directory）功能：切换目录语法：cd [目录]常用cd ~ ,切换到当前用户目录cd / ,切换到根目录cd - ,切换到上一次访问的目录cd .. ,切换到上一级目录cd ,切换到缺省当前用户目录pwd 命令pwd（print working directory）功能：显示工作目录mkdir 命令mkdir（make directory）功能：创建目录-p &emsp; 父目录不存在情况下先生成父目录（parents）-v &emsp; 显示命令执行过程中的详细信息文件管理 - 文件浏览cat 命令cat（catenate）功能：显示文本文件内容语法：cat [文件] ,显示指定文件的所有内容more 命令more功能：分页显示文件内容，还支持直接跳转行等功能。语法：more file操作Enter &emsp; 向下n行，需要定义。默认1行空格键 &emsp; 向下滚动一屏 或 Ctrl+FB &emsp; 返回上一页 或 Ctrl+Bq &emsp; 退出moreless 命令less 功能：分页显示文件内容，操作更详细。语法：less[参数] 文件-m &emsp; 显示类似 more 命令的百分比-N &emsp; 显示每行的行号操作空格键：前进一页 或 page downb：后退一页 或 page upd：前进半页u：后退半页回车键：前进一行 或 方向键向下y：后退一行 或 方向键向上/字符串：向下搜索？字符串：向上搜索v：进入vim编辑器左右方向键：相当于水平滚动条q：退出tail 命令功能：用于显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。格式：tail[必要参数] [选择参数] [文件]-n&lt;行数&gt; &emsp; 显示行数-f &emsp; 循环读取&amp; 表示后台运行，否则占用终端ctrl+C退出文件管理-文件操作cp 命令cp(copy)功能：复制文件或目录语法：cp [参数] [源文件或目录] [目标文件或目录]-r 或 –recursive 递归处理，将指定目录下的文件与子目录一并处理。mv 命令mv(move)功能：移动或更名现有的文件或目录。语法：mv [源文件或目录] [目标文件或目录]-f 或 –force &emsp; 若目标文件或目录与现有的文件或目录重复，则直接覆盖现有的文件 或 目录。rm 命令rm(remove) rm 功能：删除文件或目录语法：rm[-dfirv] [–help] [–version] [文件或目录…]-f 或 –force &emsp; 强制删除文件或目录-r 或 -R 或 –recursive &emsp; 递归处理，将指定目录下的所有文件及子目录一并处理。find 命令find 功能：查找文件或目录语法：find [目录…] [参数]-name &emsp; 指定字符串作为寻找文件或目录的范本样式。文档编辑vi 或 vim 命令基本操作输入 “vim 文件名” 进入 “一般模式”按下 “i” 从一般模式，进入 “插入模式”按下 “esc” 从 “插入模式” 退出到 “一般模式”在 “一般模式” 下，输入 “：wq”，退出编辑vi 基本概念基本上 vi 可以分为三种状态，分别是命令模式（command mode）、插入模式（insert mode）和底行模式（last line mode），各模式的功能区分如下：命令行模式 command mode控制屏幕光标的移动，字符、字或行的删除，移动复制某区段及进入 inert mode 下，或者到 last line mode。插入模式（insert mode）只有在 insert mode 下，才可以做文字输出，按 [ESC] 键可回到命令行模式。底行模式（last line mode）将文件保存或退出 vi，也可以设置编辑环境，如寻找字符串、列出行号….等。常用命令分组命令描述&emsp;i在光标前插入&emsp;shift + i在光标当前行开始插入插入a在光标后插入(从一般模式进入到插入模式)shift+a在光标当前行末尾插入&emsp;o在光标当前行的下一行插入新行&emsp;shift+o在光标当前行的上一行插入新行&emsp;&emsp;&emsp;复制或粘贴(在插入模式下)yy单行复制将光标移动到将要复制的行处复制或粘贴(在插入模式下)nyy多行复制将光标移动到将要复制的首行处复制或粘贴(在插入模式下)p粘贴将光标移动到将要粘贴的行处&emsp;&emsp;&emsp;定位gg到文本的第一行定位shift+g到文本的最后一行&emsp;&emsp;&emsp;删除dd删除光标所在行删除ndd删除n行&emsp;&emsp;&emsp;退出:q退出vi（没有做任何修改时）退出:q!强制退出文件退出:w保存不退出退出:wq保存后退出管道 |linux提供管道符号 “|”。作用是 “命令1” 的输出内容，将作为 “命令2” 的输入内容，一般与 grep 命令一起使用。格式： 命令1 | 命令2grep 命令grep 全称是 Global Regular Expression Print,表示全局正则表达式版本功能：用于过滤/搜索的特定字符。可使用正则表达式能多种命令配合使用，使用上十分灵活。格式：grep [option] pattern [file]-i 或 –ignore-case &emsp; #忽略字符大小写的差别系统命令ps 命令功能：ps命令是Process Status的缩写。提供对进程的一次性查看。及执行 ps 命令的那个时刻进程信息格式：ps[参数]-e &emsp; 此参数的效果和指定 “A” 参数相同，显示所有程序-f &emsp; 显示UID,PPIP,C与STIME栏位kill 命令kill功能：删除执行中的程序或工作。语法：kill[参数] [程序]-l&lt;信息编号&gt; &emsp; 若不加&lt;信息编号&gt;选项，则-l参数会列出全部的信息名称。kill -9 &emsp; 表示强制终止ifconfig 命令功能：显示网络设备命令：ifconfigping 命令功能：测试与目标主机的连通性命令：ping 主机名或ip地址备份压缩：tar命令tar功能：文件备份压缩语法：tar命令-c &emsp; 建立一个压缩文件的参数指令（create）–压缩-x &emsp; 解开一个压缩文件的参数指令（extract）–解压-z &emsp; 是否需要用 gzip 压缩-v &emsp; 压缩的过程中显示文件（verbose）-f &emsp; 使用档名，在 f 之后要立即接档名（file）常用解压参数组合：zxvf常用压缩参数组合：zcvf关机重启重启命令：reboot关机命令：halt 立刻关机文件权限：chmod 命令chmod（change mode）功能：变更文件或目录的权限。语法：chmod[参数] [&lt;权限范围&gt;&lt;符号&gt;&lt;权限代号&gt;]-R 或 –recursive 递归处理，将指定目录下的所有文件及目录一并处理。权限范围的表示法如下：u: User,即文件或目录的拥有者。g: Group,即文件或目录的所属群组。o: Other,除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围。a: All，即全部的用户，包含拥有者，所属群组以及其他用户符号：+ &emsp; 添加权限— &emsp; 取消权限有关权限代号的部分，列表于下：r：读取权限，数字代码为 “4”。w：写入权限，数字代号为 “2”。x：执行或切换权限，数字代号为 “1”。-：不具有任何权限，数字代号为 “0”。","categories":[{"name":"Linux","slug":"Linux","permalink":"https://me.obey.fun/categories/Linux/"}],"tags":[{"name":"CentOS","slug":"CentOS","permalink":"https://me.obey.fun/tags/CentOS/"},{"name":"Ubuntu","slug":"Ubuntu","permalink":"https://me.obey.fun/tags/Ubuntu/"}],"keywords":[{"name":"Linux","slug":"Linux","permalink":"https://me.obey.fun/categories/Linux/"}]},{"title":"基于Session的认证授权","slug":"基于Session的认证授权","date":"2019-10-18T04:16:05.000Z","updated":"2019-10-19T02:24:20.000Z","comments":true,"path":"基于Session的认证授权.html","link":"","permalink":"https://me.obey.fun/基于Session的认证授权.html","excerpt":"","text":"基本概念什么是认证进入移动互联网时代，大家每天都在刷手机，常用的软件有微信、支付宝、头条等，下边拿微信来举例子说明认证相关的基本概念，在初次使用微信前需要注册成为微信用户，然后输入账号和密码即可登录微信，输入账号和密码登录微信的过程就是认证。系统为什么要认证？认证是为了保护系统的隐私数据与资源，用户的身份合法方可访问该系统的资源。认证 ：用户认证就是判断一个用户的身份是否合法的过程，用户去访问系统资源时系统要求验证用户的身份信息，身份合法方可继续访问，不合法则拒绝访问。常见的用户身份认证方式有：用户名密码登录，二维码登录，手机短信登录，指纹认证等方式。什么是会话用户认证通过后，为了避免用户的每次操作都进行认证可将用户的信息保证在会话中。会话就是系统为了保持当前用户的登录状态所提供的机制，常见的有基于session方式、基于token方式等。基于session的认证方式如下图：它的交互流程是，用户认证成功后，在服务端生成用户相关的数据保存在session(当前会话)中，发给客户端的sesssion_id 存放到 cookie中，这样用户客户端请求时带上 session_id 就可以验证服务器端是否存在 session 数据，以此完成用户的合法校验，当用户退出系统或session过期销毁时,客户端的session_id也就无效了。基于token方式如下图：它的交互流程是，用户认证成功后，服务端生成一个token发给客户端，客户端可以放到 cookie 或 localStorage等存储中，每次请求时带上 token，服务端收到token通过验证后即可确认用户身份。什么是授权还拿微信来举例子，微信登录成功后用户即可使用微信的功能，比如，发红包、发朋友圈、添加好友等，没有绑定银行卡的用户是无法发送红包的，绑定银行卡的用户才可以发红包，发红包功能、发朋友圈功能都是微信的资源即功能资源，用户拥有发红包功能的权限才可以正常使用发送红包功能，拥有发朋友圈功能的权限才可以使用发朋友圈功能，这个根据用户的权限来控制用户使用资源的过程就是授权。为什么要授权？认证是为了保证用户身份的合法性，授权则是为了更细粒度的对隐私数据进行划分，授权是在认证通过后发生的，控制不同的用户能够访问不同的资源。授权： 授权是用户认证通过根据用户的权限来控制用户访问资源的过程，拥有资源的访问权限则正常访问，没有权限则拒绝访问。授权的数据模型如何进行授权即如何对用户访问资源进行控制，首先需要学习授权相关的数据模型。授权可简单理解为Who对What(which)进行How操作，包括如下：Who，即主体（Subject），主体一般是指用户，也可以是程序，需要访问系统中的资源。 What，即资源（Resource），如系统菜单、页面、按钮、代码方法、系统商品信息、系统订单信息等。系统菜单、页面、按钮、代码方法都属于系统功能资源，对于web系统每个功能资源通常对应一个URL；系统商品信息、系统订单信息都属于实体资源（数据资源），实体资源由资源类型和资源实例组成，比如商品信息为资源类型，商品编号 为001的商品为资源实例。How，权限/许可（Permission），规定了用户对资源的操作许可，权限离开资源没有意义，如用户查询权限、用户添加权限、某个代码方法的调用权限、编号为001的用户的修改权限等，通过权限可知用户对哪些资源都有哪些操作许可。主体、资源、权限关系如下图：主体、资源、权限相关的数据模型如下：主体（用户id、账号、密码、…）资源（资源id、资源名称、访问地址、…）权限（权限id、权限标识、权限名称、资源id、…）角色（角色id、角色名称、…）角色和权限关系（角色 id、权限id、…）主体（用户）和角色关系（用户id、角色id、…）主体（用户）、资源、权限关系如下图：通常企业开发中将资源和权限表合并为一张权限表，如下：资源（资源id、资源名称、访问地址、…）权限（权限id、权限标识、权限名称、资源id、…）合并为：权限（权限id、权限标识、权限名称、资源名称、资源访问地址、…）修改后数据模型之间的关系如下图：RBAC如何实现授权？业界通常基于RBAC实现授权。基于角色的访问控制RBAC基于角色的访问控制（Role-Based Access Control）是按角色进行授权，比如：主体的角色为总经理可以查询企业运营报表，查询员工工资信息等，访问控制流程如下：根据上图中的判断逻辑，授权代码可表示如下：123if(主体.hasRole(\"总经理角色id\"))&#123;查询工资&#125;如果上图中查询工资所需要的角色变化为总经理和部门经理，此时就需要修改判断逻辑为“判断用户的角色是否是总经理或部门经理”，修改代码如下：123if(主体.hasRole(\"总经理角色id\") || 主体.hasRole(\"部门经理角色id\"))&#123; 查询工资&#125;根据上边的例子发现，当需要修改角色的权限时就需要修改授权的相关代码，系统可扩展性差。基于资源的访问控制RBAC基于资源的访问控制（Resource-Based Access Control）是按资源（或权限）进行授权，比如：用户必须具有查询工资权限才可以查询员工工资信息等，访问控制流程如下：根据上图中的判断，授权代码可以表示为：123if(主体.hasPermission(\"查询工资权限标识\"))&#123; 查询工资&#125;优点：系统设计时定义好查询工资的权限标识，即使查询工资所需要的角色变化为总经理和部门经理也不需要修改授权代码，系统可扩展性强。基于Session的认证方式认证流程基于Session认证方式的流程是，用户认证成功后，在服务端生成用户相关的数据保存在session(当前会话)，而发给客户端的 sesssion_id 存放到 cookie 中，这样用客户端请求时带上 session_id 就可以验证服务器端是否存在session 数据，以此完成用户的合法校验。当用户退出系统或session过期销毁时,客户端的session_id也就无效了。下图是session认证方式的流程图：基于Session的认证机制由Servlet规范定制，Servlet容器已实现，用户通过HttpSession的操作方法即可实现，如下是HttpSession相关的操作API。方法含义HttpSession getSession(Boolean create)获取当前HttpSession对象void setAttribute(String name,Object value)向session中存放对象object getAttribute(String name)从session中获取对象void removeAttribute(String name)移除session中对象void invalidate()使HttpSession失效创建工程本案例工程使用maven进行构建，使用SpringMVC、Servlet3.0实现。创建maven工程创建maven工程 security-springmvc，工程结构如下：引入如下依赖如下，注意：1、由于是web工程，packaging设置为war2、使用tomcat7-maven-plugin插件来运行工程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?xml version=\"1.0\" encoding=\"UTF‐8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema‐instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0http://maven.apache.org/xsd/maven‐4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.itheima.security&lt;/groupId&gt; &lt;artifactId&gt;security‐springmvc&lt;/artifactId&gt; &lt;version&gt;1.0‐SNAPSHOT&lt;/version&gt; &lt;packaging&gt;war&lt;/packaging&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF‐8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring‐webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.5.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet‐api&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.18.8&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;finalName&gt;security‐springmvc&lt;/finalName&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7‐maven‐plugin&lt;/artifactId&gt; &lt;version&gt;2.2&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven‐compiler‐plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven‐resources‐plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;encoding&gt;utf‐8&lt;/encoding&gt; &lt;useDefaultDelimiters&gt;true&lt;/useDefaultDelimiters&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;includes&gt; &lt;include&gt;**/*&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt;&lt;/project&gt;Spring 容器配置在config包下定义ApplicationConfig.java，它对应web.xml中ContextLoaderListener的配置1234567@Configuration@ComponentScan(basePackages = \"com.itheima.security.springmvc\" ,excludeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION,value =Controller.class)&#125;)public class ApplicationConfig &#123; //在此配置除了Controller的其它bean，比如：数据库链接池、事务管理器、业务bean等。&#125;servletContext配置本案例采用Servlet3.0无web.xml方式，的config包下定义WebConfig.java，它对应于DispatcherServlet配置。123456789101112131415@Configuration@EnableWebMvc@ComponentScan(basePackages = \"com.itheima.security.springmvc\" ,includeFilters = &#123;@ComponentScan.Filter(type = FilterType.ANNOTATION,value =Controller.class)&#125;)public class WebConfig implements WebMvcConfigurer &#123; //视图解析器 @Bean public InternalResourceViewResolver viewResolver()&#123; InternalResourceViewResolver viewResolver = new InternalResourceViewResolver(); viewResolver.setPrefix(\"/WEB‐INF/views/\"); viewResolver.setSuffix(\".jsp\"); return viewResolver; &#125; &#125;加载 Spring容器在init包下定义Spring容器初始化类SpringApplicationInitializer，此类实现WebApplicationInitializer接口，Spring容器启动时加载WebApplicationInitializer接口的所有实现类。123456789101112131415public class SpringApplicationInitializer extendsAbstractAnnotationConfigDispatcherServletInitializer &#123; @Override protected Class&lt;?&gt;[] getRootConfigClasses() &#123; return new Class&lt;?&gt;[] &#123; ApplicationConfig.class &#125;;//指定rootContext的配置类 &#125; @Override protected Class&lt;?&gt;[] getServletConfigClasses() &#123; return new Class&lt;?&gt;[] &#123; WebConfig.class &#125;; //指定servletContext的配置类 &#125; @Override protected String[] getServletMappings() &#123; return new String [] &#123;\"/\"&#125;; &#125;&#125;SpringApplicationInitializer相当于web.xml，使用了servlet3.0开发则不需要再定义web.xml，ApplicationConfig.class对应以下配置的application-context.xml，WebConfig.class对应以下配置的spring-mvc.xml，web.xml的内容参考：1234567891011121314151617181920212223&lt;web‐app&gt; &lt;listener&gt; &lt;listener‐class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener‐class&gt; &lt;/listener&gt; &lt;context‐param&gt; &lt;param‐name&gt;contextConfigLocation&lt;/param‐name&gt; &lt;param‐value&gt;/WEB‐INF/application‐context.xml&lt;/param‐value&gt; &lt;/context‐param&gt; &lt;servlet&gt; &lt;servlet‐name&gt;springmvc&lt;/servlet‐name&gt; &lt;servlet‐class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet‐class&gt; &lt;init‐param&gt; &lt;param‐name&gt;contextConfigLocation&lt;/param‐name&gt; &lt;param‐value&gt;/WEB‐INF/spring‐mvc.xml&lt;/param‐value&gt; &lt;/init‐param&gt; &lt;load‐on‐startup&gt;1&lt;/load‐on‐startup&gt; &lt;/servlet&gt; &lt;servlet‐mapping&gt; &lt;servlet‐name&gt;springmvc&lt;/servlet‐name&gt; &lt;url‐pattern&gt;/&lt;/url‐pattern&gt; &lt;/servlet‐mapping&gt;&lt;/web‐app&gt;实现认证功能认证页面在webapp/WEB-INF/views下定义认证页面login.jsp，本案例只是测试认证流程，页面没有添加css样式，页面实现可填入用户名，密码，触发登录将提交表单信息至/login，内容如下：1234567891011121314&lt;%@ page contentType=\"text/html;charset=UTF‐8\" pageEncoding=\"utf‐8\" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;用户登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=\"login\" method=\"post\"&gt; 用户名：&lt;input type=\"text\" name=\"username\"&gt;&lt;br&gt; 密&amp;nbsp;&amp;nbsp;&amp;nbsp;码: &lt;input type=\"password\" name=\"password\"&gt;&lt;br&gt; &lt;input type=\"submit\" value=\"登录\"&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;在WebConfig中新增如下配置，将/直接导向login.jsp页面：1234@Overridepublic void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController(\"/\").setViewName(\"login\");&#125;启动项目，访问/路径地址，进行测试认证接口用户进入认证页面，输入账号和密码，点击登录，请求/login进行身份认证。（1）定义认证接口，此接口用于对传来的用户名、密码校验，若成功则返回该用户的详细信息，否则抛出错误异常：1234567891011/** * 认证服务 */public interface AuthenticationService &#123; /** * 用户认证 * @param authenticationRequest 用户认证请求 * @return 认证成功的用户信息 */ UserDto authentication(AuthenticationRequest authenticationRequest);&#125;认证请求结构：1234567891011@Datapublic class AuthenticationRequest &#123; /** * 用户名 */ private String username; /** * 密码 */ private String password;&#125;认证成功后返回的用户详细信息，也就是当前登录用户的信息：123456789101112/** * 当前登录用户信息 */@Data@AllArgsConstructorpublic class UserDto &#123; private String id; private String username; private String password; private String fullname; private String mobile;&#125;（2）认证实现类，根据用户名查找用户信息，并校验密码，这里模拟了两个用户：1234567891011121314151617181920212223242526272829@Servicepublic class AuthenticationServiceImpl implements AuthenticationService&#123; @Override public UserDto authentication(AuthenticationRequest authenticationRequest) &#123; if(authenticationRequest == null || StringUtils.isEmpty(authenticationRequest.getUsername()) || StringUtils.isEmpty(authenticationRequest.getPassword()))&#123; throw new RuntimeException(\"账号或密码为空\"); &#125; UserDto userDto = getUserDto(authenticationRequest.getUsername()); if(userDto == null)&#123; throw new RuntimeException(\"查询不到该用户\"); &#125; if(!authenticationRequest.getPassword().equals(userDto.getPassword()))&#123; throw new RuntimeException(\"账号或密码错误\"); &#125; return userDto; &#125; //模拟用户查询 public UserDto getUserDto(String username)&#123; return userMap.get(username); &#125; //用户信息 private Map&lt;String,UserDto&gt; userMap = new HashMap&lt;&gt;(); &#123; userMap.put(\"zhangsan\",new UserDto(\"1010\",\"zhangsan\",\"123\",\"张三\",\"133443\")); userMap.put(\"lisi\",new UserDto(\"1011\",\"lisi\",\"456\",\"李四\",\"144553\")); &#125;&#125;（ 3）登录Controller，对/login请求处理，它调用AuthenticationService完成认证并返回登录结果提示信息：123456789101112131415@RestControllerpublic class LoginController &#123; @Autowired private AuthenticationService authenticationService; /** * 用户登录 * @param authenticationRequest 登录请求 * @return */ @PostMapping(value = \"/login\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;) public String login(AuthenticationRequest authenticationRequest)&#123; UserDetails userDetails = authenticationService.authentication(authenticationRequest); return userDetails.getFullname() + \" 登录成功\"; &#125;&#125;（4）测试启动项目，访问/路径地址，进行测试填入错误的用户信息，页面返回错误信息：HTTP Status 500 - Internal Server Error填入正确的用户信息，页面提示登录成功：李四登录成功以上的测试全部符合预期，到目前为止最基础的认证功能已经完成，它仅仅实现了对用户身份凭证的校验，若某用户认证成功，只能说明他是该系统的一个合法用户，仅此而已。实现会话功能会话是指用户登入系统后，系统会记住该用户的登录状态，他可以在系统连续操作直到退出系统的过程。认证的目的是对系统资源的保护，每次对资源的访问，系统必须得知道是谁在访问资源，才能对该请求进行合法性拦截。因此，在认证成功后，一般会把认证成功的用户信息放入Session中，在后续的请求中，系统能够从Session中获取到当前用户，用这样的方式来实现会话机制。（1）增加会话控制首先在UserDto中定义一个SESSION_USER_KEY，作为Session中存放登录用户信息的key。1public static final String SESSION_USER_KEY = \"_user\";然后修改LoginController，认证成功后，将用户信息放入当前会话。并增加用户登出方法，登出时将session置为失效。123456789101112131415161718/** * 用户登录 * @param authenticationRequest 登录请求 * @param session http会话 * @return */ @PostMapping(value = \"/login\",produces = \"text/plain;charset=utf‐8\") public String login(AuthenticationRequest authenticationRequest, HttpSession session)&#123; UserDto userDto = authenticationService.authentication(authenticationRequest); //用户信息存入session session.setAttribute(UserDto.SESSION_USER_KEY,userDto); return userDto.getUsername() + \"登录成功\"; &#125; @GetMapping(value = \"logout\",produces = \"text/plain;charset=utf‐8\") public String logout(HttpSession session)&#123; session.invalidate(); return \"退出成功\"; &#125;（2）增加测试资源修改LoginController，增加测试资源1，它从当前会话session中获取当前登录用户，并返回提示信息给前台。12345678910111213141516 /** * 测试资源1 * @param session * @return */ @GetMapping(value = \"/r/r1\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;) public String r1(HttpSession session)&#123; String fullname = null; Object userObj = session.getAttribute(UserDto.SESSION_USER_KEY); if(userObj != null)&#123; fullname = ((UserDto)userObj).getFullname(); &#125;else&#123; fullname = \"匿名\"; &#125; return fullname + \" 访问资源1\"; &#125;（3）测试未登录情况下直接访问测试资源/r/r1：匿名访问资源1成功登录的情况下访问测试资源/r/r1：李四访问资源1测试结果说明，在用户登录成功时，该用户信息已被成功放入session，并且后续请求可以正常从session中获取当前登录用户信息，符合预期结果。实现授权功能现在我们已经完成了用户身份凭证的校验以及登录的状态保持，并且我们也知道了如何获取当前登录用户(从Session中获取)的信息，接下来，用户访问系统需要经过授权，即需要完成如下功能：匿名用户（未登录用户）访问拦截：禁止匿名用户访问某些资源。登录用户访问拦截：根据用户的权限决定是否能访问某些资源。（1）增加权限数据为了实现这样的功能，我们需要在UserDto里增加权限属性，用于表示该登录用户所拥有的权限，同时修改UserDto的构造方法。1234567891011121314@Data@AllArgsConstructorpublic class UserDto &#123; public static final String SESSION_USER_KEY = \"_user\"; private String id; private String username; private String password; private String fullname; private String mobile; /** * 用户权限 */ private Set&lt;String&gt; authorities;&#125;并在AuthenticationServiceImpl中为模拟用户初始化权限，其中张三给了p1权限，李四给了p2权限。1234567891011121314 //用户信息 private Map&lt;String,UserDto&gt; userMap = new HashMap&lt;&gt;(); &#123; Set&lt;String&gt; authorities1 = new HashSet&lt;&gt;(); authorities1.add(\"p1\"); Set&lt;String&gt; authorities2 = new HashSet&lt;&gt;(); authorities2.add(\"p2\"); userMap.put(\"zhangsan\",new UserDto(\"1010\",\"zhangsan\",\"123\",\"张三\",\"133443\",authorities1)); userMap.put(\"lisi\",new UserDto(\"1011\",\"lisi\",\"456\",\"李四\",\"144553\",authorities2)); &#125; private UserDetails getUserDetails(String username) &#123; return userDetailsMap.get(username); &#125;（2）增加测试资源我们想实现针对不同的用户能访问不同的资源，前提是得有多个资源，因此在LoginController中增加测试资源2。12345678910111213141516/** * 测试资源2 * @param session * @return */@GetMapping(value = \"/r/r2\",produces = &#123;\"text/plain;charset=UTF‐8\"&#125;)public String r2(HttpSession session)&#123; String fullname = null; Object userObj = session.getAttribute(UserDto.SESSION_USER_KEY); if(userObj != null)&#123; fullname = ((UserDto)userObj).getFullname(); &#125;else&#123; fullname = \"匿名\"; &#125; return fullname + \" 访问资源2\";&#125;（3）实现授权拦截器在interceptor包下定义SimpleAuthenticationInterceptor拦截器，实现授权拦截：1、校验用户是否登录2、校验用户是否拥有操作权限1234567891011121314151617181920212223242526272829303132@Componentpublic class SimpleAuthenticationInterceptor implements HandlerInterceptor &#123; //请求拦截方法 @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Objecthandler) throws Exception &#123; //读取会话信息 Object object = request.getSession().getAttribute(UserDto.SESSION_USER_KEY); if(object == null)&#123; writeContent(response,\"请登录\"); &#125; UserDto user = (UserDto) object; //请求的url String requestURI = request.getRequestURI(); if(user.getAuthorities().contains(\"p1\") &amp;&amp; requestURI.contains(\"/r1\"))&#123; return true; &#125; if(user.getAuthorities().contains(\"p2\") &amp;&amp; requestURI.contains(\"/r2\"))&#123; return true; &#125; writeContent(response,\"权限不足，拒绝访问\"); return false; &#125; //响应输出 private void writeContent(HttpServletResponse response, String msg) throws IOException &#123; response.setContentType(\"text/html;charset=utf‐8\"); PrintWriter writer = response.getWriter(); writer.print(msg); writer.close(); response.resetBuffer(); &#125;&#125;在 WebConfig中配置拦截器，匹配/r/**的资源为受保护的系统资源，访问该资源的请求进入SimpleAuthenticationInterceptor拦截器。1234567@Autowired private SimpleAuthenticationInterceptor simpleAuthenticationInterceptor; @Overridepublic void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(simpleAuthenticationInterceptor).addPathPatterns(\"/r/**\");&#125;（4）测试未登录情况下，/r/r1与/r/r2均提示 “请先登录”。张三登录情况下，由于张三有p1权限，因此可以访问/r/r1，张三没有p2权限，访问/r/r2时提示 “权限不足 “。李四登录情况下，由于李四有p2权限，因此可以访问/r/r2，李四没有p1权限，访问/r/r1时提示 “权限不足 “。测试结果全部符合预期结果。小结基于Session的认证方式是一种常见的认证方式，至今还有非常多的系统在使用。我们在此小节使用Spring mvc技术对它进行简单实现，旨在让大家更清晰实在的了解用户认证、授权以及会话的功能意义及实现套路，也就是它们分别干了哪些事儿？大概需要怎么做？而在正式生产项目中，我们往往会考虑使用第三方安全框架（如 spring security，shiro等安全框架）来实现认证授权功能，因为这样做能一定程度提高生产力，提高软件标准化程度，另外往往这些框架的可扩展性考虑的非常全面。但是缺点也非常明显，这些通用化组件为了提高支持范围会增加很多可能我们不需要的功能，结构上也会比较抽象，如果我们不够了解它，一旦出现问题，将会很难定位。","categories":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://me.obey.fun/categories/SpringMVC/"},{"name":"HttpSession","slug":"SpringMVC/HttpSession","permalink":"https://me.obey.fun/categories/SpringMVC/HttpSession/"}],"tags":[{"name":"Web认证","slug":"Web认证","permalink":"https://me.obey.fun/tags/Web认证/"},{"name":"Web授权","slug":"Web授权","permalink":"https://me.obey.fun/tags/Web授权/"}],"keywords":[{"name":"SpringMVC","slug":"SpringMVC","permalink":"https://me.obey.fun/categories/SpringMVC/"},{"name":"HttpSession","slug":"SpringMVC/HttpSession","permalink":"https://me.obey.fun/categories/SpringMVC/HttpSession/"}]},{"title":"初识Dubbo","slug":"初识Dubbo","date":"2019-07-02T14:27:15.000Z","updated":"2019-07-03T14:27:15.000Z","comments":true,"path":"初识Dubbo.html","link":"","permalink":"https://me.obey.fun/初识Dubbo.html","excerpt":"","text":"初入Dubbo什么是dubboDubbo是Alibaba开源的分布式服务框架，它最大的特点是按照分层的方式来架构，使用这种方式可以使各个层之间解耦合（或者最大限度地松耦合）。从服务模型的角度来看，Dubbo采用的是一种非常简单的模型，要么是提供方提供服务，要么是消费方消费服务，所以基于这一点可以抽象出服务提供方（Provider）和服务消费方（Consumer）两个角色。关于注册中心、协议支持、服务监控等内容，详见后面描述。 Webservice也是一种服务框架，但是webservice并不是分布式的服务框架，他需要结合F5实现负载均衡。因此，dubbo除了可以提供服务之外，还可以实现软负载均衡。它还提供了两个功能Monitor 监控中心和调用中心。这两个是可选的，需要单独配置。Dubbo是阿里巴巴SOA服务化治理方案的核心框架，致力于提供高性能和透明化的RPC远程服务调用方案，以及SOA服务治理方案。其核心部分包含:远程通讯: 提供对多种基于长连接的NIO框架抽象封装，包括多种线程模型，序列化，以及“请求-响应”模式的信息交换方式。集群容错: 提供基于接口方法的透明远程过程调用，包括多协议支持，以及软负载均衡，失败容错，地址路由，动态配置等集群支持。自动发现: 基于注册中心目录服务，使服务消费方能动态的查找服务提供方，使地址透明，使服务提供方可以平滑增加或减少机器。那么，Dubbo能做什么？透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入。软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点。服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。Dubbo产生的背景随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。单一应用架构当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM) 是关键。垂直应用架构当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC) 是关键。分布式服务架构当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC) 是关键。流动计算架构当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA) 是关键。Dubbo的诞生在互联网的发展过程中，在以前，我们只需要一个服务器，将程序全部打包好就可以，但是，随着流量的增大，常规的垂直应用架构已无法应对，所以，架构就发生了演变。单一应用架构应用和数据库单独部署应用和数据库集群部署数据库压力变大，读写分离使用缓存技术加快速度数据库分库分表应用分为不同的类型拆分发展到这个阶段的时候，我们发现，应用与应用之间的关系已经十分的复杂了，就会出现以下几个问题（以下摘录于官网）：当服务越来越多时，服务 URL 配置管理变得非常困难，F5 硬件负载均衡器的单点压力也越来越大。当进一步发展，服务间依赖关系变得错踪复杂，甚至分不清哪个应用要在哪个应用之前启动，架构师都不能完整的描述应用的架构关系。接着，服务的调用量越来越大，服务的容量问题就暴露出来，这个服务需要多少机器支撑？什么时候该加机器？为了解决这由于架构的演变所产生的问题几个问题，于是，dubbo 产生了。当然，解决这个问题的技术不止 dubbo 。Dubbo技术架构我们已经非常清楚的知道为什么在我们的系统中需要 Dubbo 这项技术了，下面，我们接着唠叨唠叨 Dubbo 的架构。首先，上一张图（摘自官网）。看到图之后，可能你对上面的几个概念还是一脸懵逼，无从下手，下面，带你看看这几个角色到底是什么意思？节点角色说明节点角色说明Provider暴露服务的服务提供方Consumer调用远程服务的服务消费方Registry服务注册于发现的注册中心Monitor统计服务的调用次数和调用时间的监控中心Container服务运行容器看了这几个概念后似乎发现，其实 Dubbo 的架构也是很简单的（其实现细节是复杂的），为什么这么说呢，有没有发现，其实很像 生产者-消费者 模型。只是在这种模型上，加上了 注册中心和监控中心 ，用于管理提供方提供的 url ，以及管理整个过程。那么，整个发布-订阅的过程就非常的简单了。启动容器，加载， 运行服务提供者 。服务提供者在启动时，在注册中心 发布注册 自己提供的 服务 。服务消费者在启动时，在注册中心 订阅 自己所需的 服务 。如果考虑 失败或变更 的情况，就需要考虑下面的过程。注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。通过这番讲解，我相信 Dubbo 的架构我们也轻车熟路了，那就直接就可以直接上手了。Dubbo开始入门服务端首先，我们先把服务端的接口写好，因为其实 dubbo 的作用简单来说就是给消费端提供接口。接口定义1234567 /** * xml方式服务提供者接口 */ public interface ProviderService &#123; String SayHello(String word); &#125;这个接口非常简单，只是包含一个 SayHello 的方法。接着，定义它的实现类。123456789/** * xml方式服务提供者实现类 */public class ProviderServiceImpl implements ProviderService&#123; public String SayHello(String word) &#123; return word; &#125;&#125;这样我们就把我们的接口写好了，那么我们应该怎么将我们的服务暴露出去呢？导入 maven 依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.32.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;这里使用的 dubbo 的版本是 2.6.6 ，需要注意的是，如果你只导入 dubbo 的包的时候是 会报错 的， 找不到 netty 和 curator 的依赖 ，所以，在这里我们需要把这两个的依赖加上，就不会报错了。另外，这里我们使用 zookeeper 作为注册中心。到目前为止，dubbo 需要的环境就已经可以了，下面，我们就把上面刚刚定义的接口暴露出去。暴露接口（xml 配置方法）首先，我们在我们项目的 resource 目录下 创建 META-INF.spring 包 ，然后再创建 provider.xml 文件，名字可以任取哦，如下图。12345678910111213141516171819202122232425262728293031&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt; &lt;dubbo:application name=\"provider\" owner=\"sihai\"&gt; &lt;dubbo:parameter key=\"qos.enable\" value=\"true\"/&gt; &lt;dubbo:parameter key=\"qos.accept.foreign.ip\" value=\"false\"/&gt; &lt;dubbo:parameter key=\"qos.port\" value=\"55555\"/&gt; &lt;/dubbo:application&gt; &lt;dubbo:monitor protocol=\"registry\"/&gt; &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt; &lt;!--&lt;dubbo:registry address=\"N/A\"/&gt;--&gt; &lt;dubbo:registry address=\"N/A\" /&gt; &lt;!--当前服务发布所依赖的协议；webserovice、Thrift、Hessain、http--&gt; &lt;dubbo:protocol name=\"dubbo\" port=\"20880\"/&gt; &lt;!--服务发布的配置，需要暴露的服务接口--&gt; &lt;dubbo:service interface=\"com.sihai.dubbo.provider.service.ProviderService\" ref=\"providerService\"/&gt; &lt;!--Bean bean定义--&gt; &lt;bean id=\"providerService\" class=\"com.sihai.dubbo.provider.service.ProviderServiceImpl\"/&gt;&lt;/beans&gt;上面的文件其实就是类似 spring 的配置文件，而且，dubbo 底层就是 spring。节点：dubbo:application 就是整个项目在分布式架构中的唯一名称，可以在 name 属性中配置，另外还可以配置 owner 字段，表示属于谁。 下面的参数是可以不配置的，这里配置是因为出现了端口的冲突，所以配置。节点：dubbo:monitor 监控中心配置， 用于配置连接监控中心相关信息，可以不配置，不是必须的参数。节点：dubbo:registry 配置注册中心的信息，比如，这里我们可以配置 zookeeper 作为我们的注册中心。 address 是注册中心的地址，这里我们配置的是 N/A 表示由 dubbo 自动分配地址。或者说是一种直连的方式，不通过注册中心。节点：dubbo:protocol 服务发布的时候 dubbo 依赖什么协议，可以配置 dubbo、webserovice、Thrift、Hessain、http等协议。节点：dubbo:service 这个节点就是我们的重点了，当我们服务发布的时候，我们就是通过这个配置将我们的服务发布出去的。 interface 是接口的包路径， ref 是需要配置的接口的 bean。最后，我们需要像配置 spring 的接口一样，配置接口的 bean。到这一步，关于服务端的配置就完成了，下面我们通过 main 方法 将接口发布出去。发布接口1234567891011121314151617181920212223242526package com.sihai.dubbo.provider;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ProtocolConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.alibaba.dubbo.config.ServiceConfig;import com.alibaba.dubbo.container.Main;import com.sihai.dubbo.provider.service.ProviderService;import com.sihai.dubbo.provider.service.ProviderServiceImpl;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * xml方式启动 * */public class App &#123; public static void main( String[] args ) throws IOException &#123; //加载xml配置文件启动 ClassPathXmlApplicationContext context = new ClassPathXmlApplicationContext(\"META-INF/spring/provider.xml\"); context.start(); System.in.read(); // 按任意键退出 &#125;&#125;发布接口非常简单，因为 dubbo 底层就是依赖 spring 的，所以，我们只需要通过 ClassPathXmlApplicationContext 拿到我们刚刚配置好的 xml ，然后调用 context.start() 方法就启动了。看到下面的截图，就算是启动成功了，接口也就发布出去了。你以为到这里就结束了了，并不是的，我们拿到 dubbo 暴露出去的 url 分析分析。dubbo 暴露的 url1dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService?anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;bind.ip=192.168.234.1&amp;bind.port=20880&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=8412&amp;qos.accept.foreign.ip=false&amp;qos.enable=true&amp;qos.port=55555&amp;side=provider&amp;timestamp=1562077289380分析首先，在形式上我们发现，其实这么牛逼的 dubbo 也是用 类似于 http 的协议 发布自己的服务的，只是这里我们用的是 dubbo 协议 。dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService 上面这段链接就是 ? 之前的链接，构成： 协议://ip:端口/接口 。发现是不是也没有什么神秘的。anyhost=true&amp;application=provider&amp;bean.name=com.sihai.dubbo.provider.service.ProviderService&amp;bind.ip=192.168.234.1&amp;bind.port=20880&amp;dubbo=2.0.2&amp;generic=false&amp;interface=com.sihai.dubbo.provider.service.ProviderService&amp;methods=SayHello&amp;owner=sihai&amp;pid=8412&amp;qos.accept.foreign.ip=false&amp;qos.enable=true&amp;qos.port=55555&amp;side=provider&amp;timestamp=1562077289380 ? 之后的字符串，分析后你发现，这些都是刚刚在 provider.xml 中配置的字段，然后通过 &amp; 拼接而成的，闻到了 http 的香味了吗？终于，dubbo 服务端入门了。下面我们看看拿到了 url 后，怎么消费呢？消费端上面提到，我们在服务端提供的只是点对点的方式提供服务，并没有使用注册中心，所以，下面的配置也是会有一些不一样的。消费端环境配置首先，我们在消费端的 resource 下建立配置文件 consumer.xml 。 下建立配置文件 consumer.xml 。123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:dubbo=\"http://code.alibabatech.com/schema/dubbo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://code.alibabatech.com/schema/dubbo http://code.alibabatech.com/schema/dubbo/dubbo.xsd\"&gt; &lt;!--当前项目在整个分布式架构里面的唯一名称，计算依赖关系的标签--&gt; &lt;dubbo:application name=\"consumer\" owner=\"sihai\"/&gt; &lt;!--dubbo这个服务所要暴露的服务地址所对应的注册中心--&gt; &lt;!--点对点的方式--&gt; &lt;dubbo:registry address=\"N/A\" /&gt; &lt;!--&lt;dubbo:registry address=\"zookeeper://localhost:2181\" check=\"false\"/&gt;--&gt; &lt;!--生成一个远程服务的调用代理--&gt; &lt;!--点对点方式--&gt; &lt;dubbo:reference id=\"providerService\" interface=\"com.sihai.dubbo.provider.service.ProviderService\" url=\"dubbo://192.168.234.1:20880/com.sihai.dubbo.provider.service.ProviderService\"/&gt; &lt;!--&lt;dubbo:reference id=\"providerService\" interface=\"com.sihai.dubbo.provider.service.ProviderService\"/&gt;--&gt;&lt;/beans&gt;分析发现这里的 dubbo:application 和 dubbo:registry 是一致的。dubbo:reference ：我们这里采用 点对点 的方式，所以，需要配置在服务端暴露的 url 。maven 依赖和服务端一样12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt; &lt;artifactId&gt;dubbo-consumer&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.ouyangsihai&lt;/groupId&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba/dubbo --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;dubbo&lt;/artifactId&gt; &lt;version&gt;2.6.6&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.10&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;0.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.32.Final&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.8.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/project&gt;调用服务123456789101112131415161718192021222324252627package com.sihai.dubbo.consumer;import com.alibaba.dubbo.config.ApplicationConfig;import com.alibaba.dubbo.config.ReferenceConfig;import com.alibaba.dubbo.config.RegistryConfig;import com.sihai.dubbo.provider.service.ProviderService;import org.springframework.context.support.ClassPathXmlApplicationContext;import java.io.IOException;/** * xml的方式调用 * */public class App &#123; public static void main( String[] args ) throws IOException &#123; ClassPathXmlApplicationContext context=new ClassPathXmlApplicationContext(\"consumer.xml\"); context.start(); ProviderService providerService = (ProviderService) context.getBean(\"providerService\"); String str = providerService.SayHello(\"hello\"); System.out.println(str); System.in.read(); &#125;&#125;这里和服务端的发布如出一辙。如此，我们就成功调用接口了。","categories":[{"name":"rpc框架","slug":"rpc框架","permalink":"https://me.obey.fun/categories/rpc框架/"},{"name":"SOA","slug":"rpc框架/SOA","permalink":"https://me.obey.fun/categories/rpc框架/SOA/"}],"tags":[{"name":"rpc","slug":"rpc","permalink":"https://me.obey.fun/tags/rpc/"},{"name":"SOA","slug":"SOA","permalink":"https://me.obey.fun/tags/SOA/"}],"keywords":[{"name":"rpc框架","slug":"rpc框架","permalink":"https://me.obey.fun/categories/rpc框架/"},{"name":"SOA","slug":"rpc框架/SOA","permalink":"https://me.obey.fun/categories/rpc框架/SOA/"}]},{"title":"Maven的使用与介绍","slug":"Maven的使用与介绍","date":"2019-06-08T09:25:39.000Z","updated":"2019-06-09T09:25:39.000Z","comments":true,"path":"Maven的使用与介绍.html","link":"","permalink":"https://me.obey.fun/Maven的使用与介绍.html","excerpt":"","text":"Maven的使用入门什么是MavenMaven 翻译为”专家”、”内行”，是 Apache 下的一个纯 Java 开发的开源项目。基于项目对象模型（缩写：POM）概念，Maven利用一个中央信息片断能管理一个项目的构建、报告和文档等步骤。Maven 是一个项目管理工具，可以对 Java 项目进行构建、依赖管理。Maven 也可被用于构建和管理各种项目，例如 C#，Ruby，Scala 和其他语言编写的项目。Maven 曾是 Jakarta 项目的子项目，现为由 Apache 软件基金会主持的独立 Apache 项目。Maven的功能Maven 能够帮助开发者完成以下工作：构建文档生成报告依赖SCMs发布分发邮件列表Maven的标准目录结构Maven 提倡使用一个共同的标准目录结构，Maven 使用约定优于配置的原则，大家尽可能的遵守这样的目录结构。如下所示：目录目的${basedir}存放pom.xml和所有的子目录${basedir}/src/main/java项目的java源代码${basedir}/src/main/resources项目的资源，比如说property文件，springmvc.xml${basedir}/src/test/java项目的测试类，比如说Junit代码${basedir}/src/test/resources测试用的资源${basedir}/src/main/webapp/WEB-INFweb应用文件目录，web项目的信息，比如存放web.xml、本地图片、jsp视图页面${basedir}/target打包输出目录${basedir}/target/classes编译输出目录${basedir}/target/test-classes测试编译输出目录Test.javaMaven只会自动运行符合该命名规则的测试类~/.m2/repositoryMaven默认的本地仓库目录位置Maven的特点项目设置遵循统一的规则。任意工程中共享。依赖管理包括自动更新。一个庞大且不断增长的库。可扩展，能够轻松编写 Java 或脚本语言的插件。只需很少或不需要额外配置即可即时访问新功能。基于模型的构建 − Maven能够将任意数量的项目构建到预定义的输出类型中，如 JAR，WAR 或基于项目元数据的分发，而不需要在大多数情况下执行任何脚本。项目信息的一致性站点 − 使用与构建过程相同的元数据，Maven 能够生成一个网站或PDF，包括您要添加的任何文档，并添加到关于项目开发状态的标准报告中。发布管理和发布单独的输出 − Maven 将不需要额外的配置，就可以与源代码管理系统（如 Subversion 或 Git）集成，并可以基于某个标签管理项目的发布。它也可以将其发布到分发位置供其他项目使用。Maven 能够发布单独的输出，如 JAR，包含其他依赖和文档的归档，或者作为源代码发布。向后兼容性 − 您可以很轻松的从旧版本 Maven 的多个模块移植到 Maven 3 中。子项目使用父项目依赖时，正常情况子项目应该继承父项目依赖，无需使用版本号，并行构建 − 编译的速度能普遍提高20 - 50 %。更好的错误报告 − Maven 改进了错误报告，它为您提供了 Maven wiki 页面的链接，您可以点击链接查看错误的完整描述。Maven的环境配置Maven 是一个基于 Java 的工具，所以要做的第一件事情就是安装 JDK。系统要求项目要求JDKMaven 3.3 要求 JDK 1.7 或以上Maven3.2 要求 JDK 1.6 或以上Maven3.0/3.1 要求 JDK 1.5 或以上内存没有最低要求磁盘Maven 自身安装需要大约 10 MB 空间。除此之外，额外的磁盘空间将用于你的本地 Maven 仓库。你本地仓库的大小取决于使用情况，但预期至少 500 MB操作系统没有最低要求Maven的下载Maven 下载地址：http://maven.apache.org/download.cgi不同平台下载对应的包系统包名Windowsapache-maven-3.6.1-bin.zipLinuxapache-maven-3.6.1-bin.tar.gzMacapache-maven-3.6.1-bin.tar.gz下载包后解压到对应路径系统存储位置（根据自己情况而定）WindowsE:\\Maven\\apache-maven-3.6.1Linux/usr/local/apache-maven-3.6.1Mac/usr/local/apache-maven-3.6.1设置Maven的环境变量右键 “计算机”，选择 “属性”，之后点击 “高级系统设置”，点击”环境变量”，来设置环境变量，有以下系统变量需要配置：新建系统变量 MAVEN_HOME，变量值：E:\\Maven\\apache-maven-3.6.1编辑系统变量 Path，添加变量值：;%MAVEN_HOME%\\bin注意：注意多个值之间需要有分号隔开，然后点击确定。Maven POMPOM( Project Object Model，项目对象模型 ) 是 Maven 工程的基本工作单元，是一个XML文件，包含了项目的基本信息，用于描述项目如何构建，声明项目依赖，等等。执行任务或目标时，Maven 会在当前目录中查找 POM。它读取 POM，获取所需的配置信息，然后执行目标。POM 中可以指定以下配置：项目依赖插件执行目标项目构建 profile项目版本项目开发者列表相关邮件列表信息在创建 POM 之前，我们首先需要描述项目组 (groupId), 项目的唯一ID。12345678910111213141516&lt;project xmlns = \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi = \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation = \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;!-- 模型版本 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 公司或者组织的唯一标志，并且配置时生成的路径也是由此生成， 如com.companyname.project-group，maven会将该项目打成的jar包放本地路径：/com/companyname/project-group --&gt; &lt;groupId&gt;com.companyname.project-group&lt;/groupId&gt; &lt;!-- 项目的唯一ID，一个groupId下面可能多个项目，就是靠artifactId来区分的 --&gt; &lt;artifactId&gt;project&lt;/artifactId&gt; &lt;!-- 版本号 --&gt; &lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt;所有 POM 文件都需要 project 元素和三个必需字段：groupId，artifactId，version。节点描述project工程的根标签。modelVersion模型版本需要设置为 4.0。groupId这是工程组的标识。它在一个组织或者项目中通常是唯一的。例如，一个银行组织 com.companyname.project-group 拥有所有的和银行相关的项目。artifactId这是工程的标识。它通常是工程的名称。例如，消费者银行。groupId 和 artifactId 一起定义了 artifact 在仓库中的位置。version这是工程的版本号。在 artifact 的仓库中，它用来区分不同的版本。父（Super）POM父（Super）POM是 Maven 默认的 POM。所有的 POM 都继承自一个父 POM（无论是否显式定义了这个父 POM）。父 POM 包含了一些可以被继承的默认设置。因此，当 Maven 发现需要下载 POM 中的 依赖时，它会到 Super POM 中配置的默认仓库 http://repo1.maven.org/maven2 去下载。POM标签大全详解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0http://maven.apache.org/maven-v4_0_0.xsd\"&gt; &lt;!--父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。 --&gt; &lt;parent&gt; &lt;!--被继承的父项目的构件标识符 --&gt; &lt;artifactId /&gt; &lt;!--被继承的父项目的全球唯一标识符 --&gt; &lt;groupId /&gt; &lt;!--被继承的父项目的版本 --&gt; &lt;version /&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项 目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 --&gt; &lt;relativePath /&gt; &lt;/parent&gt; &lt;!--声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!--项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app --&gt; &lt;groupId&gt;asia.banseon&lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个 特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源 码，二进制发布和WARs等。 --&gt; &lt;artifactId&gt;banseon-maven2&lt;/artifactId&gt; &lt;!--项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型 --&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!--项目当前版本，格式为:主版本.次版本.增量版本-限定版本号 --&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!--项目的名称, Maven产生的文档用 --&gt; &lt;name&gt;banseon-maven&lt;/name&gt; &lt;!--项目主页的URL, Maven产生的文档用 --&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标 签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。 --&gt; &lt;description&gt;A maven project to study maven.&lt;/description&gt; &lt;!--描述了这个项目构建环境中的前提条件。 --&gt; &lt;prerequisites&gt; &lt;!--构建该项目或使用该插件所需要的Maven的最低版本 --&gt; &lt;maven /&gt; &lt;/prerequisites&gt; &lt;!--项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira --&gt; &lt;issueManagement&gt; &lt;!--问题管理系统（例如jira）的名字， --&gt; &lt;system&gt;jira&lt;/system&gt; &lt;!--该项目使用的问题管理系统的URL --&gt; &lt;url&gt;http://jira.baidu.com/banseon&lt;/url&gt; &lt;/issueManagement&gt; &lt;!--项目持续集成信息 --&gt; &lt;ciManagement&gt; &lt;!--持续集成系统的名字，例如continuum --&gt; &lt;system /&gt; &lt;!--该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。 --&gt; &lt;url /&gt; &lt;!--构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） --&gt; &lt;notifiers&gt; &lt;!--配置一种方式，当构建中断时，以该方式通知用户/开发者 --&gt; &lt;notifier&gt; &lt;!--传送通知的途径 --&gt; &lt;type /&gt; &lt;!--发生错误时是否通知 --&gt; &lt;sendOnError /&gt; &lt;!--构建失败时是否通知 --&gt; &lt;sendOnFailure /&gt; &lt;!--构建成功时是否通知 --&gt; &lt;sendOnSuccess /&gt; &lt;!--发生警告时是否通知 --&gt; &lt;sendOnWarning /&gt; &lt;!--不赞成使用。通知发送到哪里 --&gt; &lt;address /&gt; &lt;!--扩展配置项 --&gt; &lt;configuration /&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!--项目创建年份，4位数字。当产生版权信息时需要使用这个值。 --&gt; &lt;inceptionYear /&gt; &lt;!--项目相关邮件列表信息 --&gt; &lt;mailingLists&gt; &lt;!--该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。 --&gt; &lt;mailingList&gt; &lt;!--邮件的名称 --&gt; &lt;name&gt;Demo&lt;/name&gt; &lt;!--发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;post&gt;banseon@126.com&lt;/post&gt; &lt;!--订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;subscribe&gt;banseon@126.com&lt;/subscribe&gt; &lt;!--取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;unsubscribe&gt;banseon@126.com&lt;/unsubscribe&gt; &lt;!--你可以浏览邮件信息的URL --&gt; &lt;archive&gt;http:/hi.baidu.com/banseon/demo/dev/&lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!--项目开发者列表 --&gt; &lt;developers&gt; &lt;!--某个项目开发者的信息 --&gt; &lt;developer&gt; &lt;!--SCM里项目开发者的唯一标识符 --&gt; &lt;id&gt;HELLO WORLD&lt;/id&gt; &lt;!--项目开发者的全名 --&gt; &lt;name&gt;banseon&lt;/name&gt; &lt;!--项目开发者的email --&gt; &lt;email&gt;banseon@126.com&lt;/email&gt; &lt;!--项目开发者的主页的URL --&gt; &lt;url /&gt; &lt;!--项目开发者在项目中扮演的角色，角色元素描述了各种角色 --&gt; &lt;roles&gt; &lt;role&gt;Project Manager&lt;/role&gt; &lt;role&gt;Architect&lt;/role&gt; &lt;/roles&gt; &lt;!--项目开发者所属组织 --&gt; &lt;organization&gt;demo&lt;/organization&gt; &lt;!--项目开发者所属组织的URL --&gt; &lt;organizationUrl&gt;http://hi.baidu.com/banseon&lt;/organizationUrl&gt; &lt;!--项目开发者属性，如即时消息如何处理等 --&gt; &lt;properties&gt; &lt;dept&gt;No&lt;/dept&gt; &lt;/properties&gt; &lt;!--项目开发者所在时区， -11到12范围内的整数。 --&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!--项目的其他贡献者列表 --&gt; &lt;contributors&gt; &lt;!--项目的其他贡献者。参见developers/developer元素 --&gt; &lt;contributor&gt; &lt;name /&gt; &lt;email /&gt; &lt;url /&gt; &lt;organization /&gt; &lt;organizationUrl /&gt; &lt;roles /&gt; &lt;timezone /&gt; &lt;properties /&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!--该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。 --&gt; &lt;licenses&gt; &lt;!--描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。 --&gt; &lt;license&gt; &lt;!--license用于法律上的名称 --&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;!--官方的license正文页面的URL --&gt; &lt;url&gt;http://www.baidu.com/banseon/LICENSE-2.0.txt&lt;/url&gt; &lt;!--项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖 --&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!--关于license的补充信息 --&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!--SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。 --&gt; &lt;scm&gt; &lt;!--SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。 --&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!--给开发者使用的，类似connection元素。即该连接不仅仅只读 --&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!--当前代码的标签，在开发阶段默认为HEAD --&gt; &lt;tag /&gt; &lt;!--指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。 --&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!--描述项目所属组织的各种属性。Maven产生的文档用 --&gt; &lt;organization&gt; &lt;!--组织的全名 --&gt; &lt;name&gt;demo&lt;/name&gt; &lt;!--组织主页的URL --&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;/organization&gt; &lt;!--构建项目需要的信息 --&gt; &lt;build&gt; &lt;!--该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;sourceDirectory /&gt; &lt;!--该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。 --&gt; &lt;scriptSourceDirectory /&gt; &lt;!--该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;testSourceDirectory /&gt; &lt;!--被编译过的应用程序class文件存放的目录。 --&gt; &lt;outputDirectory /&gt; &lt;!--被编译过的测试class文件存放的目录。 --&gt; &lt;testOutputDirectory /&gt; &lt;!--使用来自该项目的一系列构建扩展 --&gt; &lt;extensions&gt; &lt;!--描述使用到的构建扩展。 --&gt; &lt;extension&gt; &lt;!--构建扩展的groupId --&gt; &lt;groupId /&gt; &lt;!--构建扩展的artifactId --&gt; &lt;artifactId /&gt; &lt;!--构建扩展的版本 --&gt; &lt;version /&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!--当项目没有规定目标（Maven2 叫做阶段）时的默认值 --&gt; &lt;defaultGoal /&gt; &lt;!--这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。 --&gt; &lt;resources&gt; &lt;!--这个元素描述了项目相关或测试相关的所有资源路径 --&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例 子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven /messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。 --&gt; &lt;targetPath /&gt; &lt;!--是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。 --&gt; &lt;filtering /&gt; &lt;!--描述存放资源的目录，该路径相对POM路径 --&gt; &lt;directory /&gt; &lt;!--包含的模式列表，例如**/*.xml. --&gt; &lt;includes /&gt; &lt;!--排除的模式列表，例如**/*.xml --&gt; &lt;excludes /&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!--这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。 --&gt; &lt;testResources&gt; &lt;!--这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明 --&gt; &lt;testResource&gt; &lt;targetPath /&gt; &lt;filtering /&gt; &lt;directory /&gt; &lt;includes /&gt; &lt;excludes /&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!--构建产生的所有文件存放的目录 --&gt; &lt;directory /&gt; &lt;!--产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。 --&gt; &lt;finalName /&gt; &lt;!--当filtering开关打开时，使用到的过滤器属性文件列表 --&gt; &lt;filters /&gt; &lt;!--子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置 --&gt; &lt;pluginManagement&gt; &lt;!--使用的插件列表 。 --&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述插件所需要的信息。 --&gt; &lt;plugin&gt; &lt;!--插件在仓库里的group ID --&gt; &lt;groupId /&gt; &lt;!--插件在仓库里的artifact ID --&gt; &lt;artifactId /&gt; &lt;!--被使用的插件的版本（或版本范围） --&gt; &lt;version /&gt; &lt;!--是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。 --&gt; &lt;extensions /&gt; &lt;!--在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。 --&gt; &lt;executions&gt; &lt;!--execution元素包含了插件执行需要的信息 --&gt; &lt;execution&gt; &lt;!--执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标 --&gt; &lt;id /&gt; &lt;!--绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段 --&gt; &lt;phase /&gt; &lt;!--配置的执行目标 --&gt; &lt;goals /&gt; &lt;!--配置是否被传播到子POM --&gt; &lt;inherited /&gt; &lt;!--作为DOM对象的配置 --&gt; &lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!--项目引入插件所需要的额外依赖 --&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素 --&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--任何配置是否被传播到子项目 --&gt; &lt;inherited /&gt; &lt;!--作为DOM对象的配置 --&gt; &lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!--使用的插件列表 --&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId /&gt; &lt;artifactId /&gt; &lt;version /&gt; &lt;extensions /&gt; &lt;executions&gt; &lt;execution&gt; &lt;id /&gt; &lt;phase /&gt; &lt;goals /&gt; &lt;inherited /&gt; &lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素 --&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals /&gt; &lt;inherited /&gt; &lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--在列的项目构建profile，如果被激活，会修改构建处理 --&gt; &lt;profiles&gt; &lt;!--根据环境参数或命令行参数激活某个构建处理 --&gt; &lt;profile&gt; &lt;!--构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。 --&gt; &lt;id /&gt; &lt;!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。 --&gt; &lt;activation&gt; &lt;!--profile默认是否激活的标志 --&gt; &lt;activeByDefault /&gt; &lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --&gt; &lt;jdk /&gt; &lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt; &lt;os&gt; &lt;!--激活profile的操作系统的名字 --&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!--激活profile的操作系统所属家族(如 'windows') --&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!--激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!--激活profile的操作系统版本 --&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt; &lt;property&gt; &lt;!--激活profile的属性的名称 --&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!--激活profile的属性的值 --&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt; &lt;file&gt; &lt;!--如果指定的文件存在，则激活profile。 --&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ &lt;/exists&gt; &lt;!--如果指定的文件不存在，则激活profile。 --&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/ &lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!--构建项目所需要的信息。参见build元素 --&gt; &lt;build&gt; &lt;defaultGoal /&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath /&gt; &lt;filtering /&gt; &lt;directory /&gt; &lt;includes /&gt; &lt;excludes /&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath /&gt; &lt;filtering /&gt; &lt;directory /&gt; &lt;includes /&gt; &lt;excludes /&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory /&gt; &lt;finalName /&gt; &lt;filters /&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId /&gt; &lt;artifactId /&gt; &lt;version /&gt; &lt;extensions /&gt; &lt;executions&gt; &lt;execution&gt; &lt;id /&gt; &lt;phase /&gt; &lt;goals /&gt; &lt;inherited /&gt; &lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素 --&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals /&gt; &lt;inherited /&gt; &lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!--参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId /&gt; &lt;artifactId /&gt; &lt;version /&gt; &lt;extensions /&gt; &lt;executions&gt; &lt;execution&gt; &lt;id /&gt; &lt;phase /&gt; &lt;goals /&gt; &lt;inherited /&gt; &lt;configuration /&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素 --&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals /&gt; &lt;inherited /&gt; &lt;configuration /&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules /&gt; &lt;!--发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!--参见repositories/repository元素 --&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;id /&gt; &lt;name /&gt; &lt;url /&gt; &lt;layout /&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;id /&gt; &lt;name /&gt; &lt;url /&gt; &lt;layout /&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素 --&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports /&gt; &lt;!--该元素包括使用报表插件产生报表的规范。当用户执行\"mvn site\"，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素 --&gt; &lt;reporting&gt; ...... &lt;/reporting&gt; &lt;!--参见dependencyManagement元素 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素 --&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--参见distributionManagement元素 --&gt; &lt;distributionManagement&gt; ...... &lt;/distributionManagement&gt; &lt;!--参见properties元素 --&gt; &lt;properties /&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!--模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules /&gt; &lt;!--发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!--包含需要连接到远程仓库的信息 --&gt; &lt;repository&gt; &lt;!--如何处理远程仓库里发布版本的下载 --&gt; &lt;releases&gt; &lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled /&gt; &lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt; &lt;updatePolicy /&gt; &lt;!--当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。 --&gt; &lt;checksumPolicy /&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的 策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled /&gt; &lt;updatePolicy /&gt; &lt;checksumPolicy /&gt; &lt;/snapshots&gt; &lt;!--远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库 --&gt; &lt;id&gt;banseon-repository-proxy&lt;/id&gt; &lt;!--远程仓库名称 --&gt; &lt;name&gt;banseon-repository-proxy&lt;/name&gt; &lt;!--远程仓库URL，按protocol://hostname/path形式 --&gt; &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然 而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!--发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!--包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; ...... &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!--该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!--依赖的group ID --&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!--依赖的artifact ID --&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!--依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。 --&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应， 尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在 plugin里定义新的类型。所以前面的类型的例子不完整。 --&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成 JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。 --&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!--依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用 --&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!--仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。 --&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!--当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!--可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。 --&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!--不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!--该元素描述使用报表插件产生报表的规范。当用户执行\"mvn site\"，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 --&gt; &lt;reporting&gt; &lt;!--true，则，网站不包括默认的报表。这包括\"项目信息\"菜单中的报表。 --&gt; &lt;excludeDefaults /&gt; &lt;!--所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。 --&gt; &lt;outputDirectory /&gt; &lt;!--使用的报表插件和他们的配置。 --&gt; &lt;plugins&gt; &lt;!--plugin元素包含描述报表插件需要的信息 --&gt; &lt;plugin&gt; &lt;!--报表插件在仓库里的group ID --&gt; &lt;groupId /&gt; &lt;!--报表插件在仓库里的artifact ID --&gt; &lt;artifactId /&gt; &lt;!--被使用的报表插件的版本（或版本范围） --&gt; &lt;version /&gt; &lt;!--任何配置是否被传播到子项目 --&gt; &lt;inherited /&gt; &lt;!--报表插件的配置 --&gt; &lt;configuration /&gt; &lt;!--一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标 --&gt; &lt;reportSets&gt; &lt;!--表示报表的一个集合，以及产生该集合的配置 --&gt; &lt;reportSet&gt; &lt;!--报表集合的唯一标识符，POM继承时用到 --&gt; &lt;id /&gt; &lt;!--产生报表集合时，被使用的报表的配置 --&gt; &lt;configuration /&gt; &lt;!--配置是否被继承到子POMs --&gt; &lt;inherited /&gt; &lt;!--这个集合里使用到哪些报表 --&gt; &lt;reports /&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和 artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID 匹配到这里的依赖，并使用这里的依赖信息。 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!--参见dependencies/dependency元素 --&gt; &lt;dependency&gt; ...... &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!--项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。 --&gt; &lt;distributionManagement&gt; &lt;!--部署项目产生的构件到远程仓库需要的信息 --&gt; &lt;repository&gt; &lt;!--是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素 --&gt; &lt;uniqueVersion /&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout /&gt; &lt;/repository&gt; &lt;!--构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion /&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout /&gt; &lt;/snapshotRepository&gt; &lt;!--部署项目的网站需要的信息 --&gt; &lt;site&gt; &lt;!--部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置 --&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!--部署位置的名称 --&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!--部署位置的URL，按protocol://hostname/path形式 --&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!--项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。 --&gt; &lt;downloadUrl /&gt; &lt;!--如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。 --&gt; &lt;relocation&gt; &lt;!--构件新的group ID --&gt; &lt;groupId /&gt; &lt;!--构件新的artifact ID --&gt; &lt;artifactId /&gt; &lt;!--构件新的版本号 --&gt; &lt;version /&gt; &lt;!--显示给用户的，关于移动的额外信息，例如原因。 --&gt; &lt;message /&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从 Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部 署），verified（被核实时正确的和最终的）。 --&gt; &lt;status /&gt; &lt;/distributionManagement&gt; &lt;!--以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。 --&gt; &lt;properties /&gt;&lt;/project&gt;Maven 构建生命周期Maven 构建生命周期定义了一个项目构建跟发布的过程。一个典型的 Maven 构建（build）生命周期是由以下几个阶段的序列组成的：阶段处理描述验证 validate验证项目验证项目是否正确且所有必须信息是可用的编译 compile执行编译源代码编译在此阶段完成测试 Test测试使用适当的单元测试框架（例如JUnit）运行测试。包装 package打包创建JAR/WAR包如在 pom.xml 中定义提及的包检查 verify检查对集成测试的结果进行检查，以保证质量达标安装 install安装安装打包的项目到本地仓库，以供其他项目使用部署 deploy部署拷贝最终的工程包到远程仓库中，以共享给其他开发人员和工程为了完成 default 生命周期，这些阶段（包括其他未在上面罗列的生命周期阶段）将被按顺序地执行。Maven 有以下三个标准的生命周期：clean：项目清理的处理default(或 build)：项目部署的处理site：项目站点文档创建的处理Clean生命周期当我们执行 mvn post-clean 命令时，Maven 调用 clean 生命周期，它包含以下阶段：pre-clean：执行一些需要在clean之前完成的工作clean：移除所有上一次构建生成的文件post-clean：执行一些需要在clean之后立刻完成的工作mvn clean 中的 clean 就是上面的 clean，在一个生命周期中，运行某个阶段的时候，它之前的所有阶段都会被运行，也就是说，如果执行 mvn clean 将运行以下两个生命周期阶段：1pre-clean,clean如果我们运行 mvn post-clean ，则运行以下三个生命周期阶段：1pre-clean,clean，post-cleanDefault（Build）生命周期这是 Maven 的主要生命周期，被用于构建应用，包括下面的 23 个阶段：生命周期阶段描述validate（校验）校验项目是否正确并且所有必要的信息可以完成项目的构建过程。initialize（初始化）初始化构建状态，比如设置属性值。generate-sources（生成源代码）生成包含在编译阶段中的任何源代码。process-sources（处理源代码）处理源代码，比如说，过滤任意值。generate-resources（生成资源文件）生成将会包含在项目包中的资源文件。process-resources （处理资源文件）复制和处理资源到目标目录，为打包阶段最好准备。compile（编译）编译项目的源代码。process-classes（处理类文件）处理编译生成的文件，比如说对Java class文件做字节码改善优化。generate-test-sources（生成测试源代码）生成包含在编译阶段中的任何测试源代码。process-test-sources（处理测试源代码）处理测试源代码，比如说，过滤任意值。generate-test-resources（生成测试资源文件）为测试创建资源文件。process-test-resources（处理测试资源文件）复制和处理测试资源到目标目录。test-compile（编译测试源码）编译测试源代码到测试目标目录.process-test-classes（处理测试类文件）处理测试源码编译生成的文件。test（测试）使用合适的单元测试框架运行测试（Juint是其中之一）。prepare-package（准备打包）在实际打包之前，执行任何的必要的操作为打包做准备。package（打包）将编译后的代码打包成可分发格式的文件，比如JAR、WAR或者EAR文件。pre-integration-test（集成测试前）在执行集成测试前进行必要的动作。比如说，搭建需要的环境。integration-test（集成测试）处理和部署项目到可以运行集成测试环境中。post-integration-test（集成测试后）在执行集成测试完成后进行必要的动作。比如说，清理集成测试环境。verify （验证）运行任意的检查来验证项目包有效且达到质量标准。install（安装）安装项目包到本地仓库，这样项目包可以用作其他本地项目的依赖。deploy（部署）将最终的项目包复制到远程仓库中与其他开发者和项目共享。有一些与 Maven 生命周期相关的重要概念需要说明：当一个阶段通过 Maven 命令调用时，例如 mvn compile，只有该阶段之前以及包括该阶段在内的所有阶段会被执行。不同的 maven 目标将根据打包的类型（JAR / WAR / EAR），被绑定到不同的 Maven 生命周期阶段。Site生命周期Maven Site 插件一般用来创建新的报告文档、部署站点等。pre-site：执行一些需要在生成站点文档之前完成的工作site：生成项目的站点文档post-site： 执行一些需要在生成站点文档之后完成的工作，并且为部署做准备site-deploy：将生成的站点文档部署到特定的服务器上项目构建（Idea）现在我们开始构建项目了，本项目由IDEA来进行构建。首先我们打开Idea，选择新键项目，选择Maven项目。点击next.填写GroupId和artifactId后，继续点击next。其中groupid一般为工程组的id，而artifactId一般为工程的id。然后选择保存的文件夹，就这样一个Maven项目建立成功","categories":[{"name":"依赖管理","slug":"依赖管理","permalink":"https://me.obey.fun/categories/依赖管理/"},{"name":"项目一键构建","slug":"依赖管理/项目一键构建","permalink":"https://me.obey.fun/categories/依赖管理/项目一键构建/"}],"tags":[{"name":"版本控制","slug":"版本控制","permalink":"https://me.obey.fun/tags/版本控制/"},{"name":"依赖管理","slug":"依赖管理","permalink":"https://me.obey.fun/tags/依赖管理/"}],"keywords":[{"name":"依赖管理","slug":"依赖管理","permalink":"https://me.obey.fun/categories/依赖管理/"},{"name":"项目一键构建","slug":"依赖管理/项目一键构建","permalink":"https://me.obey.fun/categories/依赖管理/项目一键构建/"}]},{"title":"Hibernate（了解与使用）","slug":"Hibernate（了解与使用）","date":"2019-05-12T01:43:47.000Z","updated":"2019-10-28T05:44:55.188Z","comments":true,"path":"Hibernate（了解与使用）.html","link":"","permalink":"https://me.obey.fun/Hibernate（了解与使用）.html","excerpt":"","text":"Hiberante的了解框架的概述框架（framework）是一个框子——指其约束性，也是一个架子——指其支撑性。是一个基本概念上的结构，用于去解决或者处理复杂的问题。什么是框架框架：指的是软件的半成品，已经完成了部分功能。EE的三层架构EE的经典三层结构Hibernate的概述Hibernate 是一个开放源代码的对象关系映射框架，它对JDBC进行了非常轻量级的对象封装，它将POJO与数据库表建立映射关系，是一个全自动的orm框架，hibernate可以自动生成SQL语句，自动执行，使得Java程序员可以随心所欲的使用对象编程思维来操纵数据库。 Hibernate可以应用在任何使用JDBC的场合，既可以在Java的客户端程序使用，也可以在Servlet/JSP的Web应用中使用，最具革命意义的是，Hibernate可以在应用EJB的JaveEE架构中取代CMP，完成数据持久化的重任。什么是HibernateHibernate是一种ORM框架，在Java对象与关系数据库之间建立某种映射，以实现直接存取Java对象！什么是ORMORM：Object Relational Mapping（对象关系映射）。指的是将一个Java中的对象与关系型数据库中的表建立一种映射关系，从而操作对象就可以操作数据库中的表。为什么要学习Hibernate与其他操作数据库的技术相比，Hibernate具有以下几点优势Hibernate对 JBDC 访问数据库的代码做了轻量级封装，大大简化了数据访问层繁琐的重复性代码，并且减少了内存消耗，加快了运行效率。Hibernate 是一个基于 JDBC 的主流持久化框架，是一个优秀的ORM实现，它很大程度的简化 DAO（Date Access Object，数据访问对象）层编码工作。Hibernate 的性能非常好，映射的灵活性很出色。它支持很多关系型数据库，从一对一到多对多的各种复杂关系。可扩展性强，由于源代码的开源以及API的开放，当本身功能不够用时，可以自行编码进行扩展。Hibernate的入门下载Hibernate开发环境Hibernate3.x &emsp; Hibernate4.x &emsp; Hibernate5.xhttps://sourceforge.net/projects/hibernate/files/hibernate-orm/5.0.7.Final/解压 Hibernate解压完成会看到三个文件夹：documentation :Hibernate开发的文档lib :Hibernate开发包required :Hibernate开发的必须的依赖包optional :Hibernate开发的可选的jar包project :Hibernate提供的项目创建一个项目，引入jar包数据库驱动包Hibernate开发的必须的jar包Hibernate引入日志记录包创建表12345678910CREATE TABLE `cst_customer` ( `cust_id` bigint(32) NOT NULL AUTO_INCREMENT COMMENT '客户编号(主键)', `cust_name` varchar(32) NOT NULL COMMENT '客户名称(公司名称)', `cust_source` varchar(32) DEFAULT NULL COMMENT '客户信息来源', `cust_industry` varchar(32) DEFAULT NULL COMMENT '客户所属行业', `cust_level` varchar(32) DEFAULT NULL COMMENT '客户级别', `cust_phone` varchar(64) DEFAULT NULL COMMENT '固定电话', `cust_mobile` varchar(16) DEFAULT NULL COMMENT '移动电话', PRIMARY KEY (`cust_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;创建实体类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class Customer &#123; private Long cust_id; private String cust_name; private String cust_source; private String cust_industry; private String cust_level; private String cust_phone; private String cust_mobile; public Long getCust_id() &#123; return cust_id; &#125; public void setCust_id(Long cust_id) &#123; this.cust_id = cust_id; &#125; public String getCust_name() &#123; return cust_name; &#125; public void setCust_name(String cust_name) &#123; this.cust_name = cust_name; &#125; public String getCust_source() &#123; return cust_source; &#125; public void setCust_source(String cust_source) &#123; this.cust_source = cust_source; &#125; public String getCust_industry() &#123; return cust_industry; &#125; public void setCust_industry(String cust_industry) &#123; this.cust_industry = cust_industry; &#125; public String getCust_level() &#123; return cust_level; &#125; public void setCust_level(String cust_level) &#123; this.cust_level = cust_level; &#125; public String getCust_phone() &#123; return cust_phone; &#125; public void setCust_phone(String cust_phone) &#123; this.cust_phone = cust_phone; &#125; public String getCust_mobile() &#123; return cust_mobile; &#125; public void setCust_mobile(String cust_mobile) &#123; this.cust_mobile = cust_mobile; &#125; @Override public String toString() &#123; return \"Customer [cust_id=\" + cust_id + \", cust_name=\" + cust_name + \", cust_source=\" + cust_source + \", cust_industry=\" + cust_industry + \", cust_level=\" + cust_level + \", cust_phone=\" + cust_phone + \", cust_mobile=\" + cust_mobile + \"]\"; &#125; &#125;创建映射映射需要通过XML的配置文件来完成，这个配置文件可以任意命名。尽量统一命名规范（类名.hbm.xml）123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;!-- 建立类与表的映射 --&gt; &lt;class name=\"com.hibernate.demo1.Customer\" table=\"cst_customer\"&gt; &lt;!-- 建立类中的属性与表中的主键对应 --&gt; &lt;id name=\"cust_id\" column=\"cust_id\" &gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;!-- 建立类中的普通的属性和表的字段的对应 --&gt; &lt;property name=\"cust_name\" column=\"cust_name\" length=\"32\" /&gt; &lt;property name=\"cust_source\" column=\"cust_source\" length=\"32\"/&gt; &lt;property name=\"cust_industry\" column=\"cust_industry\"/&gt; &lt;property name=\"cust_level\" column=\"cust_level\"/&gt; &lt;property name=\"cust_phone\" column=\"cust_phone\"/&gt; &lt;property name=\"cust_mobile\" column=\"cust_mobile\"/&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;创建一个Hibernate的核心配置文件Hibernate的核心配置文件的名称：hibernate.cfg.xml12345678910111213141516171819202122232425262728293031323334353637&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 连接数据库的基本参数 --&gt; &lt;property name=\"hibernate.connection.driver_class\"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=\"hibernate.connection.url\"&gt;jdbc:mysql:///hibernate_day01&lt;/property&gt; &lt;property name=\"hibernate.connection.username\"&gt;root&lt;/property&gt; &lt;property name=\"hibernate.connection.password\"&gt;abc&lt;/property&gt; &lt;!-- 配置Hibernate的方言 --&gt; &lt;property name=\"hibernate.dialect\"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- 可选配置================ --&gt; &lt;!-- 打印SQL --&gt; &lt;property name=\"hibernate.show_sql\"&gt;true&lt;/property&gt; &lt;!-- 格式化SQL --&gt; &lt;property name=\"hibernate.format_sql\"&gt;true&lt;/property&gt; &lt;!-- 自动创建表 --&gt; &lt;property name=\"hibernate.hbm2ddl.auto\"&gt;update&lt;/property&gt; &lt;!-- 配置C3P0连接池 --&gt; &lt;property name=\"connection.provider_class\"&gt;org.hibernate.connection.C3P0ConnectionProvider&lt;/property&gt; &lt;!--在连接池中可用的数据库连接的最少数目 --&gt; &lt;property name=\"c3p0.min_size\"&gt;5&lt;/property&gt; &lt;!--在连接池中所有数据库连接的最大数目 --&gt; &lt;property name=\"c3p0.max_size\"&gt;20&lt;/property&gt; &lt;!--设定数据库连接的过期时间,以秒为单位, 如果连接池中的某个数据库连接处于空闲状态的时间超过了timeout时间,就会从连接池中清除 --&gt; &lt;property name=\"c3p0.timeout\"&gt;120&lt;/property&gt; &lt;!--每3000秒检查所有连接池中的空闲连接 以秒为单位--&gt; &lt;property name=\"c3p0.idle_test_period\"&gt;3000&lt;/property&gt; &lt;mapping resource=\"com/hibernate/demo1/Customer.hbm.xml\"/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt;编写测试代码1234567891011121314151617181920212223242526272829public class HibernateDemo1 &#123; @Test // 保存客户的案例 public void demo1()&#123; // 1.加载Hibernate的核心配置文件 Configuration configuration = new Configuration().configure(); // 手动加载映射 // configuration.addResource(\"com/itheima/hibernate/demo1/Customer.hbm.xml\"); // 2.创建一个SessionFactory对象：类似于JDBC中连接池 SessionFactory sessionFactory = configuration.buildSessionFactory(); // 3.通过SessionFactory获取到Session对象：类似于JDBC中Connection Session session = sessionFactory.openSession(); // 4.手动开启事务： Transaction transaction = session.beginTransaction(); // 5.编写代码 Customer customer = new Customer(); customer.setCust_name(\"王西\"); session.save(customer); // 6.事务提交 transaction.commit(); // 7.资源释放 session.close(); sessionFactory.close(); &#125;&#125;Hibernate的常见配置Hibernate的映射的配置映射的配置【class标签的配置】标签用来建立类与表的映射关系属性：name ：类的全路径table ：表名（类名与表名一致，table可以省略）catalog ：数据库名【id标签的配置】标签用来建立类中的属性与表中的主键的对应关系属性：name ：类中的属性名column ：表中的字段名（类中的属性名和表中的字段名如果一致，column可以省略）length ：长度type ：类型【property标签的配置】标签用来建立类中的普通属性与表的字段的对应关系属性：name ：类中的属性名column ：表中的字段名length ：长度type ：类型not-null ：设置非空unique ：设置唯一Hibernate的核心的配置Hibernate的核心配置方式（了解）一种方式:属性文件的方式hibernate.propertieshibernate.connection.driver_class=com.mysql.jdbc.Driver…hibernate.show_sql=true属性文件的方式不能引入映射文件（手动编写代码加载映射文件）二种方式:XML文件的方式hibernate.cfg.xml核心的配置必须的配置连接数据库的基本的参数驱动类url路径用户名密码方言可选的配置显示SQL ：hibernate.show_sql格式化SQL ：hibernate.format_sql自动建表 ：hibernate.hbm2ddl.autonone ：不使用hibernate的自动建表create ：如果数据库中已经有表，删除原有表，重新创建，如果没有表，新建表。（测试）create-drop ：如果数据库中已经有表，删除原有表，执行操作，删除这个表。如果没有表，新建一个，使用完了删除该表。（测试）update ：如果数据库中有表，使用原有表，如果没有表，创建新表（更新表结构）validate ：如果没有表，不会创建表。只会使用数据库中原有的表。（校验映射和表结构）。映射文件的引入引入映射文件的位置Hibernate的核心APIHibernate的APIConfiguration：Hibernate的配置对象Configurationconfiguration类的作用是对Hibernate进行配置，以及对它进行启动，在启动过程中，Configuration类的实例首先定位映射文档的位置，读取这些配置，然后创建一个SessionFactory对象，虽然Configuration类在整个Hibernate项目中只扮演着一个很小的角色，但它是启动hibernate时所遇到的第一个对象作用：加载核心配置文件hibernate.propertiesConfiguration cfg = new Configuration();hibernate.cfg.xmlConfiguration cfg = new Configuration().configure();加载映射文件12// 手动加载映射configuration.addResource(\"com/itheima/hibernate/demo1/ Customer.hbm.xml\");SessionFactory：Session工厂SessionFactorySessionFactory接口负责初始化Hibernate，它充当数据存储源的代理，并负责创建Session对象，这里用到了工厂模式。需要注意的事SessionFactory并不是轻量级的，因为在一般情况下，一个项目通常只需要一个SessionFactory就够，当需要操作多个数据库时，可以为每个库指定一个SessionFactory。SessionFactory内部维护了Hibernate的连接池和Hibernate的二级缓存。是线程安全的对象。一个项目创建一个对象即可。配置连接池：（了解）1234567891011&lt;!-- 配置C3P0连接池 --&gt; &lt;property name=\"connection.provider_class\"&gt;org.hibernate.connection.C3P0ConnectionProvider&lt;/property&gt; &lt;!--在连接池中可用的数据库连接的最少数目 --&gt; &lt;property name=\"c3p0.min_size\"&gt;5&lt;/property&gt; &lt;!--在连接池中所有数据库连接的最大数目 --&gt; &lt;property name=\"c3p0.max_size\"&gt;20&lt;/property&gt; &lt;!--设定数据库连接的过期时间,以秒为单位, 如果连接池中的某个数据库连接处于空闲状态的时间超过了timeout时间,就会从连接池中清除 --&gt; &lt;property name=\"c3p0.timeout\"&gt;120&lt;/property&gt; &lt;!--每3000秒检查所有连接池中的空闲连接 以秒为单位--&gt; &lt;property name=\"c3p0.idle_test_period\"&gt;3000&lt;/property&gt;抽取工具类1234567891011121314public class HibernateUtils &#123; public static final Configuration cfg; public static final SessionFactory sf; static&#123; cfg = new Configuration().configure(); sf = cfg.buildSessionFactory(); &#125; public static Session openSession()&#123; return sf.openSession(); &#125;&#125;Session：类似Connection对象是连接对象Session接口负责执行被持久化对象的CRUD操作（CRUD的任务是完成与数据库的交流，包含很多藏剑的SQL语句）。但需要注意的事Session对象是非线程安全的。同时，Hibernate的Session不同于JSP应用中的HttpSession。这里当使用Session这个术语时，其实指的是Hibernate中的Session，而以后会将HttpSession对象称为用户Session。Session代表的是Hibernate与数据库的链接对象。不是线程安全的。与数据库交互桥梁。Session中的API保存方法：Serializable save(Object obj);查询方法：T get(Class c,Serializable id);T load(Class c,Serializable id);get方法和load方法的区别？12345678910111213141516171819202122232425public void demo2()&#123; Session session = HibernateUtils.openSession(); Transaction tx = session.beginTransaction(); /** * get方法 * * 采用的是立即加载，执行到这行代码的时候，就会马上发送SQL语句去查询。 * * 查询后返回是真实对象本身。 * * 查询一个找不到的对象的时候，返回null * * load方法 * * 采用的是延迟加载（lazy懒加载），执行到这行代码的时候，不会发送SQL语句，当真正使用这个对象的时候才会发送SQL语句。 * * 查询后返回的是代理对象。javassist-3.18.1-GA.jar 利用javassist技术产生的代理。 * * 查询一个找不到的对象的时候，返回ObjectNotFoundException */ // 使用get方法查询 /*Customer customer = session.get(Customer.class, 100l); // 发送SQL语句 System.out.println(customer);*/ // 使用load方法查询 Customer customer = session.load(Customer.class, 200l); System.out.println(customer); tx.commit(); session.close(); &#125;修改方法void update(Object obj);123456789101112131415161718public void demo3()&#123; Session session = HibernateUtils.openSession(); Transaction tx = session.beginTransaction(); // 直接创建对象，进行修改 /*Customer customer = new Customer(); customer.setCust_id(1l); customer.setCust_name(\"王聪\"); session.update(customer);*/ // 先查询，再修改(推荐) Customer customer = session.get(Customer.class, 1l); customer.setCust_name(\"王小贱\"); session.update(customer); tx.commit(); session.close(); &#125;删除方法void delete(Object obj);1234567891011121314151617// 删除操作 public void demo4()&#123; Session session = HibernateUtils.openSession(); Transaction tx = session.beginTransaction(); // 直接创建对象，删除 /* Customer customer = new Customer(); customer.setCust_id(1l); session.delete(customer);*/ // 先查询再删除(推荐)--级联删除 Customer customer = session.get(Customer.class, 2l); session.delete(customer); tx.commit(); session.close(); &#125;保存或更新void saveOrUpdate(Object obj)12345678910111213141516public void demo5()&#123; Session session = HibernateUtils.openSession(); Transaction tx = session.beginTransaction(); /*Customer customer = new Customer(); customer.setCust_name(\"王凤\"); session.saveOrUpdate(customer);*/ Customer customer = new Customer(); customer.setCust_id(3l); customer.setCust_name(\"李如花\"); session.saveOrUpdate(customer); tx.commit(); session.close(); &#125;查询所有1234567891011121314151617181920// 查询所有 public void demo6()&#123; Session session = HibernateUtils.openSession(); Transaction tx = session.beginTransaction(); // 接收HQL：Hibernate Query Language 面向对象的查询语言 /*Query query = session.createQuery(\"from Customer\"); List&lt;Customer&gt; list = query.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125;*/ // 接收SQL： SQLQuery query = session.createSQLQuery(\"select * from cst_customer\"); List&lt;Object[]&gt; list = query.list(); for (Object[] objects : list) &#123; System.out.println(Arrays.toString(objects)); &#125; tx.commit(); session.close(); &#125;Transaction：事务对象Hibernate中管理事务的对象。commit();rollback();主键生成策略&amp;一级缓存&amp;事物管理Hibernate持久化类的编写规则什么是持久化类Hibernate 是持久层的ORM映射框架，专注于数据的持久化工作。所谓的持久化，就是将内存中的数据永久存储到关系型数据库中。那么知道了什么是持久化，什么又是持久化类呢？其实所谓的持久化类指的是一个Java类与数据库表建立了映射关系，那么这个类称为持久化类。其实你可以简单的理解为持久化类就是一个Java类有了一个映射文件与数据库的表建立了关系。持久化类的编写规则我们在编写持久化类的时候需要有以下几点需要注意：持久化类需要提供无参数的构造方法。因为在Hibernate的底层需要使用反射生成类的实例。持久化类的属性需要私有，对私有的属性提供公有的get和set方法。因为在Hibernate底层会将查询到的数据进行封装。持久化类的属性要尽量使用包装类的类型。因为包装类和基本数据类型的默认值不同，包装类的类型语义描述更清晰而基本数据类型不容易描述。持久化类要有一个唯一标识OID与表的主键对应。因为Hibernate中需要通过这个唯一标识OID区分在内存中是否是同一个持久化类。在Java中通过地址区分是否是同一个对象的，在关系型数据库的表中式通过主键区分是否同一条记录。那么Hibernate就是通过这个OID来进行区分的。Hibernate是不允许在内存中出现两个ODI相同的持久化对象的。持久化类尽量不要使用final进行修饰。因为Hibernate中有延迟加载的机制，这个机制中会产生代理对象，Hibernate产生代理对象使用的是字节码的增强技术完成的，其实就是产生了当前类的一个子类对象实现的。如果使用了final修饰持久化类。那么久不能产生子类，从而就不会产生代理对象，那么Hibernate的延迟加载策略（是一种优化手段）就会失效。Hibernate主键生成策略主键的类型在讲解Hibernate的逐渐生成策略之前，先来了解两个概念，即自然主键和代理主键，具体如下：自然主键：把具有业务含义的字段作为主键，称之为自然主键。例如在customer表中，如果把那么字段作为主键，其前提条件必须是：每一个客户的姓名不允许为null，不允许客户重名，并且不允许修改客户姓名。尽管着也是可行的，但是不能满足不断变化的业务需求，一旦出现了允许客户重名的业务需求，就必须修改数据模型，重新定义表的主键，这给数据库的维护增加了难度。代理主键：把不具备业务含义的字段作为主键，称之为代理主键。该字段一般取名为“ID”，通常为整数类型，因为整数类型比字符串类型要节省更多的数据库空间。Hibernate的主键生成策略：Hibernate中，提供了几个内置的主键生成策略，其常用主键生成策略的名称和描述如下名称描述increment用于long、short、或int类型，由Hibernate自动以递增的方式生成唯一标识符，每次增量为1。只有当没有用其它进程想同一张表中插入数据时才可以使用，不能在集群环境下使用。适用于代理主键。identity采用底层数据库本身提供的主键生成标识符，条件是数据库支持自动增长数据类型。在DB2、MySQL、MS SQL Server、Sybase和HypersonicSQL数据库中可以使用该生成器，该生成器要求在数据库中把主键定义成为自增长类型。适用于代理主键。sequenceHiberante根据底层数据库序列生成标识符。条件是数据库支持序列。适用于代理主键。native根据底层数据库对自动生成标识符的能力来选择identity、sequence、hilo三种生成器中的一种，适合跨数据库平台开发。适用于代理主键。uuidHibernate采用128位的UUID算法来生成标识符。该算法能够在网络环境中生成唯一的字符串标识符，其UUID被编码为一个长度为32为的十六进制字符串。这种策略并不流行，因为字符串类型的主键比整数类型的主键占用更多的数据库空间。适用于代理主键。assigned由java程序负责生成标识符，如果不指定id元素的generator属性，则默认使用该主键策略。适用于自然主键。Hibernate的持久化对象的三种状态持久化对象三种状态的概述了解了主键的生成策略之后，我们可以进一步来了解持久化类了。Hibernate为了更好的来管理持久化类，特将持久化类分成了三种状态。在Hibernate中持久化的对象可以划分为三种状态，分别是瞬时态、持久态和脱管态，一个持久化类的实例可能处于三种不同状态中的某一种，三种状态详细介绍如下。瞬时态（transient）也被称为临时态或者自由态，瞬时态的实例是由new命令创建、开辟内存空间的对象，不存在持久化标识OID（相当于主键值），尚未与Hiberante Session关联，在数据库中也米有记录，失去引用后将被JVM回收。瞬时状态的对象在内存中式孤立存在的，与数据库中的数据无如何关联，仅是一个信息携带的载体。持久态（persistent）的对象存在持久化标识OID，加入到了Session缓存中，并且相关联的Session没有关闭，在数据库中有对应的记录，每条记录只对应唯一的持久化对象，需要注意的是，持久态对象是在事务还未提交前变成持久态的。脱管态（detached）也被称为离线态或者游离态，当某个持久化状态的实例与Session的管理被关闭时就变成了脱管态。脱管态对象存在持久化标识OID，并且仍然与数据库中的数据存在关联，只是失去了与当前Session的关联，脱管状态对象发生改变时Hibernate不能检测到。区分对象的三种状态为了帮助大家更好的理解持久化对象的三种状态，接下来通过具体的案例来演示持久化对象的三种状态。12345678910111213141516171819202122232425//测试对象的三种状态public class Demo &#123; @Test //查看三种状态 public void fun1()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 Customer c = new Customer(); // 没有id, 没有与session关联 =&gt; 瞬时状态 c.setCust_name(\"联想\"); // 瞬时状态 Serializable id = session.save(c); // 持久化状态, 有id,有关联 //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 System.out.println(c);//托管态对象：有持久化标识OID，没有被session管理 &#125;&#125;c 对象由new关键字创建,此时还未与Session进行关联，它的状态称为瞬时态；在执行了session.save(c)操作后，c对象纳入了Session的管理范围，这时的 c 对象变成了持久态对象，此时Session的事务还没有被提交；程序执行完commit()操作并关闭了Session后，c对象与Session的关联被关闭，此时 c 对象就变成脱管态。Hibernate持久化对象的三种状态转换从图中可以看出，当一个对象被执行new关键字创建后，该对象处于瞬时态；当对瞬时态对象执行Session的save()或saveOrUpdate()方法后，该对象将被放入Session的以及缓存，对象进入持久态；当对持久态对象执行evict()、close()或clear()操作后，对象进入托管态；当直接执行Session的get()、load()、find()或iterate()等方法从数据库里查询对象时，查询到的对象也处于持久态；当对数据库中的记录进行update()、saveOrUpdate()以及lock()等操作后，此时脱管态的对象就过渡到持久态；由于瞬时态和脱管态的对象不在session的管理范围，所以会在一段时间后被JVM回收。持久化对象的三种状态可以通过调用Session中的一系列方法实现状态间的转换，具体如下：瞬时态转换到其他状态通过前面学习可知，瞬时态的对象由new关键字创建，瞬时态对象转换到其他状态总结如下：瞬间态转换为持久态：执行Session的save()或saveOrUpdate()方法。瞬时态转换为脱管态：为瞬时态对象设置持久化标识OID。由于持久化对象状态演化图中没有涉及到瞬时态转换到脱管态的情况，这里做下简要的说明，在前面学习中可知，脱管态对象窜OID，但是没有Session的关联，也就是说脱管态和瞬时态的区别就是OID有没有值，所以可以通过为瞬时态对象设置OID，使其变成脱管态对象。12Customer customer = new Customer(); //瞬时态customer.setCust_id(1); //脱管态持久态对象转换到其他状态持久化对象可以直接通过Hibernate中Session的get()、load()方法，或者Query查询从数据库中获得，持久态对象转换到其他的状态总结如下：持久态转换为瞬时态：执行Session的delete()方法，需要注意的是被删除的持久化对象，不建议再次使用持久态转换为脱管态：执行Session的evict()、close()或clear()方法。evict()方法用于清除异己缓存的所有对象。脱管态对象转换到其他状态脱管态对象无法直接获得，是由其他状态对象转换而来的，脱管态对象转换到其他状态总结如下：脱管态转换为持久态：执行Session的update()、saveOrUpdate()或lock()方法。脱管态转换为瞬时态：将脱管态对象的持久化标识OID设置为null。由于持久化对象状态演化图中没有涉及到脱管态换到瞬时态的情况，这里做下简要的说明，跟瞬时态转换到脱管态的情况相似，脱管态和瞬时态的区别就是OID有没有值，所以可以通过将脱管对象的OID设置为null，使其变成瞬时态对象。例如在session.close()操作后，加入代码customer.setCust_id(null);，customer对象将由脱管态转换为瞬时态。持久态对象能够自动更新数据库我们已经持久化对象的三种状态了，其实我们主要去研究持久态对象就够了，持久态对象其实有一个非常重要的特性：持久态对象可以自动更新数据库。123456789101112131415161718// 持久化状态特点: 持久化状态对象的任何变化都会自动同步到数据库中. public void fun3()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 Customer c = session.get(Customer.class, 1l);//持久化状态对象 c.setCust_name(\"微软公司\"); //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125;执行测试我们会发现，我们并没有手动调用update方法，Hibernate就可以将数据自动更新了。持久态对象就有这样的一个功能。持久态对象之所以有这样的功能其实都依赖了Hibernate的一级缓存。接下来我们就开始学习Hibernate缓存。Hibernate的一级缓存缓存是计算机领域非常通用的概念。它介于应用程序和永久性数据存储源(如硬盘上的文件或者数据库）之间，其作用是降低应用程序直接读写永久性数据存储源的频率，从而提高应用的运行性能。缓存中的数据是数据存储源中数据的拷贝。缓存的物理介质通常是内存。Hibernate的缓存分为一级缓存和二级缓存,Hibernate的这两级缓存都位于持久化层，存储的都是数据的备份。其中第一级缓存为Hibernate的内置缓存，不能被卸载。接下来围绕Hibernate的一级缓存进行详细地讲解。什么是Hibernate的一级缓存Hibernate的一级缓存就是指Session缓存，Session缓存是一块内存空间，用来存放相互管理的java对象，在使用Hibernate查询对象的时候，首先会使用对象属性的OID值在Hibernate的一级缓存中进行查找，如果找到匹配OID值的对象，就知己将该对象从一级缓存中取出使用，不会再查询数据库；如果没有找到相同OID值的对象，则会去数据库中查找相应数据。当从数据库中查询到所需数据时，该数据信息也会放置到一级缓存中。Hibernate的一级缓存的作用就是减少对数据库的访问次数。在Session接口的实现中包含一系列的Java集合，这些Java集合构成了Session缓存。只要Session实例没有结束生命周期，存放在它缓存中的对象也不会结束生命周期。固一级缓存也被称为是Session基本的缓存。Hibernate的一级缓存有如下特点：当应用程序调用Session接口的save()、update()、saveOrUpdate，如果Session缓存中没有相应的对象，Hibernate就会自动的把从数据库中查询到的相应对象信息加入到一级缓存中去。当调用Session接口的load()、get()方法，一级Query接口的list()、iterator()方法时，会判断缓存中是否存在该对象，有则返回，不会查询数据库，如果缓存中没有要查询对象，在去数据库中查询对应对象，并添加到一级缓存中。当调用Session的close()方法时，Session缓存会被清空。测试一级缓存我们已经大致了解什么是一级缓存，那么一级缓存具体是否存在呢，我们可以通过如下的程序来证明以及缓存是存在的。1234567891011121314@Test//证明Hibernate的一级缓存的存在：public void demo1()&#123; Sesion session = HibernateUtils.openSession(); Transaction tx = session.beginTransaction(); Customer customer1 = session.get(Customer.class,1l)//马上发送一条sql查询1号客服，并将数据存入了一级缓存 System.out.println(customer1); Customer customer2 = session.get(Customer.class,1l)//没有发生SQL语句从一级缓存中获取数据 System.out.println(customer2); System.out.println(customer1 == customer2);//true 一级缓存 缓存的是对象的地址。 tx.commit(); session.close();&#125;在以上代码中，第一次执行Session的get()方法获取customer1对象时，由于一级缓存中没有数据，所以Hibernate会向数据库发送一条sql语句，查询id等于1的对象；当再次调用了session的get()方法获取customer2对象时，将不会再发送sql语句，这是因为customer2对象是从一级缓存中获取的。一级缓存的内部结构：（快照区）Hibernate向一级缓存放入数据时，同时复制一份数据放入到Hibernate快照中，当使用commit()方法提交事务时，同时会清理Session的一级缓存，这时会使用OID判断一级缓存中的对象和快照中的对象是否一致，如果两个对象中的属性发生变化，则执行update语句，将缓存的内容同步到数据库，并更新快照；如果一致，则不执行update语句。Hibernate快照的作用就是确保一级缓存中的数据和数据库中的数据一致。Hibernate 的事务控制Hibernate是对JDBC的轻量级封装，其主要功能是操作数据库。在操作数据库过程中，经常会遇到事务处理的问题，那么我们接下来就来介绍Hibernate中的事务管理。什么是事务在数据库操作中，一项事务(Transaction)是由一条或多条操作数据库的SQL语句组成的一个不可分割的工作单元。当食物中的所有操作都正常完成时，整个事务才能被提交到数据库中，如果有一项操作没有完成，则整个事务都会被回滚。事务的四个特性事务有很严格的定义，需要同时满足四个特性，即原子性、一致性、隔离性、持久性。这四个特性通常称之为ACID特性，具体如下：原子性（Atomic）: 表示将事务中所做的操作捆绑成一个不可分割的单元，即对事务所进行的数据修改等操作，要么全部执行，要么全都不执行。一致性（Consistency）: 表示事务完成时，必须使所有的数据都保持一致状态。隔离性（Isolation）: 指一个事物的执行不能被其它事务干扰。即一个事务内部的操作及使用的数据对并发的其他事务是隔离性的，并发执行的各个事务之间不能相互干扰。持久性（Durability）: 持久性也称为永久性（permanence），指一个事务一旦提交，它对数据库中数据的改变就应该是永久性的。提交后的其他操作或故障不会对其有任何影响。事务的并发问题在实际应用过程中，数据库是要被多个用户所共同访问的。在多个事务同时使用相同的数据时，可能会发生并发的问题，具体如下。脏读：一个事务读取到另一个事务未提交的数据。不可重复读：一个事务读到了另一个事务已经提交的update的数据，导致在同一个事务中的多次查询结果不一致。虚读/幻读：一个事务读到了另一个事务已经提交的insert的数据，导致在同一个事务中的多次查询结果不一致事务的隔离级别为了避免事务并发问题的发生，在标准SQL规范中，定义了4个事务隔离级别，不同隔离级别对事务的处理不同。读未提交（ReadUncommitted，1级）：一个事务在执行过程中，既可以访问其他事务未提交的新插入的数据，又可以访问未提交的修改数据。如果一个事务已经开始写数据，则另外一个事务则不允许同时进行写操作，但允许其他事务读此行数据。此隔离级别可防止丢失更新。已提交读（Read Committed，2级）：一个事务在执行过程中，既可以访问其他事务成功提交的新插入的数据，又可以访问成功修改的数据。读取数据的事务允许其他事务继续访问该行数据，但是未提交的写事务将会禁止其他事务访问该行。此隔离级别可有效防止脏读。可重复读（Repeatable Read，4级）：一个事务在执行过程中，可以访问其他事务成功提交的新插入数据，但不可以访问成功修改的数据。读取数据的事务将会禁止写事务（但允许读事务），写事务则禁止任何其他事务，此隔离级别可有效的防止不可重复读和脏读。序列化/串行化（Serializable，8级）：提供严格的事务隔离，它要求事务序列化执行，事务只能一个接着一个地执行，但不能并发执行。此隔离级别可有效的防止脏读、不可重复读和幻读。隔离级别含义READ_UNCOMMITTED允许你读取还未提交的改变了的数据。可能导致脏、幻、不可重复读READ_COMMITED允许在并发事务已经提交后读取。可防止脏读，但幻读和不可重复读仍可发生REPEATABLE_READ对相同字段的多次读取是一致的，除非数据被事务本身改变。可以防止脏、不可重复读，但幻读仍可能发生。SERIALIZABLE完全服从ACID的隔离级别，确保不发生脏、幻、不可重复读。这在所有的隔离级别中是最慢的，它是典型的通过完全锁定在事务中涉及的数据表来完成的事务的隔离界别，是由数据库提供的，并不是所有数据库都支持四种隔离级别MySQL：READ_UNCOMMITTED、READ_COMMITTED、REPEATABLE_READ、SERIALIZABLE(默认 REPEATABLE_READ)Oracle：READ_UNCOMMITTED、READ_COMMITTED、SERIALIZABLE(默认 READ_COMMITTED)在使用数据库时候，隔离级别越高，安全性越高，性能越低。实际开发中，不会选择最高或者最低隔离级别，选择READ_COMMITTED(Oracle 默认)、REPEATABLE_READ(Mysql 默认)Hibernate 中的事务管理在 Hibernate 中，可以通过代码来操作管理实务，如通过 Transaction tx = session.beginTransaction(); 开启一个事务；持久化操作后，通过 tx.commit();提交事务；如果食物出现异常，又通过tx.rollback();操作来撤销事务（事务回滚）。除了在代码块中队事务开启，提交和回滚操作外，还可以在 Hibernate 的配置文件中队事务进行配置。配置文件中，可以设置事务的隔离级别。其具体的配置方法是在 hibernate.cfg.xml 文件中的&lt;session-factory&gt;标签元素中进行的。配置方法如下所示。1234567891011&lt;!-- 引入orm元数据 路径书写: 填写src下的路径 --&gt; &lt;!-- 指定hibernate操作数据库时的隔离级别 #hibernate.connection.isolation 1|2|4|8 0001 1 读未提交 0010 2 读已提交 0100 4 可重复读 1000 8 串行化 --&gt; &lt;property name=\"hibernate.connection.isolation\"&gt;4&lt;/property&gt;到这我们已经设置了事务的隔离级别，那么我们在真正进行事务管理的时候，需要考虑事务的应用的场景，也就是说我们的事务控制不应该是在DAO层实现的，应该在Service层实现，并且在Service中调用多个Dao实现一个业务逻辑的操作。具体操作如下显示：其实最主要的是如何保证在Service中开启的事务时使用的Session对象和DAO中多个操作使用的是同一个Session对象。其实有两个方法可以实现：可以在业务层获取到Session，并将Session作为参数传递给DAO。可以使用ThreadLocal将业务层获取的Session绑定到当前线程中，然后再DAO中获取Session的时候，都从当前线程中获取。其实使用第二种方式肯定是最优方案，那么具体的实现已经不用我们来完成了，Hibernate的内部已经将这个事情做完了。我们只需要完成一段配置即可。Hibernate5中自身提供了三种管理Session对象的方法Session对象的生命周期与本地线程绑定、Session对象的生命周期与 JTA 事务绑定Hibernate委托程序管理 Session 对象的生命周期在 Hibernate 的配置文件中，hibernate.current_session_context_class 属性用于指定 Session 管理方式，可选值包括Thread：Session对象的生命周期与本地线程绑定jta： Session对象的生命周期与JTA事务绑定managed： Hibernate 委托程序来管理 Session 对象的生命周期在hibernate.cfg.xml中进行如下配置：12&lt;!-- 指定session与当前线程绑定 --&gt; &lt;property name=\"hibernate.current_session_context_class\"&gt;thread&lt;/property&gt;hibernate提供sessionFactory.getCurrentSession()创建一个session和ThreadLocal绑定方法。在HibernateUtil工具类中更改getCurrentSession方法：1234//获取当前线程绑定的会话public static Session getCurrentSession()&#123; return sessionFactory.getCurrentSession();&#125;而且Hibernate中提供的这个与线程绑定的 session 可以不用关闭，当线程执行结束后，就会自动关闭了。Hibernate的其他APIQueryQuery代表面向对象的一个 Hibernate 查询操作。在 Hibernate 中，通常使用session.createQuery()方法接受一个HQL语句，然后调用 Query 的list()或uniqueResult() 方法执行查询。所谓的 HQL 是Hibernate Query Language 缩写，其语法很像 SQL 语法，但它是完全面向对象的。在 Hibernate中使用 Query对象的步骤，具体所示：获得Hibernate的Session对象。编写HQL语句。调用session.createQuery 创建查询对象。如果HQL语句包含参数，则调用Query的 setXxx 设置参数。调用 Query 对象的 list()或 uniqueResult() 方法执行查询。了解了使用 Query 对象的步骤后，接下来，通过具体示例来演示 Query 对象的查询操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141//测试HQL语句public class Demo &#123; @Test //基本查询 public void fun1()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1&gt; 书写HQL语句// String hql = \" from cn.itheima.domain.Customer \"; String hql = \" from Customer \"; // 查询所有Customer对象 //2&gt; 根据HQL语句创建查询对象 Query query = session.createQuery(hql); //3&gt; 根据查询对象获得查询结果 List&lt;Customer&gt; list = query.list(); // 返回list结果 //query.uniqueResult();//接收唯一的查询结果 System.out.println(list); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //条件查询 //HQL语句中,不可能出现任何数据库相关的信息的 public void fun2()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1&gt; 书写HQL语句 String hql = \" from Customer where cust_id = 1 \"; // 查询所有Customer对象 //2&gt; 根据HQL语句创建查询对象 Query query = session.createQuery(hql); //3&gt; 根据查询对象获得查询结果 Customer c = (Customer) query.uniqueResult(); System.out.println(c); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //条件查询 //问号占位符 public void fun3()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1&gt; 书写HQL语句 String hql = \" from Customer where cust_id = ? \"; // 查询所有Customer对象 //2&gt; 根据HQL语句创建查询对象 Query query = session.createQuery(hql); //设置参数 //query.setLong(0, 1l); query.setParameter(0, 1l); //3&gt; 根据查询对象获得查询结果 Customer c = (Customer) query.uniqueResult(); System.out.println(c); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //条件查询 //命名占位符 public void fun4()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1&gt; 书写HQL语句 String hql = \" from Customer where cust_id = :cust_id \"; // 查询所有Customer对象 //2&gt; 根据HQL语句创建查询对象 Query query = session.createQuery(hql); //设置参数 query.setParameter(\"cust_id\", 1l); //3&gt; 根据查询对象获得查询结果 Customer c = (Customer) query.uniqueResult(); System.out.println(c); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //分页查询 public void fun5()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1&gt; 书写HQL语句 String hql = \" from Customer \"; // 查询所有Customer对象 //2&gt; 根据HQL语句创建查询对象 Query query = session.createQuery(hql); //设置分页信息 limit ?,? query.setFirstResult(1); query.setMaxResults(1); //3&gt; 根据查询对象获得查询结果 List&lt;Customer&gt; list = query.list(); System.out.println(list); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125;&#125;Query中出来使用list()方法查询全部数据外，还有其它一些常用方法，具体如下：setter方法： Query接口中提供了一系列的 setter 方法用于设置查询语句的参数，针对不同的数据类型，需要用到不同的setter方法。iterator()方法：该方法用于查询语句，返回的结果是一个Iterator对象，在读取时只能按照顺序方式读取，它仅把使用到的数据转换成Java实体对象。uniqueResult()方法：该方法用于返回唯一的结果，在确保只有一条记录的查询时可以使用该方法。executeUpdate()方法：该方法是 Hibernate 的新特性，它支持 HQL 语句的更新和删除操作。setFirstResult()方法：该方法可以设置获取第一个记录的位置，也就是它表示从第几条记录开始查询，默认从0开始计算。setMaxResult()方法：该方法用于设置结果集的最大记录数，通常与setFirstResult() 方法结合使用，用于限制结果集的范围，以实现分页功能。CriteriaCriteria 是一个完全面向对象，可扩展的条件查询API，通过它完全不需要考虑数据库底层如何实现，以及SQL语句如何编写，它是Hibernate框架的核心查询对象。Criteria查询，又称为 QBC 查询（Query By Criteria），它是Hibernate的另一种对象检索方式。org.hibernate.criterion.Criterion是 Hibernate 提供的一个面向对象查询条件接口，一个单独的查询就是 Criterion 接口的一个实例，用于限制 Criteria 对象的查询，在 Hibernate 中 Criterion 对象的创建通常是通过 Restrictions 工厂类完成的，它提供饿了条件查询方法。通常，使用 Criteria 对象查询数据的主要步骤，具体如下：获得Hibernate的 Session 对象。通过 Session 获得 Criteria 对象。使用 Restrictions 的静态方法创建 Criterion 条件对象。Restrictions 类中提供了一系列用于设定查询条件的静态方法，这些静态方法都返回Criterion 实例，每个 Criterion 实例代表一个查询条件。向 Criteria 对象中添加 Criterion 查询条件。Criteria的 add() 方法用于查询条件。执行 Criterita 的 list() 或 uniqueResult() 获得结果。了解了 Criteria 对象的使用步骤后，接下来，通过具体示例来演示 Criterria 对象的查询操作。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121//测试Criteria查询public class Demo &#123; @Test //基本查询 public void fun1()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //查询所有的Customer对象 Criteria criteria = session.createCriteria(Customer.class); List&lt;Customer&gt; list = criteria.list(); System.out.println(list); // Customer c = (Customer) criteria.uniqueResult(); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //条件查询 //HQL语句中,不可能出现任何数据库相关的信息的 // &gt; gt // &gt;= ge // &lt; lt // &lt;= le // == eq // != ne // in in // between and between // like like // is not null isNotNull // is null isNull // or or // and and public void fun2()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //创建criteria查询对象 Criteria criteria = session.createCriteria(Customer.class); //添加查询参数 =&gt; 查询cust_id为1的Customer对象 criteria.add(Restrictions.eq(\"cust_id\", 1l)); //执行查询获得结果 Customer c = (Customer) criteria.uniqueResult(); System.out.println(c); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //分页查询 public void fun3()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //创建criteria查询对象 Criteria criteria = session.createCriteria(Customer.class); //设置分页信息 limit ?,? criteria.setFirstResult(1); criteria.setMaxResults(2); //执行查询 List&lt;Customer&gt; list = criteria.list(); System.out.println(list); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //查询总记录数 public void fun4()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //创建criteria查询对象 Criteria criteria = session.createCriteria(Customer.class); //设置查询的聚合函数 =&gt; 总行数 criteria.setProjection(Projections.rowCount()); //执行查询 Long count = (Long) criteria.uniqueResult(); System.out.println(count); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125;&#125;SQLQuerySQLQuery 这个就比较简单了，这个接口用于接收一个sql语句进行查询，然后调用 list()或者 uniqueResult() 方法进行查询。但是 sql 语句不会直接封装到实体对象中，需要我们手动写代码才可以封装到实体中。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126//测试原生SQL查询public class Demo &#123; @Test //基本查询 public void fun1()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1 书写sql语句 String sql = \"select * from cst_customer\"; //2 创建sql查询对象 SQLQuery query = session.createSQLQuery(sql); //3 调用方法查询结果 List&lt;Object[]&gt; list = query.list(); //query.uniqueResult(); for(Object[] objs : list)&#123; System.out.println(Arrays.toString(objs)); &#125; //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //基本查询 public void fun2()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1 书写sql语句 String sql = \"select * from cst_customer\"; //2 创建sql查询对象 SQLQuery query = session.createSQLQuery(sql); //指定将结果集封装到哪个对象中 query.addEntity(Customer.class); //3 调用方法查询结果 List&lt;Customer&gt; list = query.list(); System.out.println(list); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //条件查询 public void fun3()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1 书写sql语句 String sql = \"select * from cst_customer where cust_id = ? \"; //2 创建sql查询对象 SQLQuery query = session.createSQLQuery(sql); query.setParameter(0, 1l); //指定将结果集封装到哪个对象中 query.addEntity(Customer.class); //3 调用方法查询结果 List&lt;Customer&gt; list = query.list(); System.out.println(list); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125; @Test //分页查询 public void fun4()&#123; //1 获得session Session session = HibernateUtils.openSession(); //2 控制事务 Transaction tx = session.beginTransaction(); //3执行操作 //------------------------------------------- //1 书写sql语句 String sql = \"select * from cst_customer limit ?,? \"; //2 创建sql查询对象 SQLQuery query = session.createSQLQuery(sql); query.setParameter(0, 0); query.setParameter(1, 1); //指定将结果集封装到哪个对象中 query.addEntity(Customer.class); //3 调用方法查询结果 List&lt;Customer&gt; list = query.list(); System.out.println(list); //------------------------------------------- //4提交事务.关闭资源 tx.commit(); session.close();// 游离|托管 状态, 有id , 没有关联 &#125;&#125;Hibernate的进阶表操作-多对多配置数据库表与表之间的关系一对多关系什么样关系属于一对多？一个部门对应多个员工，一个员工只能属于某一个部门。一个客户对应多个联系人，一个联系人只能属于某一个客服。多对多关系什么关系属于多对多？一个学生可以选择多门课程，一门课程也可以被多个学生选择。一个用户可以选择多个角色，一个角色也可以被多个用户选择一对一关系（了解）什么样关系属于一对一？一个公司只能有一个注册地址，一个注册地址只能被一个公司注册。Hibernate 一对多的关系配置创建一个项目，引入相应 jar 包创建数据库和表12345678910111213141516171819202122232425262728CREATE TABLE `cst_customer` ( `cust_id` bigint(32) NOT NULL AUTO_INCREMENT COMMENT '客户编号(主键)', `cust_name` varchar(32) NOT NULL COMMENT '客户名称(公司名称)', `cust_source` varchar(32) DEFAULT NULL COMMENT '客户信息来源', `cust_industry` varchar(32) DEFAULT NULL COMMENT '客户所属行业', `cust_level` varchar(32) DEFAULT NULL COMMENT '客户级别', `cust_phone` varchar(64) DEFAULT NULL COMMENT '固定电话', `cust_mobile` varchar(16) DEFAULT NULL COMMENT '移动电话', PRIMARY KEY (`cust_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;CREATE TABLE `cst_linkman` ( `lkm_id` bigint(32) NOT NULL AUTO_INCREMENT COMMENT '联系人编号(主键)', `lkm_name` varchar(16) DEFAULT NULL COMMENT '联系人姓名', `lkm_cust_id` bigint(32) DEFAULT NULL COMMENT '客户id', `lkm_gender` char(1) DEFAULT NULL COMMENT '联系人性别', `lkm_phone` varchar(16) DEFAULT NULL COMMENT '联系人办公电话', `lkm_mobile` varchar(16) DEFAULT NULL COMMENT '联系人手机', `lkm_email` varchar(64) DEFAULT NULL COMMENT '联系人邮箱', `lkm_qq` varchar(16) DEFAULT NULL COMMENT '联系人qq', `lkm_position` varchar(16) DEFAULT NULL COMMENT '联系人职位', `lkm_memo` varchar(512) DEFAULT NULL COMMENT '联系人备注', PRIMARY KEY (`lkm_id`), KEY `FK_cst_linkman_lkm_cust_id` (`lkm_cust_id`), CONSTRAINT `FK_cst_linkman_lkm_cust_id` FOREIGN KEY (`lkm_cust_id`) REFERENCES `cst_customer` (`cust_id`) ON DELETE NO ACTION ON UPDATE NO ACTION) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;创建实体一的一方的实体12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class Customer &#123; private Long cust_id; private String cust_name; private String cust_source; private String cust_industry; private String cust_level; private String cust_phone; private String cust_mobile; // 通过ORM方式表示：一个客户对应多个联系人。 // 放置的多的一方的集合。Hibernate默认使用的是Set集合。 private Set&lt;LinkMan&gt; linkMans = new HashSet&lt;LinkMan&gt;(); public Long getCust_id() &#123; return cust_id; &#125; public void setCust_id(Long cust_id) &#123; this.cust_id = cust_id; &#125; public String getCust_name() &#123; return cust_name; &#125; public void setCust_name(String cust_name) &#123; this.cust_name = cust_name; &#125; public String getCust_source() &#123; return cust_source; &#125; public void setCust_source(String cust_source) &#123; this.cust_source = cust_source; &#125; public String getCust_industry() &#123; return cust_industry; &#125; public void setCust_industry(String cust_industry) &#123; this.cust_industry = cust_industry; &#125; public String getCust_level() &#123; return cust_level; &#125; public void setCust_level(String cust_level) &#123; this.cust_level = cust_level; &#125; public String getCust_phone() &#123; return cust_phone; &#125; public void setCust_phone(String cust_phone) &#123; this.cust_phone = cust_phone; &#125; public String getCust_mobile() &#123; return cust_mobile; &#125; public void setCust_mobile(String cust_mobile) &#123; this.cust_mobile = cust_mobile; &#125; public Set&lt;LinkMan&gt; getLinkMans() &#123; return linkMans; &#125; public void setLinkMans(Set&lt;LinkMan&gt; linkMans) &#123; this.linkMans = linkMans; &#125; &#125;多的一方的实体12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576public class LinkMan &#123; private Long lkm_id; private String lkm_name; private String lkm_gender; private String lkm_phone; private String lkm_mobile; private String lkm_email; private String lkm_qq; private String lkm_position; private String lkm_memo; // 通过ORM方式表示：一个联系人只能属于某一个客户。 // 放置的是一的一方的对象。 private Customer customer; public Long getLkm_id() &#123; return lkm_id; &#125; public void setLkm_id(Long lkm_id) &#123; this.lkm_id = lkm_id; &#125; public String getLkm_name() &#123; return lkm_name; &#125; public void setLkm_name(String lkm_name) &#123; this.lkm_name = lkm_name; &#125; public String getLkm_gender() &#123; return lkm_gender; &#125; public void setLkm_gender(String lkm_gender) &#123; this.lkm_gender = lkm_gender; &#125; public String getLkm_phone() &#123; return lkm_phone; &#125; public void setLkm_phone(String lkm_phone) &#123; this.lkm_phone = lkm_phone; &#125; public String getLkm_mobile() &#123; return lkm_mobile; &#125; public void setLkm_mobile(String lkm_mobile) &#123; this.lkm_mobile = lkm_mobile; &#125; public String getLkm_email() &#123; return lkm_email; &#125; public void setLkm_email(String lkm_email) &#123; this.lkm_email = lkm_email; &#125; public String getLkm_qq() &#123; return lkm_qq; &#125; public void setLkm_qq(String lkm_qq) &#123; this.lkm_qq = lkm_qq; &#125; public String getLkm_position() &#123; return lkm_position; &#125; public void setLkm_position(String lkm_position) &#123; this.lkm_position = lkm_position; &#125; public String getLkm_memo() &#123; return lkm_memo; &#125; public void setLkm_memo(String lkm_memo) &#123; this.lkm_memo = lkm_memo; &#125; public Customer getCustomer() &#123; return customer; &#125; public void setCustomer(Customer customer) &#123; this.customer = customer; &#125; &#125;创建映射文件多的一方的映射的创建1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"com.hibernate.domain.LinkMan\" table=\"cst_linkman\"&gt; &lt;!-- 建立OID与主键映射 --&gt; &lt;id name=\"lkm_id\" column=\"lkm_id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;!-- 建立普通属性与表字段映射 --&gt; &lt;property name=\"lkm_name\"/&gt; &lt;property name=\"lkm_gender\"/&gt; &lt;property name=\"lkm_phone\"/&gt; &lt;property name=\"lkm_mobile\"/&gt; &lt;property name=\"lkm_email\"/&gt; &lt;property name=\"lkm_qq\"/&gt; &lt;property name=\"lkm_position\"/&gt; &lt;property name=\"lkm_memo\"/&gt; &lt;!-- 配置多对一的关系：放置的是一的一方的对象 --&gt; &lt;!-- many-to-one标签 * name :一的一方的对象的属性名称。 * class :一的一方的类的全路径。 * column :在多的一方的表的外键的名称。 --&gt; &lt;many-to-one name=\"customer\" class=\"com.hibernate.domain.Customer\" column=\"lkm_cust_id\"/&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;一的一方的映射的创建1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"com.hibernate.domain.Customer\" table=\"cst_customer\"&gt; &lt;!-- 建立OID与主键映射 --&gt; &lt;id name=\"cust_id\" column=\"cust_id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;!-- 建立普通属性与数据库表字段映射 --&gt; &lt;property name=\"cust_name\" column=\"cust_name\" /&gt; &lt;property name=\"cust_source\" column=\"cust_source\"/&gt; &lt;property name=\"cust_industry\" column=\"cust_industry\"/&gt; &lt;property name=\"cust_level\" column=\"cust_level\"/&gt; &lt;property name=\"cust_phone\" column=\"cust_phone\"/&gt; &lt;property name=\"cust_mobile\" column=\"cust_mobile\"/&gt; &lt;!-- 配置一对多的映射：放置的多的一方的集合 --&gt; &lt;!-- set标签 ： * name ：多的一方的对象集合的属性名称。 * cascade：级联 * inverse：放弃外键维护权。 --&gt; &lt;set name=\"linkMans\" cascade=\"save-update\" inverse=\"true\"&gt; &lt;!-- key标签 * column：多的一方的外键的名称。 --&gt; &lt;key column=\"lkm_cust_id\"/&gt; &lt;!-- one-to-many标签 * class :多的一方的类的全路径 --&gt; &lt;one-to-many class=\"com.hibernate.domain.LinkMan\"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;创建核心配置文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-configuration PUBLIC \"-//Hibernate/Hibernate Configuration DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-configuration-3.0.dtd\"&gt;&lt;hibernate-configuration&gt; &lt;session-factory&gt; &lt;!-- 连接数据库的基本参数 --&gt; &lt;property name=\"hibernate.connection.driver_class\"&gt;com.mysql.jdbc.Driver&lt;/property&gt; &lt;property name=\"hibernate.connection.url\"&gt;jdbc:mysql:///hibernate&lt;/property&gt; &lt;property name=\"hibernate.connection.username\"&gt;root&lt;/property&gt; &lt;property name=\"hibernate.connection.password\"&gt;abc&lt;/property&gt; &lt;!-- 配置Hibernate的方言 --&gt; &lt;property name=\"hibernate.dialect\"&gt;org.hibernate.dialect.MySQLDialect&lt;/property&gt; &lt;!-- 可选配置================ --&gt; &lt;!-- 打印SQL --&gt; &lt;property name=\"hibernate.show_sql\"&gt;true&lt;/property&gt; &lt;!-- 格式化SQL --&gt; &lt;property name=\"hibernate.format_sql\"&gt;true&lt;/property&gt; &lt;!-- 自动创建表 --&gt; &lt;property name=\"hibernate.hbm2ddl.auto\"&gt;update&lt;/property&gt; &lt;!-- 配置C3P0连接池 --&gt; &lt;property name=\"connection.provider_class\"&gt;org.hibernate.connection.C3P0ConnectionProvider&lt;/property&gt; &lt;!--在连接池中可用的数据库连接的最少数目 --&gt; &lt;property name=\"c3p0.min_size\"&gt;5&lt;/property&gt; &lt;!--在连接池中所有数据库连接的最大数目 --&gt; &lt;property name=\"c3p0.max_size\"&gt;20&lt;/property&gt; &lt;!--设定数据库连接的过期时间,以秒为单位, 如果连接池中的某个数据库连接处于空闲状态的时间超过了timeout时间,就会从连接池中清除 --&gt; &lt;property name=\"c3p0.timeout\"&gt;120&lt;/property&gt; &lt;!--每3000秒检查所有连接池中的空闲连接 以秒为单位--&gt; &lt;property name=\"c3p0.idle_test_period\"&gt;3000&lt;/property&gt; &lt;!-- 设置事务隔离级别 --&gt; &lt;property name=\"hibernate.connection.isolation\"&gt;4&lt;/property&gt; &lt;!-- 配置当前线程绑定的Session --&gt; &lt;property name=\"hibernate.current_session_context_class\"&gt;thread&lt;/property&gt; &lt;!-- 引入映射 --&gt; &lt;!-- &lt;mapping resource=\"com/hibernate/domain/Customer.hbm.xml\"/&gt; &lt;mapping resource=\"com/hibernate/domain/LinkMan.hbm.xml\"/&gt; --&gt; &lt;mapping resource=\"com/hibernate/domain/User.hbm.xml\"/&gt; &lt;mapping resource=\"com/hibernate/domain/Role.hbm.xml\"/&gt; &lt;/session-factory&gt;&lt;/hibernate-configuration&gt;引入工具类123456789101112131415161718public class HibernateUtils &#123; public static final Configuration cfg; public static final SessionFactory sf; static&#123; cfg = new Configuration().configure(); sf = cfg.buildSessionFactory(); &#125; public static Session openSession()&#123; return sf.openSession(); &#125; public static Session getCurrentSession()&#123; return sf.getCurrentSession(); &#125;&#125;编写测试类12345678910111213141516171819202122232425262728293031323334353637383940public class HibernateDemo1 &#123; @Test // 保存2个客户 和 3个联系人 并且建立好关系 public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 创建两个客户 Customer customer1 = new Customer(); customer1.setCust_name(\"王东\"); Customer customer2 = new Customer(); customer2.setCust_name(\"赵洪\"); // 创建三个联系人 LinkMan linkMan1 = new LinkMan(); linkMan1.setLkm_name(\"凤姐\"); LinkMan linkMan2 = new LinkMan(); linkMan2.setLkm_name(\"如花\"); LinkMan linkMan3 = new LinkMan(); linkMan3.setLkm_name(\"旺财\"); // 设置关系: linkMan1.setCustomer(customer1); linkMan2.setCustomer(customer1); linkMan3.setCustomer(customer2); customer1.getLinkMans().add(linkMan1); customer1.getLinkMans().add(linkMan2); customer2.getLinkMans().add(linkMan3); // 保存数据: session.save(linkMan1); session.save(linkMan2); session.save(linkMan3); session.save(customer1); session.save(customer2); tx.commit(); &#125;&#125;Hibernate 的一对多相关操作一对多关系只保存一边是否可以1234567891011121314151617181920@Test // 一对多关系只保存一边是否可以 public void demo2()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); Customer customer = new Customer(); customer.setCust_name(\"赵洪\"); LinkMan linkMan = new LinkMan(); linkMan.setLkm_name(\"如花\"); customer.getLinkMans().add(linkMan); linkMan.setCustomer(customer); // 只保存一边是否可以：不可以，报一个瞬时对象异常：持久态对象关联了一个瞬时态对象。 // session.save(customer); session.save(linkMan); tx.commit(); &#125;一对多的级联操作什么叫级联级联指的是，操作一个对象的时候，是否会同时操作其关联的对象。级联是有方向性操作一的一方的时候，是否操作到多的一方操作多的一方的时候，是否操作到一的一方级联保存或更新保存客户级联联系人1234567&lt;!-- set标签 ： * name ：多的一方的对象集合的属性名称。 * cascade：级联 * inverse：放弃外键维护权。 --&gt; &lt;set name=\"linkMans\" cascade=\"save-update\" inverse=\"true\"&gt;1234567891011121314151617181920212223@Test /** * 级联保存或更新操作： * * 保存客户级联联系人，操作的主体是客户对象，需要在Customer.hbm.xml中进行配置 * * &lt;set name=\"linkMans\" cascade=\"save-update\"&gt; */ public void demo3()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); Customer customer = new Customer(); customer.setCust_name(\"赵洪\"); LinkMan linkMan = new LinkMan(); linkMan.setLkm_name(\"如花\"); customer.getLinkMans().add(linkMan); linkMan.setCustomer(customer); session.save(customer); tx.commit(); &#125;保存联系人联系人级联客户12345678&lt;!-- 配置多对一的关系：放置的是一的一方的对象 --&gt; &lt;!-- many-to-one标签 * name :一的一方的对象的属性名称。 * class :一的一方的类的全路径。 * column :在多的一方的表的外键的名称。 --&gt; &lt;many-to-one name=\"customer\" class=\"com.itheima.hibernate.domain.Customer\" column=\"lkm_cust_id\"/&gt;1234567891011121314151617181920212223@Test /** * 级联保存或更新操作： * * 保存联系人级联客户，操作的主体是联系人对象，需要在LinkMan.hbm.xml中进行配置 * * &lt;many-to-one name=\"customer\" cascade=\"save-update\" class=\"com.itheima.hibernate.domain.Customer\" column=\"lkm_cust_id\"/&gt; */ public void demo4()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); Customer customer = new Customer(); customer.setCust_name(\"李兵\"); LinkMan linkMan = new LinkMan(); linkMan.setLkm_name(\"凤姐\"); customer.getLinkMans().add(linkMan); linkMan.setCustomer(customer); session.save(linkMan); tx.commit(); &#125;测试对象的导航123456789101112131415161718192021222324252627282930@Test /** * 测试对象的导航 * * 前提：一对多的双方都设置cascade=\"save-update\" */ public void demo5()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); Customer customer = new Customer(); customer.setCust_name(\"李兵\"); LinkMan linkMan1 = new LinkMan(); linkMan1.setLkm_name(\"凤姐\"); LinkMan linkMan2 = new LinkMan(); linkMan2.setLkm_name(\"如花\"); LinkMan linkMan3 = new LinkMan(); linkMan3.setLkm_name(\"芙蓉\"); linkMan1.setCustomer(customer); customer.getLinkMans().add(linkMan2); customer.getLinkMans().add(linkMan3); // 双方都设置了cascade// session.save(linkMan1); // 发送几条insert语句 4条// session.save(customer); // 发送几条insert语句 3条 session.save(linkMan2); // 发送几条insert语句 1条 tx.commit(); &#125;级联删除级联删除：删除一边的时候，同时将另一方的数据也一并删除。删除客户级联删除联系人1234567891011121314151617181920@Test /** * 级联删除： * * 删除客户级联删除联系人，删除的主体是客户，需要在Customer.hbm.xml中配置 * * &lt;set name=\"linkMans\" cascade=\"delete\"&gt; */ public void demo6()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 没有设置级联删除，默认情况:修改了联系人的外键，删除客户 /*Customer customer = session.get(Customer.class, 1l); session.delete(customer);*/ // 删除客户，同时删除联系人 Customer customer = session.get(Customer.class, 1l); session.delete(customer); tx.commit(); &#125;删除联系人级联删除客户（基本不用）12345678910111213141516@Test /** * 级联删除： * * 删除联系人级联删除客户，删除的主体是联系人，需要在LinkMan.hbm.xml中配置 * * &lt;many-to-one name=\"customer\" cascade=\"delete\"&gt; */ public void demo7()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 删除客户，同时删除联系人 LinkMan linkMan = session.get(LinkMan.class, 3l); session.delete(linkMan); tx.commit(); &#125;一对多设置了双向关联产生多余的SQL语句123456789101112131415161718@Test /** * 将2号联系人原来归1号客户，现在改为2号客户 */ public void demo8()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询2号联系人 LinkMan linkMan = session.get(LinkMan.class, 2l); // 查询2号客户 Customer customer = session.get(Customer.class, 2l); // 双向的关联 linkMan.setCustomer(customer); customer.getLinkMans().add(linkMan); tx.commit(); &#125;解决多余的SQL语句单向维护：使一方放弃外键维护权：一的一方放弃。在set上配置inverse=”true”一对多的关联查询的修改的时候。（CRM练习–）区分cascade和inverse12345678910111213141516171819202122@Test /** * 区分cascade和inverse的区别 */ public void demo9()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); Customer customer = new Customer(); customer.setCust_name(\"李兵\"); LinkMan linkMan = new LinkMan(); linkMan.setLkm_name(\"凤姐\"); customer.getLinkMans().add(linkMan); // 条件在Customer.hbm.xml上的set中配置了cascade=\"save-update\" inverse=\"true\" session.save(customer); // 客户会插入到数据库，联系人也会插入到数据库，但是外键为null tx.commit(); &#125;&#125;Hibernate多对多关系的配置创建表用户表12345678CREATE TABLE `sys_user` ( `user_id` bigint(32) NOT NULL AUTO_INCREMENT COMMENT '用户id', `user_code` varchar(32) NOT NULL COMMENT '用户账号', `user_name` varchar(64) NOT NULL COMMENT '用户名称', `user_password` varchar(32) NOT NULL COMMENT '用户密码', `user_state` char(1) NOT NULL COMMENT '1:正常,0:暂停', PRIMARY KEY (`user_id`)) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;角色表123456CREATE TABLE `sys_role` ( `role_id` bigint(32) NOT NULL AUTO_INCREMENT, `role_name` varchar(32) NOT NULL COMMENT '角色名称', `role_memo` varchar(128) DEFAULT NULL COMMENT '备注', PRIMARY KEY (`role_id`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;中间表12345678CREATE TABLE `sys_user_role` ( `role_id` bigint(32) NOT NULL COMMENT '角色id', `user_id` bigint(32) NOT NULL COMMENT '用户id', PRIMARY KEY (`role_id`,`user_id`), KEY `FK_user_role_user_id` (`user_id`), CONSTRAINT `FK_user_role_role_id` FOREIGN KEY (`role_id`) REFERENCES `sys_role` (`role_id`) ON DELETE NO ACTION ON UPDATE NO ACTION, CONSTRAINT `FK_user_role_user_id` FOREIGN KEY (`user_id`) REFERENCES `sys_user` (`user_id`) ON DELETE NO ACTION ON UPDATE NO ACTION) ENGINE=InnoDB DEFAULT CHARSET=utf8;创建实体用户的实体1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class User &#123; private Long user_id; private String user_code; private String user_name; private String user_password; private String user_state; // 设置多对多关系：表示一个用户选择多个角色？ // 放置的是角色的集合 private Set&lt;Role&gt; roles = new HashSet&lt;Role&gt;(); public Long getUser_id() &#123; return user_id; &#125; public void setUser_id(Long user_id) &#123; this.user_id = user_id; &#125; public String getUser_code() &#123; return user_code; &#125; public void setUser_code(String user_code) &#123; this.user_code = user_code; &#125; public String getUser_name() &#123; return user_name; &#125; public void setUser_name(String user_name) &#123; this.user_name = user_name; &#125; public String getUser_password() &#123; return user_password; &#125; public void setUser_password(String user_password) &#123; this.user_password = user_password; &#125; public String getUser_state() &#123; return user_state; &#125; public void setUser_state(String user_state) &#123; this.user_state = user_state; &#125; public Set&lt;Role&gt; getRoles() &#123; return roles; &#125; public void setRoles(Set&lt;Role&gt; roles) &#123; this.roles = roles; &#125; &#125;角色的实体123456789101112131415161718192021222324252627282930313233public class Role &#123; private Long role_id; private String role_name; private String role_memo; // 一个角色被多个用户选择： // 放置的是用户的集合 private Set&lt;User&gt; users = new HashSet&lt;User&gt;(); public Long getRole_id() &#123; return role_id; &#125; public void setRole_id(Long role_id) &#123; this.role_id = role_id; &#125; public String getRole_name() &#123; return role_name; &#125; public void setRole_name(String role_name) &#123; this.role_name = role_name; &#125; public String getRole_memo() &#123; return role_memo; &#125; public void setRole_memo(String role_memo) &#123; this.role_memo = role_memo; &#125; public Set&lt;User&gt; getUsers() &#123; return users; &#125; public void setUsers(Set&lt;User&gt; users) &#123; this.users = users; &#125; &#125;创建映射用户的映射123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"com.hibernate.domain.User\" table=\"sys_user\"&gt; &lt;!-- 建立OID与主键的映射 --&gt; &lt;id name=\"user_id\" column=\"user_id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;!-- 建立普通属性与字段映射 --&gt; &lt;property name=\"user_code\" column=\"user_code\"/&gt; &lt;property name=\"user_name\" column=\"user_name\"/&gt; &lt;property name=\"user_password\" column=\"user_password\"/&gt; &lt;property name=\"user_state\" column=\"user_state\"/&gt; &lt;!-- 建立与角色的多对多的映射关系 --&gt; &lt;!-- set标签 * name ：对方的集合的属性名称。 * table ：多对多的关系需要使用中间表，放的是中间表的名称。 --&gt; &lt;set name=\"roles\" table=\"sys_user_role\" cascade=\"save-update,delete\" &gt; &lt;!-- key标签： * column ：当前的对象对应中间表的外键的名称。 --&gt; &lt;key column=\"user_id\"/&gt; &lt;!-- many-to-many标签： * class ：对方的类的全路径 * column ：对方的对象在中间表中的外键的名称。 --&gt; &lt;many-to-many class=\"com.hibernate.domain.Role\" column=\"role_id\"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;角色的映射12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE hibernate-mapping PUBLIC \"-//Hibernate/Hibernate Mapping DTD 3.0//EN\" \"http://www.hibernate.org/dtd/hibernate-mapping-3.0.dtd\"&gt;&lt;hibernate-mapping&gt; &lt;class name=\"com.hibernate.domain.Role\" table=\"sys_role\"&gt; &lt;!-- 建立OID与主键的映射 --&gt; &lt;id name=\"role_id\" column=\"role_id\"&gt; &lt;generator class=\"native\"/&gt; &lt;/id&gt; &lt;!-- 建立普通属性与字段的映射 --&gt; &lt;property name=\"role_name\" column=\"role_name\"/&gt; &lt;property name=\"role_memo\" column=\"role_memo\"/&gt; &lt;!-- 与用户的多对多的映射关系 --&gt; &lt;!-- set标签 * name ：对方的集合的属性名称。 * table ：多对多的关系需要使用中间表，放的是中间表的名称。 --&gt; &lt;set name=\"users\" table=\"sys_user_role\" cascade=\"save-update,delete\" inverse=\"true\"&gt; &lt;!-- key标签： * column ：当前的对象对应中间表的外键的名称。 --&gt; &lt;key column=\"role_id\"/&gt; &lt;!-- many-to-many标签： * class ：对方的类的全路径 * column ：对方的对象在中间表中的外键的名称。 --&gt; &lt;many-to-many class=\"com.hibernate.domain.User\" column=\"user_id\"/&gt; &lt;/set&gt; &lt;/class&gt;&lt;/hibernate-mapping&gt;编写测试类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.itheima.hibernate.demo2;import org.hibernate.Session;import org.hibernate.Transaction;import org.junit.Test;import com.itheima.hibernate.domain.Role;import com.itheima.hibernate.domain.User;import com.itheima.hibernate.utils.HibernateUtils;/** * Hibernate的多对多的映射 * @author jt * */public class HibernateDemo2 &#123; @Test /** * 保存多条记录：保存多个用户和角色 */ public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 创建2个用户 User user1 = new User(); user1.setUser_name(\"赵洪\"); User user2 = new User(); user2.setUser_name(\"李兵\"); // 创建3个角色 Role role1 = new Role(); role1.setRole_name(\"研发部\"); Role role2 = new Role(); role2.setRole_name(\"市场部\"); Role role3 = new Role(); role3.setRole_name(\"公关部\"); // 设置双向的关联关系: user1.getRoles().add(role1); user1.getRoles().add(role2); user2.getRoles().add(role2); user2.getRoles().add(role3); role1.getUsers().add(user1); role2.getUsers().add(user1); role2.getUsers().add(user2); role3.getUsers().add(user2); // 保存操作:多对多建立了双向的关系必须有一方放弃外键维护。 // 一般是被动方放弃外键维护权。 session.save(user1); session.save(user2); session.save(role1); session.save(role2); session.save(role3); tx.commit(); &#125;&#125;Hibernated 多对多的操作只保存一边是否可以1234567891011121314151617181920212223242526@Test /** * 多对多的操作： * * 只保存一边是否可以？不可以，瞬时对象异常 */ public void demo2()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 创建2个用户 User user1 = new User(); user1.setUser_name(\"赵洪\"); // 创建3个角色 Role role1 = new Role(); role1.setRole_name(\"研发部\"); // 设置双向的关联关系: user1.getRoles().add(role1); role1.getUsers().add(user1); // 只保存用户： // session.save(user1); session.save(role1); tx.commit(); &#125;多对多的级联保存或更新保存用户级联保存角色1234567891011121314151617181920212223242526@Test /** * 多对多的级联保存： * * 保存用户级联保存角色。在用户的映射文件中配置。 * * 在User.hbm.xml中的set上配置 cascade=\"save-update\" */ public void demo3()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 创建2个用户 User user1 = new User(); user1.setUser_name(\"赵洪\"); // 创建3个角色 Role role1 = new Role(); role1.setRole_name(\"研发部\"); // 设置双向的关联关系: user1.getRoles().add(role1); role1.getUsers().add(user1); // 只保存用户： session.save(user1); tx.commit(); &#125;保存角色级联保存用户1234567891011121314151617181920212223242526/** * 多对多的级联保存： * * 保存角色级联保存用户。在角色的映射文件中配置。 * * 在Role.hbm.xml中的set上配置 cascade=\"save-update\" */ @Test public void demo4()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 创建2个用户 User user1 = new User(); user1.setUser_name(\"李兵\"); // 创建3个角色 Role role1 = new Role(); role1.setRole_name(\"公关部\"); // 设置双向的关联关系: user1.getRoles().add(role1); role1.getUsers().add(user1); // 只保存用户： session.save(role1); tx.commit(); &#125;多对多的级联删除（基本用不上）删除用户级联删除角色12345678910111213141516/** * 多对多的级联删除： * * 删除用户级联删除角色 * * 在User.hbm.xml中的set上配置 cascade=\"delete\" */ @Test public void demo5()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询1号用户: User user = session.get(User.class, 1l); session.delete(user); tx.commit(); &#125;删除角色级联删除用户12345678910111213141516/** * 多对多的级联删除： * * 删除角色级联删除用户 * * 在Role.hbm.xml中的set上配置 cascade=\"delete\" */ @Test public void demo6()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询2号角色: Role role = session.get(Role.class, 2l); session.delete(role); tx.commit(); &#125;多对多的其他的操作给用户选择角色1234567891011121314151617@Test /** * 给用户选择角色 */ public void demo7()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 给1号用户多选2号角色 // 查询1号用户 User user = session.get(User.class, 1l); // 查询2号角色 Role role = session.get(Role.class, 2l); user.getRoles().add(role); tx.commit(); &#125;给用户改选角色12345678910111213141516171819@Test /** * 给用户改选角色 */ public void demo8()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 给2号用户将原有的2号角色改为3号角色 // 查询2号用户 User user = session.get(User.class, 2l); // 查询2号角色 Role role2 = session.get(Role.class, 2l); Role role3 = session.get(Role.class, 3l); user.getRoles().remove(role2); user.getRoles().add(role3); tx.commit(); &#125;给用户删除角色123456789101112131415161718@Test /** * 给用户改选角色 */ public void demo9()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 给2号用户删除1号角色 // 查询2号用户 User user = session.get(User.class, 2l); // 查询2号角色 Role role = session.get(Role.class, 1l); user.getRoles().remove(role); tx.commit(); &#125;&#125;Hibernate的查询的方式在Hibernate中提供了很多种的查询的方式。Hibernate共提供了五种查询方式。Hibernate的查询方式：OID查询OID检索：Hibernate根据对象的OID（主键）进行检索使用get方法1Customer customer = session.get(Customer.class,1l);使用load方法1Customer customer = session.load(Customer.class,1l);Hibernate的查询方式：对象导航检索对象导航检索：Hibernate根据一个已经查询到的对象，获得其关联的对象的一种查询方式。1234567LinkMan linkMan = session.get(LinkMan.class,1l);Customer customer =linkMan.getCustomer();Customer customer = session.get(Customer.class,2l);Set&lt;LinkMan&gt; linkMans = customer.getLinkMans();Hibernate的查询方式：HQL检索HQL查询：Hibernate Query Language，Hibernate的查询语言，是一种面向对象的方式的查询语言，语法类似SQL。通过session.createQuery()，用于接收一个HQL进行查询方式。初始化一些数据12345678910111213141516171819202122232425@Test /** * 初始化数据 */ public void demo1() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 创建一个客户 Customer customer = new Customer(); customer.setCust_name(\"李向文\"); for (int i = 1; i &lt;= 10; i++) &#123; LinkMan linkMan = new LinkMan(); linkMan.setLkm_name(\"王东\" + i); linkMan.setCustomer(customer); customer.getLinkMans().add(linkMan); session.save(linkMan); &#125; session.save(customer); tx.commit(); &#125;HQL的简单查询12345678910111213141516171819202122@Test /** * HQL的简单查询 */ public void demo2() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 简单的查询 Query query = session.createQuery(\"from Customer\"); List&lt;Customer&gt; list = query.list(); // sql中支持*号的写法：select * from cst_customer; 但是在HQL中不支持*号的写法。 /* * Query query = session.createQuery(\"select * from Customer\");// 报错 * List&lt;Customer&gt; list = query.list(); */ for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;HQL的别名查询123456789101112131415161718192021@Test /** * 别名查询 */ public void demo3() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 别名的查询 /* * Query query = session.createQuery(\"from Customer c\"); List&lt;Customer&gt; * list = query.list(); */ Query query = session.createQuery(\"select c from Customer c\"); List&lt;Customer&gt; list = query.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;HQL的排序查询12345678910111213141516171819@Test /** * 排序查询 */ public void demo4() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 排序的查询 // 默认情况 // List&lt;Customer&gt; list = session.createQuery(\"from Customer order by // cust_id\").list(); // 设置降序排序 升序使用asc 降序使用desc List&lt;Customer&gt; list = session.createQuery(\"from Customer order by cust_id desc\").list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;HQL的条件查询1234567891011121314151617181920212223242526272829303132333435@Test /** * 条件查询 */ public void demo5() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 条件的查询 // 一、按位置绑定：根据参数的位置进行绑定。 // 一个条件 /* * Query query = session.createQuery(\"from Customer where cust_name = ?\" * ); query.setParameter(0, \"李兵\"); List&lt;Customer&gt; list = query.list(); */ // 多个条件 /* * Query query = session.createQuery( * \"from Customer where cust_source = ? and cust_name like ?\"); * query.setParameter(0, \"小广告\"); query.setParameter(1, \"李%\"); * List&lt;Customer&gt; list = query.list(); */ // 二、按名称绑定 Query query = session.createQuery(\"from Customer where cust_source = :aaa and cust_name like :bbb\"); // 设置参数: query.setParameter(\"aaa\", \"朋友推荐\"); query.setParameter(\"bbb\", \"李%\"); List&lt;Customer&gt; list = query.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;HQL的投影查询投影查询：查询对象的某个或某些属性12345678910111213141516171819202122232425262728293031@Test /** * 投影查询 */ public void demo6() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 投影查询 // 单个属性 /* * List&lt;Object&gt; list = session.createQuery( * \"select c.cust_name from Customer c\").list(); for (Object object : * list) &#123; System.out.println(object); &#125; */ // 多个属性: /* * List&lt;Object[]&gt; list = session.createQuery( * \"select c.cust_name,c.cust_source from Customer c\").list(); for * (Object[] objects : list) &#123; * System.out.println(Arrays.toString(objects)); &#125; */ // 查询多个属性，但是我想封装到对象中。 List&lt;Customer&gt; list = session.createQuery(\"select new Customer(cust_name,cust_source) from Customer\").list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;HQL的分页查询12345678910111213141516171819@Test /** * 分页查询 */ public void demo7() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 分页查询 Query query = session.createQuery(\"from LinkMan\"); query.setFirstResult(20); query.setMaxResults(10); List&lt;LinkMan&gt; list = query.list(); for (LinkMan linkMan : list) &#123; System.out.println(linkMan); &#125; tx.commit(); &#125;HQL的分组统计查询12345678910111213141516171819@Test /** * 分组统计查询 */ public void demo8() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 聚合函数的使用：count(),max(),min(),avg(),sum() Object object = session.createQuery(\"select count(*) from Customer\").uniqueResult(); System.out.println(object); // 分组统计： List&lt;Object[]&gt; list = session.createQuery(\"select cust_source,count(*) from Customer group by cust_source\") .list(); for (Object[] objects : list) &#123; System.out.println(Arrays.toString(objects)); &#125; tx.commit(); &#125;HQL的多表查询SQL的多表查询连接查询交叉连接：笛卡尔积1select * from A,B;内连接 : inner join (inner 可以省略)隐式内连接：1select * from A,B where A.id = B.aid;显示内连接：1select * from A inner join B on A.id = B.aid;外连接 :左外连接:left outer join(outer 可以省略)1select * from A left outer join B on A.id= B.aid;右外连接:right outer join(outer 可以省略)1select * from A right outer join B on A.id = B.aid;子查询HQL的多表查询连接查询交叉连接内连接显示内连接隐式内连接迫切内连接外连接左外连接右外连接迫切左外连接1234567891011121314151617181920212223242526@Test /** * HQL的多表查询 */ public void demo9() &#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // SQL:SELECT * FROM cst_customer c INNER JOIN cst_linkman l ON // c.cust_id = l.lkm_cust_id; // HQL:内连接 from Customer c inner join c.linkMans /* * List&lt;Object[]&gt; list = session.createQuery( * \"from Customer c inner join c.linkMans\").list(); for (Object[] * objects : list) &#123; System.out.println(Arrays.toString(objects)); &#125; */ // HQL:迫切内连接 其实就在普通的内连接inner join后添加一个关键字fetch. from Customer c inner // join fetch c.linkMans List&lt;Customer&gt; list = session.createQuery(\"select distinct c from Customer c inner join fetch c.linkMans\") .list();// 通知hibernate，将另一个对象的数据封装到该对象中 for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;Hibernate的查询方式：QBC检索QBC查询：Query By Criteria，条件查询。是一种更加面向对象化的查询的方式。简单查询1234567891011121314151617@Test /** * 简单的查询 */ public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 获得Criteria的对象 Criteria criteria = session.createCriteria(Customer.class); List&lt;Customer&gt; list = criteria.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;排序查询1234567891011121314151617181920@Test /** * 排序查询 */ public void demo2()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 排序查询 Criteria criteria = session.createCriteria(Customer.class);// criteria.addOrder(Order.asc(\"cust_id\")); // 升序 criteria.addOrder(Order.desc(\"cust_id\")); // 降序 List&lt;Customer&gt; list = criteria.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;分页查询12345678910111213141516171819@Test /** * 分页查询 */ public void demo3()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 分页查询 Criteria criteria = session.createCriteria(LinkMan.class); criteria.setFirstResult(10); criteria.setMaxResults(10); List&lt;LinkMan&gt; list = criteria.list(); for (LinkMan linkMan : list) &#123; System.out.println(linkMan); &#125; tx.commit(); &#125;条件查询1234567891011121314151617181920212223242526272829303132@Test /** * 条件查询 */ public void demo4()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 条件查询 Criteria criteria = session.createCriteria(Customer.class); // 设置条件: /** * = eq * &gt; gt * &gt;= ge * &lt; lt * &lt;= le * &lt;&gt; ne * like * in * and * or */ criteria.add(Restrictions.eq(\"cust_source\", \"小广告\"));// criteria.add(Restrictions.or(Restrictions.like(\"cust_name\", \"李%\"))); criteria.add(Restrictions.like(\"cust_name\", \"李%\")); List&lt;Customer&gt; list = criteria.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;统计查询12345678910111213141516171819@Test /** * 统计查询 */ public void demo5()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); Criteria criteria = session.createCriteria(Customer.class); /** * add :普通的条件。where后面条件 * addOrder :排序 * setProjection :聚合函数 和 group by having */ criteria.setProjection(Projections.rowCount()); Long num = (Long) criteria.uniqueResult(); System.out.println(num); tx.commit(); &#125;离线条件查询（SSH）—DetachedCriteria12345678910111213141516171819@Test /** * 离线条件查询 */ public void demo6()&#123; DetachedCriteria detachedCriteria = DetachedCriteria.forClass(Customer.class); detachedCriteria.add(Restrictions.like(\"cust_name\", \"李%\")); Session session = HibernateUtils.getCurrentSession(); Transaction transaction = session.beginTransaction(); Criteria criteria = detachedCriteria.getExecutableCriteria(session); List&lt;Customer&gt; list = criteria.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; transaction.commit(); &#125;&#125;Hibernate的查询方式：SQL检索SQL查询SQL查询：通过使用sql语句进行查询12345678910111213141516171819202122public class HibernateDemo3 &#123; @Test public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); /*SQLQuery sqlQuery = session.createSQLQuery(\"select * from cst_customer\"); List&lt;Object[]&gt; list = sqlQuery.list(); for (Object[] objects : list) &#123; System.out.println(Arrays.toString(objects)); &#125;*/ SQLQuery sqlQuery = session.createSQLQuery(\"select * from cst_customer\"); sqlQuery.addEntity(Customer.class); List&lt;Customer&gt; list = sqlQuery.list(); for (Customer customer : list) &#123; System.out.println(customer); &#125; tx.commit(); &#125;&#125;Hibernate的抓取策略（优化）延迟加载的概述什么是延迟加载延迟加载：lazy（懒加载）。执行到该行代码的时候，不会发送语句去进行查询，在真正使用这个对象的属性的时候才会发送SQL语句进行查询。延迟加载的分类类级别的延迟加载指的是通过load方法查询某个对象的时候，是否采用延迟。session.load(Customer.class,1l);类级别延迟加载通过上的lazy进行配置，如果让lazy失效将lazy设置为false将持久化类使用final修饰Hibernate. Initialize()关联级别的延迟加载指的是在查询到某个对象的时候，查询其关联的对象的时候，是否采用延迟加载。1Customer customer = session.get(Customer.class,1l);customer.getLinkMans();—-通过客户获得联系人的时候，联系人对象是否采用了延迟加载，称为是关联级别的延迟。抓取策略往往会和关联级别的延迟加载一起使用，优化语句。123456789101112131415161718public class HibernateDemo1 &#123; @Test /** * 类级别的延迟加载 * * 在&lt;class&gt;的标签上配置的lazy */ public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); Customer customer = session.load(Customer.class, 1l); Hibernate.initialize(customer); System.out.println(customer); tx.commit(); &#125;&#125;抓取策略抓取策略的概述通过一个对象抓取到关联对象需要发送SQL语句，SQL语句如何发送，发送成什么样格式通过策略进行配置。通过&lt;set&gt;或者&lt;many-to-one&gt;上通过fetch属性进行设置fetch和这些标签上的lazy如何设置优化发送的SQL语句&lt;set&gt;上的fetch和lazyfetch：抓取策略，控制SQL语句格式select ：默认值，发送普通的select语句，查询关联对象join ：发送一条迫切左外连接查询关联对象subselect ：发送一条子查询查询其关联对象lazy：延迟加载，控制查询关联对象的时候是否采用延迟true ：默认值，查询关联对象的时候，采用延迟加载false ：查询关联对象的时候，不采用延迟加载extra ：及其懒惰。在实际开发中，一般都采用默认值。如果有特殊的需求，可能需要配置join。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131/** * 在&lt;set&gt;上的fetch和lazy * @author jt * */public class HibernateDemo2 &#123; @Test /** * 默认情况： */ public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询1号客户 Customer customer = session.get(Customer.class, 1l);// 发送一条查询客户的SQL System.out.println(customer.getCust_name()); // 查看1号客户的每个联系人的信息 for (LinkMan linkMan : customer.getLinkMans()) &#123;// 发送一条根据客户ID查询联系人的SQL System.out.println(linkMan.getLkm_name()); &#125; tx.commit(); &#125; @Test /** * 设置fetch=\"select\" lazy=\"true\" */ public void demo2()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询1号客户 Customer customer = session.get(Customer.class, 1l);// 发送一条查询客户的SQL System.out.println(customer.getCust_name()); // 查看1号客户的每个联系人的信息 for (LinkMan linkMan : customer.getLinkMans()) &#123;// 发送一条根据客户ID查询联系人的SQL System.out.println(linkMan.getLkm_name()); &#125; tx.commit(); &#125; @Test /** * 设置 fetch=\"select\" lazy=\"false\" */ public void demo3()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询1号客户 Customer customer = session.get(Customer.class, 1l);// 发送两条SQL语句：查询客户的名称，查询客户关联联系人 System.out.println(customer.getCust_name()); /*// 查看1号客户的每个联系人的信息 for (LinkMan linkMan : customer.getLinkMans()) &#123;// System.out.println(linkMan.getLkm_name()); &#125;*/ System.out.println(customer.getLinkMans().size()); tx.commit(); &#125; @Test /** * 设置fetch=\"select\" lazy=\"extra\" */ public void demo4()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询1号客户 Customer customer = session.get(Customer.class, 1l);// 发送一条查询1号客户的SQL语句 System.out.println(customer.getCust_name()); System.out.println(customer.getLinkMans().size());// 发送一条select count() from ...; tx.commit(); &#125; @Test /** * 设置fetch=\"join\" lazy=失效 */ public void demo5()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); // 查询1号客户 Customer customer = session.get(Customer.class, 1l);// 发送一条迫切左外连接查询记录 System.out.println(customer.getCust_name()); System.out.println(customer.getLinkMans().size());// 不发送 tx.commit(); &#125; @SuppressWarnings(\"unchecked\") @Test /** * 设置fetch=\"subselect\" lazy=\"true\" */ public void demo6()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); List&lt;Customer&gt; list = session.createQuery(\"from Customer\").list();// 发送查询所有客户的SQL for (Customer customer : list) &#123; System.out.println(customer.getCust_name()); System.out.println(customer.getLinkMans().size());// 发送一条子查询 &#125; tx.commit(); &#125; @SuppressWarnings(\"unchecked\") @Test /** * 设置fetch=\"subselect\" lazy=\"false\" */ public void demo7()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); List&lt;Customer&gt; list = session.createQuery(\"from Customer\").list();// 发送查询所有客户的SQL，发送一条子查询 for (Customer customer : list) &#123; System.out.println(customer.getCust_name()); System.out.println(customer.getLinkMans().size());// &#125; tx.commit(); &#125;&#125;&lt;many-to-one&gt;上的fetch和lazyfetch ：抓取策略，控制SQL语句格式。select ：默认值，发送普通的select语句，查询关联对象。join ：发送一条迫切左外连接。lazy ：延迟加载，控制查询关联对象的时候是否采用延迟。proxy ：默认值，proxy具体的取值，取决于另一端的&lt;class&gt;上的lazy的值。false ：查询关联对象，不采用延迟。no-proxy ：（不会使用）在实际开发中，一般都采用默认值。如果有特殊的需求，可能需要配置join。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * many-to-one上的fetch和lazy测试 * @author jt * */public class HibernateDemo3 &#123; @Test /** * 默认值 */ public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); LinkMan linkMan = session.get(LinkMan.class, 1l);// 发送一条查询联系人语句 System.out.println(linkMan.getLkm_name()); System.out.println(linkMan.getCustomer().getCust_name());// 发送一条select语句查询联系人所关联的客户 tx.commit(); &#125; @Test /** * fetch=\"select\" lazy=\"proxy\" */ public void demo2()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); LinkMan linkMan = session.get(LinkMan.class, 1l);// 发送一条查询联系人语句 System.out.println(linkMan.getLkm_name()); System.out.println(linkMan.getCustomer().getCust_name());// 发送一条select语句查询联系人所关联的客户 tx.commit(); &#125; @Test /** * fetch=\"select\" lazy=\"false\" */ public void demo3()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); LinkMan linkMan = session.get(LinkMan.class, 1l);// 发送一条查询联系人语句,发送一条select语句查询联系人所关联的客户 System.out.println(linkMan.getLkm_name()); System.out.println(linkMan.getCustomer().getCust_name());// tx.commit(); &#125; @Test /** * fetch=\"join\" lazy=失效 */ public void demo4()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); LinkMan linkMan = session.get(LinkMan.class, 1l);// 发送一条迫切左外连接查询联系人所关联的客户。 System.out.println(linkMan.getLkm_name()); System.out.println(linkMan.getCustomer().getCust_name());// tx.commit(); &#125;&#125;批量抓取什么是批量抓取一批关联对象一起抓取，batch-size测试批量抓取123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 批量抓取 * @author jt * */public class HibernateDemo4 &#123; @SuppressWarnings(\"unchecked\") @Test /** * 获取客户的时候，批量抓取联系人 * 在Customer.hbm.xml中set上配置batch-size */ public void demo1()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); List&lt;Customer&gt; list = session.createQuery(\"from Customer\").list(); for (Customer customer : list) &#123; System.out.println(customer.getCust_name()); for (LinkMan linkMan : customer.getLinkMans()) &#123; System.out.println(linkMan.getLkm_name()); &#125; &#125; tx.commit(); &#125; @SuppressWarnings(\"unchecked\") @Test /** * 获取联系人的时候，批量抓取客户 * * 在Customer.hbm.xml中&lt;class&gt;上配置 */ public void demo2()&#123; Session session = HibernateUtils.getCurrentSession(); Transaction tx = session.beginTransaction(); List&lt;LinkMan&gt; list = session.createQuery(\"from LinkMan\").list(); for (LinkMan linkMan : list) &#123; System.out.println(linkMan.getLkm_name()); System.out.println(linkMan.getCustomer().getCust_name()); &#125; tx.commit(); &#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Hibernate","slug":"后端/Java/Hibernate","permalink":"https://me.obey.fun/categories/后端/Java/Hibernate/"}],"tags":[{"name":"Hibernate","slug":"Hibernate","permalink":"https://me.obey.fun/tags/Hibernate/"},{"name":"ORM","slug":"ORM","permalink":"https://me.obey.fun/tags/ORM/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Hibernate","slug":"后端/Java/Hibernate","permalink":"https://me.obey.fun/categories/后端/Java/Hibernate/"}]},{"title":"SpringMvc（简单入门）","slug":"SpringMvc（简单入门）","date":"2019-05-04T08:44:03.000Z","updated":"2019-06-03T14:07:56.147Z","comments":true,"path":"SpringMvc（简单入门）.html","link":"","permalink":"https://me.obey.fun/SpringMvc（简单入门）.html","excerpt":"","text":"Spring 入门Springmvc是什么Spring web mvc和Struts2都属于表现层的框架,它是Spring框架的一部分,我们可以从Spring的整体结构中看得出来,如下图：Springmvc处理流程如下图所示：入门程序需求：使用浏览器显示商品列表创建web工程springMVC是表现层框架，需要搭建web工程开发。如下图创建动态web工程：输入工程名，选择配置Tomcat（如果已有，则直接使用），如下图：配置Tomcat，如下图：选择准备好的Tomcat，这里用的是Tomcat7，如下图：选择成功，点击Finish，如下图：选择刚刚设置成功的Tomcat，如下图：如下图选择web的版本是2.5，可以自动生成web.xml配置文件，创建效果如下图：导入jar包从课前资料中导入springMVC的jar包，位置如下图：复制jar到lib目录，工程直接加载jar包，如下图：加入配置文件创建config资源文件夹，存放配置文件，如下图：创建springmvc.xml创建SpringMVC的核心配置文件SpringMVC本身就是Spring的子项目，对Spring兼容性很好，不需要做很多配置。这里只配置一个Controller扫描就可以了，让Spring对页面控制层Controller进行管理。创建springmvc.xml12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd\"&gt; &lt;!-- 配置controller扫描包 --&gt; &lt;context:component-scan base-package=\"fun.obey.springmvc.controller\" /&gt;&lt;/beans&gt;创建包fun.obey.springmvc.controller配置前端控制器配置SpringMVC的前端控制器DispatcherServlet在web.xml中123456789101112131415161718192021222324252627282930313233&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" id=\"WebApp_ID\" version=\"2.5\"&gt; &lt;display-name&gt;springmvc-first&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 配置SpringMVC前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc-first&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- 指定SpringMVC配置文件 --&gt; &lt;!-- SpringMVC的配置文件的默认路径是/WEB-INF/$&#123;servlet-name&#125;-servlet.xml --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc-first&lt;/servlet-name&gt; &lt;!-- 设置所有以action结尾的请求进入SpringMVC --&gt; &lt;url-pattern&gt;*.action&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt;加入jsp页面把写好的itemList.jsp复制到工程的/WEB-INF/jsp目录下，itemList.jsp1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;%@ page language=\"java\" contentType=\"text/html; charset=UTF-8\" pageEncoding=\"UTF-8\"%&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/core\" prefix=\"c\" %&gt;&lt;%@ taglib uri=\"http://java.sun.com/jsp/jstl/fmt\" prefix=\"fmt\"%&gt;&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\"&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"&gt;&lt;title&gt;查询商品列表&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=\"$&#123;pageContext.request.contextPath &#125;/item/queryitem.action\" method=\"post\"&gt;查询条件：&lt;table width=\"100%\" border=1&gt;&lt;tr&gt;&lt;td&gt;&lt;input type=\"submit\" value=\"查询\"/&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;商品列表：&lt;table width=\"100%\" border=1&gt;&lt;tr&gt; &lt;td&gt;商品名称&lt;/td&gt; &lt;td&gt;商品价格&lt;/td&gt; &lt;td&gt;生产日期&lt;/td&gt; &lt;td&gt;商品描述&lt;/td&gt; &lt;td&gt;操作&lt;/td&gt;&lt;/tr&gt;&lt;c:forEach items=\"$&#123;itemList &#125;\" var=\"item\"&gt;&lt;tr&gt; &lt;td&gt;$&#123;item.name &#125;&lt;/td&gt; &lt;td&gt;$&#123;item.price &#125;&lt;/td&gt; &lt;td&gt;&lt;fmt:formatDate value=\"$&#123;item.createtime&#125;\" pattern=\"yyyy-MM-dd HH:mm:ss\"/&gt;&lt;/td&gt; &lt;td&gt;$&#123;item.detail &#125;&lt;/td&gt; &lt;td&gt;&lt;a href=\"$&#123;pageContext.request.contextPath &#125;/toEdit.form?id=$&#123;item.id&#125;\"&gt;修改&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/c:forEach&gt;&lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt;实现显示商品列表页创建pojo分析页面，查看页面需要的数据，1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package fun.obey.springmvc.pojo;import java.util.Date;public class Items &#123; private Integer id; private String name; private Float price; private String pic; private Date createtime; private String detail; public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name == null ? null : name.trim(); &#125; public Float getPrice() &#123; return price; &#125; public void setPrice(Float price) &#123; this.price = price; &#125; public String getPic() &#123; return pic; &#125; public void setPic(String pic) &#123; this.pic = pic == null ? null : pic.trim(); &#125; public Date getCreatetime() &#123; return createtime; &#125; public void setCreatetime(Date createtime) &#123; this.createtime = createtime; &#125; public String getDetail() &#123; return detail; &#125; public void setDetail(String detail) &#123; this.detail = detail == null ? null : detail.trim(); &#125;&#125;创建ItemControllerItemController是一个普通的java类，不需要实现任何接口。需要在类上添加@Controller注解，把Controller交由Spring管理在方法上面添加@RequestMapping注解，里面指定请求的url。其中“.action”可以加也可以不加。1234567891011121314151617181920212223242526@Controllerpublic class ItemController &#123; // @RequestMapping：里面放的是请求的url，和用户请求的url进行匹配 // action可以写也可以不写 @RequestMapping(\"/itemList.action\") public ModelAndView queryItemList() &#123; // 创建页面需要显示的商品数据 List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(1, \"1华为 荣耀8\", 2399, new Date(), \"质量好！1\")); list.add(new Item(2, \"2华为 荣耀8\", 2399, new Date(), \"质量好！2\")); list.add(new Item(3, \"3华为 荣耀8\", 2399, new Date(), \"质量好！3\")); list.add(new Item(4, \"4华为 荣耀8\", 2399, new Date(), \"质量好！4\")); list.add(new Item(5, \"5华为 荣耀8\", 2399, new Date(), \"质量好！5\")); list.add(new Item(6, \"6华为 荣耀8\", 2399, new Date(), \"质量好！6\")); // 创建ModelAndView，用来存放数据和视图 ModelAndView modelAndView = new ModelAndView(); // 设置数据到模型中 modelAndView.addObject(\"list\", list); // 设置视图jsp，需要设置视图的物理地址 modelAndView.setViewName(\"/WEB-INF/jsp/itemList.jsp\"); return modelAndView; &#125;&#125;启动项目测试启动项目，浏览器访问地址http://127.0.0.1:8080/springmvc-first/itemList.action效果如下图：为什么可以用呢？我们需要分析一下springMVC的架构图。Springmvc架构框架结构框架结构如下图：架构流程用户发送请求至前端控制器DispatcherServletDispatcherServlet收到请求调用HandlerMapping处理器映射器。处理器映射器根据请求url找到具体的处理器，生成处理器对象及处理器拦截器(如果有则生成)一并返回给DispatcherServlet。DispatcherServlet通过HandlerAdapter处理器适配器调用处理器执行处理器(Controller，也叫后端控制器)。Controller执行完成返回ModelAndViewHandlerAdapter将controller执行结果ModelAndView返回给DispatcherServletDispatcherServlet将ModelAndView传给ViewReslover视图解析器ViewReslover解析后返回具体ViewDispatcherServlet对View进行渲染视图（即将模型数据填充至视图中）。DispatcherServlet响应用户组件说明以下组件通常使用框架提供实现：DispatcherServlet：前端控制器用户请求到达前端控制器，它就相当于mvc模式中的c，dispatcherServlet是整个流程控制的中心，由它调用其它组件处理用户的请求，dispatcherServlet的存在降低了组件之间的耦合性。HandlerMapping：处理器映射器HandlerMapping负责根据用户请求url找到Handler即处理器，springmvc提供了不同的映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。Handler：处理器Handler 是继DispatcherServlet前端控制器的后端控制器，在DispatcherServlet的控制下Handler对具体的用户请求进行处理。由于Handler涉及到具体的用户业务请求，所以一般情况需要程序员根据业务需求开发Handler。HandlAdapter：处理器适配器通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。下图是许多不同的适配器，最终都可以使用usb接口连接ViewResolver：视图解析器View Resolver负责将处理结果生成View视图，View Resolver首先根据逻辑视图名解析成物理视图名即具体的页面地址，再生成View视图对象，最后对View进行渲染将处理结果通过页面展示给用户。View：视图springmvc框架提供了很多的View视图类型的支持，包括：jstlView、freemarkerView、pdfView等。我们最常用的视图就是jsp。一般情况下需要通过页面标签或页面模版技术将模型数据通过页面展示给用户，需要由程序员根据业务需求开发具体的页面。说明：在springmvc的各个组件中，处理器映射器、处理器适配器、视图解析器称为springmvc的三大组件。需要用户开发的组件有handler、view默认加载的组件我们没有做任何配置，就可以使用这些组件因为框架已经默认加载这些组件了，配置文件位置如下图：123456789101112131415161718192021222324# Default implementation classes for DispatcherServlet's strategy interfaces.# Used as fallback when no matching beans are found in the DispatcherServlet context.# Not meant to be customized by application developers.org.springframework.web.servlet.LocaleResolver=org.springframework.web.servlet.i18n.AcceptHeaderLocaleResolverorg.springframework.web.servlet.ThemeResolver=org.springframework.web.servlet.theme.FixedThemeResolverorg.springframework.web.servlet.HandlerMapping=org.springframework.web.servlet.handler.BeanNameUrlHandlerMapping,\\ org.springframework.web.servlet.mvc.annotation.DefaultAnnotationHandlerMappingorg.springframework.web.servlet.HandlerAdapter=org.springframework.web.servlet.mvc.HttpRequestHandlerAdapter,\\ org.springframework.web.servlet.mvc.SimpleControllerHandlerAdapter,\\ org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerAdapterorg.springframework.web.servlet.HandlerExceptionResolver=org.springframework.web.servlet.mvc.annotation.AnnotationMethodHandlerExceptionResolver,\\ org.springframework.web.servlet.mvc.annotation.ResponseStatusExceptionResolver,\\ org.springframework.web.servlet.mvc.support.DefaultHandlerExceptionResolverorg.springframework.web.servlet.RequestToViewNameTranslator=org.springframework.web.servlet.view.DefaultRequestToViewNameTranslatororg.springframework.web.servlet.ViewResolver=org.springframework.web.servlet.view.InternalResourceViewResolverorg.springframework.web.servlet.FlashMapManager=org.springframework.web.servlet.support.SessionFlashMapManager组件扫描器使用组件扫描器省去在spring容器配置每个Controller类的繁琐。使用&lt;context:component-scan&gt;自动扫描标记@Controller的控制器类，在springmvc.xml配置文件中配置如下：12&lt;!-- 配置controller扫描包，多个包之间用,分隔 --&gt;&lt;context:component-scan base-package=\"cn.itcast.springmvc.controller\" /&gt;注解映射器和适配器配置处理器映射器注解式处理器映射器，对类中标记了@ResquestMapping的方法进行映射。根据@ResquestMapping定义的url匹配@ResquestMapping标记的方法，匹配成功返回HandlerMethod对象给前端控制器。HandlerMethod对象中封装url对应的方法Method。从spring3.1版本开始，废除了DefaultAnnotationHandlerMapping的使用，推荐使用RequestMappingHandlerMapping完成注解式处理器映射。在springmvc.xml配置文件中配置如下：123&lt;!-- 配置处理器映射器 --&gt;&lt;bean class=\"org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerMapping\" /&gt;注解描述：@RequestMapping：定义请求url到处理器功能方法的映射配置处理器适配器注解式处理器适配器，对标记@ResquestMapping的方法进行适配。从spring3.1版本开始，废除了AnnotationMethodHandlerAdapter的使用，推荐使用RequestMappingHandlerAdapter完成注解式处理器适配。在springmvc.xml配置文件中配置如下：123&lt;!-- 配置处理器适配器 --&gt;&lt;bean class=\"org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter\" /&gt;注解驱动直接配置处理器映射器和处理器适配器比较麻烦，可以使用注解驱动来加载。SpringMVC使用&lt;mvc:annotation-driven&gt;自动加载RequestMappingHandlerMapping和RequestMappingHandlerAdapter可以在springmvc.xml配置文件中使用&lt;mvc:annotation-driven&gt;替代注解处理器和适配器的配置。12&lt;!-- 注解驱动 --&gt;&lt;mvc:annotation-driven /&gt;视图解析器视图解析器使用SpringMVC框架默认的InternalResourceViewResolver，这个视图解析器支持JSP视图解析在springmvc.xml配置文件中配置如下：12345678910&lt;!-- Example: prefix=\"/WEB-INF/jsp/\", suffix=\".jsp\", viewname=\"test\" -&gt; \"/WEB-INF/jsp/test.jsp\" --&gt;&lt;!-- 配置视图解析器 --&gt;&lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!-- 配置逻辑视图的前缀 --&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\" /&gt; &lt;!-- 配置逻辑视图的后缀 --&gt; &lt;property name=\"suffix\" value=\".jsp\" /&gt;&lt;/bean&gt;逻辑视图名需要在controller中返回ModelAndView指定，比如逻辑视图名为ItemList，则最终返回的jsp视图地址:“WEB-INF/jsp/itemList.jsp”最终jsp物理地址：前缀+逻辑视图名+后缀修改ItemController修改ItemController中设置视图的代码12345678910111213141516171819202122232425// @RequestMapping：里面放的是请求的url，和用户请求的url进行匹配// action可以写也可以不写@RequestMapping(\"/itemList.action\")public ModelAndView queryItemList() &#123; // 创建页面需要显示的商品数据 List&lt;Item&gt; list = new ArrayList&lt;&gt;(); list.add(new Item(1, \"1华为 荣耀8\", 2399, new Date(), \"质量好！1\")); list.add(new Item(2, \"2华为 荣耀8\", 2399, new Date(), \"质量好！2\")); list.add(new Item(3, \"3华为 荣耀8\", 2399, new Date(), \"质量好！3\")); list.add(new Item(4, \"4华为 荣耀8\", 2399, new Date(), \"质量好！4\")); list.add(new Item(5, \"5华为 荣耀8\", 2399, new Date(), \"质量好！5\")); list.add(new Item(6, \"6华为 荣耀8\", 2399, new Date(), \"质量好！6\")); // 创建ModelAndView，用来存放数据和视图 ModelAndView modelAndView = new ModelAndView(); // 设置数据到模型中 modelAndView.addObject(\"itemList\", list); // 设置视图jsp，需要设置视图的物理地址 // modelAndView.setViewName(\"/WEB-INF/jsp/itemList.jsp\"); // 配置好视图解析器前缀和后缀，这里只需要设置逻辑视图就可以了。 // 视图解析器根据前缀+逻辑视图名+后缀拼接出来物理路径 modelAndView.setViewName(\"itemList\"); return modelAndView;&#125;效果效果和之前一样，如下图：整合mybatis为了更好的学习 springmvc和mybatis整合开发的方法，需要将springmvc和mybatis进行整合。整合目标： 控制层采用springmvc、持久层使用mybatis实现。需要的jar包spring（包括springmvc）mybatismybatis-spring整合包数据库驱动第三方连接池。整合思路Dao层：1、SqlMapConfig.xml，空文件即可，但是需要文件头。2、applicationContext-dao.xmla) 数据库连接池b) SqlSessionFactory对象，需要spring和mybatis整合包下的。c) 配置mapper文件扫描器。Service层：1、applicationContext-service.xml包扫描器，扫描@service注解的类。2、applicationContext-trans.xml配置事务。Controller层：1、Springmvc.xmla) 包扫描器，扫描@Controller注解的类。b) 配置注解驱动c) 配置视图解析器Web.xml文件：1、配置spring2、配置前端控制器。加入jar包复制jar包到/WEB-INF/lib中工程自动加载jar包加入配置文件创建资源文件夹config在其下创建mybatis和spring文件夹，用来存放配置文件.sqlMapConfig.xml使用逆向工程来生成Mapper相关代码，不需要配置别名。在config/mybatis下创建SqlMapConfig.xml1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt;&lt;/configuration&gt;applicationContext-dao.xml配置数据源、配置SqlSessionFactory、mapper扫描器。123456789101112131415161718192021222324252627282930313233343536373839&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd\"&gt; &lt;!-- 加载配置文件 --&gt; &lt;context:property-placeholder location=\"classpath:db.properties\" /&gt; &lt;!-- 数据库连接池 --&gt; &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;jdbc.driver&#125;\" /&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;property name=\"maxActive\" value=\"10\" /&gt; &lt;property name=\"maxIdle\" value=\"5\" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactory --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!-- 数据库连接池 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;!-- 加载mybatis的全局配置文件 --&gt; &lt;property name=\"configLocation\" value=\"classpath:mybatis/SqlMapConfig.xml\" /&gt; &lt;/bean&gt; &lt;!-- 配置Mapper扫描 --&gt; &lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;!-- 配置Mapper扫描包 --&gt; &lt;property name=\"basePackage\" value=\"cn.itcast.ssm.mapper\" /&gt; &lt;/bean&gt;&lt;/beans&gt;db.properties配置数据库相关信息1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/springmvc?characterEncoding=utf-8jdbc.username=rootjdbc.password=rootapplicationContext-service.xml1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd\"&gt; &lt;!-- 配置service扫描 --&gt; &lt;context:component-scan base-package=\"cn.itcast.ssm.service\" /&gt;&lt;/beans&gt;applicationContext-trans.xml1234567891011121314151617181920212223242526272829303132333435363738&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd\"&gt; &lt;!-- 事务管理器 --&gt; &lt;bean id=\"transactionManager\" class=\"org.springframework.jdbc.datasource.DataSourceTransactionManager\"&gt; &lt;!-- 数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt; &lt;!-- 通知 --&gt; &lt;tx:advice id=\"txAdvice\" transaction-manager=\"transactionManager\"&gt; &lt;tx:attributes&gt; &lt;!-- 传播行为 --&gt; &lt;tx:method name=\"save*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"insert*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"delete*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"update*\" propagation=\"REQUIRED\" /&gt; &lt;tx:method name=\"find*\" propagation=\"SUPPORTS\" read-only=\"true\" /&gt; &lt;tx:method name=\"get*\" propagation=\"SUPPORTS\" read-only=\"true\" /&gt; &lt;tx:method name=\"query*\" propagation=\"SUPPORTS\" read-only=\"true\" /&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;!-- 切面 --&gt; &lt;aop:config&gt; &lt;aop:advisor advice-ref=\"txAdvice\" pointcut=\"execution(* cn.itcast.ssm.service.*.*(..))\" /&gt; &lt;/aop:config&gt;&lt;/beans&gt;springmvc.xml123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:mvc=\"http://www.springframework.org/schema/mvc\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd\"&gt; &lt;!-- 配置controller扫描包 --&gt; &lt;context:component-scan base-package=\"cn.itcast.ssm.controller\" /&gt; &lt;!-- 注解驱动 --&gt; &lt;mvc:annotation-driven /&gt; &lt;!-- Example: prefix=\"/WEB-INF/jsp/\", suffix=\".jsp\", viewname=\"test\" -&gt; \"/WEB-INF/jsp/test.jsp\" --&gt; &lt;!-- 配置视图解析器 --&gt; &lt;bean class=\"org.springframework.web.servlet.view.InternalResourceViewResolver\"&gt; &lt;!-- 配置逻辑视图的前缀 --&gt; &lt;property name=\"prefix\" value=\"/WEB-INF/jsp/\" /&gt; &lt;!-- 配置逻辑视图的后缀 --&gt; &lt;property name=\"suffix\" value=\".jsp\" /&gt; &lt;/bean&gt;&lt;/beans&gt;web.xml12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://java.sun.com/xml/ns/javaee\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd\" id=\"WebApp_ID\" version=\"2.5\"&gt; &lt;display-name&gt;springmvc-web&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;default.html&lt;/welcome-file&gt; &lt;welcome-file&gt;default.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;default.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 配置spring --&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/applicationContext*.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!-- 使用监听器加载Spring配置文件 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!-- 配置SrpingMVC的前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc-web&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc-web&lt;/servlet-name&gt; &lt;!-- 配置所有以action结尾的请求进入SpringMVC --&gt; &lt;url-pattern&gt;*.action&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt;加入jsp页面增加itemList.jsp和itemEdit.jsp页面到工程中。结果就这样，基本整合完毕了，现在我们进行一个实战小项目实现商品列表显示需求实现商品查询列表，从mysql数据库查询商品信息。DAO开发使用逆向工程，生成代码，不在描述。ItemService接口12345678910public interface ItemService &#123; /** * 查询商品列表 * * @return */ List&lt;Item&gt; queryItemList();&#125;ItemServiceImpl实现类123456789101112131415@Servicepublic class ItemServiceImpl implements ItemService &#123; @Autowired private ItemMapper itemMapper; @Override public List&lt;Item&gt; queryItemList() &#123; // 从数据库查询商品数据 List&lt;Item&gt; list = this.itemMapper.selectByExample(null); return list; &#125;&#125;ItemController1234567891011121314151617181920212223242526@Controllerpublic class ItemController &#123; @Autowired private ItemService itemService; /** * 显示商品列表 * * @return */ @RequestMapping(\"/itemList\") public ModelAndView queryItemList() &#123; // 获取商品数据 List&lt;Item&gt; list = this.itemService.queryItemList(); ModelAndView modelAndView = new ModelAndView(); // 把商品数据放到模型中 modelAndView.addObject(\"itemList\", list); // 设置逻辑视图 modelAndView.setViewName(\"itemList\"); return modelAndView; &#125;&#125;测试结果如下图","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"SpringMvc","slug":"后端/Java/SpringMvc","permalink":"https://me.obey.fun/categories/后端/Java/SpringMvc/"}],"tags":[{"name":"SprimgMvc","slug":"SprimgMvc","permalink":"https://me.obey.fun/tags/SprimgMvc/"},{"name":"Spring","slug":"Spring","permalink":"https://me.obey.fun/tags/Spring/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"SpringMvc","slug":"后端/Java/SpringMvc","permalink":"https://me.obey.fun/categories/后端/Java/SpringMvc/"}]},{"title":"BootStrap入门","slug":"BootStrap入门","date":"2019-04-21T08:51:04.000Z","updated":"2019-04-21T11:49:21.416Z","comments":true,"path":"BootStrap入门.html","link":"","permalink":"https://me.obey.fun/BootStrap入门.html","excerpt":"","text":"什么是BootStrapBootstrap是美国Twitter公司的设计师Mark Otto和Jacob Thornton合作基于HTML、CSS、JavaScript 开发的简洁、直观、强悍的前端开发框架，使得 Web 开发更加快捷。Bootstrap提供了优雅的HTML和CSS规范，它即是由动态CSS语言Less写成。Bootstrap一经推出后颇受欢迎，一直是GitHub上的热门开源项目，包括NASA的MSNBC（微软全国广播公司）的Breaking News都使用了该项目。国内一些移动开发者较为熟悉的框架，如WeX5前端开源框架等，也是基于Bootstrap源码进行性能优化而来。 [2]​BootStrap有什么作用能够提高开发人员的工作效率什么是响应式页面适应不同的分辨率显示不同样式,提高用户的体验BootStrap的中文网http://www.bootcss.com下载BootStrapBootStrap结构全局CSSbootStrap中已经定义好了一套CSS的样式表组件BootStrap定义的一套按钮,导航条等组件JS插件BootStrap定义了一套JS的插件,这些插件已经默认实现了很多种效果BootStrap的入门开发引入相关的头文件12345678910&lt;!-- 最新版本的 Bootstrap 核心 CSS 文件 --&gt;&lt;link rel=\"stylesheet\" href=\"../css/bootstrap.css\" /&gt;&lt;!--需要引入JQuery--&gt;&lt;script type=\"text/javascript\" src=\"../js/jquery-1.11.0.js\" &gt;&lt;/script&gt;&lt;!-- 最新的 Bootstrap 核心 JavaScript 文件 --&gt;&lt;script type=\"text/javascript\" src=\"../js/bootstrap.js\" &gt;&lt;/script&gt;&lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt;BootStrap的布局容器.container 类用于固定宽度并支持响应式布局的容器。123&lt;div class=&quot;container&quot;&gt; ...&lt;/div&gt;.container-fluid 类用于 100% 宽度，占据全部视口（viewport）的容器。123&lt;div class=&quot;container-fluid&quot;&gt; ...&lt;/div&gt;校验表单扩展:1234567trigger : 触发浏览器默认行为triggerHandler : 不会触发is : 判断find : 查找老黄历:什么json: 轻量级的数据交换格式json对象: {“username”:”zhangsan”}json数组: [ {“username”:”zhangsan”}, {“username”:”zhangsan”}, {“username”:”zhangsan”}]ajax异步请求:​ 同步和异步Bootstrap 栅格系统的工作原理：“行（row）”必须包含在 .container （固定宽度）或 .container-fluid （100% 宽度）中，以便为其赋予合适的排列（aligment）和内补（padding）。通过“行（row）”在水平方向创建一组“列（column）”。你的内容应当放置于“列（column）”内，并且，只有“列（column）”可以作为行（row）”的直接子元素。类似 .row 和 .col-xs-4 这种预定义的类，可以用来快速创建栅格布局。Bootstrap 源码中定义的 mixin 也可以用来创建语义化的布局。通过为“列（column）”设置 padding 属性，从而创建列与列之间的间隔（gutter）。通过为 .row 元素设置负值 margin 从而抵消掉为 .container 元素设置的 padding，也就间接为“行（row）”所包含的“列（column）”抵消掉了padding​BootStrap的栅格系统响应式设计: 这种设计依赖于CSS3中的媒体查询栅格样式:设备分辨率大于1200 使用lg样式设备分辨率大于992 &lt; 1200 使用md样式设备分辨率大于768 &lt; 992 使用sm样式设备分辨率小于768使用xs样式BootStrap的全局CSS定义了一套CSS对页面中的元素进行定义列表元素,表单,按钮,图片…使用BootStrap布局网站首页需求分析请使用BootStrap对我们的首页进行优化技术分析步骤分析新建一个HTML页面.引入bootStrap相关的js和CSS定义一个整体的div, 将整体的div分成8个部分完成没部分的内容显示代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;&lt;/title&gt; &lt;!-- 准备工作: &lt;meta name='viewport'&gt; 1.导入bootstrap css文件 2.导入JQuery 3.bootstrap.js 4.写一个div class = container 支持响应式的布局容器 --&gt; &lt;link rel=\"stylesheet\" href=\"../css/bootstrap.min.css\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;!-- jQuery文件。务必在bootstrap.min.js 之前引入 --&gt; &lt;script src=\"../js/jquery-1.11.0.js\"&gt;&lt;/script&gt; &lt;!-- 最新的 Bootstrap 核心 JavaScript 文件 --&gt; &lt;script src=\"../js/bootstrap.min.js\"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=\"container\"&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-4\"&gt; &lt;img src=\"../img/logo2.png\" /&gt; &lt;/div&gt; &lt;div class=\"col-md-4 hidden-xs\"&gt; &lt;img src=\"../img/header.png\" /&gt; &lt;/div&gt; &lt;div class=\"col-md-4\"&gt; &lt;a href=\"#\"&gt;登录&lt;/a&gt; &lt;a href=\"#\"&gt;注册&lt;/a&gt; &lt;a href=\"#\"&gt;购物车&lt;/a&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--菜单--&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-12\"&gt; &lt;nav class=\"navbar navbar-inverse\" role=\"navigation\"&gt; &lt;div class=\"container-fluid\"&gt; &lt;!-- Brand and toggle get grouped for better mobile display --&gt; &lt;div class=\"navbar-header\"&gt; &lt;button type=\"button\" class=\"navbar-toggle collapsed\" data-toggle=\"collapse\" data-target=\"#bs-example-navbar-collapse-1\"&gt; &lt;span class=\"sr-only\"&gt;Toggle navigation&lt;/span&gt; &lt;span class=\"icon-bar\"&gt;&lt;/span&gt; &lt;span class=\"icon-bar\"&gt;&lt;/span&gt; &lt;span class=\"icon-bar\"&gt;&lt;/span&gt; &lt;/button&gt; &lt;a class=\"navbar-brand\" href=\"#\"&gt;首页&lt;/a&gt; &lt;/div&gt; &lt;!-- Collect the nav links, forms, and other content for toggling --&gt; &lt;div class=\"collapse navbar-collapse\" id=\"bs-example-navbar-collapse-1\"&gt; &lt;ul class=\"nav navbar-nav\"&gt; &lt;li class=\"active\"&gt; &lt;a href=\"#\"&gt;手机数码&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;鞋靴箱包&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;电脑办公&lt;/a&gt; &lt;/li&gt; &lt;li class=\"dropdown\"&gt; &lt;a href=\"#\" class=\"dropdown-toggle\" data-toggle=\"dropdown\"&gt;所有分类 &lt;span class=\"caret\"&gt;&lt;/span&gt;&lt;/a&gt; &lt;ul class=\"dropdown-menu\" role=\"menu\"&gt; &lt;li&gt; &lt;a href=\"#\"&gt;手机数码&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;鞋靴箱包&lt;/a&gt; &lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;电脑办公&lt;/a&gt; &lt;/li&gt; &lt;li class=\"divider\"&gt;&lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;Separated link&lt;/a&gt; &lt;/li&gt; &lt;li class=\"divider\"&gt;&lt;/li&gt; &lt;li&gt; &lt;a href=\"#\"&gt;One more separated link&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;form class=\"navbar-form navbar-right\" role=\"search\"&gt; &lt;div class=\"form-group\"&gt; &lt;input type=\"text\" class=\"form-control\" placeholder=\"请输入要搜索的商品\"&gt; &lt;/div&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;搜索&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;!-- /.navbar-collapse --&gt; &lt;/div&gt; &lt;!-- /.container-fluid --&gt; &lt;/nav&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;div id=\"carousel-example-generic\" class=\"carousel slide\" data-ride=\"carousel\"&gt; &lt;!-- Indicators --&gt; &lt;ol class=\"carousel-indicators\"&gt; &lt;li data-target=\"#carousel-example-generic\" data-slide-to=\"0\" class=\"active\"&gt;&lt;/li&gt; &lt;li data-target=\"#carousel-example-generic\" data-slide-to=\"1\"&gt;&lt;/li&gt; &lt;li data-target=\"#carousel-example-generic\" data-slide-to=\"2\"&gt;&lt;/li&gt; &lt;/ol&gt; &lt;!-- Wrapper for slides --&gt; &lt;div class=\"carousel-inner\" role=\"listbox\"&gt; &lt;div class=\"item active\"&gt; &lt;img src=\"../img/1.jpg\" alt=\"...\"&gt; &lt;div class=\"carousel-caption\"&gt; ... &lt;/div&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;img src=\"../img/2.jpg\" alt=\"...\"&gt; &lt;div class=\"carousel-caption\"&gt; ... &lt;/div&gt; &lt;/div&gt; &lt;div class=\"item\"&gt; &lt;img src=\"../img/3.jpg\" alt=\"...\"&gt; &lt;div class=\"carousel-caption\"&gt; ... &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;!-- Controls --&gt; &lt;a class=\"left carousel-control\" href=\"#carousel-example-generic\" role=\"button\" data-slide=\"prev\"&gt; &lt;span class=\"glyphicon glyphicon-chevron-left\"&gt;&lt;/span&gt; &lt;span class=\"sr-only\"&gt;Previous&lt;/span&gt; &lt;/a&gt; &lt;a class=\"right carousel-control\" href=\"#carousel-example-generic\" role=\"button\" data-slide=\"next\"&gt; &lt;span class=\"glyphicon glyphicon-chevron-right\"&gt;&lt;/span&gt; &lt;span class=\"sr-only\"&gt;Next&lt;/span&gt; &lt;/a&gt;&lt;/div&gt; &lt;/div&gt; &lt;!--最新商品这里--&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-12\"&gt; &lt;h3&gt;最新商品&lt;img src=\"../images/title2.jpg\"/&gt;&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--商品部分 --&gt; &lt;div class=\"row\"&gt; &lt;!--左边div--&gt; &lt;div class=\"col-md-2 hidden-sm hidden-xs\"&gt; &lt;img src=\"../products/hao/big01.jpg\" width=\"100%\" height=\"100%\" /&gt; &lt;/div&gt; &lt;!--右边div--&gt; &lt;div class=\"col-md-10\"&gt; &lt;!--上面部分--&gt; &lt;div class=\"row\"&gt; &lt;!--中等广告图--&gt; &lt;div class=\"col-md-6\"&gt; &lt;img src=\"../products/hao/middle01.jpg\" width=\"100%\" /&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--下面部分--&gt; &lt;div class=\"row\"&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-12\"&gt; &lt;img src=\"../products/hao/ad.jpg\" width=\"100%\" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--最新商品这里--&gt; &lt;div class=\"row\"&gt; &lt;div class=\"col-md-12\"&gt; &lt;h3&gt;最新商品&lt;img src=\"../images/title2.jpg\"/&gt;&lt;/h3&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--商品部分 --&gt; &lt;div class=\"row\"&gt; &lt;!--左边div--&gt; &lt;div class=\"col-md-2 hidden-sm hidden-xs\"&gt; &lt;img src=\"../products/hao/big01.jpg\" width=\"100%\" height=\"100%\" /&gt; &lt;/div&gt; &lt;!--右边div--&gt; &lt;div class=\"col-md-10\"&gt; &lt;!--上面部分--&gt; &lt;div class=\"row\"&gt; &lt;!--中等广告图--&gt; &lt;div class=\"col-md-6\"&gt; &lt;img src=\"../products/hao/middle01.jpg\" width=\"100%\" /&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--下面部分--&gt; &lt;div class=\"row\"&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;!--商品项--&gt; &lt;div class=\"col-md-2 col-xs-4\" style=\"text-align: center;\"&gt; &lt;img src=\"../products/hao/small01.jpg\" /&gt; &lt;p&gt;豆浆机&lt;/p&gt; &lt;p&gt;$998&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;!--页脚广告--&gt; &lt;div&gt; &lt;img src=\"../image/footer.jpg\" width=\"100%\" /&gt; &lt;/div&gt; &lt;!--网站声明--&gt; &lt;div style=\"text-align: center;\"&gt; &lt;a href=\"http://www.itheima.com\"&gt;关于我们&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;联系我们&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;招贤纳士&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;法律声明&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;友情链接&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;支付方式&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;配送方式&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;服务声明&lt;/a&gt; &lt;a href=\"http://www.itheima.com\"&gt;广告声明&lt;/a&gt; &lt;br /&gt; Copyright © 2018-2019 HuiProgramer &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt;","categories":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"CSS","slug":"前端/CSS","permalink":"https://me.obey.fun/categories/前端/CSS/"},{"name":"BootStarp","slug":"前端/CSS/BootStarp","permalink":"https://me.obey.fun/categories/前端/CSS/BootStarp/"}],"tags":[{"name":"BootStrap","slug":"BootStrap","permalink":"https://me.obey.fun/tags/BootStrap/"},{"name":"前端框架","slug":"前端框架","permalink":"https://me.obey.fun/tags/前端框架/"}],"keywords":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"CSS","slug":"前端/CSS","permalink":"https://me.obey.fun/categories/前端/CSS/"},{"name":"BootStarp","slug":"前端/CSS/BootStarp","permalink":"https://me.obey.fun/categories/前端/CSS/BootStarp/"}]},{"title":"Jquery入门","slug":"JQuery入门","date":"2019-04-21T08:50:04.000Z","updated":"2019-04-26T01:09:20.951Z","comments":true,"path":"JQuery入门.html","link":"","permalink":"https://me.obey.fun/JQuery入门.html","excerpt":"","text":"什么是JQuery:jQuery是一个快速、简洁的JavaScript框架，是继Prototype之后又一个优秀的JavaScript代码库（或JavaScript框架）。jQuery设计的宗旨是“write Less，Do More”，即倡导写更少的代码，做更多的事情。它封装JavaScript常用的功能代码，提供一种简便的JavaScript设计模式，优化HTML文档操作、事件处理、动画设计和Ajax交互。jQuery的核心特性可以总结为：具有独特的链式语法和短小清晰的多功能接口；具有高效灵活的css选择器，并且可对CSS选择器进行扩展；拥有便捷的插件扩展机制和丰富的插件。jQuery兼容各种主流浏览器，如IE 6.0+、FF 1.5+、Safari 2.0+、Opera 9.0+等JQuery的作用:写更少的代码,做更多的事情: write Less,Do more将我们页面的JS代码和HTML页面代码进行分离为什么学习JQuery:​ 提高我们的工作效率JQ的入门1234567891011121314151617181920212223242526272829&lt;script&gt; //js文档加载完成的事件 window.onload = function()&#123; alert(\"window.onload 111\"); &#125; window.onload = function()&#123; alert(\"window.onload 222\"); &#125; /*文档加载完成的事件*/ jQuery(document).ready(function()&#123; alert(\"jQuery(document).ready(function()\"); &#125;); /* jQuery 简写成 $ */ $(document).ready(function()&#123; alert(\"$(document).ready(function()\"); &#125;); /* 最简单的写法 */ $(function()&#123; alert(\"$(function()&#123;\"); &#125;); &lt;/script&gt;【JQ中根据ID查找元素】1234全都是根据选择器去找的#ID&#123;&#125;.类名&#123;&#125;$(\"#ID的名称\")【JQ和JS之间的转换】JQ对象,只能调用JQ的属性和方法JS对象 只能调用JS的属性和方法12345678910111213141516171819function changeJS()&#123; var div = document.getElementById(\"div1\");// div.innerHTML = \"JS成功修改了内容\" //将JS对象转成JQ对象 $(div).html(\"转成JQ对象来修改内容\") &#125; $(function()&#123; //给按钮绑定事件 $(\"#btn2\").click(function()&#123; //找到div1// $(\"#div1\").html(\"JQ方式成功修改了内容\"); //将JQ对象转成JS对象来调用 var $div = $(\"#div1\");// var jsDiv = $div.get(0); var jsDiv = $div[0]; jsDiv.innerHTML=\"jq转成JS对象成功\"; &#125;); &#125;);JQ的开发步骤: (将我们页面的JS代码和HTML页面代码进行分离)导入JQ相关的文件文档加载完成事件: $(function) : 页面初始化的操作: 绑定事件, 启动页面定时器确定相关操作的事件事件触发函数函数里面再去操作相关的元素显示和隐藏 img.style.display【JQ中的动画效果】1234567show()hide()slideUpslideDownfadeInfadeOutanimate : 自定义动画使用JQuery完成页面定时弹出广告需求分析：当用户打开界面，3秒钟之后弹出广告，这个广告显示5秒钟，隐藏广告技术分析定时器: setTimeout显示和隐藏: style.display = “block/none”步骤分析：导入JQ的文件编写JQ的文档加载事件启动定时器 setTimeout(“”,3000);编写显示广告的函数在显示广告里面再启动一个定时器编写隐藏广告的函数代码实现1234567891011121314&lt;script&gt; //显示广告 function showAd()&#123; $(\"#img1\").slideDown(2000); setTimeout(\"hideAd()\",3000); &#125; //隐藏广告 function hideAd()&#123; $(\"#img1\").slideUp(2000); &#125; $(function()&#123; setTimeout(\"showAd()\",3000); &#125;); &lt;/script&gt;JQuery中的选择器让我们能够更加精确找到我们要操作的元素基本选择器ID选择器 : #ID的名称类选择器: 以 . 开头 .类名元素选择器: 标签的名称通配符选择器: *选择器,选择器: 选择器1,选择器2基本选择器的案例12345678910111213141516171819202122232425262728293031323334&lt;!-- - ID选择器 : #ID的名称 - 类选择器: 以 . 开头 .类名 - 元素选择器: 标签的名称 - 通配符选择器: * - 选择器,选择器: 选择器1,选择器2 --&gt; &lt;script&gt; //文档加载事件,页面初始化的操作 $(function()&#123; //初始化操作: 给按钮绑定事件 $(\"#btn1\").click(function()&#123; $(\"#two\").css(\"background-color\",\"palegreen\"); &#125;); //找出mini类的所有元素 $(\"#btn2\").click(function()&#123; $(\".mini\").css(\"background-color\",\"palegreen\"); &#125;); $(\"#btn3\").click(function()&#123; $(\"div\").css(\"background-color\",\"palegreen\"); &#125;); $(\"#btn4\").click(function()&#123; $(\"*\").css(\"background-color\",\"palegreen\"); &#125;); /*选择器分组*/ //找出mini类 和 span元素 $(\"#btn5\").click(function()&#123; $(\".mini,span\").css(\"background-color\",\"palegreen\"); &#125;); &#125;); &lt;/script&gt;JQ中的层级选择器子元素选择器: 选择器1 &gt; 选择器2后代选择器: 选择器1 儿孙相邻兄弟选择器 : 选择器1 + 选择器2 : 找出紧挨着的一个弟弟找出所有弟弟: 选择器1~ 选择器2 : 找出所有的弟弟123456789101112131415161718192021&lt;script&gt; //文档加载事件,页面初始化的操作 $(function()&#123; //初始化操作: 给按钮绑定事件 //找出body下面的子div $(\"#btn1\").click(function()&#123; $(\"body &gt; div\").css(\"background-color\",\"palegreen\"); &#125;); //找出body下面的所有div $(\"#btn2\").click(function()&#123; $(\"body div\").css(\"background-color\",\"palegreen\"); &#125;); $(\"#btn3\").click(function()&#123; $(\"#one+div\").css(\"background-color\",\"palegreen\"); &#125;); $(\"#btn4\").click(function()&#123; $(\"#two~div\").css(\"background-color\",\"palegreen\"); &#125;); &#125;); &lt;/script&gt;JQ中的基本过滤器12345678910111213141516171819202122232425&lt;script&gt; $(function()&#123; /&lt;script&gt; //文档加载事件,页面初始化的操作 $(function()&#123; //初始化操作: 给按钮绑定事件 //过滤出所有div中第一个元素 $(\"#btn1\").click(function()&#123; $(\"div:first\").css(\"background-color\",\"palegreen\"); &#125;); //过滤出所有div中偶数位的div $(\"#btn2\").click(function()&#123; $(\"div:even\").css(\"background-color\",\"palegreen\"); &#125;); $(\"#btn3\").click(function()&#123; $(\"div:odd\").css(\"background-color\",\"palegreen\"); &#125;); $(\"#btn4\").click(function()&#123; $(\"div:gt(2)\").css(\"background-color\",\"palegreen\"); &#125;); &#125;);&lt;/script&gt;JQ中的属性选择器123456789101112$(function()&#123; //找到有name属性的input $(\"#btn1\").click(function()&#123; $(\"input[name]\").attr(\"checked\",true); &#125;); $(\"#btn2\").click(function()&#123; $(\"input[name='accept']\").attr(\"checked\",true); &#125;); $(\"#btn3\").click(function()&#123; $(\"input[name='newsletter'][value='Hot Fuzz']\").attr(\"checked\",true); &#125;); &#125;);JQ中的表单过滤器123456&lt;script&gt; //1.文档加载事件 $(function()&#123; $(\":text\").css(\"background-color\",\"pink\"); &#125;);&lt;/script&gt;使用JQ完成表格的隔行换色需求分析:在我们的实际开发过程中,我们的表格如果所有的行都是一样的话,很容易看花眼,所以我们需要让我们的表格隔行换色技术分析:获取所有行 table.rows遍历所有行根据行号去修改每一行的背景颜色: bgColor​ style.backgroundColor = “red”步骤分析:导入JQ的包文档加载完成函数: 页面初始化获得所有的行 : 元素选择器根据行号去修改颜色代码实现:123456789 $(function()&#123; //获得所有的行 : 元素选择器 $(\"tbody &gt; tr:even\").css(\"background-color\",\"#CCCCCC\"); //修改基数行 $(\"tbody &gt; tr:odd\").css(\"background-color\",\"#FFF38F\");// $(\"tbody &gt; tr\").css(\"background-color\",\"#FFF38F\"); &#125;);使用JQuery完成表单的全选全不选功能需求分析​ 在我们对表格处理的时,有些情况下,我们需要对表格进行批量处理,技术分析:代码实现:使用JQ完成省市联动效果需求分析:​ 在我们的注册表单中,通常我们需要知道用户的籍贯,需要一个给用选择的项,当用户选中了省份之后,列出省下面所有的城市技术分析:准备工作 : 城市信息的数据添加节点 : appendChild (JS)append : 添加子元素到末尾appendTo : 给自己找一个爹,将自己添加到别人家里prepend : 在子元素前面添加after : 在自己的后面添加一个兄弟遍历的操作:​步骤分析:导入JQ的文件文档加载事件:页面初始化进一步确定事件: change事件函数: 得到当前选中省份得到城市, 遍历城市数据将遍历出来的城市添加到城市的select中代码实现:123456789101112131415161718$(function()&#123; $(\"#province\").change(function()&#123;// alert(this.value); //得到城市信息 var cities = provinces[this.value]; //清空城市select中的option /*var $city = $(\"#city\"); //将JQ对象转成JS对象 var citySelect = $city.get(0) citySelect.options.length = 0;*/ $(\"#city\").empty(); //采用JQ的方式清空 //遍历城市数据 $(cities).each(function(i,n)&#123; $(\"#city\").append(\"&lt;option&gt;\"+n+\"&lt;/option&gt;\"); &#125;); &#125;); &#125;);使用JQ完成下拉列表左右选择需求分析我们的商品通常包含已经有了的, 还有没有的,现在我们需要有一个页面用于动态编辑这些商品技术分析步骤分析导入JQ的文件文档加载函数 :页面初始化确定事件 : 点击事件 onclick事件触发函数移动被选中的那一项到右边代码实现12345678910111213141516&lt;script type=\"text/javascript\" src=\"../js/jquery-1.11.0.js\" &gt;&lt;/script&gt;&lt;script&gt; $(function()&#123; $(\"#a1\").click(function()&#123; //找到被选中的那一项 //将被选中项添加到右边 $(\"#rightSelect\").append($(\"#leftSelect option:selected\")); &#125;); //将左边所有商品移动到右边 $(\"#a2\").click(function()&#123; $(\"#rightSelect\").append($(\"#leftSelect option\")); &#125;); &#125;);&lt;/script&gt;总结:定时器动画效果: show hide slideDown slideUp fadeIn fadeOut animate基本选择器:ID选择器: #ID名称类选择器: .类名元素选择器: 元素/标签名称通配符选择器: * 找出所有页面元素 包含页面上所有的标签选择器分组 : 选择器1, 选择器2 [选择器1,选择器2]层级选择器:后代选择器: 选择器1 选择器2 找出所有的后代,儿子孙子曾孙子元素选择器: 选择器1 &gt;选择器2 找出所有儿子相邻兄弟选择器: 选择器1+选择器2 : 找出紧挨着自己那个弟弟兄弟选择器 : 选择器1~选择器2 : 找出所有的弟弟​​​属性选择器:选择器[属性名称]​12选择器[属性名称][属性名名]选择器[属性名称='属性值'][属性名称='属性值'][属性名称='属性值']表单选择器:123456​ :input 找出所有的输入项 : 不单单找出input textarea select ​ :text 找出type类型为 text​ :password基本过滤器:12345678910111213​ :even​ :odd​ :gt​ :lt​ :eq​ :first​ :last表单对象属性:123​ :selected​ :checked12345678910111213141516171819202122$(function) : 文档加载完成的事件css() : 修改css样式prop() : 修改属性/ 获取属性html() : 修改innerHTMLappend : 给自己添加子节点appendTo : 将自己添加到别人家,给自己找一个爹prepend : 在自己最前面添加子节点after : 在自己后面添加一个兄弟empty : 清空所有子节点$(cities).each(function(i,n)&#123; &#125;)$.each(arr,function(i,n)&#123; &#125;);了解, 熟悉, 熟练, 精通 经过一个项目,将所有学过串起来使用JQ完成表单的校验(扩展)需求分析在用户提交表单的时候, 我们最好是能够在用户数据提交给服务器之前去做一次校验,防止服务器压力过大,并且需要给用户一个友好提示技术分析triggertriggerHandleris()步骤分析首先给必填项,添加尾部添加一个小红点获取用户输入的信息,做相应的校验事件: 获得焦点, 失去焦点, 按键抬起表单提交的事件代码实现使用JQuery发送请求局部刷新页面​ 数据交换格式:​ json​ xml​什么是JSONJSON(JavaScript Object Notation) 是一种轻量级的数据交换格式。它基于ECMAScript的一个子集。 JSON采用完全独立于语言的文本格式，但是也使用了类似于C语言家族的习惯（包括C、C++、C#、Java、JavaScript、Perl、Python等）。这些特性使JSON成为理想的数据交换语言。 易于人阅读和编写，同时也易于机器解析和生成(一般用于提升网络传输速率)。JSON格式​ JSON对象12&#123; key1:value&#125; &#123;\"username\":\"zhangsan\",\"password\":\"123\"&#125;​ JSON数组1[&#123; key1:value&#125;,&#123; key1:value&#125;,&#123; key1:value&#125;]","categories":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"JavaScript","slug":"前端/JavaScript","permalink":"https://me.obey.fun/categories/前端/JavaScript/"},{"name":"JQuery","slug":"前端/JavaScript/JQuery","permalink":"https://me.obey.fun/categories/前端/JavaScript/JQuery/"}],"tags":[{"name":"前端框架","slug":"前端框架","permalink":"https://me.obey.fun/tags/前端框架/"},{"name":"JQuery","slug":"JQuery","permalink":"https://me.obey.fun/tags/JQuery/"}],"keywords":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"JavaScript","slug":"前端/JavaScript","permalink":"https://me.obey.fun/categories/前端/JavaScript/"},{"name":"JQuery","slug":"前端/JavaScript/JQuery","permalink":"https://me.obey.fun/categories/前端/JavaScript/JQuery/"}]},{"title":"Mybatis教程（简单入门）","slug":"Mybatis-入门","date":"2019-03-26T07:53:07.000Z","updated":"2019-11-06T02:41:38.378Z","comments":true,"path":"Mybatis-入门.html","link":"","permalink":"https://me.obey.fun/Mybatis-入门.html","excerpt":"","text":"Mybatis入门Mybatis的介绍MyBatis 本是 apache 的一个开源项目 iBatis, 2010年这个项目由apache software foundation 迁移到了 google code，并且改名为MyBatis 。2013年11月迁移到 Github。MyBatis是一个优秀的持久层框架，它对 jdbc 的操作数据库的过程进行封装，使开发者只需要关注 SQL 本身，而不需要花费精力去处理例如注册驱动、创建connection、创建statement、手动设置参数、结果集检索等 jdbc 繁杂的过程代码。Mybatis 通过 xml 或注解的方式将要执行的各种 statement（statement、preparedStatemnt、CallableStatement）配置起来，并通过java对象和 statement 中的sql进行映射生成最终执行的 sql 语句，最后由 mybatis 框架执行 sql 并将结果映射成 java 对象并返回。使用jdbc编程问题总结创建mysql数据库创建数据库将sql脚本文件导入到数据库中创建工程开发环境IDE: Intellij IDEAJDK: 1.9创建一个Java工程按下图进行创建导入需要的数据库驱动在 file -&gt; project Setting -&gt; Moudules -&gt; Dependencies里，添加jar文件。jdbc编程步骤加载数据库驱动创建并获取数据库链接创建jdbc statement对象设置sql语句设置sql语句中的参数(使用preparedStatement)通过statement执行sql并获取结果对sql执行结果进行解析处理释放资源(resultSet、preparedstatement、connection)jdbc程序1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static void main(String[] args) &#123; Connection connection = null; PreparedStatement preparedStatement = null; ResultSet resultSet = null; try &#123; // 加载数据库驱动 Class.forName(\"com.mysql.jdbc.Driver\"); // 通过驱动管理类获取数据库链接 connection = DriverManager.getConnection(\"jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8\", \"root\", \"root\"); // 定义sql语句 ?表示占位符 String sql = \"select * from user where username = ?\"; // 获取预处理statement preparedStatement = connection.prepareStatement(sql);// 设置参数，第一个参数为sql语句中参数的序号（从1开始），第二个参数为设置的参数值 preparedStatement.setString(1, \"王五\"); // 向数据库发出sql执行查询，查询出结果集 resultSet = preparedStatement.executeQuery(); // 遍历查询结果集 while (resultSet.next()) &#123; System.out.println(resultSet.getString(\"id\") + \" \" + resultSet.getString(\"username\")); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; // 释放资源 if (resultSet != null) &#123; try &#123; resultSet.close(); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; if (preparedStatement != null) &#123; try &#123; preparedStatement.close(); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; if (connection != null) &#123; try &#123; connection.close(); &#125; catch (SQLException e) &#123; // TODO Auto-generated catch block e.printStackTrace(); &#125; &#125; &#125;&#125;上边使用jdbc的原始方法（未经封装）实现了查询数据库表记录的操作。jdbc问题总结如下数据库连接创建、释放频繁造成系统资源浪费，从而影响系统性能。如果使用数据库连接池可解决此问题。Sql语句在代码中硬编码，造成代码不易维护，实际应用中sql变化的可能较大，sql变动需要改变java代码。使用preparedStatement向占有位符号传参数存在硬编码，因为sql语句的where条件不一定，可能多也可能少，修改sql还要修改代码，系统不易维护。对结果集解析存在硬编码（查询列名），sql变化导致解析代码变化，系统不易维护，如果能将数据库记录封装成pojo对象解析比较方便。Mybatis架构mybatis配置SqlMapConfig.xml，此文件作为mybatis的全局配置文件，配置了mybatis的运行环境等信息。mapper.xml文件即sql映射文件，文件中配置了操作数据库的sql语句。此文件需要在SqlMapConfig.xml中加载。通过mybatis环境等配置信息构造SqlSessionFactory即会话工厂由会话工厂创建sqlSession即会话，操作数据库需要通过sqlSession进行。mybatis底层自定义了Executor执行器接口操作数据库，Executor接口有两个实现，一个是基本执行器、一个是缓存执行器。Mapped Statement也是mybatis一个底层封装对象，它包装了mybatis配置信息及sql映射信息等。mapper.xml文件中一个sql对应一个Mapped Statement对象，sql的id即是Mapped statement的id。Mapped Statement对sql执行输入参数进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql前将输入的java对象映射至sql中，输入参数映射就是jdbc编程中对preparedStatement设置参数。Mapped Statement对sql执行输出结果进行定义，包括HashMap、基本类型、pojo，Executor通过Mapped Statement在执行sql后将输出结果映射至java对象中，输出结果映射过程相当于jdbc编程中对结果的解析处理过程。Mybatis入门程序mybatis下载mybaits的代码由github.com管理下载地址：https://github.com/mybatis/mybatis-3/releasesmybatis-3.2.7.jar &emsp;——-》&emsp;mybatis的核心包lib文件夹 &emsp;&nbsp;&emsp;&emsp;&emsp;&nbsp;——-》&emsp;mybatis的依赖包所在mybatis-3.2.7.pdf&emsp; ——-》&emsp;mybatis使用手册业务需求使用MyBatis实现以下功能：根据用户id查询一个用户根据用户名称模糊查询用户列表添加用户更新用户删除用户环境搭建创建Java工程这个前面讲过，直接省略。。。加入jar包加入mybatis核心包、依赖包、数据驱动包。mybatis核心包mybatis依赖包数据库驱动包效果：加入配置文件在src文件夹下，加入log4j.properties和SqlMapConfig.xml配置文件log4j.properties在 src 下创建log4j.properties如下：123456# Global logging configurationlog4j.rootLogger=DEBUG, stdout# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%n注意：mybatis默认使用log4j作为输出日志信息。SqlMapConfig.XML在 src 下创建SqlMapConfig.xml，如下：123456789101112131415161718192021&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 和spring整合后 environments配置将废除 --&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!-- 使用jdbc事务管理 --&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;!-- 数据库连接池 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.jdbc.Driver\" /&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8\" /&gt; &lt;property name=\"username\" value=\"root\" /&gt; &lt;property name=\"password\" value=\"root\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt;&lt;/configuration&gt;注意：SqlMapConfig.xml是mybatis核心配置文件，配置文件内容为数据源、事务管理。效果：创建pojopojo类作为mybatis进行sql映射使用，po类通常与数据库表对应，数据库如下所示：123456789DROP TABLE IF EXISTS `user`;CREATE TABLE `user` ( `id` int(11) NOT NULL AUTO_INCREMENT, `username` varchar(32) NOT NULL COMMENT '用户名称', `birthday` date DEFAULT NULL COMMENT '生日', `sex` char(1) DEFAULT NULL COMMENT '性别', `address` varchar(256) DEFAULT NULL COMMENT '地址', PRIMARY KEY (`id`)) ENGINE=InnoDB AUTO_INCREMENT=27 DEFAULT CHARSET=utf8;User.java如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.share.mybatis.pojo;import java.io.Serializable;import java.util.Date;public class User implements Serializable &#123; private static final long serialVersionUID = 1L; private Integer id; private String username;// 用户姓名 private String sex;// 性别 private Date birthday;// 生日 private String address;// 地址 public Integer getId() &#123; return id; &#125; public void setId(Integer id) &#123; this.id = id; &#125; public String getUsername() &#123; return username; &#125; public void setUsername(String username) &#123; this.username = username; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public Date getBirthday() &#123; return birthday; &#125; public void setBirthday(Date birthday) &#123; this.birthday = birthday; &#125; public String getAddress() &#123; return address; &#125; public void setAddress(String address) &#123; this.address = address; &#125; @Override public String toString() &#123; return \"User [id=\" + id + \", username=\" + username + \", sex=\" + sex + \", birthday=\" + birthday + \", address=\" + address + \"]\"; &#125;&#125;sql映射文件User.xml:1234567&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- namespace：命名空间，用于隔离sql --&gt;&lt;mapper namespace=\"test\"&gt;&lt;/mapper&gt;加载映射文件mybatis框架需要加载Mapper.xml映射文件将users.xml添加在SqlMapConfig.xml，如下：1234&lt;!-- Mapper位置 --&gt; &lt;mappers&gt; &lt;mapper resource=\"sqlmap/User.xml\"&gt;&lt;/mapper&gt; &lt;/mappers&gt;根据id查询用户使用的sql:SELECT * FROM &#39;user&#39; WHERE id = 1映射文件在user.xml中添加select标签，编写sql：1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- namespace：命名空间，用于隔离sql --&gt;&lt;mapper namespace=\"test\"&gt; &lt;!-- id:statement的id 或者叫做sql的id--&gt; &lt;!-- parameterType:声明输入参数的类型 --&gt; &lt;!-- resultType:声明输出结果的类型，应该填写pojo的全路径 --&gt; &lt;!-- #&#123;&#125;：输入参数的占位符，相当于jdbc的？ --&gt; &lt;select id=\"queryUserById\" parameterType=\"int\" resultType=\"fun.obey.mybatis.pojo.User\"&gt; SELECT * FROM `user` WHERE id = #&#123;id&#125; &lt;/select&gt;&lt;/mapper&gt;测试程序：测试程序步骤：创建SqlSessionFactoryBuilder对象加载SqlMapConfig.xml配置文件创建SqlSessionFactory对象创建SqlSession对象执行SqlSession对象执行查询，获取结果User打印结果释放资源MybatisTest编写测试程序如下：12345678910111213141516171819202122232425262728293031public class MybatisTest &#123; private SqlSessionFactory sqlSessionFactory = null; @Before public void init() throws Exception &#123; // 1. 创建SqlSessionFactoryBuilder对象 SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); // 2. 加载SqlMapConfig.xml配置文件 InputStream inputStream = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); // 3. 创建SqlSessionFactory对象 this.sqlSessionFactory = sqlSessionFactoryBuilder.build(inputStream); &#125; @Test public void testQueryUserById() throws Exception &#123; // 4. 创建SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); // 5. 执行SqlSession对象执行查询，获取结果User // 第一个参数是User.xml的statement的id，第二个参数是执行sql需要的参数； Object user = sqlSession.selectOne(\"queryUserById\", 1); // 6. 打印结果 System.out.println(user); // 7. 释放资源 sqlSession.close(); &#125;&#125;效果DEBUG [main] - PooledDataSource forcefully closed/removed all connections.DEBUG [main] - PooledDataSource forcefully closed/removed all connections.DEBUG [main] - PooledDataSource forcefully closed/removed all connections.DEBUG [main] - PooledDataSource forcefully closed/removed all connections.DEBUG [main] - Opening JDBC ConnectionDEBUG [main] - Created connection 1077072774.DEBUG [main] - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@4032d386]DEBUG [main] - ==&gt; Preparing: select * from user where id = ?DEBUG [main] - ==&gt; Parameters: 1(Integer)DEBUG [main] - &lt;== Total: 1User [id=1, username=王五, sex=2, birthday=null, address=null]实现根据用户名模糊查询用户查询sql：SELECT * FROM &#39;user&#39; WHERE username LIKE &#39;%王%&#39;方法一映射文件在User.xml配置文件中添加如下内容：123456 &lt;!-- 如果返回多个结果，mybatis会自动把返回的结果放在list容器中 --&gt;&lt;!-- resultType的配置和返回一个结果的配置一样 --&gt;&lt;select id=\"queryUserByUsername1\" parameterType=\"string\" resultType=\"fun.obey.mybatis.pojo.User\"&gt; SELECT * FROM `user` WHERE username LIKE #&#123;username&#125;&lt;/select&gt;测试程序MybatisTest中添加测试方法如下：1234567891011121314151617 @Testpublic void testQueryUserByUsername1() throws Exception &#123; // 4. 创建SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); // 5. 执行SqlSession对象执行查询，获取结果User // 查询多条数据使用selectList方法 List&lt;Object&gt; list = sqlSession.selectList(\"queryUserByUsername1\", \"%王%\"); // 6. 打印结果 for (Object user : list) &#123; System.out.println(user); &#125; // 7. 释放资源 sqlSession.close();&#125;结果DEBUG [main] - PooledDataSource forcefully closed/removed all connections.DEBUG [main] - Opening JDBC ConnectionDEBUG [main] - Created connection 554868511.DEBUG [main] - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@21129f1f]DEBUG [main] - ==&gt; Preparing: select * from user where username like &#39;%%五%&#39;DEBUG [main] - ==&gt; Parameters:DEBUG [main] - &lt;== Total: 2User [id=1, username=王五, sex=2, birthday=null, address=null]User [id=26, username=王五, sex=null, birthday=null, address=null]方法二映射文件：在User.xml配置文件中添加如下内容：12345&lt;!-- 如果传入的参数是简单数据类型，$&#123;&#125;里面必须写value --&gt;&lt;select id=\"queryUserByUsername2\" parameterType=\"string\" resultType=\"fun.obey.mybatis.pojo.User\"&gt; SELECT * FROM `user` WHERE username LIKE '%$&#123;value&#125;%'&lt;/select&gt;测试程序：MybatisTest中添加测试方法如下：1234567891011121314151617@Testpublic void testQueryUserByUsername2() throws Exception &#123; // 4. 创建SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); // 5. 执行SqlSession对象执行查询，获取结果User // 查询多条数据使用selectList方法 List&lt;Object&gt; list = sqlSession.selectList(\"queryUserByUsername2\", \"王\"); // 6. 打印结果 for (Object user : list) &#123; System.out.println(user); &#125; // 7. 释放资源 sqlSession.close();&#125;效果DEBUG [main] - PooledDataSource forcefully closed/removed all connections.DEBUG [main] - Opening JDBC ConnectionDEBUG [main] - Created connection 554868511.DEBUG [main] - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@21129f1f]DEBUG [main] - ==&gt; Preparing: select * from user where username like &#39;%%五%&#39;DEBUG [main] - ==&gt; Parameters:DEBUG [main] - &lt;== Total: 2User [id=1, username=王五, sex=2, birthday=null, address=null]User [id=26, username=王五, sex=null, birthday=null, address=null]小结#{}和${}#{}表示一个占位符号，通过#{}可以实现preparedStatement向占位符中设置值，自动进行java类型和jdbc类型转换。#{}可以有效防止sql注入。 #{}可以接收简单类型值或pojo属性值。 如果parameterType传输单个简单类型值，#{}括号中可以是value或其它名称。${}表示拼接sql串，通过${}可以将parameterType 传入的内容拼接在sql中且不进行jdbc类型转换， ${}可以接收简单类型值或pojo属性值，如果parameterType传输单个简单类型值，${}括号中只能是value。parameterType和resultTypeparameterType：指定输入参数类型，mybatis通过ognl从输入对象中获取参数值拼接在sql中。resultType：指定输出结果类型，mybatis将sql查询结果的一行记录数据映射为resultType指定类型的对象。如果有多条数据，则分别进行映射，并把对象放到容器List中selectOne和selectListselectOne查询一条记录，如果使用selectOne查询多条记录则抛出异常：12org.apache.ibatis.exceptions.TooManyResultsException: Expected one result (or null) to be returned by selectOne(), but found: 3 at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:70)selectList可以查询一条或多条记录。实现添加用户使用的sql：INSERT INTO &#39;user&#39; (username,birthday,sex,address) VALUES (&#39;黄忠&#39;,&#39;2016-07-26&#39;,&#39;1&#39;,&#39;三国&#39;)映射文件：在User.xml配置文件中添加如下内容：123456&lt;!-- 保存用户 --&gt;&lt;insert id=\"saveUser\" parameterType=\"fun.obey.mybatis.pojo.User\"&gt; INSERT INTO `user` (username,birthday,sex,address) VALUES (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;)&lt;/insert&gt;测试程序MybatisTest中添加测试方法如下：12345678910111213141516171819202122@Testpublic void testSaveUser() &#123; // 4. 创建SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); // 5. 执行SqlSession对象执行保存 // 创建需要保存的User User user = new User(); user.setUsername(\"张飞\"); user.setSex(\"1\"); user.setBirthday(new Date()); user.setAddress(\"蜀国\"); sqlSession.insert(\"saveUser\", user); System.out.println(user); // 需要进行事务提交 sqlSession.commit(); // 7. 释放资源 sqlSession.close();&#125;效果123456789DEBUG [main] - Created connection 1550228904.DEBUG [main] - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5c669da8]DEBUG [main] - ==&gt; Preparing: insert into user(username,birthday,address,sex) values(?,?,?,?) DEBUG [main] - ==&gt; Parameters: 张飞(String), 2019-03-26 19:20:25.336(Timestamp), 蜀国(String), 1(String)DEBUG [main] - &lt;== Updates: 1DEBUG [main] - ==&gt; Preparing: select LAST_INSERT_ID() DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 1User [id=0, username=张飞, sex=1, birthday=Tue Mar 26 19:20:25 CST 2019, address=蜀国]如上所示，保存成功，但是id=0，需要解决id返回不正常的问题。mysql自增主键返回查询id的sqlSELECT LAST_INSERT_ID()通过修改User.xml映射文件，可以将mysql自增主键返回：如下添加selectKey 标签123456789101112131415&lt;!-- 保存用户 --&gt;&lt;insert id=\"saveUser\" parameterType=\"fun.obey.mybatis.pojo.User\"&gt; &lt;!-- selectKey 标签实现主键返回 --&gt; &lt;!-- keyColumn:主键对应的表中的哪一列 --&gt; &lt;!-- keyProperty：主键对应的pojo中的哪一个属性 --&gt; &lt;!-- order：设置在执行insert语句前执行查询id的sql，孩纸在执行insert语句之后执行查询id的sql --&gt; &lt;!-- resultType：设置返回的id的类型 --&gt; &lt;selectKey keyColumn=\"id\" keyProperty=\"id\" order=\"AFTER\" resultType=\"int\"&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; INSERT INTO `user` (username,birthday,sex,address) VALUES (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;)&lt;/insert&gt;LAST_INSERT_ID() : 是mysql的函数，返回auto_increment自增列新记录id值。效果:123456789DEBUG [main] - Created connection 1550228904.DEBUG [main] - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@5c669da8]DEBUG [main] - ==&gt; Preparing: insert into user(username,birthday,address,sex) values(?,?,?,?) DEBUG [main] - ==&gt; Parameters: 张飞(String), 2019-03-26 19:20:25.336(Timestamp), 蜀国(String), 1(String)DEBUG [main] - &lt;== Updates: 1DEBUG [main] - ==&gt; Preparing: select LAST_INSERT_ID() DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 1User [id=29, username=张飞, sex=1, birthday=Tue Mar 26 19:20:25 CST 2019, address=蜀国]Mysql使用 uuid实现主键需要增加通过select uuid()得到uuid值123456789101112131415&lt;!-- 保存用户 --&gt;&lt;insert id=\"saveUser\" parameterType=\"fun.obey.mybatis.pojo.User\"&gt; &lt;!-- selectKey 标签实现主键返回 --&gt; &lt;!-- keyColumn:主键对应的表中的哪一列 --&gt; &lt;!-- keyProperty：主键对应的pojo中的哪一个属性 --&gt; &lt;!-- order：设置在执行insert语句前执行查询id的sql，孩纸在执行insert语句之后执行查询id的sql --&gt; &lt;!-- resultType：设置返回的id的类型 --&gt; &lt;selectKey keyColumn=\"id\" keyProperty=\"id\" order=\"BEFORE\" resultType=\"string\"&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; INSERT INTO `user` (username,birthday,sex,address) VALUES (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;)&lt;/insert&gt;注意: 这里使用的order是“BEFORE”修改用户根据用户id修改用户名使用的sql：UPDATE &#39;user&#39; SET username = &#39;赵云&#39; WHERE id = 26映射文件在User.xml配置文件中添加如下内容：12345&lt;!-- 更新用户 --&gt;&lt;update id=\"updateUserById\" parameterType=\"fun.obey.mybatis.pojo.User\"&gt; UPDATE `user` SET username = #&#123;username&#125; WHERE id = #&#123;id&#125;&lt;/update&gt;测试程序MybatisTest中添加测试方法如下：12345678910111213141516171819202122@Testpublic void testUpdateUserById() &#123; // 4. 创建SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); // 5. 执行SqlSession对象执行更新 // 创建需要更新的User User user = new User(); user.setId(26); user.setUsername(\"关羽\"); user.setSex(\"1\"); user.setBirthday(new Date()); user.setAddress(\"蜀国\"); sqlSession.update(\"updateUserById\", user); // 需要进行事务提交 sqlSession.commit(); // 7. 释放资源 sqlSession.close();&#125;效果123456DEBUG [main] - Opening JDBC ConnectionDEBUG [main] - Created connection 684822005.DEBUG [main] - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@28d18df5]DEBUG [main] - ==&gt; Preparing: update user set username = ?,sex = ?,address = ?,birthday=? where id = ? DEBUG [main] - ==&gt; Parameters: 关羽(String), 1(String), 蜀国(String), 2019-03-26 19:50:34.234(Timestamp), 26(Integer)DEBUG [main] - &lt;== Updates: 1删除用户根据用户id删除用户使用的sqlDELETE FROM &#39;user&#39; WHERE id = 47映射文件：在User.xml配置文件中添加如下内容：12345&lt;!-- 删除用户 --&gt;&lt;delete id=\"deleteUserById\" parameterType=\"int\"&gt; delete from user where id=#&#123;id&#125;&lt;/delete&gt;测试程序：MybatisTest中添加测试方法如下：1234567891011121314@Testpublic void testDeleteUserById() &#123; // 4. 创建SqlSession对象 SqlSession sqlSession = sqlSessionFactory.openSession(); // 5. 执行SqlSession对象执行删除 sqlSession.delete(\"deleteUserById\", 48); // 需要进行事务提交 sqlSession.commit(); // 7. 释放资源 sqlSession.close();&#125;效果123456DEBUG [main] - Opening JDBC ConnectionDEBUG [main] - Created connection 684822005.DEBUG [main] - Setting autocommit to false on JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@28d18df5]DEBUG [main] - ==&gt; Preparing: delete from user where id = ? DEBUG [main] - ==&gt; Parameters: 26(Integer)DEBUG [main] - &lt;== Updates: 1Mybatis解决jdbc编程的问题数据库连接创建、释放频繁造成系统资源浪费从而影响系统性能，如果使用数据库连接池可解决此问题。解决：在SqlMapConfig.xml中配置数据连接池，使用连接池管理数据库链接。Sql语句写在代码中造成代码不易维护，实际应用sql变化的可能较大，sql变动需要改变java代码。解决：将Sql语句配置在XXXXmapper.xml文件中与java代码分离。向sql语句传参数麻烦，因为sql语句的where条件不一定，可能多也可能少，占位符需要和参数一一对应。解决：Mybatis自动将java对象映射至sql语句，通过statement中的parameterType定义输入参数的类型。对结果集解析麻烦，sql变化导致解析代码变化，且解析前需要遍历，如果能将数据库记录封装成pojo对象解析比较方便。解决：Mybatis自动将sql执行结果映射至java对象，通过statement中的resultType定义输出结果的类型。mybatis与hibernate不同Mybatis和hibernate不同，它不完全是一个ORM框架，因为MyBatis需要程序员自己编写Sql语句。mybatis可以通过XML或注解方式灵活配置要运行的sql语句，并将java对象和sql语句映射生成最终执行的sql，最后将sql执行的结果再映射生成java对象。Mybatis学习门槛低，简单易学，程序员直接编写原生态sql，可严格控制sql执行性能，灵活度高，非常适合对关系数据模型要求不高的软件开发，例如互联网软件、企业运营类软件等，因为这类软件需求变化频繁，一但需求变化要求成果输出迅速。但是灵活的前提是mybatis无法做到数据库无关性，如果需要实现支持多种数据库的软件则需要自定义多套sql映射文件，工作量大。Hibernate对象/关系映射能力强，数据库无关性好，对于关系模型要求高的软件（例如需求固定的定制化软件）如果用hibernate开发可以节省很多代码，提高效率。但是Hibernate的学习门槛高，要精通门槛更高，而且怎么设计O/R映射，在性能和对象模型之间如何权衡，以及怎样用好Hibernate需要具有很强的经验和能力才行。总之，按照用户的需求在有限的资源环境下只要能做出维护性、扩展性良好的软件架构都是好架构，所以框架只有适合才是最好。Dao开发方法使用MyBatis开发Dao，通常有两个方法，即原始Dao开发方法和Mapper动态代理开发方法。需求使用MyBatis开发DAO实现以下的功能：根据用户id查询一个用户信息根据用户名称模糊查询用户信息列表添加用户信息SqlSession的使用范围SqlSession中封装了对数据库的操作，如：查询、插入、更新、删除等。SqlSession通过SqlSessionFactory创建。SqlSessionFactory是通过SqlSessionFactoryBuilder进行创建。SqlSessionFactoryBuilderSqlSessionFactoryBuilder用于创建SqlSessionFacoty，SqlSessionFacoty一旦创建完成就不需要SqlSessionFactoryBuilder了，因为SqlSession是通过SqlSessionFactory创建的。所以可以将SqlSessionFactoryBuilder当成一个工具类使用，最佳使用范围是方法范围即方法体内局部变量。SqlSessionFactorySqlSessionFactory是一个接口，接口中定义了openSession的不同重载方法，SqlSessionFactory的最佳使用范围是整个应用运行期间，一旦创建后可以重复使用，通常以单例模式管理SqlSessionFactory。SqlSessionSqlSession是一个面向用户的接口，sqlSession中定义了数据库操作方法。每个线程都应该有它自己的SqlSession实例。SqlSession的实例不能共享使用，它也是线程不安全的。因此最佳的范围是请求或方法范围。绝对不能将SqlSession实例的引用放在一个类的静态字段或实例字段中。打开一个 SqlSession；使用完毕就要关闭它。通常把这个关闭操作放到 finally 块中以确保每次都能执行关闭。如下：123456SqlSession session = sqlSessionFactory.openSession();try &#123; // do work&#125; finally &#123; session.close();&#125;原始Dao开发方式原始Dao开发方法需要程序员编写Dao接口和Dao实现类。映射文件编写映射文件如下：（也可以使用入门程序完成的映射文件）1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- namespace：命名空间，用于隔离sql，还有一个很重要的作用，后面会讲 --&gt;&lt;mapper namespace=\"test\"&gt; &lt;!-- 根据id查询用户 --&gt; &lt;select id=\"queryUserById\" parameterType=\"int\" resultType=\"fun.obey.mybatis.pojo.User\"&gt; select * from user where id = #&#123;id&#125; &lt;/select&gt; &lt;!-- 根据username模糊查询用户 --&gt; &lt;select id=\"queryUserByUsername\" parameterType=\"string\" resultType=\"fun.obey.mybatis.pojo.User\"&gt; select * from user where username like '%$&#123;value&#125;%' &lt;/select&gt; &lt;!-- 保存用户 --&gt; &lt;insert id=\"saveUser\" parameterType=\"fun.obey.mybatis.pojo.User\"&gt; &lt;selectKey keyProperty=\"id\" keyColumn=\"id\" order=\"AFTER\" resultType=\"int\"&gt; SELECT LAST_INSERT_ID() &lt;/selectKey&gt; insert into user(username,birthday,sex,address) values(#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;) &lt;/insert&gt;&lt;/mapper&gt;Dao接口先进行DAO的接口开发，编码如下：123456789101112131415161718192021222324public interface UserDao &#123; /** * 根据id查询用户 * * @param id * @return */ User queryUserById(int id); /** * 根据用户名模糊查询用户 * * @param username * @return */ List&lt;User&gt; queryUserByUsername(String username); /** * 保存用户 * * @param user */ void saveUser(User user);&#125;Dao实现类编写的Dao实现类如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445public class UserDaoImpl implements UserDao &#123; private SqlSessionFactory sqlSessionFactory; public UserDaoImpl(SqlSessionFactory sqlSessionFactory) &#123; super(); this.sqlSessionFactory = sqlSessionFactory; &#125; @Override public User queryUserById(int id) &#123; // 创建SqlSession SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 执行查询逻辑 User user = sqlSession.selectOne(\"queryUserById\", id); // 释放资源 sqlSession.close(); return user; &#125; @Override public List&lt;User&gt; queryUserByUsername(String username) &#123; // 创建SqlSession SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 执行查询逻辑 List&lt;User&gt; list = sqlSession.selectList(\"queryUserByUsername\", username); // 释放资源 sqlSession.close(); return list; &#125; @Override public void saveUser(User user) &#123; // 创建SqlSession SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 执行保存逻辑 sqlSession.insert(\"saveUser\", user); // 提交事务 sqlSession.commit(); // 释放资源 sqlSession.close(); &#125;&#125;Dao测试创建一个JUnit的测试类，对UserDao进行测试，测试代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class UserDaoTest &#123; private SqlSessionFactory sqlSessionFactory; @Before public void init() throws Exception &#123; // 创建SqlSessionFactoryBuilder SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); // 加载SqlMapConfig.xml配置文件 InputStream inputStream = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); // 创建SqlsessionFactory this.sqlSessionFactory = sqlSessionFactoryBuilder.build(inputStream); &#125; @Test public void testQueryUserById() &#123; // 创建DAO UserDao userDao = new UserDaoImpl(this.sqlSessionFactory); // 执行查询 User user = userDao.queryUserById(1); System.out.println(user); &#125; @Test public void testQueryUserByUsername() &#123; // 创建DAO UserDao userDao = new UserDaoImpl(this.sqlSessionFactory); // 执行查询 List&lt;User&gt; list = userDao.queryUserByUsername(\"张\"); for (User user : list) &#123; System.out.println(user); &#125; &#125; @Test public void testSaveUser() &#123; // 创建DAO UserDao userDao = new UserDaoImpl(this.sqlSessionFactory); // 创建保存对象 User user = new User(); user.setUsername(\"刘备\"); user.setBirthday(new Date()); user.setSex(\"1\"); user.setAddress(\"蜀国\"); // 执行保存 userDao.saveUser(user); System.out.println(user); &#125;&#125;问题原始Dao开发中存在以下问题：Dao方法体存在重复代码：通过SqlSessionFactory创建SqlSession，调用SqlSession的数据库操作方法调用sqlSession的数据库操作方法需要指定statement的id，这里存在硬编码，不得于开发维护。Mapper动态代理方式开发规范Mapper接口开发方法只需要程序员编写Mapper接口（相当于Dao接口），由Mybatis框架根据接口定义创建接口的动态代理对象，代理对象的方法体同上边Dao接口实现类方法。Mapper接口开发需要遵循以下规范：Mapper.xml文件中的namespace与mapper接口的类路径相同。Mapper接口方法名和Mapper.xml中定义的每个statement的id相同Mapper接口方法的输入参数类型和mapper.xml中定义的每个sql 的parameterType的类型相同Mapper接口方法的输出参数类型和mapper.xml中定义的每个sql的resultType的类型相同Mapper.xml(映射文件)定义mapper映射文件UserMapper.xml将UserMapper.xml放在src下sqlmap目录下UserMapper.xml配置文件内容：123456789101112131415161718192021222324252627282930313233&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- namespace：命名空间，用于隔离sql --&gt;&lt;!-- 还有一个很重要的作用，使用动态代理开发DAO，1. namespace必须和Mapper接口类路径一致 --&gt;&lt;mapper namespace=\"fun.obey.mybatis.mapper.UserMapper\"&gt; &lt;!-- 根据用户id查询用户 --&gt; &lt;!-- 2. id必须和Mapper接口方法名一致 --&gt; &lt;!-- 3. parameterType必须和接口方法参数类型一致 --&gt; &lt;!-- 4. resultType必须和接口方法返回值类型一致 --&gt; &lt;select id=\"queryUserById\" parameterType=\"int\" resultType=\"fun.obey.mybatis.pojo.User\"&gt; select * from user where id = #&#123;id&#125; &lt;/select&gt; &lt;!-- 根据用户名查询用户 --&gt; &lt;select id=\"queryUserByUsername\" parameterType=\"string\" resultType=\"fun.obey.mybatis.pojo.User\"&gt; select * from user where username like '%$&#123;value&#125;%' &lt;/select&gt; &lt;!-- 保存用户 --&gt; &lt;insert id=\"saveUser\" parameterType=\"fun.obey.mybatis.pojo.User\"&gt; &lt;selectKey keyProperty=\"id\" keyColumn=\"id\" order=\"AFTER\" resultType=\"int\"&gt; select last_insert_id() &lt;/selectKey&gt; insert into user(username,birthday,sex,address) values (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;); &lt;/insert&gt;&lt;/mapper&gt;UserMapper(接口文件)创建UserMapper接口代码如下：123456789101112131415161718192021222324public interface UserMapper &#123; /** * 根据id查询 * * @param id * @return */ User queryUserById(int id); /** * 根据用户名查询用户 * * @param username * @return */ List&lt;User&gt; queryUserByUsername(String username); /** * 保存用户 * * @param user */ void saveUser(User user);&#125;加载UserMapper.xml文件修改SqlMapConfig.xml文件，添加以下所示的内容：12345&lt;!-- 加载映射文件 --&gt;&lt;mappers&gt; &lt;mapper resource=\"sqlmap/User.xml\" /&gt; &lt;mapper resource=\"mapper/UserMapper.xml\" /&gt;&lt;/mappers&gt;测试编写的测试方法如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class UserMapperTest &#123; private SqlSessionFactory sqlSessionFactory; @Before public void init() throws Exception &#123; // 创建SqlSessionFactoryBuilder SqlSessionFactoryBuilder sqlSessionFactoryBuilder = new SqlSessionFactoryBuilder(); // 加载SqlMapConfig.xml配置文件 InputStream inputStream = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); // 创建SqlsessionFactory this.sqlSessionFactory = sqlSessionFactoryBuilder.build(inputStream); &#125; @Test public void testQueryUserById() &#123; // 获取sqlSession，和spring整合后由spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 从sqlSession中获取Mapper接口的代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 执行查询方法 User user = userMapper.queryUserById(1); System.out.println(user); // 和spring整合后由spring管理 sqlSession.close(); &#125; @Test public void testQueryUserByUsername() &#123; // 获取sqlSession，和spring整合后由spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 从sqlSession中获取Mapper接口的代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 执行查询方法 List&lt;User&gt; list = userMapper.queryUserByUsername(\"张\"); for (User user : list) &#123; System.out.println(user); &#125; // 和spring整合后由spring管理 sqlSession.close(); &#125; @Test public void testSaveUser() &#123; // 获取sqlSession，和spring整合后由spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 从sqlSession中获取Mapper接口的代理对象 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 创建保存对象 User user = new User(); user.setUsername(\"刘备\"); user.setBirthday(new Date()); user.setSex(\"1\"); user.setAddress(\"蜀国\"); // 执行查询方法 userMapper.saveUser(user); System.out.println(user); // 和spring整合后由spring管理 sqlSession.commit(); sqlSession.close(); &#125;&#125;小结selectOne和selectList动态代理对象调用sqlSession.selectOne()和sqlSession.selectList()是根据mapper接口方法的返回值决定，如果返回list则调用selectList方法，如果返回单个对象则调用selectOne方法。namespacemybatis官方推荐使用mapper代理方法开发mapper接口，程序员不用编写mapper接口实现类，使用mapper代理方法时，输入参数可以使用pojo包装对象或map对象，保证dao的通用性。SqlMapConfig.xml配置文件配置内容SqlMapConfig.xml中配置的内容和顺序如下：properties（属性）settings（全局配置参数）typeAliases（类型别名）typeHandlers（类型处理器）objectFactory（对象工厂）plugins（插件）environments（环境集合属性对象）environment（环境子属性对象）transactionManager（事务管理）dataSource（数据源）mappers（映射器）properties（属性）SqlMapConfig.xml可以引用java属性文件中的配置信息如下：在config下定义jdbc.properties文件，如下所示：jdbc.properties配置文件内容如下:1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8jdbc.username=rootjdbc.password=rootSqlMapConfig.xml引用如下：12345678910111213141516171819202122232425262728293031323334&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 是用resource属性加载外部配置文件 --&gt; &lt;properties resource=\"db.properties\"&gt; &lt;!-- 在properties内部用property定义属性 --&gt; &lt;!-- 如果外部配置文件有该属性，则内部定义属性被外部属性覆盖 --&gt; &lt;property name=\"jdbc.username\" value=\"root123\" /&gt; &lt;property name=\"jdbc.password\" value=\"root123\" /&gt; &lt;/properties&gt; &lt;!-- 和spring整合后 environments配置将废除 --&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!-- 使用jdbc事务管理 --&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;!-- 数据库连接池 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\" /&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 加载映射文件 --&gt; &lt;mappers&gt; &lt;mapper resource=\"sqlmap/User.xml\" /&gt; &lt;mapper resource=\"mapper/UserMapper.xml\" /&gt; &lt;/mappers&gt;&lt;/configuration&gt;注意： MyBatis 将按照下面的顺序来加载属性：在 properties 元素体内定义的属性首先被读取。然后会读取properties 元素中resource或 url 加载的属性，它会覆盖已读取的同名属性。typeAliases（类型别名）mybatis支持别名：别名映射的类型_bytebyte_longlong_shortshort_intint_integerint_doubledouble_floatfloat_booleanbooleanstringStringbyteBytelongLongshortShortintIntegerintegerIntegerdoubleDoublefloatFloatbooleanBooleandateDatedecimalBigDecimalbigdecimalBigDecimalmapMap自定义别名：在SqlMapConfig.xml中配置如下：1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 是用resource属性加载外部配置文件 --&gt; &lt;properties resource=\"db.properties\"&gt; &lt;!-- 在properties内部用property定义属性 --&gt; &lt;property name=\"jdbc.username\" value=\"root123\" /&gt; &lt;property name=\"jdbc.password\" value=\"root123\" /&gt; &lt;/properties&gt; &lt;typeAliases&gt; &lt;!-- 单个别名定义 --&gt; &lt;typeAlias alias=\"user\" type=\"fun.obey.pojo.User\" /&gt; &lt;!-- 批量别名定义，扫描整个包下的类，别名为类名（大小写不敏感） --&gt; &lt;package name=\"fun.obey.mybatis.pojo\" /&gt; &lt;package name=\"其它包\" /&gt; &lt;/typeAliases&gt; &lt;!-- 和spring整合后 environments配置将废除 --&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;!-- 使用jdbc事务管理 --&gt; &lt;transactionManager type=\"JDBC\" /&gt; &lt;!-- 数据库连接池 --&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"$&#123;jdbc.driver&#125;\" /&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;!-- 加载映射文件 --&gt; &lt;mappers&gt; &lt;mapper resource=\"sqlmap/User.xml\" /&gt; &lt;mapper resource=\"mapper/UserMapper.xml\" /&gt; &lt;/mappers&gt;&lt;/configuration&gt;在mapper.xml配置文件中，就可以使用设置的别名了提示：别名大小写不敏感mappers（映射器）Mapper配置的几种方法：&lt;mapper resource=” “ /&gt;使用相对于类路径的资源（现在的使用方式）如：&lt;mapper resource=&quot;sqlmap/User.xml&quot; /&gt;&lt;mapper class=” “ /&gt;使用mapper接口类路径如：&lt;mapper class=&quot;fun.obey.mybatis.mapper.UserMapper&quot;/&gt;注意：此种方法要求mapper接口名称和mapper映射文件名称相同，且放在同一个目录中。&lt;package name=””/&gt;注册指定包下的所有mapper接口如：&lt;package name=&quot;fun.obey.mybatis.mapper&quot;/&gt;注意：此种方法要求mapper接口名称和mapper映射文件名称相同，且放在同一个目录中。Mybatis进阶parameterType(输入类型)传递简单类型参考入门的内容。使用#{}占位符，或者${}进行sql拼接。传递pojo对象参考入门的内容。Mybatis使用ognl表达式解析对象字段的值，#{}或者${}括号中的值为pojo属性名称。传递pojo包装对象开发中通过可以使用pojo传递查询条件。查询条件可能是综合的查询条件，不仅包括用户查询条件还包括其它的查询条件（比如查询用户信息的时候，将用户购买商品信息也作为查询条件），这时可以使用包装对象传递输入参数。包装对象：Pojo类中的一个属性是另外一个pojo。需求：根据用户名模糊查询用户信息，查询条件放到QueryVo的user属性中。编写QueryVo1234567891011public class QueryVo &#123; // 包含其他的pojo private User user; public User getUser() &#123; return user; &#125; public void setUser(User user) &#123; this.user = user; &#125;&#125;Sql语句SELECT * FROM user WHERE username LIKE &#39;%张%&#39;Mapper.xml文件123&lt;select id=\"queryUserByQueryVo\" parameterType=\"queryVo\" resultType=\"user\"&gt; select * from user where username like '%$&#123;user.username&#125;%' &lt;/select&gt;Mapper接口List&lt;User&gt; queryUserByQueryVo(Query queryVo);测试方法在UserMapeprTest增加测试方法，如下：123456789101112131415161718192021222324@Testpublic void testQueryUserByQueryVo() &#123; // mybatis和spring整合，整合之后，交给spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 创建Mapper接口的动态代理对象，整合之后，交给spring管理 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 使用userMapper执行查询，使用包装对象 QueryVo queryVo = new QueryVo(); // 设置user条件 User user = new User(); user.setUsername(\"张\"); // 设置到包装对象中 queryVo.setUser(user); // 执行查询 List&lt;User&gt; list = userMapper.queryUserByQueryVo(queryVo); for (User u : list) &#123; System.out.println(u); &#125; // mybatis和spring整合，整合之后，交给spring管理 sqlSession.close();&#125;效果123456DEBUG [main] - ==&gt; Preparing: select * from user where username like &apos;%%张%&apos; DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 3User [id=10, username=张三, sex=1, birthday=Thu Jul 10 00:00:00 CST 2014, address=北京市]User [id=16, username=张小明, sex=1, birthday=null, address=河南郑州]User [id=24, username=张三丰, sex=1, birthday=null, address=河南郑州]resultType(输出类型)输出简单类型需求:查询用户表数据条数sql：SELECT count(*) FROM userMapper.xml文件123&lt;select id = \"queryUserCount\" resultType = \"int\"&gt; select count(*) from 'user'&lt;/select&gt;Mapper接口int queryUserCount();测试方法在UserMapeprTest增加测试方法，如下：1234567891011121314@Testpublic void testQueryUserCount() &#123; // mybatis和spring整合，整合之后，交给spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 创建Mapper接口的动态代理对象，整合之后，交给spring管理 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 使用userMapper执行查询用户数据条数 int count = userMapper.queryUserCount(); System.out.println(count); // mybatis和spring整合，整合之后，交给spring管理 sqlSession.close();&#125;效果1234DEBUG [main] - ==&gt; Preparing: select count(*) from &apos;user&apos;DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 114注意：输出简单类型必须查询出来的结果集有一条记录，最终将第一个字段的值转换为输出类型。resultMapresultType可以指定将查询结果映射为pojo，但需要pojo的属性名和sql查询的列名一致方可映射成功。如果sql查询字段名和pojo的属性名不一致，可以通过resultMap将字段名和属性名作一个对应关系 ，resultMap实质上还需要将查询结果映射到pojo对象中。resultMap可以实现将查询结果映射为复杂类型的pojo，比如在查询结果映射对象中包括pojo和list实现一对一查询和一对多查询。需求：查询订单表order的所有数据sql：SELECT id, user_id, number, createtime, note FROM order声明pojo对象数据库如下：1234567891011DROP TABLE IF EXISTS `orders`;CREATE TABLE `orders` ( `id` int(11) NOT NULL AUTO_INCREMENT, `user_id` int(11) NOT NULL COMMENT '下单用户id', `number` varchar(32) NOT NULL COMMENT '订单号', `createtime` datetime NOT NULL COMMENT '创建订单时间', `note` varchar(100) DEFAULT NULL COMMENT '备注', PRIMARY KEY (`id`), KEY `FK_orders_1` (`user_id`), CONSTRAINT `FK_orders_id` FOREIGN KEY (`user_id`) REFERENCES `user` (`id`) ON DELETE NO ACTION ON UPDATE NO ACTION) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=utf8;Order对象：12345678910111213public class Order &#123; // 订单id private int id; // 用户id private Integer userId; // 订单号 private String number; // 订单创建时间 private Date createtime; // 备注 private String note;get/set。。。&#125;Mapper.xml文件创建OrderMapper.xml配置文件，如下：12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- namespace：命名空间，用于隔离sql，还有一个很重要的作用，Mapper动态代理开发的时候使用，需要指定Mapper的类路径 --&gt;&lt;mapper namespace=\"fun.obey.mybatis.mapper.OrderMapper\"&gt; &lt;!-- 查询所有的订单数据 --&gt; &lt;select id=\"queryOrderAll\" resultType=\"order\"&gt; SELECT id, user_id, number, createtime, note FROM `order` &lt;/select&gt;&lt;/mapper&gt;Mapper接口编写接口如下：12345678public interface OrderMapper &#123; /** * 查询所有订单 * * @return */ List&lt;Order&gt; queryOrderAll();&#125;测试方法编写测试方法OrderMapperTest如下：1234567891011121314151617181920212223public class OrderMapperTest &#123; private SqlSessionFactory sqlSessionFactory; @Before public void init() throws Exception &#123; InputStream inputStream = Resources.getResourceAsStream(\"SqlMapConfig.xml\"); this.sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; @Test public void testQueryAll() &#123; // 获取sqlSession SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 获取OrderMapper OrderMapper orderMapper = sqlSession.getMapper(OrderMapper.class); // 执行查询 List&lt;Order&gt; list = orderMapper.queryOrderAll(); for (Order order : list) &#123; System.out.println(order); &#125; &#125;&#125;效果123456DEBUG [main] - ==&gt; Preparing: select id,user_id,number,createtime,not from &apos;order&apos;DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 3Order[id = 3,userId=null,number=1000010,createtime=Wed Feb 04 13:22:35 CST 2015,note = null]Order[id = 4,userId=null,number=1000011,createtime=Wed Feb 04 13:22:35 CST 2015,note = null]Order[id = 5,userId=null,number=1000012,createtime=Wed Feb 04 13:22:35 CST 2015,note = null]发现userId为null解决方案：使用resultMap使用resultMap由于上边的mapper.xml中sql查询列(user_id)和Order类属性(userId)不一致，所以查询结果不能映射到pojo中。需要定义resultMap，把orderResultMap将sql查询列(user_id)和Order类属性(userId)对应起来改造OrderMapper.xml，如下：123456789101112131415161718192021222324252627282930&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;!-- namespace：命名空间，用于隔离sql，还有一个很重要的作用，Mapper动态代理开发的时候使用，需要指定Mapper的类路径 --&gt;&lt;mapper namespace=\"fun.obey.mybatis.mapper.OrderMapper\"&gt; &lt;!-- resultMap最终还是要将结果映射到pojo上，type就是指定映射到哪一个pojo --&gt; &lt;!-- id：设置ResultMap的id --&gt; &lt;resultMap type=\"order\" id=\"orderResultMap\"&gt; &lt;!-- 定义主键 ,非常重要。如果是多个字段,则定义多个id --&gt; &lt;!-- property：主键在pojo中的属性名 --&gt; &lt;!-- column：主键在数据库中的列名 --&gt; &lt;id property=\"id\" column=\"id\" /&gt; &lt;!-- 定义普通属性 --&gt; &lt;result property=\"userId\" column=\"user_id\" /&gt; &lt;result property=\"number\" column=\"number\" /&gt; &lt;result property=\"createtime\" column=\"createtime\" /&gt; &lt;result property=\"note\" column=\"note\" /&gt; &lt;/resultMap&gt; &lt;!-- 查询所有的订单数据 --&gt; &lt;select id=\"queryOrderAll\" resultMap=\"orderResultMap\"&gt; SELECT id, user_id, number, createtime, note FROM `order` &lt;/select&gt;&lt;/mapper&gt;效果只需要修改Mapper.xml就可以了，再次测试结果如下：123456DEBUG [main] - ==&gt; Preparing: select id,user_id,number,createtime,not from &apos;order&apos;DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 3Order[id = 3,userId=1,number=1000010,createtime=Wed Feb 04 13:22:35 CST 2015,note = null]Order[id = 4,userId=1,number=1000011,createtime=Wed Feb 04 13:22:35 CST 2015,note = null]Order[id = 5,userId=10,number=1000012,createtime=Wed Feb 04 13:22:35 CST 2015,note = null]动态sql通过mybatis提供的各种标签方法实现动态拼接sql。需求：根据性别和名字查询用户查询sql：SELECT id, username, birthday, sex, address FROM user WHERE sex = 1 AND username LIKE ‘%张%’If标签Mapper.xml文件UserMapper.xml配置sql，如下：123456&lt;!-- 根据条件查询用户 --&gt;&lt;select id=\"queryUserByWhere\" parameterType=\"user\" resultType=\"user\"&gt; SELECT id, username, birthday, sex, address FROM `user` WHERE sex = #&#123;sex&#125; AND username LIKE '%$&#123;username&#125;%'&lt;/select&gt;Mapper接口List&lt;User&gt; queryUserByWhere(User user);测试方法在UserMapperTest添加测试方法，如下：123456789101112131415161718192021@Testpublic void testQueryUserByWhere() &#123; // mybatis和spring整合，整合之后，交给spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 创建Mapper接口的动态代理对象，整合之后，交给spring管理 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 使用userMapper执行根据条件查询用户 User user = new User(); user.setSex(\"1\"); user.setUsername(\"张\"); List&lt;User&gt; list = userMapper.queryUserByWhere(user); for (User u : list) &#123; System.out.println(u); &#125; // mybatis和spring整合，整合之后，交给spring管理 sqlSession.close();&#125;效果123456DEBUG [main] - ==&gt; Preparing: SELECT id, username, birthday, sex, address FROM user WHERE sex = 1 AND username LIKE &apos;张&apos;DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 3User [id=10, username=张三, sex=1, birthday=Thu Jul 10 00:00:00 CST 2014, address=北京市]User [id=16, username=张小明, sex=1, birthday=null, address=河南郑州]User [id=22, username=陈小明, sex=1, birthday=null, address=河南郑州]如果注释掉user.setSex(“1”)，测试结果如下图：123DEBUG [main] - ==&gt; Preparing: SELECT id, username, birthday, sex, address FROM user WHERE sex = 1 AND username LIKE nullDEBUG [main] - ==&gt; Parameters: nullDEBUG [main] - &lt;== Total: 0测试结果二很显然不合理。按照之前所学的，要解决这个问题，需要编写多个sql，查询条件越多，需要编写的sql就更多了，显然这样是不靠谱的。解决方案，使用动态sql的if标签使用if标签改造UserMapper.xml，如下：123456789101112&lt;!-- 根据条件查询用户 --&gt;&lt;select id=\"queryUserByWhere\" parameterType=\"user\" resultType=\"user\"&gt; SELECT id, username, birthday, sex, address FROM `user` WHERE 1=1 &lt;if test=\"sex != null and sex != ''\"&gt; AND sex = #&#123;sex&#125; &lt;/if&gt; &lt;if test=\"username != null and username != ''\"&gt; AND username LIKE '%$&#123;username&#125;%' &lt;/if&gt;&lt;/select&gt;注意字符串类型的数据需要要做不等于空字符串校验。效果123456DEBUG [main] - ==&gt; Preparing: SELECT id, username, birthday, sex, address FROM user WHERE sex = 1 AND username LIKE &apos;张&apos;DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 3User [id=10, username=张三, sex=1, birthday=Thu Jul 10 00:00:00 CST 2014, address=北京市]User [id=16, username=张小明, sex=1, birthday=null, address=河南郑州]User [id=22, username=陈小明, sex=1, birthday=null, address=河南郑州]如上图所示，测试OKWhere标签上面的sql还有where 1=1 这样的语句，很麻烦可以使用where标签进行改造改造UserMapper.xml，如下1234567891011121314&lt;!-- 根据条件查询用户 --&gt;&lt;select id=\"queryUserByWhere\" parameterType=\"user\" resultType=\"user\"&gt; SELECT id, username, birthday, sex, address FROM `user`&lt;!-- where标签可以自动添加where，同时处理sql语句中第一个and关键字 --&gt; &lt;where&gt; &lt;if test=\"sex != null\"&gt; AND sex = #&#123;sex&#125; &lt;/if&gt; &lt;if test=\"username != null and username != ''\"&gt; AND username LIKE '%$&#123;username&#125;%' &lt;/if&gt; &lt;/where&gt;&lt;/select&gt;效果123456DEBUG [main] - ==&gt; Preparing: SELECT id, username, birthday, sex, address FROM user WHERE sex = 1 AND username LIKE &apos;张&apos;DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 3User [id=10, username=张三, sex=1, birthday=Thu Jul 10 00:00:00 CST 2014, address=北京市]User [id=16, username=张小明, sex=1, birthday=null, address=河南郑州]User [id=22, username=陈小明, sex=1, birthday=null, address=河南郑州]Sql片段Sql中可将重复的sql提取出来，使用时用include引用即可，最终达到sql重用的目的。把上面例子中的id, username, birthday, sex, address提取出来，作为sql片段，如下：123456789101112131415161718192021&lt;!-- 根据条件查询用户 --&gt;&lt;select id=\"queryUserByWhere\" parameterType=\"user\" resultType=\"user\"&gt; &lt;!-- SELECT id, username, birthday, sex, address FROM `user` --&gt; &lt;!-- 使用include标签加载sql片段；refid是sql片段id --&gt; SELECT &lt;include refid=\"userFields\" /&gt; FROM `user` &lt;!-- where标签可以自动添加where关键字，同时处理sql语句中第一个and关键字 --&gt; &lt;where&gt; &lt;if test=\"sex != null\"&gt; AND sex = #&#123;sex&#125; &lt;/if&gt; &lt;if test=\"username != null and username != ''\"&gt; AND username LIKE '%$&#123;username&#125;%' &lt;/if&gt; &lt;/where&gt;&lt;/select&gt;&lt;!-- 声明sql片段 --&gt;&lt;sql id=\"userFields\"&gt; id, username, birthday, sex, address&lt;/sql&gt;注意：如果要使用别的Mapper.xml配置的sql片段，可以在refid前面加上对应的Mapper.xml的namespaceforeach标签向sql传递数组或List，mybatis使用foreach解析，如下：根据多个id查询用户信息查询sql：SELECT * FROM user WHERE id IN (1,10,24)改造QueryVo在pojo中定义list属性ids存储多个用户id，并添加getter/setter方法Mapper.xml文件UserMapper.xml添加sql，如下：12345678910111213141516&lt;!-- 根据ids查询用户 --&gt;&lt;select id=\"queryUserByIds\" parameterType=\"queryVo\" resultType=\"user\"&gt; SELECT * FROM `user` &lt;where&gt; &lt;!-- foreach标签，进行遍历 --&gt; &lt;!-- collection：遍历的集合，这里是QueryVo的ids属性 --&gt; &lt;!-- item：遍历的项目，可以随便写，，但是和后面的#&#123;&#125;里面要一致 --&gt; &lt;!-- open：在前面添加的sql片段 --&gt; &lt;!-- close：在结尾处添加的sql片段 --&gt; &lt;!-- separator：指定遍历的元素之间使用的分隔符 --&gt; &lt;foreach collection=\"ids\" item=\"item\" open=\"id IN (\" close=\")\" separator=\",\"&gt; #&#123;item&#125; &lt;/foreach&gt; &lt;/where&gt;&lt;/select&gt;测试方法如下图：123456789101112131415161718192021222324@Testpublic void testQueryUserByIds() &#123; // mybatis和spring整合，整合之后，交给spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 创建Mapper接口的动态代理对象，整合之后，交给spring管理 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 使用userMapper执行根据条件查询用户 QueryVo queryVo = new QueryVo(); List&lt;Integer&gt; ids = new ArrayList&lt;&gt;(); ids.add(1); ids.add(10); ids.add(24); queryVo.setIds(ids); List&lt;User&gt; list = userMapper.queryUserByIds(queryVo); for (User u : list) &#123; System.out.println(u); &#125; // mybatis和spring整合，整合之后，交给spring管理 sqlSession.close();&#125;效果123456DEBUG [main] - ==&gt; Preparing: SELECT * FROM user WHERE id in(?,?,?)DEBUG [main] - ==&gt; Parameters: 1(Integer),10(Integer),22(Integer)DEBUG [main] - &lt;== Total: 3User [id=1, username=李四, sex=2, birthday=null, address=null]User [id=10, username=张三, sex=1, birthday=Thu Jul 10 00:00:00 CST 2014, address=北京市]User [id=22, username=陈小明, sex=1, birthday=null, address=河南郑州]关联查询商品订单数据模型一对一查询需求：查询所有订单信息，关联查询下单用户信息。注意：因为一个订单信息只会是一个人下的订单，所以从查询订单信息出发关联查询用户信息为一对一查询。如果从用户信息出发查询用户下的订单信息则为一对多查询，因为一个用户可以下多个订单。sql语句：1234567891011SELECT o.id, o.user_id userId, o.number, o.createtime, o.note, u.username, u.addressFROM `order` oLEFT JOIN `user` u ON o.user_id = u.id方法一：使用resultType使用resultType，改造订单pojo类，此pojo类中包括了订单信息和用户信息这样返回对象的时候，mybatis自动把用户信息也注入进来了改造pojo类OrderUser类继承Order类后OrderUser类包括了Order类的所有字段，只需要定义用户的信息字段即可，如下：1234public class OrderUser extends Order&#123; private String username; private String address;&#125;Mapper.xml在UserMapper.xml添加sql，如下123456789101112131415&lt;!-- 查询订单，同时包含用户数据 --&gt;&lt;select id=\"queryOrderUser\" resultType=\"orderUser\"&gt; SELECT o.id, o.user_id userId, o.number, o.createtime, o.note, u.username, u.address FROM `order` o LEFT JOIN `user` u ON o.user_id = u.id&lt;/select&gt;Mapper接口在UserMapper接口添加方法，如下:1List&lt;OrderUser&gt; queryOrderUser();测试方法：在UserMapperTest添加测试方法，如下：1234567891011121314151617@Testpublic void testQueryOrderUser() &#123; // mybatis和spring整合，整合之后，交给spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 创建Mapper接口的动态代理对象，整合之后，交给spring管理 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 使用userMapper执行根据条件查询用户 List&lt;OrderUser&gt; list = userMapper.queryOrderUser(); for (OrderUser ou : list) &#123; System.out.println(ou); &#125; // mybatis和spring整合，整合之后，交给spring管理 sqlSession.close();&#125;效果测试结果如下图：小结定义专门的pojo类作为输出类型，其中定义了sql查询结果集所有的字段。此方法较为简单，企业中使用普遍。方法二：使用resultMap使用resultMap，定义专门的resultMap用于映射一对一查询结果。改造pojo类在Order类中加入User属性，user属性中用于存储关联查询的用户信息，因为订单关联查询用户是一对一关系，所以这里使用单个User对象存储关联查询的用户信息。改造Order如下:1234567891011121314public class Order&#123; private Integer id; private Integer userId; private String number; private Date createtime; private String note; //附加对象 用户对象 private User user;&#125;Mapper.xml这里resultMap指定orderUserResultMap，如下：123456789101112131415161718192021222324252627282930313233&lt;resultMap type=\"order\" id=\"orderUserResultMap\"&gt; &lt;id property=\"id\" column=\"id\" /&gt; &lt;result property=\"userId\" column=\"user_id\" /&gt; &lt;result property=\"number\" column=\"number\" /&gt; &lt;result property=\"createtime\" column=\"createtime\" /&gt; &lt;result property=\"note\" column=\"note\" /&gt; &lt;!-- association ：配置一对一属性 --&gt; &lt;!-- property:order里面的User属性名 --&gt; &lt;!-- javaType:属性类型 --&gt; &lt;association property=\"user\" javaType=\"user\"&gt; &lt;!-- id:声明主键，表示user_id是关联查询对象的唯一标识--&gt; &lt;id property=\"id\" column=\"user_id\" /&gt; &lt;result property=\"username\" column=\"username\" /&gt; &lt;result property=\"address\" column=\"address\" /&gt; &lt;/association&gt;&lt;/resultMap&gt;&lt;!-- 一对一关联，查询订单，订单内部包含用户属性 --&gt;&lt;select id=\"queryOrderUserResultMap\" resultMap=\"orderUserResultMap\"&gt; SELECT o.id, o.user_id, o.number, o.createtime, o.note, u.username, u.address FROM `order` o LEFT JOIN `user` u ON o.user_id = u.id&lt;/select&gt;Mapper接口1List&lt;Order&gt; queryOrderUserResultMap();测试方法在UserMapperTest增加测试方法，如下：1234567891011121314151617@Testpublic void testQueryOrderUserResultMap() &#123; // mybatis和spring整合，整合之后，交给spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 创建Mapper接口的动态代理对象，整合之后，交给spring管理 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 使用userMapper执行根据条件查询用户 List&lt;Order&gt; list = userMapper.queryOrderUserResultMap(); for (Order o : list) &#123; System.out.println(o); &#125; // mybatis和spring整合，整合之后，交给spring管理 sqlSession.close();&#125;效果测试效果如下图：一对多查询案例：查询所有用户信息及用户关联的订单信息。用户信息和订单信息为一对多关系。sql语句：12345678910111213SELECT u.id, u.username, u.birthday, u.sex, u.address, o.id oid, o.number, o.createtime, o.noteFROM `user` uLEFT JOIN `order` o ON u.id = o.user_id修改pojo类在User类中加入Listorders属性,如下：123456private Integer id;private String username;// 用户姓名private String sex;// 性别private Date birthday;// 生日private String address;// 地址private List&lt;Orders&gt; orders; //附加属性Mapper.xml在UserMapper.xml添加sql，如下：123456789101112131415161718192021222324252627282930313233&lt;resultMap type=\"user\" id=\"userOrderResultMap\"&gt; &lt;id property=\"id\" column=\"id\" /&gt; &lt;result property=\"username\" column=\"username\" /&gt; &lt;result property=\"birthday\" column=\"birthday\" /&gt; &lt;result property=\"sex\" column=\"sex\" /&gt; &lt;result property=\"address\" column=\"address\" /&gt; &lt;!-- 配置一对多的关系 --&gt; &lt;collection property=\"orders\" javaType=\"list\" ofType=\"order\"&gt; &lt;!-- 配置主键，是关联Order的唯一标识 --&gt; &lt;id property=\"id\" column=\"oid\" /&gt; &lt;result property=\"number\" column=\"number\" /&gt; &lt;result property=\"createtime\" column=\"createtime\" /&gt; &lt;result property=\"note\" column=\"note\" /&gt; &lt;/collection&gt;&lt;/resultMap&gt;&lt;!-- 一对多关联，查询订单同时查询该用户下的订单 --&gt;&lt;select id=\"queryUserOrder\" resultMap=\"userOrderResultMap\"&gt; SELECT u.id, u.username, u.birthday, u.sex, u.address, o.id oid, o.number, o.createtime, o.note FROM `user` u LEFT JOIN `order` o ON u.id = o.user_id&lt;/select&gt;Mapper接口编写UserMapper接口，如下：12//一对多关联查询，用户内部包含该用户的订单 List&lt;User&gt; queryUserOrder();测试方法在UserMapperTest增加测试方法，如下:1234567891011121314151617@Testpublic void testQueryUserOrder() &#123; // mybatis和spring整合，整合之后，交给spring管理 SqlSession sqlSession = this.sqlSessionFactory.openSession(); // 创建Mapper接口的动态代理对象，整合之后，交给spring管理 UserMapper userMapper = sqlSession.getMapper(UserMapper.class); // 使用userMapper执行根据条件查询用户 List&lt;User&gt; list = userMapper.queryUserOrder(); for (User u : list) &#123; System.out.println(u); &#125; // mybatis和spring整合，整合之后，交给spring管理 sqlSession.close();&#125;效果123456789101112DEBUG [main] - ==&gt; Preparing: SELECT u.id, u.username, u.birthday, u.sex, u.address, o.id oid, o.user_id, o.number, o.createtime, o.note FROM user u LEFT JOIN orders o ON u.id = o.user_id DEBUG [main] - ==&gt; Parameters: DEBUG [main] - &lt;== Total: 10User&#123;id=1, username=&apos;王五&apos;, sex=&apos;2&apos;, birthday=null, address=&apos;null&apos;, orders=[Orders&#123;id=3, userId=1, number=&apos;1000010&apos;, createtime=Wed Feb 04 13:22:35 CST 2015, note=&apos;null&apos;, user=null&#125;, Orders&#123;id=4, userId=1, number=&apos;1000011&apos;, createtime=Tue Feb 03 13:22:41 CST 2015, note=&apos;null&apos;, user=null&#125;]&#125;User&#123;id=10, username=&apos;张三&apos;, sex=&apos;1&apos;, birthday=Thu Jul 10 00:00:00 CST 2014, address=&apos;北京市&apos;, orders=[Orders&#123;id=5, userId=10, number=&apos;1000012&apos;, createtime=Thu Feb 12 16:13:23 CST 2015, note=&apos;null&apos;, user=null&#125;]&#125;User&#123;id=16, username=&apos;张小明&apos;, sex=&apos;1&apos;, birthday=null, address=&apos;河南郑州&apos;, orders=[]&#125;User&#123;id=22, username=&apos;陈小明&apos;, sex=&apos;1&apos;, birthday=null, address=&apos;河南郑州&apos;, orders=[]&#125;User&#123;id=24, username=&apos;张三丰&apos;, sex=&apos;1&apos;, birthday=null, address=&apos;河南郑州&apos;, orders=[]&#125;User&#123;id=25, username=&apos;陈小明&apos;, sex=&apos;1&apos;, birthday=null, address=&apos;河南郑州&apos;, orders=[]&#125;User&#123;id=26, username=&apos;王五&apos;, sex=&apos;null&apos;, birthday=null, address=&apos;null&apos;, orders=[]&#125;User&#123;id=27, username=&apos;HuiProgramer&apos;, sex=&apos;男&apos;, birthday=Sun Mar 24 00:00:00 CST 2019, address=&apos;湖南省衡阳市&apos;, orders=[]&#125;User&#123;id=28, username=&apos;彭于晏&apos;, sex=&apos;男&apos;, birthday=Sun Mar 24 00:00:00 CST 2019, address=&apos;湖南&apos;, orders=[]&#125;Mybatis整合spring整合思路SqlSessionFactory对象应该放到spring容器中作为单例存在。传统dao的开发方式中，应该从spring容器中获得sqlsession对象。Mapper代理形式中，应该从spring容器中直接获得mapper的代理对象。数据库的连接以及数据库连接池事务管理都交给spring容器来完成。整合需要的jar包spring的jar包Mybatis的jar包Spring+mybatis的整合包。Mysql的数据库驱动jar包。数据库连接池的jar包。整合的步骤创建工程导入jar包加入配置文件mybatisSpring的配置文件的配置文件sqlmapConfig.xmla)数据库连接及连接池b)事务管理（暂时可以不配置）c)sqlsessionFactory对象，配置到spring容器中d)mapeer代理对象或者是dao实现类配置到spring容器中。SqlMapConfig.xml配置文件是SqlMapConfig.xml，如下：123456789101112&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configurationPUBLIC \"-//mybatis.org//DTD Config 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;!-- 设置别名 --&gt; &lt;typeAliases&gt; &lt;!-- 2. 指定扫描包，会把包内所有的类都设置别名，别名的名称就是类名，大小写不敏感 --&gt; &lt;package name=\"fun.obey.mybatis.pojo\" /&gt; &lt;/typeAliases&gt;&lt;/configuration&gt;applicationContext.xmlSqlSessionFactoryBean属于mybatis-spring这个jar包对于spring来说，mybatis是另外一个架构，需要整合jar包。applicationContext.xml，配置内容如下:1234567891011121314151617181920212223242526272829303132&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:p=\"http://www.springframework.org/schema/p\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:tx=\"http://www.springframework.org/schema/tx\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-4.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-4.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-4.0.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx-4.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-4.0.xsd\"&gt; &lt;!-- 加载配置文件 --&gt; &lt;context:property-placeholder location=\"classpath:db.properties\" /&gt; &lt;!-- 数据库连接池 --&gt; &lt;bean id=\"dataSource\" class=\"org.apache.commons.dbcp.BasicDataSource\" destroy-method=\"close\"&gt; &lt;property name=\"driverClassName\" value=\"$&#123;jdbc.driver&#125;\" /&gt; &lt;property name=\"url\" value=\"$&#123;jdbc.url&#125;\" /&gt; &lt;property name=\"username\" value=\"$&#123;jdbc.username&#125;\" /&gt; &lt;property name=\"password\" value=\"$&#123;jdbc.password&#125;\" /&gt; &lt;property name=\"maxActive\" value=\"10\" /&gt; &lt;property name=\"maxIdle\" value=\"5\" /&gt; &lt;/bean&gt; &lt;!-- 配置SqlSessionFactory --&gt; &lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!-- 配置mybatis核心配置文件 --&gt; &lt;property name=\"configLocation\" value=\"classpath:SqlMapConfig.xml\" /&gt; &lt;!-- 配置数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt;&lt;/beans&gt;db.properties1234jdbc.driver=com.mysql.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/mybatis?characterEncoding=utf-8jdbc.username=rootjdbc.password=rootlog4j.properties123456# Global logging configurationlog4j.rootLogger=DEBUG, stdout# Console output...log4j.appender.stdout=org.apache.log4j.ConsoleAppenderlog4j.appender.stdout.layout=org.apache.log4j.PatternLayoutlog4j.appender.stdout.layout.ConversionPattern=%5p [%t] - %m%nDao的开发两种dao的实现方式：原始dao的开发方式使用Mapper代理形式开发方式a)直接配置Mapper代理b)使用扫描包配置Mapper代理需求：实现根据用户id查询实现根据用户名模糊查询添加用户创建pojo123456789public class User &#123; private int id; private String username;// 用户姓名 private String sex;// 性别 private Date birthday;// 生日 private String address;// 地址get/set。。。&#125;传统dao的开发方式原始的DAO开发接口+实现类来完成。需要dao实现类需要继承SqlsessionDaoSupport类实现Mapper.xml编写User.xml配置文件，如下：1234567891011121314151617181920212223242526272829&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"test\"&gt; &lt;!-- 根据用户id查询 --&gt; &lt;select id=\"queryUserById\" parameterType=\"int\" resultType=\"user\"&gt; select * from user where id = #&#123;id&#125; &lt;/select&gt; &lt;!-- 根据用户名模糊查询用户 --&gt; &lt;select id=\"queryUserByUsername\" parameterType=\"string\" resultType=\"user\"&gt; select * from user where username like '%$&#123;value&#125;%' &lt;/select&gt; &lt;!-- 添加用户 --&gt; &lt;insert id=\"saveUser\" parameterType=\"user\"&gt; &lt;selectKey keyProperty=\"id\" keyColumn=\"id\" order=\"AFTER\" resultType=\"int\"&gt; select last_insert_id() &lt;/selectKey&gt; insert into user (username,birthday,sex,address) values (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;) &lt;/insert&gt;&lt;/mapper&gt;加载Mapper.xml在SqlMapConfig进行配置:1234&lt;mappers&gt; &lt;!-- 加载User.xml配置文件 --&gt; &lt;mapper resource=\"sqlmap/User.xml\" /&gt; &lt;/mappers&gt;实现UserDao接口12345678910111213141516171819202122232425public interface UserDao &#123; /** * 根据id查询用户 * * @param id * @return */ User queryUserById(int id); /** * 根据用户名模糊查询用户列表 * * @param username * @return */ List&lt;User&gt; queryUserByUsername(String username); /** * 保存 * * @param user */ void saveUser(User user);&#125;实现UserDaoImpl实现类编写DAO实现类，实现类必须集成SqlSessionDaoSupportSqlSessionDaoSupport提供getSqlSession()方法来获取SqlSession123456789101112131415161718192021222324252627282930313233343536373839public class UserDaoImpl extends SqlSessionDaoSupport implements UserDao &#123; @Override public User queryUserById(int id) &#123; // 获取SqlSession SqlSession sqlSession = super.getSqlSession(); // 使用SqlSession执行操作 User user = sqlSession.selectOne(\"queryUserById\", id); // 不要关闭sqlSession return user; &#125; @Override public List&lt;User&gt; queryUserByUsername(String username) &#123; // 获取SqlSession SqlSession sqlSession = super.getSqlSession(); // 使用SqlSession执行操作 List&lt;User&gt; list = sqlSession.selectList(\"queryUserByUsername\", username); // 不要关闭sqlSession return list; &#125; @Override public void saveUser(User user) &#123; // 获取SqlSession SqlSession sqlSession = super.getSqlSession(); // 使用SqlSession执行操作 sqlSession.insert(\"saveUser\", user); // 不用提交,事务由spring进行管理 // 不要关闭sqlSession &#125;&#125;配置dao把dao实现类配置到spring容器中，如下:123456789101112&lt;!-- 配置SqlSessionFactory --&gt; &lt;bean id=\"sqlSessionFactoryBean\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;!-- 配置mybatis核心配置文件 --&gt; &lt;property name=\"configLocation\" value=\"config/sqlMapConfig.xml\" /&gt; &lt;!-- 配置数据源 --&gt; &lt;property name=\"dataSource\" ref=\"dataSource\" /&gt; &lt;/bean&gt; &lt;!-- Dao --&gt; &lt;bean id=\"UserDao\" class=\"fun.obey.mybatis.dao.UserDaoImpl\"&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactoryBean\" /&gt; &lt;/bean&gt;测试方法创建测试方法，可以直接创建测试Junit用例。编写测试方法如下：123456789101112131415161718192021222324252627282930313233343536373839404142public class UserDaoTest &#123; private ApplicationContext context; @Before public void setUp() throws Exception &#123; this.context = new ClassPathXmlApplicationContext(\"classpath:applicationContext.xml\"); &#125; @Test public void testQueryUserById() &#123; // 获取userDao UserDao userDao = this.context.getBean(UserDao.class); User user = userDao.queryUserById(1); System.out.println(user); &#125; @Test public void testQueryUserByUsername() &#123; // 获取userDao UserDao userDao = this.context.getBean(UserDao.class); List&lt;User&gt; list = userDao.queryUserByUsername(\"张\"); for (User user : list) &#123; System.out.println(user); &#125; &#125; @Test public void testSaveUser() &#123; // 获取userDao UserDao userDao = this.context.getBean(UserDao.class); User user = new User(); user.setUsername(\"曹操\"); user.setSex(\"1\"); user.setBirthday(new Date()); user.setAddress(\"三国\"); userDao.saveUser(user); System.out.println(user); &#125;&#125;Mapper代理形式开发dao实现Mapper.xml编写UserMapper.xml配置文件，如下：123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapperPUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\"\"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"fun.obey.mybatis.mapper.UserMapper\"&gt; &lt;!-- 根据用户id查询 --&gt; &lt;select id=\"queryUserById\" parameterType=\"int\" resultType=\"user\"&gt; select * from user where id = #&#123;id&#125; &lt;/select&gt; &lt;!-- 根据用户名模糊查询用户 --&gt; &lt;select id=\"queryUserByUsername\" parameterType=\"string\" resultType=\"user\"&gt; select * from user where username like '%$&#123;value&#125;%' &lt;/select&gt; &lt;!-- 添加用户 --&gt; &lt;insert id=\"saveUser\" parameterType=\"user\"&gt; &lt;selectKey keyProperty=\"id\" keyColumn=\"id\" order=\"AFTER\" resultType=\"int\"&gt; select last_insert_id() &lt;/selectKey&gt; insert into user (username,birthday,sex,address) values (#&#123;username&#125;,#&#123;birthday&#125;,#&#123;sex&#125;,#&#123;address&#125;) &lt;/insert&gt;&lt;/mapper&gt;实现UserMapper接口123456789101112131415161718192021222324public interface UserMapper &#123; /** * 根据用户id查询 * * @param id * @return */ User queryUserById(int id); /** * 根据用户名模糊查询用户 * * @param username * @return */ List&lt;User&gt; queryUserByUsername(String username); /** * 添加用户 * * @param user */ void saveUser(User user);&#125;方式一：配置mapper代理在applicationContext.xml添加配置MapperFactoryBean也是属于mybatis-spring整合包1234567&lt;!-- Mapper代理的方式开发方式一，配置Mapper代理对象 --&gt;&lt;bean id=\"userMapper\" class=\"org.mybatis.spring.mapper.MapperFactoryBean\"&gt; &lt;!-- 配置Mapper接口 --&gt; &lt;property name=\"mapperInterface\" value=\"fun.obey.mybatis.mapper.UserMapper\" /&gt; &lt;!-- 配置sqlSessionFactory --&gt; &lt;property name=\"sqlSessionFactory\" ref=\"sqlSessionFactory\" /&gt;&lt;/bean&gt;测试方法12345678910111213141516171819202122232425262728293031323334353637383940414243public class UserMapperTest &#123; private ApplicationContext context; @Before public void setUp() throws Exception &#123; this.context = new ClassPathXmlApplicationContext(\"classpath:applicationContext.xml\"); &#125; @Test public void testQueryUserById() &#123; // 获取Mapper UserMapper userMapper = this.context.getBean(UserMapper.class); User user = userMapper.queryUserById(1); System.out.println(user); &#125; @Test public void testQueryUserByUsername() &#123; // 获取Mapper UserMapper userMapper = this.context.getBean(UserMapper.class); List&lt;User&gt; list = userMapper.queryUserByUsername(\"张\"); for (User user : list) &#123; System.out.println(user); &#125; &#125; @Test public void testSaveUser() &#123; // 获取Mapper UserMapper userMapper = this.context.getBean(UserMapper.class); User user = new User(); user.setUsername(\"曹操\"); user.setSex(\"1\"); user.setBirthday(new Date()); user.setAddress(\"三国\"); userMapper.saveUser(user); System.out.println(user); &#125;&#125;方式二：扫描包形式配置mapper12345&lt;!-- Mapper代理的方式开发方式二，扫描包方式配置代理 --&gt;&lt;bean class=\"org.mybatis.spring.mapper.MapperScannerConfigurer\"&gt; &lt;!-- 配置Mapper接口 --&gt; &lt;property name=\"basePackage\" value=\"fun.obey.mybatis.mapper\" /&gt;&lt;/bean&gt;提示：每个mapper代理对象的id就是类名，首字母小写","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Mybatis","slug":"后端/Java/Mybatis","permalink":"https://me.obey.fun/categories/后端/Java/Mybatis/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SQL","slug":"SQL","permalink":"https://me.obey.fun/tags/SQL/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Mybatis","slug":"后端/Java/Mybatis","permalink":"https://me.obey.fun/categories/后端/Java/Mybatis/"}]},{"title":"Spring AOP","slug":"Spring-AOP","date":"2019-03-20T13:47:47.000Z","updated":"2019-05-04T12:46:32.538Z","comments":true,"path":"Spring-AOP.html","link":"","permalink":"https://me.obey.fun/Spring-AOP.html","excerpt":"","text":"AOP 前奏WHY AOP?需求1：在程序执行期间追踪正在发生的活动需求2：希望计算器只能处理正数的运算代码实现片段出现的问题代码混乱：越来越多的非业务需求(日志和验证等)加入后, 原有的业务方法急剧膨胀. 每个方法在处理核心逻辑的同时还必须兼顾其他多个关注点.代码分散：以日志需求为例, 只是为了满足这个单一需求, 就不得不在多个模块（方法）里多次重复相同的日志代码. 如果日志需求发生变化, 必须修改所有模块.使用动态代理解决上述问题代理设计模式的原理：使用一个代理将对象包装起来, 然后用该代理对象取代原始对象. 任何对原始对象的调用都要通过代理. 代理对象决定是否以及何时将方法调用转到原始对象上.ArithmeticCalculator.java12345678package com.spring.aop.impl;public interface ArithmeticCalculator &#123; int add(int i, int j); int sub(int i, int j); int mul(int i, int j); int div(int i, int j);&#125;ArithmeticCalculatorimpl.java1234567891011121314151617181920212223package com.spring.aop.helloworld;public class ArithmeticCalculatorImpl implements ArithmeticCalculator &#123; @Override public int add(int i, int j) &#123; return i+j; &#125; @Override public int sub(int i, int j) &#123; return i-j; &#125; @Override public int mul(int i, int j) &#123; return i*j; &#125; @Override public int div(int i, int j) &#123; return i/j; &#125;&#125;ArithmeticCalculatorLoggingProxy.java12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.spring.aop.helloworld;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.Arrays;public class ArithmeticCalculatorLoggingProxy &#123; //要代理的对象 private ArithmeticCalculator target; public ArithmeticCalculatorLoggingProxy(ArithmeticCalculator target) &#123; this.target = target; &#125; public ArithmeticCalculator getLoggingProxy()&#123; ArithmeticCalculator proxy = null; //代理对象由哪一个类加载器负责加载 ClassLoader loader = target.getClass().getClassLoader(); //代理对象的类型，即其中有哪些方法 Class[] interfaces = new Class[]&#123;ArithmeticCalculator.class&#125;; //当调用代理对象其中方法时，该执行的方法 InvocationHandler h = new InvocationHandler() &#123; /** * proxy:正在返回的那个代理对象，一般情况下，在invoke方法中都不使用该对象 * method:正在被调用的方法 * args:调用方法时，传入的参数 * */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; String methodName = method.getName(); //日志 System.out.println(\"The method \" + methodName + \"begins with \" + Arrays.asList(args)); //执行方法 Object result = method.invoke(target,args); //日志 System.out.println(\"The method \" + methodName+ \"ends with \" + result); return result; &#125; &#125;; proxy = (ArithmeticCalculator) Proxy.newProxyInstance(loader,interfaces,h); return proxy; &#125;&#125;测试代码1234567891011121314package com.spring.aop.helloworld;public class Main &#123; public static void main(String[] args)&#123; ArithmeticCalculator target = new ArithmeticCalculatorImpl(); ArithmeticCalculator proxy = new ArithmeticCalculatorLoggingProxy(target).getLoggingProxy(); int result = proxy.add(1,2); System.out.println(\"--&gt;\"+result); result = proxy.div(4,3); System.out.println(\"--&gt;\"+result); &#125;&#125;结果：The method addbegins with [1, 2]The method addends with 3--&gt;3The method divbegins with [4, 3]The method divends with 1--&gt;1AOP 简介AOP(Aspect-Oriented Programming, 面向切面编程): 是一种新的方法论, 是对传统 OOP(Object-Oriented Programming, 面向对象编程) 的补充.AOP 的主要编程对象是切面(aspect), 而切面模块化横切关注点.在应用 AOP 编程时, 仍然需要定义公共功能, 但可以明确的定义这个功能在哪里, 以什么方式应用, 并且不必修改受影响的类. 这样一来横切关注点就被模块化到特殊的对象(切面)里.AOP 的好处:每个事物逻辑位于一个位置, 代码不分散, 便于维护和升级业务模块更简洁, 只包含核心业务代码.AOP 术语切面(Aspect): 横切关注点(跨越应用程序多个模块的功能)被模块化的特殊对象通知(Advice): 切面必须要完成的工作目标(Target): 被通知的对象代理(Proxy): 向目标对象应用通知之后创建的对象连接点（Joinpoint）：程序执行的某个特定位置：如类某个方法调用前、调用后、方法抛出异常后等。连接点由两个信息确定：方法表示的程序执行点；相对点表示的方位。例如 ArithmethicCalculator#add() 方法执行前的连接点，执行点为 ArithmethicCalculator#add()； 方位为该方法执行前的位置切点（pointcut）：每个类都拥有多个连接点：例如 ArithmethicCalculator 的所有方法实际上都是连接点，即连接点是程序类中客观存在的事务。AOP 通过切点定位到特定的连接点。类比：连接点相当于数据库中的记录，切点相当于查询条件。切点和连接点不是一对一的关系，一个切点匹配多个连接点，切点通过 org.springframework.aop.Pointcut 接口进行描述，它使用类和方法作为连接点的查询条件。Spring AOPAspectJ：Java 社区里最完整最流行的 AOP 框架.在 Spring2.0 以上版本中, 可以使用基于 AspectJ 注解或基于 XML 配置的 AOP在Spring中启用AspectJ注解支持要在 Spring 应用中使用 AspectJ 注解, 必须在 classpath 下包含 AspectJ 类库: aopalliance.jar、aspectj.weaver.jar 和 spring-aspects.jar将 aop Schema 添加到根元素中.要在 Spring IOC 容器中启用 AspectJ 注解支持, 只要在 Bean 配置文件中定义一个空的 XML 元素 aop:aspectj-autoproxy当 Spring IOC 容器侦测到 Bean 配置文件中的 aop:aspectj-autoproxy 元素时, 会自动为与 AspectJ 切面匹配的 Bean 创建代理.用AspectJ注解声明切面要在 Spring 中声明 AspectJ 切面, 只需要在 IOC 容器中将切面声明为 Bean 实例. 当在 Spring IOC 容器中初始化 AspectJ 切面之后, Spring IOC 容器就会为那些与 AspectJ 切面相匹配的 Bean 创建代理.在 AspectJ 注解中, 切面只是一个带有 @Aspect 注解的 Java 类.通知是标注有某种注解的简单的 Java 方法.AspectJ 支持 5 种类型的通知注解:@Before: 前置通知, 在方法执行之前执行@After: 后置通知, 在方法执行之后执行@AfterRunning: 返回通知, 在方法返回结果之后执行@AfterThrowing: 异常通知, 在方法抛出异常之后@Around: 环绕通知, 围绕着方法执行前置通知前置通知:在方法执行之前执行的通知前置通知使用 @Before 注解, 并将切入点表达式的值作为注解值.123456//声明该方法时一个前置通知: 在目标方法开始之前执行 @Before(\"execution(* com.spring.aop.impl.*.add(..))\") public void beforeMethod(JoinPoint joinPoint) &#123; System.out.println(\"The method begins with \"); &#125;标识这个方法是个前置通知, 切点表达式表示执行 ArithmeticCalculator 接口的 add() 方法. * 代表匹配任意修饰符及任意返回值, 参数列表中的 .. 匹配任意数量的参数利用方法签名编写 AspectJ 切入点表达式最典型的切入点表达式时根据方法的签名来匹配各种方法:execution com.atguigu.spring.ArithmeticCalculator.(..): 匹配 ArithmeticCalculator 中声明的所有方法,第一个 代表任意修饰符及任意返回值. 第二个 代表任意方法. .. 匹配任意数量的参数. 若目标类与接口与该切面在同一个包中, 可以省略包名.execution public ArithmeticCalculator.(..): 匹配 ArithmeticCalculator 接口的所有公有方法.execution public double ArithmeticCalculator.*(..): 匹配 ArithmeticCalculator 中返回 double 类型数值的方法execution public double ArithmeticCalculator.*(double, ..): 匹配第一个参数为 double 类型的方法, .. 匹配任意数量任意类型的参数execution public double ArithmeticCalculator.*(double, double): 匹配参数类型为 double, double 类型的方法.合并切入点表达式在 AspectJ 中, 切入点表达式可以通过操作符 &amp;&amp;, ||, ! 结合起来.123456//声明该方法时一个前置通知: 在目标方法开始之前执行 @Before(\"execution(* com.spring.aop.impl.*.add(int,int))&amp;&amp;execution(* com.spring.aop.impl.*.div(int,int))\") public void beforeMethod(JoinPoint joinPoint) &#123; System.out.println(\"The method begins with \"); &#125;让通知访问当前连接点的细节可以在通知方法中声明一个类型为 JoinPoint 的参数. 然后就能访问链接细节. 如方法名称和参数值.12345678//声明该方法时一个前置通知: 在目标方法开始之前执行 @Before(\"execution(* com.spring.aop.impl.*.*(int,int))\") public void beforeMethod(JoinPoint joinPoint) &#123; String MethodName = joinPoint.getSignature().getName(); List&lt;Object&gt; args = Arrays.asList(joinPoint.getArgs()); System.out.println(\"The method \"+MethodName+\" begins with \" + args); &#125;标识这个方法是个前置通知, 切点表达式表示执行任意类的任意方法. 第一个 代表匹配任意修饰符及任意返回值, 第二个 代表任意类的对象,第三个 * 代表任意方法, 参数列表中的 .. 匹配任意数量的参数后置通知后置通知是在连接点完成之后执行的, 即连接点返回结果或者抛出异常的时候, 下面的后置通知记录了方法的终止.一个切面可以包括一个或者多个通知.1234567//后置通知：在目标方法执行后（无论是否发生异常），执行的通知 //在后置通知中还不能访问目标方法执行的结果 @After(\"execution(* com.spring.aop.impl.*.*(..))\") public void afterMethod(JoinPoint joinPoint)&#123; String MethodName = joinPoint.getSignature().getName(); System.out.println(\"The method \"+ MethodName+\" ends\"); &#125;返回通知无论连接点是正常返回还是抛出异常, 后置通知都会执行. 如果只想在连接点返回的时候记录日志, 应使用返回通知代替后置通知.1234567/** * 在方法正常结束受执行的代码 * */ @AfterReturning(\"execution(* com.spring.aop.impl.*.*(..))\") public void afterRunningMethod()&#123; System.out.println(\"afterRunning... \"); &#125;在返回通知中访问连接点的返回值在返回通知中, 只要将 returning 属性添加到 @AfterReturning 注解中, 就可以访问连接点的返回值. 该属性的值即为用来传入返回值的参数名称.必须在通知方法的签名中添加一个同名参数. 在运行时, Spring AOP 会通过这个参数传递返回值.原始的切点表达式需要出现在 pointcut 属性中123456789/** * 在方法正常结束受执行的代码 * 返回通知时可以访问到方法的返回值的！ * */ @AfterReturning(pointcut = \"execution(* com.spring.aop.impl.*.*(..))\", returning = \"result\") public void afterRunningMethod(Object result)&#123; System.out.println(\"afterRunning: \" + result); &#125;异常通知只在连接点抛出异常时才执行异常通知将 throwing 属性添加到 @AfterThrowing 注解中, 也可以访问连接点抛出的异常. Throwable 是所有错误和异常类的超类. 所以在异常通知方法可以捕获到任何错误和异常.如果只对某种特殊的异常类型感兴趣, 可以将参数声明为其他异常的参数类型. 然后通知就只在抛出这个类型及其子类的异常时才被执行.123456789/** * 在目标方法出现异常时会执行的代码 * 可以访问到异常对象；且可以指定在出现特定异常时执行通知代码qwx * */ @AfterThrowing(value = \"execution(* com.spring.aop.impl.*.*(..))\", throwing = \"ex\") public void AfterThrowingMethod(Exception ex)&#123; System.out.println(\"AfterThrowing:\"+ex); &#125;环绕通知环绕通知是所有通知类型中功能最为强大的, 能够全面地控制连接点. 甚至可以控制是否执行连接点.对于环绕通知来说, 连接点的参数类型必须是 ProceedingJoinPoint . 它是 JoinPoint 的子接口, 允许控制何时执行, 是否执行连接点.在环绕通知中需要明确调用 ProceedingJoinPoint 的 proceed() 方法来执行被代理的方法. 如果忘记这样做就会导致通知被执行了, 但目标方法没有被执行.注意: 环绕通知的方法需要返回目标方法执行之后的结果, 即调用 joinPoint.proceed(); 的返回值, 否则会出现空指针异常环绕通知示例代码123456789101112131415161718@Around(\"execution(* com.spring.aop.impl.*.*(..))\") public Object aroundMethod(ProceedingJoinPoint pjd)&#123; Object result = null; String methodName = pjd.getSignature().getName(); try &#123; //执行目标方法 //前置通知 System.out.println(\"The method \" + methodName + \" before with \" + Arrays.asList(pjd.getArgs())); result = pjd.proceed(); //后置通知 System.out.println(\"The method \" + methodName + \" after with\"); &#125; catch (Throwable throwable) &#123; //异常通知 System.out.println(\"The method \"+methodName+\"occurs exception:\"+ throwable); &#125; return result; &#125;指定切面的优先级在同一个连接点上应用不止一个切面时, 除非明确指定, 否则它们的优先级是不确定的.切面的优先级可以通过实现 Ordered 接口或利用 @Order 注解指定.实现 Ordered 接口, getOrder() 方法的返回值越小, 优先级越高.若使用 @Order 注解, 序号出现在注解中12345678910111213/** * 可以使用@Order注解指定切面的优先级，值越小优先级越高 * */@Order(1)@Aspect@Componentpublic class VlidationAspect &#123; @Before(\"execution(* com.spring.aop.impl.*.*(..))\") public void validateArgs(JoinPoint joinPoint)&#123; System.out.println(\"validate:\" + Arrays.asList(joinPoint.getArgs())); &#125;&#125;重用切入点定义在编写 AspectJ 切面时, 可以直接在通知注解中书写切入点表达式. 但同一个切点表达式可能会在多个通知中重复出现.在 AspectJ 切面中, 可以通过 @Pointcut 注解将一个切入点声明成 简单的方法. 切入点的方法体通常是空的, 因为将切入点定义与应用程序逻辑混在一起是不合理的.切入点方法的访问控制符同时也控制着这个切入点的可见性. 如果切入点要在多个切面中共用, 最好将它们集中在一个公共的类中. 在这种情况下, 它们必须被声明为 public. 在引入这个切入点时, 必须将类名也包括在内. 如果类没有与这个切面放在同一个包中, 还必须包含包名.其他通知可以通过方法名称引入该切入点.重用切入点示例代码123456789101112131415161718192021222324252627282930313233343536373839404142/** * 定义一个方法，用于声明切入点表达式，一般地，该方法中再也不需要添入其他的代码 * */ @Pointcut(\"execution(* com.spring.aop.impl.*.*(..))\") public void declareJointPointExpression()&#123;&#125; //声明该方法时一个前置通知: 在目标方法开始之前执行 @Before(\"declareJointPointExpression()\") public void beforeMethod(JoinPoint joinPoint) &#123; String MethodName = joinPoint.getSignature().getName(); List&lt;Object&gt; args = Arrays.asList(joinPoint.getArgs()); System.out.println(\"The method \"+MethodName+\" begins with \" + args); &#125; //后置通知：在目标方法执行后（无论是否发生异常），执行的通知 //在后置通知中还不能访问目标方法执行的结果 @After(\"declareJointPointExpression()\") public void afterMethod(JoinPoint joinPoint)&#123; String MethodName = joinPoint.getSignature().getName(); System.out.println(\"The method \"+ MethodName+\" ends\"); &#125; /** * 在目标方法出现异常时会执行的代码 * 可以访问到异常对象；且可以指定在出现特定异常时执行通知代码qwx * */ @AfterThrowing(value = \"declareJointPointExpression()\", throwing = \"ex\") public void AfterThrowingMethod(Exception ex)&#123; System.out.println(\"AfterThrowing:\"+ex); &#125; /** * 在方法正常结束受执行的代码 * 返回通知时可以访问到方法的返回值的！ * */ @AfterReturning(value = \"declareJointPointExpression()\", returning = \"result\") public void afterRunningMethod(Object result)&#123; System.out.println(\"afterRunning: \" + result); &#125;用基于XML的配置声明切面除了使用 AspectJ 注解声明切面, Spring 也支持在 Bean 配置文件中声明切面. 这种声明是通过 aop schema 中的 XML 元素完成的.正常情况下, 基于注解的声明要优先于基于 XML 的声明. 通过 AspectJ 注解, 切面可以与 AspectJ 兼容, 而基于 XML 的配置则是 Spring 专有的. 由于 AspectJ 得到越来越多的 AOP 框架支持, 所以以注解风格编写的切面将会有更多重用的机会.基于XML —- 声明切面当使用 XML 声明切面时, 需要在 &lt;beans&gt; 根元素中导入 aop Schema在 Bean 配置文件中, 所有的 Spring AOP 配置都必须定义在 &lt;aop:config&gt; 元素内部. 对于每个切面而言, 都要创建一个 &lt;aop:aspect&gt; 元素来为具体的切面实现引用后端 Bean 实例.切面 Bean 必须有一个标示符, 供 &lt;aop:aspect&gt; 元素引用声明切面的实例代码1234567&lt;!-- 配置切面的bean --&gt; &lt;bean id=\"calculatorvalidationAspect\" class=\"com.spring.aop.xml.VlidationAspect\"&gt;&lt;/bean&gt; &lt;!-- 配置AOP --&gt; &lt;aop:config&gt; &lt;aop:aspect id = \"validationAspect\" ref=\"calculatorvalidationAspect\"&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;基于 XML —- 声明切入点切入点使用 &lt;aop:pointcut&gt; 元素声明切入点必须定义在 &lt;aop:aspect&gt; 元素下, 或者直接定义在 &lt;aop:config&gt; 元素下.定义在 &lt;aop:aspect&gt; 元素下: 只对当前切面有效定义在 &lt;aop:config&gt; 元素下: 对所有切面都有效基于 XML 的 AOP 配置不允许在切入点表达式中用名称引用其他切入点.声明切入点的示例代码12345678910111213141516171819202122&lt;!-- 定义bean --&gt;&lt;bean id=\"arithmeticCalculator\" class=\"com.spring.aop.xml.ArithmeticCalculatorImpl\"&gt;&lt;/bean&gt;&lt;!-- 配置切面的bean --&gt;&lt;bean id=\"loggingAspect\" class=\"com.spring.aop.xml.LoggingAspect\"&gt;&lt;/bean&gt;&lt;bean id=\"validationAspect\" class=\"com.spring.aop.xml.VlidationAspect\"&gt;&lt;/bean&gt;&lt;!-- 配置AOP --&gt;&lt;aop:config&gt;&lt;!-- 配置切点表达式 --&gt; &lt;aop:pointcut expression=\"execution(* com.spring.aop.xml.*.*(..))\" id=\"pointcut\" /&gt; &lt;!-- 配置切面及通知 --&gt; &lt;aop:aspect ref=\"loggingAspect\" order=\"2\"&gt; &lt;aop:before method=\"beforeMethod\" pointcut-ref=\"pointcut\"/&gt; &lt;aop:after method=\"afterMethod\" pointcut-ref=\"pointcut\"/&gt; &lt;aop:after-returning method=\"afterRunningMethod\" pointcut-ref=\"pointcut\" returning=\"result\"/&gt; &lt;aop:after-throwing method=\"AfterThrowingMethod\" pointcut-ref=\"pointcut\" throwing=\"ex\" /&gt; &lt;/aop:aspect&gt; &lt;aop:aspect ref=\"validationAspect\" order=\"1\"&gt; &lt;aop:before method=\"validateArgs\" pointcut-ref=\"pointcut\" &gt;&lt;/aop:before&gt; &lt;/aop:aspect&gt;&lt;/aop:config&gt;","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"},{"name":"AOP&DI","slug":"AOP-DI","permalink":"https://me.obey.fun/tags/AOP-DI/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"通过工厂方法配置Bean","slug":"通过工厂方法配置Bean","date":"2019-03-13T14:11:03.000Z","updated":"2019-03-14T03:12:13.742Z","comments":true,"path":"通过工厂方法配置Bean.html","link":"","permalink":"https://me.obey.fun/通过工厂方法配置Bean.html","excerpt":"","text":"通过调用静态工厂方法创建Bean调用静态工厂方法创建Bean是将对象创建的过程封装到静态方法中。当客户端需要对象时，只需要简单地调用静态方法，而不用关心创建对象的细节。要声明通过静态方法创建的Bean。需要在Bean的class属性里指定拥有该工厂的方法的类，同时在factory-method属性里指定工厂方法的名称，最后，使用&lt;constrctor-arg&gt;元素为该方法传递参数。Car.java1234567891011121314151617181920212223242526272829303132333435363738package com.spring;public class Car &#123; private String brand; private double price; public String getBrand() &#123; return brand; &#125; public void setBrand(String brand) &#123; this.brand = brand; &#125; public double getPrice() &#123; return price; &#125; public void setPrice(double price) &#123; this.price = price; &#125; public Car(String brand, double price) &#123; this.brand = brand; this.price = price; &#125; public Car() &#123; &#125; @Override public String toString() &#123; return \"Car&#123;\" + \"brand='\" + brand + '\\'' + \", price=\" + price + '&#125;'; &#125;&#125;beans-factory.xml1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd&quot;&gt; &lt;!-- 通过静态工厂方法来配置bean，注意不是配置静态工厂方法实例，而是配置bean实例 --&gt; &lt;!-- class 属性： 指向静态工厂方法的全类名 factory-method: 指向静态工厂方法的名字 constructor-arg: 如果工厂方法需要传入参数，则使用constructor-arg 来配置参数 --&gt; &lt;bean id=&quot;car1&quot; class=&quot;com.spring.StaticCarFactory&quot; factory-method=&quot;getCar&quot;&gt; &lt;constructor-arg value=&quot;audi&quot; /&gt; &lt;/bean&gt;&lt;/beans&gt;MainTest.java12345678910111213package com.test;import com.spring.Car;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainTest &#123; public static void main(String[] args)&#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"beans-factory.xml\"); Car car = (Car)applicationContext.getBean(\"car1\"); System.out.println(car); &#125;&#125;运行结果：Car{brand=&#39;audi&#39;, price=300000.0}通过调用实例工厂方法创建Bean实例工厂方法：将对象的创建过程封装到另一个对象实例的方法里。当客户端需要请求对象时，值需要简单的调用该实例方法而不需要关心对象的创建细节。要声明通过实例工厂方法创建的Bean在bean的factory-bean属性里指定拥有该工厂方法的Bean在factory-method属性里指定该工厂方法的名称使用construtor-arg元素为工厂方法传递方法参数Car.java1234567891011121314151617181920212223242526272829303132333435363738package com.spring;public class Car &#123; private String brand; private double price; public String getBrand() &#123; return brand; &#125; public void setBrand(String brand) &#123; this.brand = brand; &#125; public double getPrice() &#123; return price; &#125; public void setPrice(double price) &#123; this.price = price; &#125; public Car(String brand, double price) &#123; this.brand = brand; this.price = price; &#125; public Car() &#123; &#125; @Override public String toString() &#123; return \"Car&#123;\" + \"brand='\" + brand + '\\'' + \", price=\" + price + '&#125;'; &#125;&#125;InstanceCarFactory.java1234567891011121314151617181920package com.spring;import java.util.HashMap;import java.util.Map;/** * 实例工厂方法：实例工厂的方法，即现需要创建工厂本身，再调用工厂的实例方法来返回bean的实例 * */public class InstanceCarFactory &#123; private Map&lt;String,Car&gt; cars = null; public InstanceCarFactory() &#123; cars = new HashMap&lt;String, Car&gt;(); cars.put(\"audi\",new Car(\"audi\",300000)); cars.put(\"ford\",new Car(\"ford\",400000)); &#125; public Car getCar(String brand)&#123; return cars.get(brand); &#125;&#125;MainTest.java12345678910111213package com.test;import com.spring.Car;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainTest &#123; public static void main(String[] args)&#123; ApplicationContext applicationContext = new ClassPathXmlApplicationContext(\"beans-factory.xml\"); Car car = (Car)applicationContext.getBean(\"car2\"); System.out.println(car); &#125;&#125;测试结果：Car{brand=&#39;ford&#39;, price=400000.0}","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Spring注解开发","slug":"Spring注解开发","date":"2019-03-13T12:39:33.000Z","updated":"2019-03-13T13:03:11.929Z","comments":true,"path":"Spring注解开发.html","link":"","permalink":"https://me.obey.fun/Spring注解开发.html","excerpt":"","text":"JavaConfig从Spring 3起，JavaConfig功能已经包含在Spring核心模块，它允许开发者将bean定义和在Spring配置XML文件到Java类中。但是，仍然允许使用经典的XML方式来定义bean和配置，JavaConfig是另一种替代解决方案。所以，在Spring3以后的版本中，支持xml方式和javaConfig两种Spring配置方式。建议：Spring项目用全注解开发，为后期学Spring Boot和Spring Cloud打好基础。通过XML配置Person.java1234567891011121314151617181920212223242526272829303132333435363738package com.spring;public class Person &#123; private String name; private String age; public Person(String name, String age) &#123; this.name = name; this.age = age; &#125; public Person() &#123; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getAge() &#123; return age; &#125; public void setAge(String age) &#123; this.age = age; &#125; @Override public String toString() &#123; return \"Person&#123;\" + \"name='\" + name + '\\'' + \", age='\" + age + '\\'' + '&#125;'; &#125;&#125;bean.xml1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 配置bean class：bean的全类名，通过反射的方式在IOC容器中创建Bean，所以要求Bean中必须有无参数的构造器 id:标识容器中的bean。id唯一 --&gt; &lt;bean id=\"person\" class=\"com.Spring.Person\"&gt; &lt;property name=\"name\" value=\"HuiProgramer\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"21\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt;Maintest.java123456789101112131415161718package com.Spring;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class MainTest &#123; public static void main(String[] args)&#123; //1.创建Spring 的IOC容器对象 //ApplicationContext 代表IOC容器 //ClassPathXmlApplicationContext：是ApplicationContext 接口的实现类 ApplicationContext act = new ClassPathXmlApplicationContext(\"bean.xml\"); //2.从IOC容器中获取Bean实例 Person person = (Person)act.getBean(\"person\"); //3.调用toString()方法并打印 System.out.println(person.toString()); &#125;&#125;&#125;结果：Person{name=&#39;HuiProgramer&#39;, age=&#39;21&#39;}以上为Xml配置的方式，Spring3.0后启用注解开发模式。使用注解模式Person.java1234567891011121314151617181920212223242526272829303132333435363738package com.spring;public class Person &#123; private String name; private String age; public Person(String name, String age) &#123; this.name = name; this.age = age; &#125; public Person() &#123; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getAge() &#123; return age; &#125; public void setAge(String age) &#123; this.age = age; &#125; @Override public String toString() &#123; return \"Person&#123;\" + \"name='\" + name + '\\'' + \", age='\" + age + '\\'' + '&#125;'; &#125;&#125;AppConfig.java123456789101112131415161718package com.spring;import org.springframework.context.ApplicationContext;import org.springframework.context.annotation.AnnotationConfigApplicationContext;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;//相当于beans@Configurationpublic class AppConfig &#123; public AppConfig()&#123; &#125; //相当于bean，默认方法名为Bean的id @Bean public Person person()&#123; return new Person(\"HuiPerson\",\"21\"); &#125;&#125;MainTest.Java123456789101112131415public class Maintest&#123; public static void main(String[] args)&#123; //通过注解获取ApplicationContext ApplicationContext context = new AnnotationConfigApplicationContext(AppConfig.class); //通过类获取Person的bean实例 Person person = context.getBean(Person.class); //打印person System.out.println(person); //通过类型获取所有Bean的person bean实例 String[] names = context.getBeanNamesForType(Person.class); //打印 for(String name:names) System.out.println(name); &#125;&#125;结果：Person{name=&#39;HuiProgramer&#39;, age=&#39;21&#39;}person此为Spring3.0后的注解开发模式！","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"},{"name":"Spring注解开发","slug":"Spring注解开发","permalink":"https://me.obey.fun/tags/Spring注解开发/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"管理Bean的生命周期","slug":"管理Bean的生命周期","date":"2019-03-09T07:46:44.000Z","updated":"2019-05-04T13:38:43.937Z","comments":true,"path":"管理Bean的生命周期.html","link":"","permalink":"https://me.obey.fun/管理Bean的生命周期.html","excerpt":"","text":"IOC容器中Bean的生命周期方法SpringIOC容器可以管理Bean的生命周期，Spring允许在Bean生命周期的特定点执行定制的任务。Spring IOC容器对Bean的生命周期进行管理的过程通过构造器或工厂方法创建Bean为Bean的属性设置值和对其他Bean的引用调用Bean的初始化方法Bean可以使用了当容器关闭时，调用Bean的销毁方法在Bean的声明里设置init-method和destroy-method属性。为Bean指定初始化和销毁方法。Car.java1234567891011121314151617181920public class Car&#123; public Car()&#123; System.out.println(\"Car's Constructor...\"); &#125; private String brand; public void setBrand(String brand)&#123; System.out.println(\"setBrand...\"); this.brand = brand; &#125; public void init()&#123; System.out.println(\"init...\"); &#125; public void destroy()&#123; System.out.println(\"destroy...\"); &#125;&#125;Bean.XML1234&lt;bean id = \"car\" class = \"com.Spring.test.Car\" init-method = \"init\" destroy-method = \"destroy\"&gt; &lt;property name = \"Brand\" value = \"Audi\" /&gt;&lt;/bean&gt;Main.XML1234567891011public class Main&#123; public static void main(String[] args)&#123; ClassPathXmlApplicationContext ctx = new ClassPathXmlApplicationContext(\"Bean.xml\"); Car car = (Car)ctx.getBean(\"car\"); System.out.println(car); //关闭IOC容器 ctx.close(); &#125;&#125;输出结果：Car&#39;s Constructor...setBrandinit...com.Spring.test.Car@bb23423destory..创建Bean后置处理器Bean后置处理器允许在调用初始化方法前后对Bean进行额外的处理Bean后置处理器对IOC容器里的所有Bean实例逐一处理，而非单一实例，其典型应用是：检查Bean属性的正确性或根据特定的标准更改Bean的属性对Bean后置处理器而言，需要实现Interface BeanPostProcessor接口，在初始化方法被调用前后。Spring将把每个Bean实例分别传递给上述接口的以下两个方法：添加Bean后置处理器后Bean的生命周期SpringIOC容器对Bean的生命周期进行管理的过程：通过构造器或工厂方法创建Bean实例为Bean的属性设置值和对其他Bean的引用将Bean实例传递给Bean后置处理器的postProcessBeforeInitialization方法调用Bean的初始化方法将Bean实例传递给Bean后置处理器的postProcessBeforeInitialization方法Bean可以使用了当容器关闭时，调用Bean的销毁方法具体操作：MyBeanPostProcessor.java123456789101112public class myBeanPostProcessor implements BeanPostProcessor&#123; @override public Object postProcessBeforeInitialization(Object bean,String beanName) throws BensException&#123; System.out.println(\"postProcessBeforeInitialization:\" + bean + \" \" + beanName); return bean; &#125; @override public Object postProcessAfterInitialization(Object bean,String beanName) throws BensException&#123; System.out.println(\"postProcessAfterInitialization:\" + bean + \" \" + beanName); return bean; &#125;&#125;Bean.XML123456789101112131415&lt;bean id = \"car\" class = \"com.Spring.test.Car\" init-method = \"init\" destroy-method = \"destroy\"&gt; &lt;property name = \"Brand\" value = \"Audi\" /&gt;&lt;/bean&gt;&lt;!-- 实现BeanPostProcessor接口，并具体提供Object postProcessBeforeInitialization(Object bean,String beanName)：init-method之前被调用 实现BeanPostProcessor接口，并具体提供Object postProcessAfterInitialization(Object bean,String beanName)：init-method之后被调用 bean: bean实例本身 beanName: IOC容器配置的bean的名字 返回值： 是实际上返回给用户的哪个Bean，注意：可以在以上两个方法中修改返回的bean，甚至返回一个新的bean --&gt;&lt;!-- 配置bean的后置处理器：不需要配置id，IOC容器自动识别是一个BenaPostProcessor --&gt;&lt;bean class = \"com.Spring.test.MyBeanPostProcessor\"&gt;&lt;/bean&gt;输出结果：Car&#39;s Constructor...setBrandpostProcessBeforeInitialization:com.Spring.test.Car@bb23423 carinit...postProcessBeforeInitialization:com.Spring.test.Car@bb23423 carcom.Spring.test.Car@bb23423destory..添加Bean后置处理器后Bean的生命周期SpringIOC容器对Bean的生命周期进行管理的过程：通过构造器或工厂方法创建Bean实例为Bean的属性设置值和对其他Bean的引用将Bean实例传递给Bean后置处理器的postProcessBeforeInitialization方法调用Bean的初始化方法将Bean实例传递给Bean后置处理器的postProcessBeforeInitialization方法Bean可以使用了当容器关闭时，调用Bean的销毁方法","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Spring表达式语言(SpEL)","slug":"Spring表达式语言-SpEL","date":"2019-03-08T13:48:44.000Z","updated":"2019-03-08T15:17:35.999Z","comments":true,"path":"Spring表达式语言-SpEL.html","link":"","permalink":"https://me.obey.fun/Spring表达式语言-SpEL.html","excerpt":"","text":"Spring表达式语言：SpELSpring表达式语言（简称SpEL）:是一个支持运行时查询和操作对象图的强大的表达式语言语法类似于EL：SpEL使用#{…}作为定界符，所有在大框号中的字符都被认为是SpELSpEL为bean的属性进行动态赋值提供了便利通过SpEL可以实现：通过bean的id对bean进行引用调用方法以及引用对象中的属性正则表达式的值正则表达式的配置SpEL：字面值整数：&lt;property name = “count” value = “#{5}“/&gt;小数：&lt;property name = “frequency” value = “#{89.7}“/&gt;科学记数法：&lt;property name = “capacity” value = “#{1e4}“/&gt;String可以使用单引号或者双引号作为字符串的定界符号：&lt;property name = “name” value = “#{Chuck}“/&gt;或&lt;property name = ‘name’ value = ‘#{Chuck}‘/&gt;Boolean：&lt;property name = “enabled” value = “#{false}“/&gt;SpEL：引用Bean、属性和方法引用其他对象：12&lt;!-- 通过value属性和 SpEL 配置 Bean 之间的应用关系 --&gt;&lt;property name = \"prefix\" value = \"#&#123;prefixGenerator&#125;\"&gt;&lt;/property&gt;引用其他对象的属性12&lt;!-- 通过value属性和 SpEL 配置 suffix 配置值为另一个bean的suffix属性值 --&gt;&lt;property name = \"suffix\" value = \"#&#123;sequenceGenerator2.suffix&#125;\"&gt;&lt;/property&gt;调用其他方法，还可以链式操作1234&lt;!-- 过value属性和 SpEL 配置 suffix 配置值为另一个bean的返回值 --&gt;&lt;property name = \"suffix\" value = \"#&#123;sequenceGenerator2.toString()&#125;\"&gt;&lt;/property&gt;&lt;!-- 方法的连缀 --&gt;&lt;property name = \"suffix\" value = \"#&#123;sequenceGenerator2.toString().toUpperCase()&#125;\"&gt;&lt;/property&gt;SpEL支持的运算符号算数运算符：+,-,*,%,^:12345&lt;property name = \"adjustedAmount\" value = \"#&#123;counter.total + 43&#125;\" /&gt;&lt;property name = \"adjustedAmount\" value = \"#&#123;counter.total - 13&#125;\" /&gt;&lt;property name = \"circumference\" value = \"#&#123;2* T(java.lang.Math).PI * circle.radius&#125;\" /&gt;&lt;property name = \"average\" value = \"#&#123;counter.total / counter.total&#125;\" /&gt;&lt;property name = \"area\" value = \"#&#123;T(java.lang.Math).PI * circle.radius * 2&#125;\" /&gt;加号还可以用作字符串连接：1&lt;constructor-arg value = \"performer.firstName + ' ' + performer.LastName\" /&gt;比较运算符：&amp;lt,&amp;gt,==,&lt;=,&gt;=,lt,gt,eq,le,ge12&lt;property name=\"equal\" value = \"#&#123;counter.total == 100&#125;\" /&gt;&lt;property name=\"hasCapacity\" value = \"#&#123;counter.total le 100000&#125;\" /&gt;逻辑运算符号：and，or，not，|123&lt;property name=\"largeCircle\" value = \"#&#123;shape.kind == 'circle' and shape.perimeter gt 10000&#125;\" /&gt;&lt;property name=\"outOfStock\" value = \"#&#123;product.available&#125;\" /&gt;&lt;property name=\"outofStock\" value = \"#&#123;not product.available&#125;\" /&gt;if-else运算符：?:(temary),?:(Elvis)1&lt;constructor-arg value = \"#&#123;songSelector.seLectSong()=='Jingle BeLLs'?piano:'Jingle Bells'&#125;\"/&gt;if-else的字体1&lt;constructor-arg value = \"#&#123;kenny.song?:'Greensleeves'&#125;\"/&gt;正则表达式:matches1&lt;constructor-arg value = \"#&#123;admin.email matches '[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]&#123;2，4&#125;'&#125;\"/&gt;调用静态方法或静态方法:通过T()调用一个类的静态方法，它将返回一个ClassObject，然后再调用相应的方法或者属性：1&lt;property name=\"initValue\" value = \"#&#123;T(java.Lang.Math).PI&#125;\" /&gt;","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Bean使用外部属性","slug":"Bean使用外部属性","date":"2019-03-07T14:10:21.000Z","updated":"2019-03-07T14:38:09.790Z","comments":true,"path":"Bean使用外部属性.html","link":"","permalink":"https://me.obey.fun/Bean使用外部属性.html","excerpt":"","text":"使用外部属性在配置文件里配置Bean时，有时需要在Bean的配置里混入系统部署的细节信息（例如：文件路径，数据源配置信息等）。而这些部署细节实际上需要和Bean部署相分离Spring提供一个PropertyPlaceholderConfigurer的BeanFactory后置处理器，这个处理器允许用户将Bean配置的部分内容外移到属性文件中，可以在Bean配置文件里使用形式为${var}的变量，PropertyPlaceholderConfigurer从属性文件里加载属性，并使用这些属性来替换变量。Spring还允许在属性文件中使用${propName},以实现属性之间的相互引用。注册PropertyPlaceholderConfigurerspring2.0：123&lt;bean class = \"org.springframework.beans.factory.config.PropertyPlaceholderConfigurer\"&gt; &lt;property name = \"Location\" value = \"classpath:jdbc.properties\"&gt;&lt;/property&gt;&lt;/bean&gt;Spring2.5之后：可通过&lt;context:property-placeholder&gt;元素简化：&lt;beans&gt;中添加context Schema定义在配置文件中加入如下配置：1&lt;context:property-placeholder location= \"classpath:db.properties\"/&gt;db.properties1234user=rootpassword=1230driverClass=com.mysql.jdbc.DriverjdbcUrl=jdbc:mysql:///testbean.xml12345678910&lt;!-- 导入属性文件 --&gt;&lt;context:property-placeholder location= \"classpath:db.properties\"/&gt;&lt;!-- 使用外部化属性文件的属性 --&gt;&lt;bean id = \"dataSource\" class = \"com.mchange.v2.c3p0.ComboPoolLedDataSource\"&gt; &lt;property name = \"user\" value = \"$&#123;user&#125;\"&gt;&lt;/property&gt; &lt;property name = \"password\" value = \"$&#123;password&#125;\"&gt;&lt;/property&gt; &lt;property name = \"driverClass\" value = \"$&#123;driverClass&#125;\"&gt;&lt;/property&gt; &lt;property name = \"jdbcUrl\" value = \"$&#123;jdbcUrl\"&gt;&lt;/property&gt;&lt;/bean&gt;输出结果：连接成功","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Bean的作用域","slug":"Bean的作用域","date":"2019-03-07T13:47:59.000Z","updated":"2019-03-07T14:56:02.711Z","comments":true,"path":"Bean的作用域.html","link":"","permalink":"https://me.obey.fun/Bean的作用域.html","excerpt":"","text":"Bean的作用域：singleton；prototype；WEB环境作用域配置作用域singletonbean.xml1234&lt;!-- 默认作用域是singleton（单例），通过scope配置 。 容器初始化时创建bean实例。在整个容器的生命周期内置创建这一个bean。--&gt;&lt;bean id = \"car\" class = \"com.spring.helloWorld.Car\"p:brand = \"Audi\" p:price = \"300000\" scope=\"singleton\"&gt;&lt;/bean&gt;Main.java123456public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"bean.xml\"); Car car = (Car)ctx.getBean(\"car\"); Car car2 = (Car)ctx.getBean(\"car\"); System.out.println(car == car2);&#125;输出结果：true配置作用域prototypebean.xml1234&lt;!-- 此作用域是prototype（不是单例），通过scope配置。 prototype：原型的，容器初始化时不创建bean的实例，而在每次请求时都创建一个新的Bean实例，并返回。--&gt;&lt;bean id = \"car\" class = \"com.spring.helloWorld.Car\"p:brand = \"Audi\" p:price = \"300000\" scope=\"prototype\"&gt;&lt;/bean&gt;Main.java123456public static void main(String[] args)&#123; ApplicationContext ctx = new ClassPathXmlApplicationContext(\"bean.xml\"); Car car = (Car)ctx.getBean(\"car\"); Car car2 = (Car)ctx.getBean(\"car\"); System.out.println(car == car2);&#125;输出结果：false","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Bean之间的关系","slug":"Bean之间的关系","date":"2019-03-06T12:18:58.000Z","updated":"2019-03-07T14:38:37.123Z","comments":true,"path":"Bean之间的关系.html","link":"","permalink":"https://me.obey.fun/Bean之间的关系.html","excerpt":"","text":"Bean之间的关系：继承；依赖Bean配置的继承Spring允许继承bean的配置，被继承的bean成为父bean。继承这个父Bean的Bean称为子Bean子Bean从父Bean中继承配置，包括Bean的属性配置子Bean也可以覆盖从父Bean继承过来的配置父Bean可以作为配置模板，也可以作为Bean的实例。若只想把父Bean作为模板，可以设置&lt;bean&gt;的abstract属性为true，这样Spring将不会实例化这个Bean并不是&lt;bean&gt;元素里的所有属性都会被继承。比如：autowire，abstract等。也可以忽略父Bean的class属性，让子Bean指定自己的类，而共享相同的属性配置，但此时abstract必须设为true继承父Bean实例：123456&lt;bean id = \"address\" class = \"com.spring.helloWorld.Address\" p:city = \"Beijing\" p:street=\"WuDaoKou\"&gt;&lt;/bean&gt;&lt;!-- bean 配置的继承：使用 bean 的 parent 属性指定继承哪个 bean 的配置 --&gt;&lt;bean id = \"address2\" class = \"com.spring.helloWorld.Address\" p:street=\"DaZhongSi\" parent = \"address\"&gt;&lt;/bean&gt;输出结果：Address [city=BeiJing,street=WuDaoKou]Address [city=BeiJing,street=DaZhongSi]抽象Bean实例：12345678&lt;!-- 抽象Bean：bean的abstract属性为true的bean，不能被IOC容器实例化，可以作为模板被继承。若某一个bean的class属性没有指定，则该bean必须是一个抽象bean。 --&gt;&lt;bean id = \"address\" p:city = \"Beijing\" p:street=\"WuDaoKou\" abstract = \"true\"&gt;&lt;/bean&gt;&lt;!-- 继承模板Bean --&gt;&lt;bean id = \"address2\" class = \"com.spring.helloWorld.Address\" parent = \"address\"&gt;&lt;/bean&gt;输出结果：Address [city=BeiJing,street=WuDaoKou]Address [city=BeiJing,street=WuDaoKou]依赖Bean配置Spring允许用户通过depends-on属性设定Bean前置依赖的Bean，前置依赖的Bean会在本Bean实例化之前创建好如果前置依赖于多个Bean，则可以通过逗号，空格的方式配置Bean的名称依赖Bean实例：1234567&lt;!-- 缺少这个bean会报错 --&gt;&lt;bean id = \"car\" class = \"com.spring.helloWorld.Car\"p:brand = \"Audi\" p:price = \"300000\" &gt;&lt;/bean&gt;&lt;!-- 要求配置Person时，必须有一个关联的car！换句话说person这个bean依赖于Car这个bean，如果缺少就会报错 --&gt;&lt;bean id = \"person\" class = \"com.spring.helloWorld.person\"p:name = \"Tom\" p:address-ref=\"address2\" depends-on=\"car\"&gt;&lt;/bean&gt;","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Spring自动装配","slug":"Spring自动装配","date":"2019-03-05T01:15:20.000Z","updated":"2019-03-05T13:03:30.575Z","comments":true,"path":"Spring自动装配.html","link":"","permalink":"https://me.obey.fun/Spring自动装配.html","excerpt":"","text":"XML配置里的Bean自动装配Spring IOC容器可以自动装配Bean。需要做的仅仅是在&lt;bean&gt;的autowire属性里指定自动装配的模式byType(根据类型自动装配)：若IOC容器中有多个与目标Bean类型一致的Bean。在这种情况下，Spring将无法判定哪个Bean最适合属性，所以不能执行自动装配。byName(根据名称自动装配)：必须将目标Bean的名称和属性名设置完全相同。constructor（通过构造器自动装配）：当Bean中存在多个构造器时，此种自动装配方式将会很复杂。不推荐使用自动装配byName实例：123456789&lt;!-- 通过p命名空间为bean的属性赋值，需要先导入 p 命名空间,相对于传统的配置更加的简洁 --&gt;&lt;bean id = \"address\" calss = \"com.spring.hellowrld.address\" p:city = \"Beijing\" p:street = \"HuiLongGuan\"&gt;&lt;/bean&gt;&lt;!-- 通过p命名空间为bean的属性赋值，需要先导入 p 命名空间,相对于传统的配置更加的简洁 --&gt;&lt;bean id = \"car\" calss = \"com.spring.hellowrld.Car\" p:brand = \"Audi\" p:price = \"30000\"&gt;&lt;/bean&gt;&lt;!-- 可以使用 autowire 属性指定自动装配的方式 byName 根据 bean 的名字和当前bean的 setter 风格的属性名进行自动装配，若有匹配的，则进行自动装配，若没有匹配的，则不装配 --&gt;&lt;bean id = \"Person\" calss = \"com.spring.hellowrld.person\" p:name = \"Tom\" autowire = \"byName\"&gt;&lt;/bean&gt;自动装配byType实例：12345678&lt;!-- 通过p命名空间为bean的属性赋值，需要先导入 p 命名空间,相对于传统的配置更加的简洁 --&gt;&lt;bean id = \"address2\" calss = \"com.spring.hellowrld.address\" p:city = \"Beijing\" p:street = \"HuiLongGuan\"&gt;&lt;/bean&gt;&lt;!-- 通过p命名空间为bean的属性赋值，需要先导入 p 命名空间,相对于传统的配置更加的简洁 --&gt;&lt;bean id = \"car2\" calss = \"com.spring.hellowrld.Car\" p:brand = \"Audi\" p:price = \"30000\"&gt;&lt;/bean&gt;&lt;!-- byType 根据 bean 的类型和当前 bean 的属性的类型进行自动装配，若IOC容器中有一个以上的类型匹配的bean，则抛异常。 --&gt;&lt;bean id = \"Person2\" calss = \"com.spring.hellowrld.person\" p:name = \"Rose\" autowire = \"byType\"&gt;&lt;/bean&gt;XML配置里的Bean自动装配的缺点在 Bean 配置文建立设置 autowire 属性进行自动装配将会装配 Bean 的所有属性。然而，若值希望装配个别属性时， autowire属性就不够灵活了。autowire 属性要么根据类型自动装配，要么根据名称自动装配，不能两者兼而有之。一般情况下，在实际项目中很少使用自动装配功能，因为和自动装配功能所带来的好处比起来，明确清晰的配置文档更有说服力一些。","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Hexo常见错误","slug":"Hexo常见错误","date":"2019-03-02T09:28:22.000Z","updated":"2019-05-04T09:57:51.017Z","comments":true,"path":"Hexo常见错误.html","link":"","permalink":"https://me.obey.fun/Hexo常见错误.html","excerpt":"","text":"启用腾讯云图床错误为了加快网站访问，本站启用了腾讯云图床，但就在生成文章时，出现了一系列问题。最终将问题定在md文件里。解决办法将平常用的md语法改写为&lt;img&gt;标签，并将在主题目录下的images文件夹里新产生的文件夹删除。1234&lt;!-- 出现错误的方式 --&gt;![Error](https://blog-1258364678.cos.ap-guangzhou.myqcloud.com/Hexo_error1.png \"Error\")&lt;!-- 正确的方式 --&gt;&lt;img src = \"https://blog-1258364678.cos.ap-guangzhou.myqcloud.com/Hexo_error1.pn\" title = \"Error\" alt =\"Error\"&gt;总结出现问题时，要多多分析可能存在的原因；只有找到源头时，才能解决问题。","categories":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"Node.js","slug":"前端/Node-js","permalink":"https://me.obey.fun/categories/前端/Node-js/"},{"name":"Hexo","slug":"前端/Node-js/Hexo","permalink":"https://me.obey.fun/categories/前端/Node-js/Hexo/"}],"tags":[{"name":"博客","slug":"博客","permalink":"https://me.obey.fun/tags/博客/"},{"name":"常见错误","slug":"常见错误","permalink":"https://me.obey.fun/tags/常见错误/"}],"keywords":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"Node.js","slug":"前端/Node-js","permalink":"https://me.obey.fun/categories/前端/Node-js/"},{"name":"Hexo","slug":"前端/Node-js/Hexo","permalink":"https://me.obey.fun/categories/前端/Node-js/Hexo/"}]},{"title":"Spring中Bean的配置","slug":"Spring中Bean的配置","date":"2019-03-02T02:40:41.000Z","updated":"2019-05-04T13:26:19.099Z","comments":true,"path":"Spring中Bean的配置.html","link":"","permalink":"https://me.obey.fun/Spring中Bean的配置.html","excerpt":"","text":"IOC&amp;DI概述配置Bean配置形式：基于XML文件的方式；基于注解的方式Bean的配置方式：通过全类名（反射）、通过工厂方法（静态工厂方法&amp;实例工厂方法）、FactoryBeanIOC容器BeanFactory&amp;ApplicationContext概述依赖注入的方式：属性注入；构造器注入注入属性值的细节自动装配bean之间的关系：继承；依赖bean的作用域：singleton；prototype；WEB环境作用域使用外部属性文件spELIOC容器中的Bean的生命周期Spring4.x新特性：泛型依赖注入IOC和DIIOC(Inversion of Control)：其思想是反转资源获取的方向。传统的资源查找方式要求组件向容器发起请求查找资源。作为回应，容器适时的返回资源。而应用了IOC之后，则是容器主动地将资源送给它所管理的组件，组件要做的仅仅是选择一种合适的方式来介绍资源。这种行为也被称为查找的被动形式DI(Dependency Injection)–IOC的另一种表述方式：即组件以一些预先定义好的方式（例如：setter方法）接受来自如容器的资源注入。相对于IOC而言，这种表述更直接IOC&amp;DI原理IOC前生 — 分离接口与实现需求：生成HTML或PDF格式的不同类型的报表IOC前生 — 采用工厂设计模式IOC — 采用反转控制Bean的配置方式在Spring的IOC容器里配置Bean在XML文件中通过bean节点来配置bean1234&lt;!-- 通过全类名的方式来配置bean --&gt;&lt;bean id = \"helloWorld\" class = \"com.spring.helloworld.HelloWorld\"&gt;&lt;/bean&gt;id:Bean的名称在IOC容器中必须是唯一若id没有指定，Spring自动将权限定性类名作为Bean的名字id可以指定多个名字，名字之间可用逗号、分号、或者空格分隔Spring容器在SpringIOC容器容器读取Bean配置创建Bean实例之前，必须对它进行实例化。只有在容器实例化后，才可以从IOC容器里获取Bean实例并使用。Spring提供了两种类型的IOC容器实现。BeanFactory:IOC容器的基本实现。ApplicationContext：提供了更多的高级特性。是BeanFactory的子接口。BeanFactory是Spring框架的基础设施，面向Spring本身；ApplicationContext面向使用Spring框架的开发者，几乎所有的应用场合都直接使用ApplicationContext而非底层的BeanFactory无论使用何种方式，配置文件时相同的。ApplicationContextApplicationContext的主要实现类：ClassPathXmlApplicationContext:从类路径下加载配置文件FileSystemXmlApplicationContext：从文件系统中加载配置文件ConfigurableApplicationContext扩展与ApplicationContext，新增两个主要方法：refresh()和close(),让ApplicationContext具有启动、刷新和关闭上下文的能力ApplicationContext在初始化上下文时就实例化所有单例的Bean。WebApplicationContext是专门为WEB应用而准备的，它允许从相对于WEB根目录的路径中完成初始化工作从IOC容器中获取BeanBeanFactoryFACTORY_BEAN_PREFIX:StringgetBean(String):ObjectgetBean(String,Class&lt;T&gt;)&lt;T&gt;:TgetBean(Class&lt;T&gt;)&lt;T&gt;:TgetBean(String,Object…):ObjectcontainsBean(String):booleanisSingleton(String):booleanisPrototype(String):booleanisTypeMatch(String,Class&lt;?&gt;):booleangetType(String):Class&lt;?&gt;getAliases(String):String[]具体实例12345678//1.创建Spring 的IOC容器对象 //ApplicationContext 代表IOC容器 //ClassPathXmlApplicationContext：是ApplicationContext 接口的实现类 ApplicationContext act = new ClassPathXmlApplicationContext(\"spring-config.xml\"); //2.从IOC容器中获取Bean实例 HelloWorld helloWorld = (HelloWorld)act.getBean(\"helloWorld\"); //3.调用hello方法 helloWorld.hello();属性注入属性注入即通过setter方法注入Bean的属性值或依赖的对象属性注入使用&lt;property&gt;元素，使用name属性指定Bean的属性名称，value属性或&lt;value&gt;子节点指定属性值属性注入是实际应用中最常见的注入方式123456&lt;!-- 通过全类名的方式来配置bean --&gt;&lt;bean id = \"helloWorld\" class = \"com.spring.helloworld.HelloWorld\"&gt; &lt;property name=\"name\" value=\"HuiProgramer\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"22\"&gt;&lt;/property&gt;&lt;/bean&gt;构造方法注入通过构造方法注入Bean的属性值或者依赖的对象，它保证了Bean实例在实例化后就可以使用构造器注入在&lt;constructor-arg&gt;元素里声明属性，&lt;constructor-arg&gt;中没有name属性按顺序配置123456&lt;!-- 通过构造方法来配置bean属性 --&gt;&lt;bean id = \"car\" class = \"com.spring.helloworld.Car\"&gt; &lt;constructor-arg value = \"Audi\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"ShangHai\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"30000\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;按index配置123456&lt;!-- 通过构造器注入属性值可以指定参数的位置 --&gt;&lt;bean id = \"car\" class = \"com.spring.helloworld.Car\"&gt; &lt;constructor-arg value = \"Audi\" index = \"0\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"30000\" index = \"2\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"ShangHai\" index = \"1\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;按type配置123456&lt;!-- 通过构造器注入属性值可以指定参数的类型 --&gt;&lt;bean id = \"car\" class = \"com.spring.helloworld.Car\"&gt; &lt;constructor-arg value = \"Audi\" type = \"java.lang.String\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"30000\" type = \"long\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"ShangHai\" type = \"java.lang.String\"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;提示: 通过构造器注入参数的类型和位置可以混合使用字面值字面值：可用字符串表示的值，可以通过&lt;value&gt;元素标签或value属性进行注入基本数据类型及其封装类，String等类型都可以采用字面值注入的方式若字面值中包含特殊字符，可用使用&lt;![CDATA[]]&gt;把字面值包裹起来实例：123456789&lt;!-- 通过构造器注入属性值可以指定参数的位置和类型 --&gt;&lt;bean id = \"car2\" class = \"com.spring.helloworld.Car\"&gt; &lt;constructor-arg value = \"Audi\" index = \"0\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"30000\" index = \"2\"&gt;&lt;/constructor-arg&gt; &lt;!-- 如果字面值包含特殊字符可以用&lt;![CDATA[ ]]&gt;包裹起来 --&gt; &lt;constructor-arg type = \"java.lang.String\"&gt; &lt;value&gt;&lt;![CDATA[&lt;ShangHai&gt;]]&gt;&lt;/value&gt; &lt;/constructor-arg&gt;&lt;/bean&gt;输出结果：&lt;ShangHai&gt;引用其它Bean组成应用程序的Bean经常需要相互协作以完成应用程序的功能，要使Bean能够相互访问，就必须在Bean配置文件中指定对Bean的引用在Bean的配置文件中，可用通过&lt;ref&gt;元素或ref属性为Bean的属性或构造器参数指定对Bean的引用也可以在属性或构造器里包含Bean的声明,这样的Bean称为内部Bean外部Bean实例：12345&lt;!-- 通过方法注入属性值 --&gt;&lt;bean id = \"person\" calss = \"com.spring.hellowrld.person\"&gt; &lt;property name=\"name\" value=\"HuiProgramer\"&gt;&lt;/property&gt; &lt;property name=\"Car\" ref = \"car\"&gt;&lt;/property&gt;&lt;/bean&gt;内部Bean实例：123456789101112&lt;!-- 通过方法注入属性值 --&gt;&lt;bean id = \"person\" calss = \"com.spring.hellowrld.person\"&gt; &lt;property name=\"name\" value=\"HuiProgramer\"&gt;&lt;/property&gt; &lt;property name=\"Car\"&gt; &lt;!-- 通过构造器注入属性值可以指定参数的类型 --&gt; &lt;bean id = \"car\" class = \"com.spring.helloworld.Car\"&gt; &lt;constructor-arg value = \"Audi\" type = \"java.lang.String\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"30000\" type = \"long\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"ShangHai\" type = \"java.lang.String\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/property&gt;&lt;/bean&gt;null值和级联属性可以使用专用的&lt;null/&gt;元素标签为Bean的字符串或其它对象类型的属性注入null值和Struts、Hiberante等框架一样，Spring支持级联属性的配置。null值注入实例:1234567&lt;!-- 通过构造方法来配置bean属性 --&gt;&lt;bean id = \"car3\" class = \"com.spring.helloworld.Car\"&gt; &lt;constructor-arg value = \"Audi\"&gt;&lt;/constructor-arg&gt; &lt;!-- 注入null值 --&gt; &lt;constructor-arg &gt;&lt;value&gt;&lt;null/&gt;&lt;/value&gt;&lt;/constructor-arg&gt; &lt;constructor-arg &gt;&lt;value&gt;&lt;null/&gt;&lt;/value&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;级联属性的配置:1234567&lt;!-- 通过方法注入属性值 --&gt;&lt;bean id = \"person\" calss = \"com.spring.hellowrld.person\"&gt; &lt;property name=\"name\" value=\"HuiProgramer\"&gt;&lt;/property&gt; &lt;property name=\"Car\" ref = \"car\"&gt;&lt;/property&gt; &lt;!-- 给级联属性赋值,注意：属性需要先初始化后才可以给级联属性赋值，否则会发生异常，和Struts2不同 --&gt; &lt;property name=\"Car.corp\" value = \"50000\"&gt;&lt;/property&gt;&lt;/bean&gt;集合属性在Spring中可以通过一组内置的XML标签（例如：&lt;list&gt;,&lt;set&gt;或&lt;map&gt;）来配置集合属性配置java.util.List类型的属性，需要指定&lt;list&gt;标签，在标签里包含一些元素，这些标签可以通过&lt;value&gt;指定简单的常量值，通过&lt;ref&gt;指定对其他Bean的引用，通过&lt;bean&gt;指定内置Bean定义。通过&lt;null/&gt;指定空元素，设置可以内嵌其他集合数组的定义和List一样，都使用&lt;list&gt;配置java.util.Set需要使用&lt;set&gt;标签，定义元素的方法与List一样。Java.util.Map通过&lt;map&gt;标签定义，&lt;map&gt;标签里可以使用多个&lt;entry&gt;作为子标签，每个条目包含一个键和一个值。必须在&lt;key&gt;标签里定义键因为键和值的类型没有限制，所以可以自由地为他们指定&lt;value&gt;,&lt;ref&gt;,&lt;bean&gt;或&lt;null&gt;元素。可以将Map的键和值作为&lt;entry&gt;的属性定义：简单常量使用key和value来定义；Bean引用通过key-ref和value-ref属性定义使用&lt;props&gt;定义java.util.Properties,该标签使用多个&lt;prop&gt;作为子标签，每个&lt;prop&gt;标签必须定义key属性.List实例：123456789101112131415161718&lt;!-- 通过方法注入属性值 --&gt;&lt;bean id = \"person\" calss = \"com.spring.hellowrld.person\"&gt; &lt;property name=\"name\" value=\"HuiProgramer\"&gt;&lt;/property&gt; &lt;property name=\"Cars\" &gt; &lt;!-- 使用list节点为List类型的属性赋值 --&gt; &lt;list&gt; &lt;ref bean = \"car2\" /&gt; &lt;ref bean = \"car3\" /&gt; &lt;!-- 通过Bean直接指定 --&gt; &lt;bean id = \"car\" class = \"com.spring.helloworld.Car\"&gt; &lt;constructor-arg value = \"Audi\" type = \"java.lang.String\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"30000\" type = \"long\"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value = \"ShangHai\" type = \"java.lang.String\"&gt;&lt;/constructor-arg&gt; &lt;/bean&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt;Map实例：123456789101112&lt;!-- 配置Map属性值 --&gt;&lt;bean id = \"Person\" calss = \"com.spring.hellowrld.person\"&gt; &lt;property name = \"name\" value = \"Rose\"&gt;&lt;/property&gt; &lt;property name = \"age\" value = \"28\"&gt;&lt;/property&gt; &lt;property name = \"Cars\"&gt; &lt;!-- 使用 map 节点及map的entry子节点配置 Map --&gt; &lt;map&gt; &lt;entry key = \"AA\" value-ref = \"car3\"&gt;&lt;/entry&gt; &lt;entry key = \"BB\" value-ref = \"car2\"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt;&lt;/bean&gt;Properties实例：123456789101112&lt;!-- 配置Properties 属性值 --&gt;&lt;bean id = \"dataSource\" calss = \"com.spring.hellowrld.dataSource\"&gt; &lt;property name = \"properties\"&gt; &lt;!-- 使用 props 和 prop 子节点来为 Properties 属性赋值 --&gt; &lt;props&gt; &lt;prop key = \"user\"&gt;root&lt;/prop&gt; &lt;prop key = \"password\"&gt;1234&lt;/prop&gt; &lt;prop key = \"jdbcUrl\"&gt;jdbc:mysql:///test&lt;/prop&gt; &lt;prop key = \"driverClass\"&gt;com.mysql.jdbc.Driver&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt;&lt;/bean&gt;使用utility scheme定义集合使用基本的集合标签定义集合时，不能将集合作为独立的Bean定义，导致其他Bean无法引用该集合，所以无法在不同Bean之间共享集合。可以使用util schema里的集合标签定义独立的集合Bean，需要注意的事，必须在&lt;beans&gt;根元素里添加退了 schema 定义。配置单例集合Bean:12345678910111213&lt;!-- 配置单例的集合Bean，以供多个bean进行引用，需要导入util命名空间 --&gt;&lt;util:list id = \"cars\"&gt; &lt;ref bean = \"car3\" /&gt; &lt;ref bean = \"car2\"&gt;&lt;/util:list&gt;&lt;bean id = \"Person2\" calss = \"com.spring.hellowrld.person\"&gt; &lt;property name = \"name\" value = \"Tom\"&gt;&lt;/property&gt; &lt;property name = \"age\" value = \"22\"&gt;&lt;/property&gt; &lt;!-- 被引用 --&gt; &lt;property name = \"Cars\" ref = \"cars\"&gt; &lt;/property&gt;&lt;/bean&gt;使用P命名空间为了简化XML文件的配置，越来越多的XML的XML文件采用属性而飞子元素配置信息。Spring从2.5版本开始引入了一个新的p命名空间，可以通过&lt;bean&gt;元素属性的方式配置Bean的属性。使用p命名空间后，基于XML的配置方式将进一步简化。123&lt;!-- 通过p命名空间为bean的属性赋值，需要先导入 p 命名空间,相对于传统的配置更加的简洁 --&gt;&lt;bean id = \"person3\" class = \"com.spring.hellowrld.person\" p:age = \"30\" p:name = \"Queen\" p:car-ref=\"cars\"&gt;&lt;/bean&gt;","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Spring的HelloWorld(使用Idea)","slug":"Spring的HelloWorld（使用Idea）","date":"2019-02-22T11:48:04.000Z","updated":"2019-05-04T13:10:56.558Z","comments":true,"path":"Spring的HelloWorld（使用Idea）.html","link":"","permalink":"https://me.obey.fun/Spring的HelloWorld（使用Idea）.html","excerpt":"","text":"创建Spring项目我们在idea中创建一个Spring项目，具体如下：勾选Spring选择好后点击Next选择项目路径以及项目名（自动下载所需jar包）简单的IOC（反转控制）我们在src目录下新建com.Test包，并创建一个HelloWorld类，实现一个简单的自我介绍功能，代码如下：12345678910111213141516171819202122232425package com.Test;public class HelloWorld &#123; private String name; private int age; public void setName(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; public void setAge(int age) &#123; this.age = age; &#125; public int getAge() &#123; return age; &#125; public void hello()&#123; System.out.println(\"我是\"+name+\",今年\"+age+\"岁啦\"); &#125;&#125;Bean的配置接下来我们配置Spring-config.xml文件1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"&gt; &lt;!-- 配置bean class：bean的全类名，通过反射的方式在IOC容器中创建Bean，所以要求Bean中必须有无参数的构造器 id:标识容器中的bean。id唯一 --&gt; &lt;bean id=\"hello\" class=\"com.Test.HelloWorld\"&gt; &lt;property name=\"name\" value=\"HuiProgramer\"&gt;&lt;/property&gt; &lt;property name=\"age\" value=\"22\"&gt;&lt;/property&gt; &lt;/bean&gt;&lt;/beans&gt;注意：这里使用的是属性注入，通过getxx(),setxx()方法。解析：name为setxx()方法的xx，value为setxx()方法里面的行参。运行效果这里我们再新建一个类Main来运行看效果：123456789101112131415161718package com.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class Main &#123; public static void main(String[] args)&#123; //1.创建Spring 的IOC容器对象 //ApplicationContext 代表IOC容器 //ClassPathXmlApplicationContext：是ApplicationContext 接口的实现类 ApplicationContext act = new ClassPathXmlApplicationContext(\"spring-config.xml\"); //2.从IOC容器中获取Bean实例 HelloWorld helloWorld = (HelloWorld)act.getBean(\"hello\"); //3.调用hello方法 helloWorld.hello(); &#125;&#125;&#125;运行后的结果：","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}],"tags":[{"name":"SSM","slug":"SSM","permalink":"https://me.obey.fun/tags/SSM/"},{"name":"SSH","slug":"SSH","permalink":"https://me.obey.fun/tags/SSH/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"},{"name":"Spring","slug":"后端/Java/Spring","permalink":"https://me.obey.fun/categories/后端/Java/Spring/"}]},{"title":"Java学习路线图","slug":"Java学习路线图","date":"2019-01-06T08:33:58.000Z","updated":"2019-10-28T05:24:25.422Z","comments":true,"path":"Java学习路线图.html","link":"","permalink":"https://me.obey.fun/Java学习路线图.html","excerpt":"","text":"前言本文为转载文章，想要详细了解请到文章末尾查看 原文地址JavaJava是一门面向对象编程语言，不仅吸收了C++语言的各种优点，还摒弃了C++里难以理解的多继承、指针等概念，因此Java语言具有功能强大和简单易用两个特征。Java语言作为静态面向对象编程语言的代表，极好地实现了面向对象理论，允许程序员以优雅的思维方式进行复杂的编程 。Java具有简单性、面向对象、分布式、健壮性、安全性、平台独立与可移植性、多线程、动态性等特点 。Java可以编写桌面应用程序、Web应用程序、分布式系统和嵌入式系统应用程序等 。Java学习路线图如何学习JavaJava基础Java 是一门纯粹的面向对象的编程语言，所以除了基础语法之外，必须得弄懂它的 oop 特性：封装、继承、多态。此外还有泛型、反射的特性，很多框架的技术都依赖它，比如 Spring 核心的 Ioc 和 AOP，都用到了反射，而且 Java 自身的动态代理也是利用反射实现的。此外还有 Java 一些标准库也是非常常见，比如集合、I/O、并发，几乎在 Web 开发中无处不在，也是面试经常会被问到的，所以在自学 Java 后端之前，不妨先打好这些基础，另外还有 Java8 的一些新特性，也要重点关注，比如 Lambda 表达式、集合的 Stream 流操作、全新的 Date API 等等数据库SQL建议学习MySQL在你了解了一些基础语法之后，就可以开始实战演练了，多练习熟练了就可以了。JDBC你需要弄懂 JDBC API 的用法，其实它只是一组规范接口，所有数据库驱动只要实现了 JDBC，那么我们就可以通过标准的 API 调用相应的驱动，完全不用知道驱动是怎么实现的，这就是面向接口编程的好处。Web基础Http 协议可以参考：Http协议JSP你只要了解它其实就是一个 Servlet 就行了，关于它的一些标签用法，我认为可以直接忽略，因为现在互联网几乎没哪间公司还用 JSP，除了一些老旧的项目。现在都是流行前后端分离，单页应用，后端只做 API 接口的时代了，所以时间宝贵，把这些时间重点放在 Servlet 规范上面吧。Tomcat它是一个 Web 容器，我们写的后端项目都要部署到Web容器才能运行，它其实是一个遵循 Http，通过 Socket 通信与客户端进行交互的服务端程序.可以参考：Tomcat结构及处理请求过程Web 主流框架Java Web 框架多如牛毛，等你有一定经验了，你也可以写一个 Web 框架，网上很多说 Spring、Struts2、Hibernate 是 Java 三架马车，我只想说，那是很久远的事情了，我严重不推荐 Struts2、Hibernate，相信我，一开始只需要上手 Spring、SpringMVC、Mybatis 就可以了，特别是 Spring 框架，其实 Spring 家族的框架都是很不错的。但是提醒一点就是，千万不要沉迷于各种框架不能自拔，以会多种用法而沾沾自喜，导致知其然而不知其所以然。Spring核心思想就是 IOC 和 AOP：谈谈对 Spring IOC 的理解Spring 面向切面编程SpringMVC它的思想是全部请求统一用一个 Servlet 去做请求转发与控制，这个 Servlet 叫 DispatcherServlet：SpringMVC 初始化过程SpringMVC 处理请求过程Mybatis它可实现动态拼装 sql，避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集：mybatis 入门教程Mybatis 深入浅出系列Web 框架进阶使用了 SSM 框架后，你会觉得框架也不过这么回事，如果你对 Spring 有过大概了解，你也会产生想写一个「山寨版」Spring 的心思了，一个轻量级 Web 框架主要具备以下功能：可读取用户自定义配置文件，并以此来初始化框架；具备 Bean 容器，管理项目的类的对象生命周期；具备依赖注入，降低类之间的耦合性；具备 AOP 功能，使项目可进行横向编程，可不改变原有代码的情况增加业务逻辑；具备 MVC 框架模式。其实除了 SSM 之外，Web 框架可谓是百家齐放，其中以 Spring 全家桶最为耀眼，在这里我极力推荐两个 Spring 家族框架：SpringBoot 和 SpringCloud。SpringBoot弥补了 Spring 配置上的缺点，再也不用为繁杂的 xml 费劲精力了，堪称是 Java 后端开发的颠覆者，推荐书籍「Java EE 开发的颠覆者：SpringBoot实战」SpringBoot 构建 web 项目SpringBoot 自动化配置源码分析自定义 SpringBoot Starterspring-boot-starter-tutorialSpringCloud一个微服务架构，能够将项目按照业务分成一个个微服务，每个微服务都可独立部署，服务之间互相协调。当一个项目越来越大时，随之而来的是越来越难以维护，此时将项目拆分成若干个微服务、单独维护、单独部署，也可以降低项目不同业务间的耦合度。推荐书籍「Spring Cloud 与 Docker 微服务架构实战」，这本书将 Docker 与微服务完美地结合在一起，堪称完美！Spring Cloud 中文官网史上最简单的 Spring Cloud 教程关于 Spring Cloud 的博客有：SpringCloud微服务架构之服务注册与发现SpringCloud微服务架构之服务消费者SpringCloud微服务架构之断路器SpringCloud微服务架构之服务网关其它技术Redis一个高性能的 key-value 数据库，当有并发量很高的请求时，将数据缓存在 Redis 中，将提高服务器的响应性能，大大减轻数据库的压力。redis 中文官网redis 教程Git世界上最先进的分布式版本控制系统，建议所有初学者从命令行开始使用 Git！Git 官网Git 教程Maven一个用于构建项目的工具，将项目间的依赖通过 xml 完美地组织到一起，可通过编译插件将项目编译成字节码文件。还有类似的 Gradle 也是不错的选择。maven 的 pom.xml 文件详解Linux：至少要求常用的命令会用，能够在 linux 环境下部署项目。Linux 命令大全最全的 SSH 连接远程终端教程Docker简直是项目部署神器啊，来不及解释了，看下面一些 Docker 系列博客，开启 Docker 之旅吧！推荐书籍「Docker 技术入门与实战」，中国首部 Docker 著作！Docker 实战（一）Docker 实战（二）Docker 实战（三）docker-deploy-tutorial原文地址Java学习路线图","categories":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"}],"tags":[{"name":"Java学习路线","slug":"Java学习路线","permalink":"https://me.obey.fun/tags/Java学习路线/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"https://me.obey.fun/categories/后端/"},{"name":"Java","slug":"后端/Java","permalink":"https://me.obey.fun/categories/后端/Java/"}]},{"title":"Git教程（持续更新）","slug":"Git教程","date":"2018-12-24T14:06:36.000Z","updated":"2020-10-14T13:20:41.310Z","comments":true,"path":"Git教程.html","link":"","permalink":"https://me.obey.fun/Git教程.html","excerpt":"","text":"GIT （分布式版本控制系统）简介Git(读音为/gɪt/。)是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。什么是Git，Git可以用来干嘛？GIt是什么？Git是目前世界上最先进的分布式版本控制系统Git可以用来干嘛？如果你用Microsoft Word写过长篇大论，那你一定有这样的经历：想删除一个段落，又怕将来想恢复找不回来怎么办？有办法，先把当前文件“另存为……”一个新的Word文件，再接着改，改到一定程度，再“另存为……”一个新文件，这样一直改下去，最后你的Word文档就“魂飞魄散”了！过了一周，你想找回被删除的文字，但是已经记不清删除前保存在哪个文件里了，只好一个一个文件去找，真麻烦。看着一堆乱七八糟的文件，想保留最新的一个，然后把其他的删掉，又怕哪天会用上，还不敢删，真郁闷。更要命的是，有些部分需要你的财务同事帮助填写，于是你把文件Copy到U盘里给她（也可能通过Email发送一份给她），然后，你继续修改Word文件。一天后，同事再把Word文件传给你，此时，你必须想想，发给她之后到你收到她的文件期间，你作了哪些改动，得把你的改动和她的部分合并，真困难。于是你想，如果有一个软件，不但能自动帮我记录每次文件的改动，还可以让同事协作编辑，这样就不用自己管理一堆类似的文件了，也不需要把文件传来传去。如果想查看某次改动，只需要在软件里瞄一眼就可以，岂不是很方便？这个软件用起来就应该像这个样子，能记录每次文件的改动：版本用户说明日期1张三删除了软件服务条款57/12 10:382张三增加了License人数限制7/12 18:093李四财务部门调整了合同金额7/13 9:514张三延长了免费升级周期7/14 15:17Git与SVN的区别GIT不仅仅是个版本控制系统，它也是个内容管理系统(CMS),工作管理系统等。如果你是一个具有使用SVN背景的人，你需要做一定的思想转换，来适应GIT提供的一些概念和特征。Git 与 SVN 区别点：GIT是分布式的，SVN不是：这是GIT和其它非分布式的版本控制系统，例如SVN，CVS等，最核心的区别。GIT把内容按元数据方式存储，而SVN是按文件：所有的资源控制系统都是把文件的元信息隐藏在一个类似.svn,.cvs等的文件夹里。GIT分支和SVN的分支不同：分支在SVN中一点不特别，就是版本库中的另外的一个目录。GIT没有一个全局的版本号，而SVN有：目前为止这是跟SVN相比GIT缺少的最大的一个特征。GIT的内容完整性要优于SVN：GIT的内容存储使用的是SHA-1哈希算法。这能确保代码内容的完整性，确保在遇到磁盘故障和网络问题时降低对版本库的破坏。安装Git最早Git是在Linux上开发的，很长一段时间内，Git也只能在Linux和Unix系统上跑。不过，慢慢地有人把它移植到了Windows上。现在，Git可以在Linux、Unix、Mac和Windows这几大平台上正常运行了。Git 各平台安装包下载地址为：http://git-scm.com/downloads在Linux平台安装GitGit 的工作需要调用 curl，zlib，openssl，expat，libiconv 等库的代码，所以需要先安装这些依赖工具。在有 yum 的系统上（比如 Fedora）或者有 apt-get 的系统上（比如 Debian 体系），可以用下面的命令安装：各 Linux 系统可以使用其安装包管理工具（apt-get、yum 等）进行安装：Debian/UbuntuDebian/Ubuntu Git 安装命令为：1234567$ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ libz-dev libssl-dev$ apt-get install git$ git --versiongit version 1.8.1.2Centos/RedHat如果你使用的系统是 Centos/RedHat 安装命令为：1234567$ yum install curl-devel expat-devel gettext-devel \\ openssl-devel zlib-devel$ yum -y install git-core$ git --versiongit version 1.7.1在Mac OS X上安装Git如果你正在使用Mac做开发，有两种安装Git的方法。一是安装homebrew，然后通过homebrew安装Git，具体方法请参考homebrew的文档：http://brew.sh/ 。第二种方法更简单，也是推荐的方法，就是直接从AppStore安装Xcode，Xcode集成了Git，不过默认没有安装，你需要运行Xcode，选择菜单“Xcode”-&gt;“Preferences”，在弹出窗口中找到“Downloads”，选择“Command Line Tools”，点“Install”就可以完成安装了。在Windows上安装Git在Windows上使用Git，可以从Git官网直接下载安装程序，（网速慢的同学请移步国内镜像），然后按默认选项安装即可。安装完成后，在开始菜单里找到“Git”-&gt;“Git Bash”，蹦出一个类似命令行窗口的东西，就说明Git安装成功！Git配置Git 提供了一个叫做 git config 的工具，专门用来配置或读取相应的工作环境变量。这些环境变量，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下三个不同的地方：/etc/gitconfig 文件：系统中对所有用户都普遍适用的配置。若使用 git config 时用 –system 选项，读写的就是这个文件。~/.gitconfig 文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 –global 选项，读写的就是这个文件。当前项目的 Git 目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 .git/config 里的配置会覆盖 /etc/gitconfig 中的同名变量。在 Windows 系统上，Git 会找寻用户主目录下的 .gitconfig 文件。主目录即 $HOME 变量指定的目录，一般都是 C:\\Documents and Settings\\$USER。此外，Git 还会尝试找寻 /etc/gitconfig 文件，只不过看当初 Git 装在什么目录，就以此作为根目录来定位。用户信息配置个人的用户名称和电子邮件地址：12$ git config --global user.name \"Your Name\"$ git config --global user.email \"email@example.com\"因为Git是分布式版本控制系统，所以，每个机器都必须自报家门：你的名字和Email地址。你也许会担心，如果有人故意冒充别人怎么办？这个不必担心，首先我们相信大家都是善良无知的群众，其次，真的有冒充的也是有办法可查的。如果用了 –global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 –global 选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。注意: 用了这个参数，表示你这台机器上所有的Git仓库都会使用这个配置，当然也可以对某个仓库指定不同的用户名和Email地址。查看配置信息要检查已有的配置信息，可以使用 git config –list 命令：1234$ git config --listcredential.helper=manageruser.name=ProgramerHuiuser.email=1712817197@qq.comGit工作流程一般工作流程如下：克隆 Git 资源作为工作目录。在克隆的资源上添加或修改文件。如果其他人修改了，你可以更新资源。在提交前查看修改。提交修改。在修改完成后，如果发现错误，可以撤回提交并再次修改并提交。Git工作区、暂存区和版本库基本概念工作区：就是你在电脑里能看到的目录。暂存区：英文叫stage, 或index。一般存放在 “.git目录下” 下的index文件（.git/index）中，所以我们把暂存区有时也叫作索引（index）。版本库：工作区有一个隐藏目录.git，这个不算工作区，而是Git的版本库。下面这个图展示了工作区、版本库中的暂存区和版本库之间的关系：图中左侧为工作区，右侧为版本库。在版本库中标记为 “index” 的区域是暂存区（stage, index），标记为 “master” 的是 master 分支所代表的目录树。图中我们可以看出此时 “HEAD” 实际是指向 master 分支的一个”游标”。所以图示的命令中出现 HEAD 的地方可以用 master 来替换。图中的 objects 标识的区域为 Git 的对象库，实际位于 “.git/objects” 目录下，里面包含了创建的各种对象及内容。当对工作区修改（或新增）的文件执行 “git add” 命令时，暂存区的目录树被更新，同时工作区修改（或新增）的文件内容被写入到对象库中的一个新的对象中，而该对象的ID被记录在暂存区的文件索引中。当执行提交操作（git commit）时，暂存区的目录树写到版本库（对象库）中，master 分支会做相应的更新。即 master 指向的目录树就是提交时暂存区的目录树。当执行 “git reset HEAD” 命令时，暂存区的目录树会被重写，被 master 分支指向的目录树所替换，但是工作区不受影响。当执行 “git rm –cached“ 命令时，会直接从暂存区删除文件，工作区则不做出改变。当执行 “git checkout .” 或者 “git checkout –“ 命令时，会用暂存区全部或指定的文件替换工作区的文件。这个操作很危险，会清除工作区中未添加到暂存区的改动。当执行 “git checkout HEAD .” 或者 “git checkout HEAD“ 命令时，会用 HEAD 指向的 master 分支中的全部或者部分文件替换暂存区和以及工作区中的文件。这个命令也是极具危险性的，因为不但会清除工作区中未提交的改动，也会清除暂存区中未提交的改动。Git创建版本库(仓库)什么是版本库呢？版本库又名仓库，英文名repository，你可以简单理解成一个目录，这个目录里面的所有文件都可以被Git管理起来，每个文件的修改、删除，Git都能跟踪，以便任何时刻都可以追踪历史，或者在将来某个时刻可以“还原”。所以，创建一个版本库非常简单，首先，选择一个合适的地方，创建一个空目录：12345$ pwd/c/Users/Administrator$ cd E:$ mkdir Git$ cd Gitpwd命令用于显示当前目录，cd命令用于切换目录，mkdir用于创建文件夹，在我的Windows上，这个仓库位于E:/Git.注意：文件夹应避免使用中文，防止乱码。让文件夹成为真正的仓库上面步骤只是创建了一个文件夹，严格意义上并不算是一个Git版本库，so，现在，我们让这个文件夹变成一个真正的仓库。输入git init命令把这个目录变成Git可管理的仓库12$ git initInitialized empty Git repository in E:/Git/.git/瞬间Git就把仓库建好了，而且告诉你是一个空的仓库（empty Git repository），细心的读者可以发现当前目录下多了一个.git的目录，这个目录是Git来跟踪管理版本库的，没事千万不要手动修改这个目录里面的文件，不然改乱了，就把Git仓库给破坏了。如果你没有看到.git目录，那是因为这个目录默认是隐藏的，用ls -ah命令就可以看见。把文件添加到版本库首先这里再明确一下，所有的版本控制系统，其实只能跟踪文本文件的改动，比如TXT文件，网页，所有的程序代码等等，Git也不例外。版本控制系统可以告诉你每次的改动，比如在第5行加了一个单词“Linux”，在第8行删了一个单词“Windows”。而图片、视频这些二进制文件，虽然也能由版本控制系统管理，但没法跟踪文件的变化，只能把二进制文件每次改动串起来，也就是只知道图片从100KB改成了120KB，但到底改了啥，版本控制系统不知道，也没法知道。不幸的是，Microsoft的Word格式是二进制格式，因此，版本控制系统是没法跟踪Word文件的改动的，前面我们举的例子只是为了演示，如果要真正使用版本控制系统，就要以纯文本方式编写文件。建议：编辑文本最好使用Notepad++代替记事本，因为微软自带记事本会在每个文件开头添加0xefbbbf（十六进制）的字符。现在，我们编写一个readme.txt文件，内容如下:1Hello,Git!注意:文件应该放在Git文件夹里，因为这是一个Git仓库，放到其他地方Git会找不到这个文件。Git add通过git add告诉Git，把文件添加到仓库（暂存区）：1$ git add readme.txt执行上面的命令，没有任何显示,代表执行成功。Git commit通过git commit告诉Git，把文件提交到仓库（版本库）：1234$ git commit -m \"wrote a readme file\"[master (root-commit) eacdf4e] wrote a readme file 1 file changed, 2 insertions(+) create mode 100644 readme.txt其中：git commit -m &quot;wrote a readme file&quot;中的-m &quot;xxx&quot;代表本次提交的说明。例如：$ git commit -m &quot;本次提交解决了若干个BUG&quot;当然,提交说明也可以带表情，具体表情参考Github表情提交指南。Git 基本操作获取和创建项目命令git init此命令在创建版本库的时候就讲过，git init命令就是将一个文件夹初始化为一个Git仓库，创建成功后在该文件夹下会生成一个.git的文件夹.例如：12$ git initInitialized empty Git repository in E:/Git/.git/现在你能看见该仓库中的.git文件了。12$ ls -a. .. .git注意：这里的ls -a中的ls就是列表，清单的意思，在终端就是显示当前目录的所有文件，而-a的意思是显示隐藏文件。git clone使用 git clone 拷贝一个 Git 仓库到本地，让自己能够查看该项目，或者进行修改。1$ git clone [url]url是你想克隆（复制）的网上仓库。例如：我们克隆Github上的项目1234567$ git clone git@github.com:HuiProgramer/HTML5_Learning.gitCloning into 'HTML5_Learning'...remote: Counting objects: 26, done.remote: Total 26 (delta 0), reused 0 (delta 0), pack-reused 26Receiving objects: 100% (26/26), done.Resolving deltas: 100% (5/5), done.Checking connectivity... done.克隆完成后，在当前目录下会生成一个 HTML5_Learning 目录：1234$ cd HTML5_Learning&amp; lsCSS/ index.html logo.png Screen1.pngimg/ JavaScript/ README.MD Screen2.png至此，一个Github上的项目就克隆完成了，你可以尝试修改或者查看。常用命令git add此命令前面就讲过了，这里再举一个例子，这次我们往暂存区添加多个文件：123456789101112131415161718$ touch hello.py hello.c hello.java hello.html$ lshello.py hello.c hello.java hello.html$ git add hello.c hello.java hello.html hello.py$ git statusOn branch masterNo commits yetChanges to be committed: (use \"git rm --cached &lt;file&gt;...\" to unstage) new file: hello.c new file: hello.html new file: hello.java new file: hello.py我们分别向暂存区提交了多个语言hello world程序源文件，touch代表我们新建这几个文件，git status的意思是查看当前暂存区的状态。扩展： 通过git add .可以将该文件夹的东西都添加到暂存区。git statusgit status用于查看在你上次提交之后是否有修改，便于查看当前暂存区的状态，通过增加-s参数可以获得简短的输出结果，如果没有加该参数将会得到详细的输出。例如：123456789101112131415161718$ git statusOn branch masterNo commits yetChanges to be committed: (use \"git rm --cached &lt;file&gt;...\" to unstage) new file: hello.c new file: hello.html new file: hello.java new file: hello.py$ git status -sA hello.cA hello.htmlA hello.javaA hello.py补充说明：A的意思是文件添加到了暂存区，而AM的意思是文件添加到暂存区后在工作区又有所改动。git diff执行 git diff 来查看执行 git status 的结果的详细信息。git diff 命令显示已写入缓存与已修改但尚未写入缓存的改动的区别。git diff 有如下几个主要的应用场景。尚未缓存的改动（工作区）：git diff查看已缓存的改动（暂存区）： git diff –cached查看已缓存的与未缓存的所有改动（工作区与暂存区）：git diff HEAD显示摘要而非整个 diff：git diff –stat例如我们利用notepad++编辑器修改hello.c文件内容如下：12345#include&lt;stdio.h&gt;int main(void)&#123; printf(\"hello,world\"); return 0;&#125;现在我们使用git diff file命令来看看结果：123456789101112$ git diff hello.cdiff --git a/hello.c b/hello.cindex e69de29..fb0c3bd 100644--- a/hello.c+++ b/hello.c@@ -0,0 +1,5 @@+#include&lt;stdio.h&gt;+int main(void)&#123;+ printf(\"hello,world\");+ return 0;+&#125;\\ No newline at end of file果然，git将整个文件的变化都列了出来。扩展：diff就是单词different的缩写，其原意是“区别，不同”。git commit此命令在讲述创建版本库的时候就介绍过，主要用于将暂存区的东西提交到版本库中。例如：12345678910111213$ git status -sAM hello.cA hello.htmlA hello.javaA hello.py$ git commit -m\"第一次提交\"[master (root-commit) ac81931] 第一次提交 4 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 hello.c create mode 100644 hello.html create mode 100644 hello.java create mode 100644 hello.py我们将暂存区的内容提交到版本库后再次执行git status命令123456789$ git statusOn branch masterChanges not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: hello.cno changes added to commit (use \"git add\" and/or \"git commit -a\")此时，我们发现，暂存区的内容已经全部提交到版本库中，只有一条工作区内容被修改的记录。git reset HEADgit reset HEAD file 命令用于取消已缓存(暂存区)的内容。可以理解为：撤销暂存区的修改。可单个撤销，也可以全部撤销。这里，我们先提交hello.c源文件123456789101112131415161718$ git statusOn branch masterChanges not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: hello.cno changes added to commit (use \"git add\" and/or \"git commit -a\")$ git add hello.c$ git statusOn branch masterChanges to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: hello.c好的，现在hello.c源文件已经进入了暂存区了，那么，如果我不想提交该内容，该怎么解决呢？其实，通过git reset HEAD命令是可以丢弃掉暂存区里的内容的。现在，我们来试试吧！12345678910111213$ git reset HEADUnstaged changes after reset:M hello.c$ git statusOn branch masterChanges not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: hello.cno changes added to commit (use \"git add\" and/or \"git commit -a\")果然，暂存区的内容被撤销掉了。要点：git reset HEAD filename实现单个或多个文件在暂存区中撤销，git reset HEAD实现整个暂存区的撤销。注意：如果你提交暂存区后，在工作区又进行了修改，git reset HEAD命令并不会让你在工作区的内容回退到上一次提交的数据，该只是单纯的丢弃掉暂存区里的内容。git checkout – filegit checkout --file命令用于取消未缓存的内容（工作区）。可以理解为：丢弃工作区的修改，回到上次修改的样子。那么，我们现在来试试1234567891011121314151617181920$ git statusOn branch masterChanges not staged for commit: (use \"git add &lt;file&gt;...\" to update what will be committed) (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory) modified: hello.cno changes added to commit (use \"git add\" and/or \"git commit -a\")$ cat hello.c#include&lt;stdio.h&gt;int main(void)&#123; printf(\"hello,world\"); return 0;&#125;$ git checkout -- hello.c$ cat hello.c在这里，我们使用git status命令可以看到该文件只是在工作区进行了修改，接着我们使用了cat命令查看了文件内容，发现里面是C语言源代码，然后我们使用了git checkout -- hello.c命令丢弃了本次修改。等我们再次使用cat命令查看hello.c内容时发现里面已经没有内容了，这是为什么呢？原来这里的git checkout -- &lt;file&gt;命令的结果分为了两种情况:当文件在工作区修改后还没有被添加到暂存区，此时使用该命令，会使工作区回到和版本库一模一样的状态。当文件在工作区修改后被添加到了暂存区，此时使用该命令，会使工作区回到把文件添加到暂存区后的状态那么，这里就是第一种状态了，因为我们并没有提交到暂存区，而版本库的hello.c里面恰恰是没有内容的。（因为当时并没有写内容）git rm如果只是简单地从工作目录中手工删除文件，运行 git status 时就会在 Changes not staged for commit 的提示。要从 Git 中移除某个文件，就必须要从已跟踪文件清单中移除，然后提交。可以用以下命令完成此项工作1$ rm &lt;file&gt;如果删除之前修改过并且已经放到暂存区域的话，则必须要用强制删除选项 -f1$ rm -f &lt;file&gt;如果把文件从暂存区域移除，但仍然希望保留在当前工作目录中，换句话说，仅是从跟踪清单中删除，使用 –cached 选项即可1$ git rm --cached &lt;file&gt;我们先在hello.py增加如下代码1print(\"hello\")然后，我们将文件添加到暂存区后，在暂存区中删除hello.py文件12345678910111213141516171819202122$ git add hello.py$ git statusOn branch masterChanges to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) modified: hello.py$ git rm --cached hello.pyrm 'hello.py'$ git statusOn branch masterChanges to be committed: (use \"git reset HEAD &lt;file&gt;...\" to unstage) deleted: hello.pyUntracked files: (use \"git add &lt;file&gt;...\" to include in what will be committed) hello.py可以看到，我们在暂存区移除了该文件，现在，我们将工作区的文件也移除掉。1234$ rm hello.pyrm 'hello.py'$ lshello.c hello.html hello.java至此，基本命令到此结束。Git查看提交历史git log在使用 Git 提交了若干更新之后，又或者克隆了某个项目，想回顾下提交历史，我们可以使用 git log 命令查看。123456$ git logcommit ac81931794f4e232398796f5d4e09be155fc5bc2 (master)Author: ProgramerHui &lt;1712817197@qq.com&gt;Date: Fri Dec 28 19:17:51 2018 +0800 第一次提交git log –onelinegit log --oneline 命令用来查看历史记录的简洁的版本。12$ git log --onelineac81931 (master) 第一次提交git log –graphgit log --graph 命令，用于查看历史中什么时候出现了分支、合并。以下为相同的命令，开启了拓扑图选项：123456$ git log --graph* commit ac81931794f4e232398796f5d4e09be155fc5bc2 (master) Author: ProgramerHui &lt;1712817197@qq.com&gt; Date: Fri Dec 28 19:17:51 2018 +0800 第一次提交git log –authorgit log --author命令用于查看指定用户的提交日志。示例如下：123456$ git log --author=ProgramerHuicommit ac81931794f4e232398796f5d4e09be155fc5bc2 (master)Author: ProgramerHui &lt;1712817197@qq.com&gt;Date: Fri Dec 28 19:17:51 2018 +0800 第一次提交Git版本回退早在前面就说过Git能干什么的特性.你可以理解为Git就是一个时空穿梭机，能够回退版本和前进版本。现在，我们来修改一下readme.txt的内容。1234567$ cat readme.txthello,Git$ echo \"HuiProgramer is handsome!\" &gt;&gt; readme.txt$ cat readme.txtHuiProgramer is handsome!扩展：echo &quot; &quot; &gt;&gt; file是一个批处理命令，用于清空文件内容后，将” “里的内容写入到文件中。我们尝试提交一下123456$ git add readme.txt$ git commit -m\"handsome\"[master dd18d87] handsome 1 file changed, 1 insertion(+) create mode 100644 readme.txt我们现在来回忆一下我们一共提交了哪几个版本的readme.txt文件。版本一：hello,Git版本二：HuiProgramer is handsome记不住也没事，我们可以通过git log命令来查看：123456789101112$ git logcommit dd18d87073e5d9a593dbfe3a89072e9f785431ad (HEAD -&gt; master)Author: ProgramerHui &lt;1712817197@qq.com&gt;Date: Sun Jan 6 12:07:01 2019 +0800 handsomecommit ac81931794f4e232398796f5d4e09be155fc5bc2Author: ProgramerHui &lt;1712817197@qq.com&gt;Date: Fri Dec 28 19:17:51 2018 +0800 wrote a readme file可以看到第一次提交就是开始介绍GIt仓库时写的readme.txt,里面的内容是hello,Git.而最近一次提交就是我们重新修改了readme.txt后提交的，里面的内容是HuiProgramer is handsome(表脸).那么，如果我想要回到上一个版本该怎么办呢？其实很简单只需要执行git reset --hard HEAD^就行了，其中^代表上一个版本，^^代表上上个版本，以此类推。12$ git reset --hard HEAD^HEAD is now at ac81931 wrote a readme fileLook，我们已经回到了上一个版本了，现在我们打开readme.txt文件看看。hello,Git哇，果然是这样，但我又如何回去呢？就像我们现在坐着时空穿梭机回到了过去，应该怎么回到现在呢？其实很简单，我们可以通过上次执行git log命令拿到的commit后面的版本号再次穿梭就可以回来了。12$ git reset --hard dd18HEAD is now at dd18d87 handsome注意：版本号没必要写全，前几位就可以了，Git会自动去找。当然也不能只写前一两位，因为Git可能会找到多个版本号，就无法确定是哪一个了。再次查看readme.txt的内容HuiProgramer is handsome嗯，不错，内容全回来了，还是一如既往的表脸。扩展：假如我关闭了git bash这个终端，然后又回退了版本，输入git log又不显示，该怎么办呢？其实很简单，你只要输入git reflog命令就能再次看到你的提交记录了。1234567891011121314151617181920$ git reflogdd18d87 (HEAD -&gt; master) HEAD@&#123;0&#125;: reset: moving to dd18ac81931 HEAD@&#123;1&#125;: reset: moving to HEAD^dd18d87 (HEAD -&gt; master) HEAD@&#123;2&#125;: commit: handsomeac81931 HEAD@&#123;3&#125;: checkout: moving from Python to masteraf26cd8 (Python) HEAD@&#123;4&#125;: checkout: moving from master to Pythonac81931 HEAD@&#123;5&#125;: checkout: moving from Python to masteraf26cd8 (Python) HEAD@&#123;6&#125;: commit: test branchac81931 HEAD@&#123;7&#125;: checkout: moving from master to Pythonac81931 HEAD@&#123;8&#125;: checkout: moving from Python to masterac81931 HEAD@&#123;9&#125;: checkout: moving from master to Pythonac81931 HEAD@&#123;10&#125;: checkout: moving from Python to masterac81931 HEAD@&#123;11&#125;: checkout: moving from master to Pythonac81931 HEAD@&#123;12&#125;: checkout: moving from Python to masterac81931 HEAD@&#123;13&#125;: checkout: moving from master to Pythonac81931 HEAD@&#123;14&#125;: reset: moving to HEADac81931 HEAD@&#123;15&#125;: reset: moving to HEADac81931 HEAD@&#123;16&#125;: reset: moving to HEAD^5a56f73 HEAD@&#123;17&#125;: commit: hello worldac81931 HEAD@&#123;18&#125;: commit (initial): wrote a readme fileGit与Github什么是GithubGitHub是一个面向开源及私有软件项目的托管平台，因为只支持git 作为唯一的版本库格式进行托管，故名gitHub。简单来说就是一个网上的仓库，而Git就是本地的仓库。拥有自己的Github注册Github账号点击这里进行注册。注册完成后，登录…创建自己的项目（仓库/版本库）点击+号进行创建填写项目名字，点击完成即可。完成后，会得到项目的提交地址。创建SSH Key打开Git Bash终端，输入：1$ ssh-keygen -t rsa -C \"youremail@example.com\"你需要把邮件地址换成你自己的邮件地址，然后一路回车，使用默认值即可，由于这个Key也不是用于军事目的，所以也无需设置密码。如果一切顺利的话，可以在用户主目录里找到.ssh目录，里面有id_rsa和id_rsa.pub两个文件，这两个就是SSH Key的秘钥对，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。绑定SSH Key进入Github,点击头像，点击Settings。点击SSH and GPG Keys点击New SSH key可以看到此页面Title可以随便取一个，Key可以去C:\\Users\\Administrator\\.ssh下找到一个id_rsa.pub的文件，双击打开后复制里面的全部内容粘贴到Key下的框框里，然后点击Add SSH Key.创建完成后就能看到这样的页面…提交项目到Githubgit remote通过git remote add origin git@github.com:YourName/RepositoryName.git即可建立一个与当前分支关联的提交名字。1$ git remote add Golang git@github.com:HuiProgramer/Golang_Learning.git解析：YourName为你的Github账户名,RepositoryName为你创建的项目名。注意：这里的origin可以任你更改，前提你得记住，后面提交要用到。git push通过git push -u origin master命令可将本地项目推送到Github的仓库中。12345678910$ git push -u Golang masterCounting objects: 9, done.Delta compression using up to 2 threads.Compressing objects: 100% (6/6), done.Writing objects: 100% (9/9), 916 bytes | 152.00 KiB/s, done.Total 9 (delta 1), reused 0 (delta 0)remote: Resolving deltas: 100% (1/1), done.To github.com:HuiProgramer/Golang_Learning.git * [new branch] master -&gt; masterBranch &apos;master&apos; set up to track remote branch &apos;master&apos; from &apos;Golang&apos;.Look,我们已经成功提交本地版本库到网上仓库了。由于远程库是空的，我们第一次推送master分支时，加上了-u参数，Git不但会把本地的master分支内容推送的远程新的master分支，还会把本地的master分支和远程的master分支关联起来，在以后的推送或者拉取时就可以简化命令。现在，我们打开我们的远程仓库看看，是否提交成功。嗯，不错，成功了，以后就这样提交。git pull通过git pull origin master可将网上仓库拉取到本地来完成同步。1234$ git pull Golang masterFrom github.com:HuiProgramer/Golang_Learning * branch master -&gt; FETCH_HEADAlready up to date.现在就会看到，本地项目和网上仓库一模一样了。Git分支管理几乎每一种版本控制系统都以某种形式支持分支。使用分支意味着你可以从开发主线上分离开来，然后在不影响主线的同时继续工作。有人把 Git 的分支模型称为”必杀技特性”，而正是因为它，将 Git 从版本控制系统家族里区分出来。分支的创建和切换创建分支命令：1$ git branch (branchname)切换分支命令：1git checkout (branchname)例如：12345$ git branch Python$ git checkout PythonSwitched to branch 'Python'D hello.py扩展：git checkout -b (branchname)命令可以创建并切换新分支，从而实现在该分支中的操作。分支的合并Git Merge在 Git 中合并两个分支时会产生一个特殊的提交记录，它有两个父结点。翻译成自然语言相当于：“我要把这两个父结点本身及它们所有的祖先都包含进来。”merge合并分支命令：1git merge (branchname)例如：1234567891011121314151617181920212223242526$ git checkout -b fixbug //创建并切换fixbug分支Switched to a new branch 'fixbug'D test.txt$ git add . warning: LF will be replaced by CRLF in hello.go.The file will have its original line endings in your working directory.$ git commit -m \"merge branch bugfix\" //在分支上提交[fixbug dbed58a] merge branch bugfix 2 files changed, 1 insertion(+), 1 deletion(-) create mode 100644 hello.go delete mode 100644 test.txt$ git checkout master //切换回主分支Switched to branch 'master'Your branch is up to date with 'Golang/master'.$ git merge fixbug //合并分支Updating 8d7e87d..dbed58aFast-forward hello.go | 1 + test.txt | 1 - 2 files changed, 1 insertion(+), 1 deletion(-) create mode 100644 hello.go delete mode 100644 test.txt注意：这里git merge fixbug 是把该分支fixbug合并到当前分支(master)对于前两步也同样可以使用git checkout -b fixbug一步完成。Git Rebase第二种合并分支的方法是 git rebase。Rebase 实际上就是取出一系列的提交记录，“复制”它们，然后在另外一个地方逐个的放下去。Rebase 的优势就是可以创造更线性的提交历史，这听上去有些难以理解。如果只允许使用 Rebase 的话，代码库的提交历史将会变得异常清晰。rebase合并分支命令：1git rebase (branchname)例如：1234567891011121314151617181920212223242526$ git checkout -b fixbug //创建并切换fixbug分支Switched to a new branch 'fixbug'D test.txt$ git add . warning: LF will be replaced by CRLF in hello.go.The file will have its original line endings in your working directory.$ git commit -m \"rebase branch bugfix\" //在分支上提交[fixbug dbed58a] merge branch bugfix 2 files changed, 1 insertion(+), 1 deletion(-) create mode 100644 hello.go delete mode 100644 test.txt$ git checkout master //切换回主分支Switched to branch 'master'Your branch is up to date with 'Golang/master'.$ git rebase fixbug //合并分支Updating 8d7e87d..dbed58aFast-forward hello.go | 1 + test.txt | 1 - 2 files changed, 1 insertion(+), 1 deletion(-) create mode 100644 hello.go delete mode 100644 test.txtmerge和rebase的区别两个使用场景是不一样的，merge只是合并另外一个分支的内容，rebase也合并另外一个分支的内容，但是会把本分支的commits顶到最顶端假设我们现在有3个分支master分支：线上环境使用的分支testing分支：测试环境使用的分支my_feature分支：开发新功能的分支，也就是当前分支A. 假设我在my_feature上开发了一段时间，之后另外的同事开发的功能正式上线到master分支了，那么我可以在当前的分支下rebase一下master分支，这样我这个分支的几个commits相对于master还是处于最顶端的，也就是说rebase主要用来跟上游同步，同时把自己的修改顶到最上面B. 我在my_feature上开发了一段时间了，想要放到testing分支上，那就切到testing，然后merge my_feature进来，因为是个测试分支，commits的顺序无所谓，也就没必要用rebase (当然你也可以用rebase)另外，单独使用rebase，还有调整当前分支上commits的功能(合并，丢弃，修改commites msg)建议推荐大家开发的时候，尽量及时rebase上游分支（我习惯是每周merge一次），有冲突提前就fix掉，即使我们自己的分支开发了很久（哪怕是几个月），也不会积累太多的conflict，最后合并进主分支的时候特别轻松， 非常反对从master check出新分支，自己闷头开发几个月，结果最后merge进主分支的时候，一大堆冲突，自己还嗷嗷叫的行为 。","categories":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"版本控制系统","slug":"前端/版本控制系统","permalink":"https://me.obey.fun/categories/前端/版本控制系统/"},{"name":"Git","slug":"前端/版本控制系统/Git","permalink":"https://me.obey.fun/categories/前端/版本控制系统/Git/"}],"tags":[{"name":"Github","slug":"Github","permalink":"https://me.obey.fun/tags/Github/"},{"name":"Git","slug":"Git","permalink":"https://me.obey.fun/tags/Git/"}],"keywords":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"},{"name":"版本控制系统","slug":"前端/版本控制系统","permalink":"https://me.obey.fun/categories/前端/版本控制系统/"},{"name":"Git","slug":"前端/版本控制系统/Git","permalink":"https://me.obey.fun/categories/前端/版本控制系统/Git/"}]},{"title":"Markdown基本语法","slug":"Markdown基本语法","date":"2018-12-22T13:59:58.000Z","updated":"2019-05-04T12:46:36.865Z","comments":true,"path":"Markdown基本语法.html","link":"","permalink":"https://me.obey.fun/Markdown基本语法.html","excerpt":"","text":"MarkdownMarkdown介绍Markdown是一种轻量级的标记语言，使用普通的文本编辑器，通过简单的标记语法，就可以实现漂亮的排版，被越来越多的写作爱好者、程序员所使用。Markdown自成格式，不依赖任何编辑器，且易于传播，其语法十分简单，通过几分钟的简单学习，就可以实现基本的排版，然后专注于码字。用途Markdown的语法简洁明了、学习容易，而且功能比纯文本更强，因此有很多人用它写博客。世界上最流行的博客平台WordPress和大型CMS如Joomla、Drupal都能很好的支持Markdown。完全采用Markdown编辑器的博客平台有Ghost和Typecho。用于编写说明文档，并且以“README.MD”的文件名保存在软件的目录下面。除此之外，由于我们有了RStudio这样的神级编辑器，我们还可以快速将Markdown转化为演讲PPT、Word产品文档、LaTex论文甚至是用非常少量的代码完成最小可用原型。在数据科学领域，Markdown已经广泛使用，极大地推进了动态可重复性研究的历史进程。常用语法常用语法表格输出后的效果Markdown快捷键加粗**text**Ctrl+B斜体*text*Ctrl+I链接[title](http://)Ctrl+L代码块`code`Ctrl+k图片![alt](http://)Ctrl+G有序列表1. itemCtrl+Shift+O无序列表* itemCtrl+U块级引用> quoteCtrl+Q一级标题# HeadingCtrl+1二级标题## HeadingCtrl+2标题在想要设置为标题的文字前面加#来表示一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。注意：每个#后面必须跟一个空格示例：123#### 这是四级标题##### 这是五级标题###### 这是六级标题效果如下：这是四级标题这是五级标题这是六级标题字体加粗要加粗的字体左右分别用两个*号包起来斜体要倾斜的文字左右分别用一个*号包起来斜体加粗要倾斜和加粗的文字左右分别用三个*号包起来删除线要加删除线的文字左右分别用两个~~号包起来代码示例:1234**这是加粗的文字***这是倾斜的文字****这是斜体加粗的文字***~~这是加删除线的文字~~有序无序列表有序列表通过数字1234567…后面加一个.和空格实现。无序列表通过*,-,+其中之一加一个空格来实现无序列表。代码示例：1234567891011121. 我是有序列表* 我是由*号生成无序列表* 我是由*号生成无序列表* 我是由*号生成无序列表2. 我是有序列表- 我是由-号生成无序列表- 我是由-号生成无序列表- 我是由-号生成无序列表3. 我是有序列表+ 我是由+号生成无序列表+ 我是由+号生成无序列表+ 我是由+号生成无序列表效果如下：我是有序列表我是由*号生成无序列表我是由*号生成无序列表我是由*号生成无序列表我是有序列表我是由-号生成无序列表我是由-号生成无序列表我是由-号生成无序列表我是有序列表我是由+号生成无序列表我是由+号生成无序列表我是由+号生成无序列表块级引用在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;n个…示例：123&gt;这是引用的内容&gt;&gt;这是引用的内容&gt;&gt;&gt;这是引用的内容效果如下：这是引用的内容这是引用的内容这是引用的内容代码块单行代码块通过`code`来展示单行代码块内容示例：`I’m single code.`效果如下：I&#39;m single code.多行代码块通过```code```来展示多行代码块内容示例：```Python(指定语言)def example():&emsp;&emsp;for i in range(10):&emsp;&emsp;&emsp;&emsp;print(“hello”)```效果如下：123def example(): for i in range(10): print(\"hello\")图片语法：![图片alt](图片地址 ‘’图片title’’)图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加示例：1![头像](https://ws3.sinaimg.cn/large/006MOU0zgy1g19n0u9anzj30jg0kbabt.jpg \"头像icon\")效果如下：链接语法：[超链接名](超链接地址 “超链接title”)title可加可不加示例：12[baidu](http://baidu.com)[博客](https://www.52share.online)效果如下：baidu博客表格语法：123456:---:|:---:|文字居中显示:---|:---文字靠左显示---:|---:文字靠右显示示例：123456789101112131415161718示例1：表格文字居中|表格文字居中|表格文字居中:---:|:---:|:---:文字居中|文字居中|文字居中文字居中|文字居中|文字居中示例2：表格文字靠左|表格文字靠左|表格文字靠左:---|:---|:---文字靠左|文字靠左|文字靠左文字靠左|文字靠左|文字靠左示例3：表格文字靠右|表格文字靠右|表格文字靠右---:|---:|---:文字靠右|文字靠右|文字靠右文字靠右|文字靠右|文字靠右示例1：表格文字居中表格文字居中表格文字居中文字居中文字居中文字居中文字居中文字居中文字居中示例2：表格文字靠左表格文字靠左表格文字靠左文字靠左文字靠左文字靠左文字靠左文字靠左文字靠左示例3：表格文字靠右表格文字靠右表格文字靠右文字靠右文字靠右文字靠右文字靠右文字靠右文字靠右","categories":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"}],"tags":[{"name":"Markdown","slug":"Markdown","permalink":"https://me.obey.fun/tags/Markdown/"}],"keywords":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"}]},{"title":"长难句分析（特殊结构的长难句）","slug":"长难句分析（特殊结构的长难句）","date":"2018-12-16T13:31:10.000Z","updated":"2018-12-16T13:35:51.196Z","comments":true,"path":"长难句分析（特殊结构的长难句）.html","link":"","permalink":"https://me.obey.fun/长难句分析（特殊结构的长难句）.html","excerpt":"","text":"二、特殊结构的长难句分裂结构嵌套结构平行结构特殊结构的长难句：分裂结构There is growing fear among vice-chancellors that this revenue——as well as the cultural, academic and economic benefit international students bring——is being put at risk.(CET-4, 201312 仔细阅读2)There is growing fear among vice-chancellors that this revenue is being put at risk.(CET-4, 201312 仔细阅读2)特殊结构的长难句：嵌套结构Among the government’s most interesting reports is one that estimates what parents spend on their children.(CET-6, 201312 仔细阅读 1)A survey of 439 medical technicians found that 55 percent of technicians who monitor bypass machines acknowledged that they had talked on cellphones during heart surgery.(CET-4,201406 仔细阅读 1)A sunrvey … found &emsp;&emsp;&emsp;&emsp;宾语从句 &emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp; &emsp;&emsp;定语从句&emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp; &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;定语从句that 55 percent of technicianswho monitor bypass machinesacknowledgedthat they had..特殊结构的长难句：平行结构The English, the Germans, the Dutch and the French were investing in Britain’s former colony.The English,the Germans,the Dutchand the Frenchwere investing in Britain’s former colony.Both areas are critical to producing citizens who can participate effectively in our democratic society, become innovative leaders, and benefit from the spiritual enrichment that teh reflection on the great ideas of mankind over time provides.(CET-4, 201406 仔细阅读 1)Several hours after a meal, people’s hunger levels were predicted not by how much they’d eaten but rather by how much food they’d seen in front of them…(CET-4, 201312 仔细阅读 1)But brains are the superior choice when you want information to change, in interesting and useful ways: to connect up with other facts and ideas, to acquire successive layers of meaning, to steep for a while in your accumulated knowledge and experience…(CET-6, 201406 仔细阅读 1)长难句综合运用indeed, according to surveys, employers have expressed a preference for students who have received a broadly-based education that has taught them to write well, think critically, research creatively and communicate easily.(CET-4, 201406 仔细阅读 1)Cole and Fredrickson found that people who are happy but have little to no sense of meaning in their lives have the same gene expression patterns as people who are responding to and enduring chronic adversity.(CET-6, 201412 长篇阅读)","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"长难句分析（基本结构的长难句）","slug":"长难句分析（基本结构的长难句）","date":"2018-12-15T12:58:51.000Z","updated":"2018-12-15T13:03:30.115Z","comments":true,"path":"长难句分析（基本结构的长难句）.html","link":"","permalink":"https://me.obey.fun/长难句分析（基本结构的长难句）.html","excerpt":"","text":"一、基本结构的长难句断开简化基本结构的长难句&emsp;长难句&emsp;多个句子/多件事&emsp;简单句&emsp;一个句子/一件&emsp;简单句的核心&nbsp;一件事的核心内容断开1 标点&emsp;2 连接词&emsp;&emsp;3 分析主谓简化1 定位谓语动词2 去修饰找核心基本结构的长难句：1. 断开（1）标点（2）连接词：从句开始于连接词，结束于？（3）分析主谓&emsp;1) 标点&emsp;2) 下一个连接词前&emsp;3) 第二个谓语动词前连接词断开，结束于标点But this is a real-life argument before a Superme Court that has a well-earned reputation for looking out for the interests of large corporations.(CET-6,201312 仔细阅读 2)If it has to hire a caregiver for every two children,it can’t really achieve any economics of scale on labor to save money when other expenses go up.(CET-4,201412 仔细阅读 1)More than half of all recent graduates are unemployed or in jobs that do not require a degree, and the amount of student-loan debt carried by households has increased more than five times since 1999.(CET-4,201312 长篇阅读)Imagine the number of teaching jobs that might be eliminated if this could be done for math,economics,chemistry,and so on.(CET-6,201406 长篇阅读)Although it has been nearly 30 years since the first commercial mobile-phone network was launched, advertisers have yet to figure out how to get their messages out to mobile-phone users in a big way.(CET-4,201312 选词填空)连接词断开，结束于第二个谓语动词前Those who stay on for an additional two years can earn a master’s degree that qualifies them as nurse practitioners or clinical nurse spercialists.(CET-4,201312 选词填空)People who score on personality tests as more sympathetic cry more than those who are more rigid or have more self-control.(CET-4,201406 长篇阅读)Though the United States has fewer women in the workforce, American women who choose to be employed are far more likely to work full-time and to hold high-level jobs as managers or professionals.(CET-6,201406 长篇阅读)断开：分析主谓This is the best movie I have seen.The present he gave me was very amazing.Some scientists maintain that the changes we are seeing fall within the range of random variation…(CET-4,201406 选词填空)Some scientists maintain thatthe changes we are seeing fall within the range of random variation…(CET-4,201406 选词填空)When these students encounter a new problem of the same type on a test, they’re able to transfer the knowledge they’ve gathered more effectively than those who were the passive recipients of someone else’s expertise.(CET-6,201312 仔细阅读 1)二、简化：去修饰，留核心修饰成分有：形容词、副词介词短语非谓语动词(doing/done/to do)冠词、数词非限定性定语从句Over the past few months it has been working hard, with the help of media consultants, to play down its cosy reputation in favour of something more academic and serious(CET-6,201412 仔细阅读 2)Printing with moveable type on paper dramatically reduced the cost of producing a book compared with the old-fashioned ones handwritten on vellum, which comes from sheepskin.(CET-4,201406 长篇阅读)A generation ago, female faces were rare and, even today, visitors walking through the first floor of LeConte Hall will see a full corridor of exhibits honoring the many distinguished physicists who made history here,virtually all of them white males.(CET-4,201312 选词填空)基本结构的长难句：断开 + 简化The same dramatic technological changes that have provided marketers with more communications choices have also increased the risk that passionate consumers will voice their opinions in quicker, more visible, and much more damaging ways.The same dramatic technological changes 1 have also increased the risk 2.that have provided marketers with more communications choices.that passionate consumers will voice their opinions in quicker, more visible, and much more damaging ways.","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"特殊用途的句子(虚拟句)","slug":"特殊用途的句子-虚拟句","date":"2018-12-14T14:44:35.000Z","updated":"2018-12-15T13:00:47.598Z","comments":true,"path":"特殊用途的句子-虚拟句.html","link":"","permalink":"https://me.obey.fun/特殊用途的句子-虚拟句.html","excerpt":"","text":"第三章 虚拟1. 什么是虚拟？2. 怎么表示虚拟？3. 虚拟常用于？1. If 虚拟条件句（虚拟语气）&emsp;（1）虚拟条件句（假设现在）&emsp;If 从句主句假设过去&emsp;would假设现在did(were)could/should&emsp;&emsp; + do假设将来&emsp;mightIf I were you, I would do it now.练习：I am not you, so I can’t make the decision.I don’t know his phone number, so I won’t ring him up.He isn’t free at the moment, so he won’t go to the cinema.补充：If I could rearrange the alphabet, I would put U and I together.&emsp;（2）虚拟条件句（假设过去）&emsp;If 从句主句假设过去had donewould + have done假设现在&emsp;could/should假设将来&emsp;mightIf they had won the match, they would have held a party to celebrate.练习：He was not a student, so he couldn’t attend the lecture.He didn’t tell her the answer. She didn’t understand it.You were late, so you didn’t hear what he told us.&emsp; （3）虚拟语气（假设将来）&emsp;If 从句主句假设过去&emsp;would假设现在&emsp;could/should假设将来did(were)were to doshould domight + doIf I were to live my life over again, I would have you as my life.练习：如果我明天有时间，我就会帮他。（明天不太可能有时间）If I had time tomorrow（were to have/should have）,I would help him.总结：&emsp;If 从句主句假设过去had donewould + have done假设现在did(were)could/should + do假设将来did(were)were to doshould domight + doIf 非真实条件句（混合时态的虚拟）&emsp;If 从句主句假设过去&emsp;&emsp;假设现在&emsp;&emsp;假设将来&emsp;&emsp;如果你（过去）嫁给他，你（现在）就会是一个加油站服务员的妻子。If you had married him, you would be the wife of a gas station attendant.省略 If 的虚拟条件句If you had joined us, we would have had more fun.If I were you, I would think it twice.2. 名词性从句的虚拟语气：表示“建议，要求，命令”动词后的宾语从句虚拟从句中用（should）+ doHe suggested that the system should be changed.suggest, advise, propose, recommend, order, ask, demand, insist, require, request……练习：宾语从句的虚拟语气The engineers proposed they (look) at the design again.He insisted that she (send) her sister to a dancing school.The workers demanded they (give) the wages they should get.He ordered they (start) the attack before dawn.The teacher always suggests the students (go) over the text before the best.the professor recommended we (look) for the information in the library.总结：表示 “建议，要求，命令” 的名词性从句He suggested that the system should be changed.His suggestion was that the system should be changed.He gave the suggestion that the system should be changed.This year,it was suggested that the system should be changed.","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"特殊用途的句子(倒装句)","slug":"特殊用途的句子-倒装句","date":"2018-12-13T14:15:08.000Z","updated":"2018-12-13T14:17:58.610Z","comments":true,"path":"特殊用途的句子-倒装句.html","link":"","permalink":"https://me.obey.fun/特殊用途的句子-倒装句.html","excerpt":"","text":"第二章 倒装全部倒装/部分倒装1. 全部倒装：In the mountain lies a castle.Here comes the bus.全部倒装：There be 句型1. There be + n. “有”（客观存在）There is a girl.2. There be + n + 介词短语 “有…在哪里”（客观存在）There is a book on the table.There is no gap between mind and matter.注意：1）be 动词的变化&emsp;&emsp;&emsp;&emsp;&nbsp; There will now be a seven-day wait for jobseeker’s allowance.&emsp;&emsp;&emsp;2）主语的单复数&emsp;&emsp;&emsp;3）There 还可以与情态动词搭配&emsp;&emsp;&emsp;&emsp;&nbsp; There may be more matches in the database.2. 部分倒装：相当于把陈述句变成疑问句三种情况需要倒装（1）否定词位于句首&emsp;not, no, never, hardly, little, scarcely, seldom, not until, not only……（2）only 位于句首（3）虚拟if条件句举例：The poor man had not only been arrested but he had been sent to prison as well.Not only had the poor man been arrested, but he had been sent to prison as well.We can learn English well only in this way.Only in this way can we learn English well.练习：1. You will never know the truth.Never .2. He cares little for my words.Little .3. I had no sooner got the invitation than I refused.No sooner .4. He had hardly had time to settle down when he left the country.Hardly .5. He achieved his goal only by working hard.Only by working hard .6. Natural disasters will reduce, only when we solve the problems of environmental pollution.Only when .","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"特殊用途的句子(强调句)","slug":"特殊用途的句子-强调句","date":"2018-12-12T09:37:35.000Z","updated":"2018-12-12T09:51:39.056Z","comments":true,"path":"特殊用途的句子-强调句.html","link":"","permalink":"https://me.obey.fun/特殊用途的句子-强调句.html","excerpt":"","text":"第一章 强调强调句It is ….. that …..I want to go to America this summer.It is America that I want to go to this summer.补充：强调过去时态：It was …. that …强调人时：It is …. that/who …练习：It is they. not American, who have become anti-intellectual.It is they who have become anti-intellectual.It is … that …写作：Lisa likes cooking at home.We used to have meetings in the cafe.They celebrated the holiday on Nov.11th.Students don’t like too much homework.Men can solve the problems of natural disaster only by controlling the environmental pollution.注意：一个句子的动词和形容词不能强调。","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的补充(复合句/状语从句)","slug":"简单句的补充-复合句-状语从句","date":"2018-12-10T14:10:39.000Z","updated":"2018-12-16T13:41:29.656Z","comments":true,"path":"简单句的补充-复合句-状语从句.html","link":"","permalink":"https://me.obey.fun/简单句的补充-复合句-状语从句.html","excerpt":"","text":"第三章 状语从句1.状语从句的含义：一个句子作状语，表达描述性的信息。2.状语从句的写法：从属连词 + 完整的陈述句&emsp;从属连词时间状语从句when, while, as, before, after, since, until&emsp;as soon as, no sooner…than地点状语从句where原因状语从句because, since, as结果状语从句so/such…that, so that…目的状语从句so that…,in order that条件状语从句if, unless, as long as让步状语从句although, though, even though, as比较状语从句than, as方式状语从句as地点状语从句Stay where you are.Where there is a will, there is a way.结果状语从句The problem is so complicated that we cannot solve it.It is such a complicated problem that we cannot solve it.让步状语从句Although it is summer, it is very cold.It is summer, but it is very cold.比较状语从句I am as tall as you.I am as tall as you(are).方式状语从句Do it as I told you yesterday.When in Rome, do as Romans do.3.状语从句的时态：时间/条件状语从句中表示将来，要换成一般现在时。如果明天下雨，我们就不去公园。If it rains tomorrow, we will not go for a picnic.I will let him know, when he comes home later.改错练习：The boss will review your work after she will return from vacation next week.(returns)I’ll give you a call on my cell phone as soon as my plane will land .(lands)I don’t like my current job, but I’m going to stay with this company until I will find something better.(find)If it won’t be cold tomorrow. we’ll go to the beach.(isn’t)If it will be cold tomorrow, we will go to a movie.(is)4.状语从句的位置：If it rains tomorrow, we will not go to the park.We will not go to the park, If it rains tomorrow.We, If it rains tomorrow, will not go to the park.练习：He speaks English well indeed, but of course not _ a native speaker.A. as fluent as &emsp;&emsp;&emsp;&emsp;B. more fluent thanC. as fluently as &nbsp;&emsp;&emsp;&emsp;D. much fluently thanThe couple had no sooner got to the station _ the coach left.A. when &emsp;&emsp;B. as &emsp;&emsp;C. until &emsp;&emsp;D. thanMy parents don’t mind what job I do _ I am happy.A. even though &emsp;B. as soon as &emsp;C. as long as &emsp;D. as thoughThe medicine works more effectively _ you drink some hot water after taking it.A. as &emsp;&amp;emspB. until &emsp;&emsp;C. although &emsp;&emsp;D. if__ the police thought he was the most likely one, since they had no exact proof about it,they could not arrest him.A. Although &emsp;B. As long as &emsp;C. If only &emsp;D. As soon asIt just isn’t fair. __ I was working as a waiter last month, my friends were lying on the beach.A. whenever &emsp;B. though &emsp;C. for &emsp;D. whileShall we have our picnic tomorrow?_ it doesn’t rain.A.Until &emsp;&emsp;B. While &emsp;&emsp;C. Once &emsp;&emsp;D. IfThe Great Wall is _ tourist attraction that millions of people pour in every year.A. so a well-known &emsp;&emsp;&emsp;B. a so well-knownC. such well-known a &emsp;&emsp;D. such a well-knownOwen wouldn’t eat anything _ he cooked it himself.A. until &emsp;&emsp;B. since &emsp;&emsp;C. unless &emsp;&emsp;D. while答案1.C 2.D 3.C 4.D 5.A 6.D 7.D 8.D 9.C","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的补充(复合句/定语从句)","slug":"简单句的补充-复合句-定语从句","date":"2018-12-07T14:33:54.000Z","updated":"2018-12-10T08:25:02.792Z","comments":true,"path":"简单句的补充-复合句-定语从句.html","link":"","permalink":"https://me.obey.fun/简单句的补充-复合句-定语从句.html","excerpt":"","text":"第二章 定语从句1. 定语从句的含义：一个句子作定语，去修饰限定名词。2. 定语从句的写法：先把主句和从句写出两个句子，再把从句合并进去修饰限定名词。This is the 我梦想很多年的 job.This is the job. I have dream of the job for years.This is the job Which I have dreamed of for years.&emsp;&emsp;&emsp;&emsp;&emsp;↓&emsp;&emsp;&emsp;↓&emsp;&emsp;先行词 关系词&emsp;&emsp;关系词如何选择？&emsp;&emsp;&emsp;&emsp;看先行词！&emsp;先行词 = ？物人人的/物的时间地点原因&emsp;关系词 = ？which/thatwho/whom/thatwhosewhenwherewhy练习关系词的选择：1. I have a class begins at 8:00 am.2. The lawyer my brother called didn’t answer the phone.3. My daughter asked me a question I couldn’t answer.4. The people sat in the stadium cheered for the home team.5. Leo is the student bike was stolen.6. Australia is one of the few countries people drive on the left.7. Sunday is the day people usually don’t go to work.8. Is there any particular reason you can’t come?答案1. which/that 2. 不填/whom/that 3. 不填/that/which 4. who5. whose 6. where 7. when 8. why练习写定语从句1. I lost the book .&emsp;我弄丢了上周从图书馆借的书。2. The woman was feeding pigeons.&emsp;我在公园看见的那位女士正在喂鸽子。3. The bus is usually very crowed.&emsp;我每天上学坐的那辆公交车总是很拥挤。答案1. which/that/不填 I borrowed from the library 2. who/that/whom/不填 I saw in the park 3. which/that/不填 I take every day to school3. 定语从句的分类：I met your friend who is staying in Paris.&emsp;&emsp;&emsp;&emsp;限定性定语从句I met your mother,who is staying in Paris.&emsp;&emsp;&emsp;&nbsp;非限定性定语从句This is the wall which they built last week.This is the Great Wall, which is world-famous.练习（填入逗号和关系词）:1. He came from Beijing is the capital of China.(,which)2. He came from a city is in the north of China.(which/that)3. This is the businessman we are cooperating with.(who/whom/that/不填)4. This is Bill Gates many people know as the richest amn.(,whom)注意：非限定性定语从句不仅可以修饰前面的名词，还可以修饰前面的整句话。The company will get back to you in three days,which is one of the typical rules.补充：介词提前的定语从句This is the job which/that/X I have dreamed of for years.This is the job of which I have dreamed of for years.Humans have the ability to modify the environment in which they live.The theory on which it is based may be right.","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的补充(复合句/名词性从句)","slug":"简单句的补充-复合句-名词性从句","date":"2018-12-06T14:15:41.000Z","updated":"2018-12-10T08:25:12.446Z","comments":true,"path":"简单句的补充-复合句-名词性从句.html","link":"","permalink":"https://me.obey.fun/简单句的补充-复合句-名词性从句.html","excerpt":"","text":"第一章 名词性从句一、宾语从句1. 宾语从句的含义：一个句子作宾语，放在另一个句子（主句）里。2. 宾语从句的写法：&emsp;① 陈述句变成宾语从句？You are right.&emsp;&emsp;&emsp;&emsp;↓&emsp;&emsp;&emsp;&emsp;&emsp;I know __.I know (that) you are right.&emsp;② 特殊疑问句变成宾语从句？What will she say?&emsp;&emsp;&emsp;&emsp;↓&emsp;&emsp;&emsp;I know _.I know what she will say.&emsp;③ 一般疑问句变成宾语从句？Is he happy?&emsp;&emsp;&emsp;&emsp;↓&emsp;&emsp;&emsp;&emsp;&emsp;I know __.I know whether/if he is happy.总结：宾语从句的写法____ + ___&emsp;&emsp;(词 + 陈述句)练习：填入宾语从句的连接词1. 我承诺我会帮助你。&emsp;I promise I will help you.2. 你从来没告诉过我，你对我电脑做了什么。&emsp;You never told me you had done to my computer.3. 我想知道什么时候我们将会出发。&emsp;I wonder we will set out.4. 他们不知道他们是否会按时完成工作。&emsp;They don’t know they will finish the work on time.5. 你能告诉我什么时候我们将会出发吗？&emsp; Can you tell me ?答案1. that 2. what 3. when 4. whether 5. when we’ll set out3.宾语从句的位置：名词性从句：6. we know *.7. The big news is *.8. * is big news.9. We know the big news *.宾语从句：1. I don’t know when you will finish the work.No one tells me when you will finish the work.2. I worry about whether I hurt her feelings.3. Are you positive (that) you’ve never seen that man before.二、表语从句My concern is that people don’t care about others.The question remains whether people will buy it.三、同位语从句一个句子作同位语，解释说明 n.位置：需要解释的抽象 n.后。(fact, idea, news, dream, suggestion, advice, report …)最常用的是：“that+陈述句”这种 (注意： that不作成分，但不能省略)我不怀疑他将会帮我的忙。I have no doubt that he will help me.我支持这种论据, 校车问题必须被严肃对待。I support the argument that the problems of school buses must be taken seriously.四、主语从句我们是否将会去露营取决于天气。位置1：句首Whether we will go camping depends on the weather.位置2：句尾(句首用形式主语it)It depends on the weather whether we will go camping.注意：两种位置，意思相同。但更常用的是位于句尾的主语从句。练习： 填入连接词， 并判断是哪种名词性从句。1. ____ Barbara Jones offers to her fans is honesty and happiness.A. Which &emsp;&emsp;B. What &emsp;&emsp;C. That &emsp;&emsp;D. Whom2. We’ve offered her the job, but I don’t know ___ she’ll accept it.A. where &emsp;&emsp;B. what &emsp;&emsp;C. whether &emsp;&emsp;D. which3. Our teachers always tell us to believe in __ we do and who we are if we want to succeed.A. why &emsp;&emsp;B. how &emsp;&emsp;C. what &emsp;&emsp;D. which4. Modern science has given clear evidence ___ smoking can lead to many diseases.A. what &emsp;&emsp;B. which &emsp;&emsp;C. that &emsp;&emsp;D. where5. It was never clear ____ the man hadn’t reported the accident sooner.A. that &emsp;&emsp;B. how &emsp;&emsp;C. when &emsp;&emsp;D. why6. It is still under discussion ___ the old bus station should be replaced with a modern hotel or not.A. whether &emsp;&emsp;B. when &emsp;&emsp;C. which &emsp;&emsp;D. where7. I am afraid he’s more of a talker than a doer, which is ___ he never finishes anything.A. that &emsp;&emsp;B. when &emsp;&emsp;C. where &emsp;&emsp;D. why8. These wild flowers are so special that I would do __ I can to save them.A. whatever &emsp;&emsp;B. which &emsp;&emsp;C. that &emsp;&emsp;D. whichever答案1. B 主语从句 &emsp; 2. C 宾语从句 &emsp; 3. C 宾语从句 &emsp; 4. C 同位语从句5. D 主语从句 &emsp; 6. A 主语从句 &emsp; 7. D 表语从句 &emsp; 8. A 宾语从句","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的补充(并列句)","slug":"简单句的补充-并列句","date":"2018-12-05T13:53:28.000Z","updated":"2018-12-10T08:24:53.130Z","comments":true,"path":"简单句的补充-并列句.html","link":"","permalink":"https://me.obey.fun/简单句的补充-并列句.html","excerpt":"","text":"一、并列句的构成多件事（多个简单句）之间同等重要，用并列连词连接起来。四六级常用的并列连词有：1）&emsp;&emsp;&emsp;表示顺接：…and…;both…and…;not only…,but…as well/but also…2）&emsp;&emsp;&emsp;表示转折：but;yet;while3）&emsp;&emsp;&emsp;表示选择：…or…;either…or…;neither…nor…4）&emsp;&emsp;&emsp;表示因果：…for…（原因）;…so…（结果）二、并列句的省略I am a teacher and I like English.I am a teacher and like English.I am lying in bed and I am reading a book.I am lying in bed and reading a book.I want to leave and I want to go abroad.I want to leave and to go abroad.and(平行结构)练习1. You can stay at home go out to play. It doesn’t matter.A.either,or&emsp;&emsp;B.neither,nor&emsp;&emsp;C.both,and&emsp;&emsp;D.not only,but also2. We bought her a birthday present,_ she likes it very much.A.so&emsp;&emsp;&emsp;B.or&emsp;&emsp;&emsp;C.and&emsp;&emsp;&emsp;D.but3. _ you _ he is able to ski,but I am.A.both,and&emsp;&emsp;B.either,or&emsp;&emsp;C.neither,nor&emsp;&emsp;D.between,and4. The doctor tried their best to save the patient’s life,_failed.A.or&emsp;&emsp;B.so&emsp;&emsp;C.but&emsp;&emsp;D.because5. I could speak _ Japanese _ Chinese,so I had to talk with him in English.A.not only,but also&emsp;&emsp;B.both,and&emsp;&emsp;C.neither,norD.either,or6. I like pop music,but _ my father _ my mother likes it.A.both,and&emsp;&emsp;B.either,or&emsp;&emsp;C.neither,nor&emsp;&emsp;D.not only,but also7. Tom,keep away from the fire, you will get burnt.A.and&emsp;&emsp;B.so&emsp;&emsp;C.or&emsp;&emsp;D.but8. I thought we’d be late for the concert,__ we ended up getting there ahead of time.A.but&emsp;&emsp;B.or&emsp;&emsp;C.so&emsp;&emsp;D.for答案：第一题A第二题C第三题C第四题C第五题C第六题C第七题C第八题A","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的核心变化（同位语/插入语）","slug":"简单句的核心变化（同位语-插入语）","date":"2018-12-04T12:22:05.000Z","updated":"2018-12-10T08:25:50.234Z","comments":true,"path":"简单句的核心变化（同位语-插入语）.html","link":"","permalink":"https://me.obey.fun/简单句的核心变化（同位语-插入语）.html","excerpt":"","text":"三、同位语/插入语同位语，解释说明前面名词，与名词相同，说的是一件事。My teacher,Mr. Lee,is coming to the meeting.插入语，插入的补充说明，与前后无关。My teacher,together with his colleagues,is coming to the meeting.All their lives, today’s young women have been pushed to embrace both perfection and passion to pursue science and sports,math and theater and do it all as well as they possibly can.2014.06 CET4Confronted with such facts, some Swedish activists and legislators are demanding more extreme and far-reaching measures,such as replacing male and female pronouns with neutral alternative and monitoring children more closely to correct them when they gravitate toward gendered play.2014.06 CET6","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的补充（非谓语动词）","slug":"简单句的补充（非谓语动词）","date":"2018-12-03T13:58:09.000Z","updated":"2018-12-16T13:45:45.110Z","comments":true,"path":"简单句的补充（非谓语动词）.html","link":"","permalink":"https://me.obey.fun/简单句的补充（非谓语动词）.html","excerpt":"","text":"二、非谓语动词非谓语动词共3种doing表示主动done表示被动to do表示目的Passing planes can be heard night and day.The teacher came into the classroom,holding a book in his hand.He bought a used car.The teacher came into the classroom, followed by five students.I have a lot of homework to do.I am coming to see you.练习：_, you need to give all you have and try your best.A. Being a winner &emsp;&emsp;&emsp;B. To be a winnerC. Being a winner&emsp;&emsp;&emsp;D. Having been a winner_ into English, the sentence was found to have an entirely different word order.A. Translating&emsp;&emsp;&emsp;&nbsp;B. TranslatedC. To translate&emsp;&emsp;&emsp;D. Having translatedPeter received a letter just now _his grandma would come to see him soon.A. said&emsp;&emsp;&emsp;&emsp;&nbsp;B. saysC. saying&emsp;&emsp;&emsp;D. to say_ an important role in a new movie, Andy has a chance to become famous.A. Offer&emsp;&emsp;&emsp;&emsp;&nbsp;B. OfferingC. Offered&emsp;&emsp;&emsp;D. To offerThe island, __ to the mainland by a bridge,is easy to go to.A. joining&emsp;&emsp;&emsp;B. to joinC. joined&emsp;&emsp;&emsp;D. having joined","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的补充(限定词/形容词/介词短语)","slug":"简单句的补充-限定词-形容词-介词短语","date":"2018-12-02T14:34:56.000Z","updated":"2018-12-10T08:25:23.493Z","comments":true,"path":"简单句的补充-限定词-形容词-介词短语.html","link":"","permalink":"https://me.obey.fun/简单句的补充-限定词-形容词-介词短语.html","excerpt":"","text":"一、限定词/形容词/介词短语Girls play games.Girls are playing games.Lovely girls are playing games happily.Thousands of Lovely girls are playing games very happily.After class thousands of Lovely girls are playing games very happily on the playground.常见介词prep. :in on at / from to / into onto / with without / of / by / for / about其他介词 :before after / since until / during / between among / across through / against / like as","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的核心变化（主语/宾语/表语的变化）","slug":"简单句的核心变化（主语-宾语-表语的变化）","date":"2018-12-01T14:44:37.000Z","updated":"2018-12-10T08:26:07.920Z","comments":true,"path":"简单句的核心变化（主语-宾语-表语的变化）.html","link":"","permalink":"https://me.obey.fun/简单句的核心变化（主语-宾语-表语的变化）.html","excerpt":"","text":"(二)主语/宾语/表语的变化1. 名词/代词Most graduates always want a big-firm job.She is the leader of the organization.They gave us a good impression.2. doing/to doLaughing probably has great influence on health.To laugh probably has great influence on health.It probably has great influence on health to laugh.Having only a foggy view of the future is of little good.It is no use to talk about dreams without trying.We enjoy reading books in the library.The members of the board decide to vote against the new plan.Our main goal is to finish the task on time.3. 多个并列Science and technology will develop the process of society.Social science disciplines include geography, economics, political science, and psychology.That doesn’t mean sitting down and doing nothing at all.&emsp;&emsp;n. + v.名词/代词&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;动词的时态doing&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;动词的语态to do&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;动词的情态多个并列&emsp;&emsp;&emsp;&emsp;&nbsp;&nbsp;&nbsp;&nbsp;动词的否态","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的核心变化（情态）","slug":"简单句的核心变化（情态）","date":"2018-11-30T12:47:34.000Z","updated":"2018-12-15T14:07:19.892Z","comments":true,"path":"简单句的核心变化（情态）.html","link":"","permalink":"https://me.obey.fun/简单句的核心变化（情态）.html","excerpt":"","text":"3. 情态用法：情态动词 + 动词原型情态动词的人称变化无情态动词的动态变化有限情态动词变否定/疑问四六级常用的情态动词有：&emsp;现在时&emsp;&emsp;过去时&emsp;must无cancouldwillwouldshallshouldmaymightmust “必须” &emsp;can/could“能够，可以”&emsp;will/would“愿意/将要”may/might“可以，可能”&emsp;should“应该”1 情态动词表示情态We must finish the work within a week.Air pollution must be taken seriously.The government can solve the problem of water pollution.Tony could walk when he was only one year old.Will you marry me?I will travel abroad with my family.Potential buyers would cheer for lower interest rates.To some extent.expressions may influence emotions.Such bodily reaction might help moderate the work stress.Students should work hard to pass the exams.Those sick people should seek help from doctors.2 情态动词表示推测The details may be unknowable.Such searches must take years.The loss of patience can potentially have a damaging impact on our professional and personal wellbeing.The way of saying those things may have led to misunderstanding.Now something similar could be happening in the South Africa.练习：In order to be a good salesclerk, you (must not/will not) be rude to a customer.This pie is very good. You (should/must)try a piece.Rice (should/must/may) have water in order to grow.Don’t be nervous. I think you (can/must) make it.I am not sure. Probably he (may/should) come later.第一题1.must not第二题2.should第三题3.must/should第四题4.can第五题5.may","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的核心变化（语态）","slug":"简单句的核心变化（语态）","date":"2018-11-29T14:28:19.000Z","updated":"2018-12-10T08:25:56.817Z","comments":true,"path":"简单句的核心变化（语态）.html","link":"","permalink":"https://me.obey.fun/简单句的核心变化（语态）.html","excerpt":"","text":"2.语态n. + v.动词的时态动词的语态动词的情态谓语动词的变化–&gt;语态被动语态狗吃了那个蛋糕。The dog ate the cake.?吃了那个蛋糕。—-&gt;蛋糕被吃了。狗吃了那个蛋糕。主语&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;宾语蛋糕被狗吃了。被动适用范围 1：及物动词。 2：不及物动词+介词。被动语态 be + done备注：be表示被动的时间 (把be变成对应的各种形态), 还表达主语单复数。done 表示被动的动作教师每天都打扫。Classrooms are cleaned(clean) every day.一座新的大楼去年建造的。A new building was built(build) last year.与时态相结合被动语态&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;be + done他每天被打。&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;He is beaten every day.他昨天被打了。&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;He was beaten yesterday.他明天将要被打。&emsp;&emsp;&emsp;&emsp;&emsp;He will be beaten tomorrow.他现在正在被打。&emsp;&emsp;&emsp;&emsp;&emsp;He is being beaten.(现在进行时的被动am/is/are + being done)他现在已经被打了。&emsp;&emsp;&emsp;&emsp;He has been beaten.(现在完成时的被动have/has + been done)Our morning paper is read(read) by over 200,000 people every day.Last night my favorite TV program was interrupted(interrupt) by a special news bulletin.His bike will be repaired(repair) by his grandfather tomorrow.The new machine has been used(use) in our factory for two week.与情态动词想结合被动语态&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;be + donePlanes are heard.Planes can be heard.Planes could be heard.Planes may be heard.Planes must be heard.这封信必须马上寄出。The letter must be sent immediately.天气不能被人们所控制。Weather cannot be controlled by people.","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"简单句的核心变化（时态）","slug":"简单句的核心变化（时态）","date":"2018-11-27T02:22:00.000Z","updated":"2018-12-15T13:40:07.582Z","comments":true,"path":"简单句的核心变化（时态）.html","link":"","permalink":"https://me.obey.fun/简单句的核心变化（时态）.html","excerpt":"","text":"二、简单句的核心变化(一)谓语动词的变化&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n. + v.动词的时态动词的语态动词的情态动词的否定1. 时态：时态过去现在将来过去将来一般did/was/weredo/doeswill/am/is/are going to + V.原型would/were/was going to + V.原型进行be + doingbe + doingbe + doingbe + doing完成had + donehave/has+done&emsp;&emsp;完成进行&emsp;have/has been + doing&emsp;&emsp;一般过去时 Simple Past形式：V.过去式(did/was/were)用法：过去的事、过去的动作(无关现在)例子：He was a student.He liked music.She had a boyfriend.变否定或者疑问He was happy.He liked English.He was not happy.He did not like English.Was he happy?Did he like English?What was he?What did he like?补充：&emsp;V.过去式V.过去分词looklookedlookedbuyboughtboughtseesawseeneatateeatenV.过去式&nbsp;&nbsp;&emsp;丨V.过去分词一般过去时&nbsp;&nbsp;丨完成时&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;丨被动语态&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;丨不做谓语一般现在时 Simple Present形式：V.原型/V.第三人称单数(do/does)You like English.He likes English.用法：1.现在经常性习惯性的动作We have the English class every day.He often gets up late.2.现在的状态I am a teacher.We are in China.3.永恒The earth is round.The earth moves around the sun.Knowledge is power.Practice makes perfect.变否定或者疑问He is happy.You like English.He likes English.He is not happy.You do not like English.He does not like English.Is he happy?Do you like English?Does he like English?How is he?What do you like?What does he like?补充：与频率连用(every,once a week,twice a month,three times a …)alwaysusually,often,frequentlysometimes,occasionallyseldom,hardlynever一般将来时 Simple Future形式：Will/am/is/are going to + V.原型用法：将来的事(现在的将来)I will make a new plan tomorrow.We are going to study abroad next year.变否定或者疑问He will leave.He is going to leave.He will not leave.He is not going to leave.Will he leave?Is he going to leave?What will he?What is he going to do?过去将来时 Past Future形式：Would/was/were going to + V.原型用法：将来的事(过去的将来)I said that I would become a cook in the future.Tony finished his work,and then he would leave for London.三种进行时 Progressive TenseAt 10 o’clock yesterday some students were taking an exam in their classrooms.We are taking about the water pollution.A great many candidates will be meeting here at this time tomorrow.现在完成时 Present Perfect Tense形式：have/has + done用法：现在全部完成 He has left.现在部分完成 We have studied English for ten years.过去完成时 Past Perfect Tense形式：had + done用法：过去的之前When he got there,she had left.She was not there.完成进行时 = “完成” + “进行” =**时间的之前，强调进行的过程角度相同都表示“现在的之前”两种时态现在完成时have/has + done现在完成进行时have/has been + doing强调不同强调结果(做完与否都可以)强调过程例句We have not won the match.We have been working hardfor several months.They on the program for almost one week before I joined them, and now we are still working on it as no good results so far.A.have been working;have come outB.had worked;came outC.had been working;have come outD.have worked;are coming out显示答案答案：C","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]},{"title":"Github提交表情指南","slug":"Github表情提交指南","date":"2018-11-26T09:35:51.000Z","updated":"2019-03-03T07:14:14.913Z","comments":true,"path":"Github表情提交指南.html","link":"","permalink":"https://me.obey.fun/Github表情提交指南.html","excerpt":"","text":"Github提交表情指南emojiemoji 代码commit 说明:art:(调色板):art:改进代码结构/代码格式:zap:(闪电):racehorse:(赛马):zap: :racehorse:提升性能:fire:(火焰):fire:移除代码或文件:bug:(bug):bug:修复bug:ambulance:(急救车):ambulance:重要补丁:sparkles:(火花):sparkles:引入新功能:memo:(备忘录):memo:撰写文档:rocket:(火箭):rocket:部署功能:lipstick:(口红):lipstick:更新 UI 和样式文件:tada:(庆祝):tada:初次提交:white_check_mark:(白色复选框):white_check_mark:增加测试:lock:(锁):lock:修复安全问题:apple:(苹果:apple:修复 macOS 下的问题:penguin:(企鹅):penguin:修复 Linux 下的问题:checkered_flag:(旗帜):checked_flag:修复 Windows 下的问题:bookmark:(书签):bookmark:发行/版本标签:rotating_light:(警车灯):rotating_light:移除 linter 警告:construction:(施工):construction:工作进行中:green_heart:(绿心):green_heart:修复 CI 构建问题:arrow_down:(下降箭头):arrow_down:降级依赖:arrow_up:(上升箭头):arrow_up:升级依赖:construction_worker:(工人):construction_worker:添加 CI 构建系统:chart_with_upwards_trend:(上升趋势图):chart_with_upwards_trend:添加分析或跟踪代码:hammer:(锤子):hammer:重大重构:heavy_minus_sign: (减号):heavy_minus_sign:减少一个依赖:whale:(鲸鱼):whale:Docker 相关工作:heavy_plus_sign: (加号):heavy_plug_sign:增加一个依赖:wrench:(扳手):wrench:修改配置文件:globe_with_meridians: (地球):globe_with_meridians:国际化与本地化:pencil2:(铅笔):pencil2:修复 typo","categories":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"}],"tags":[{"name":"Github","slug":"Github","permalink":"https://me.obey.fun/tags/Github/"}],"keywords":[{"name":"前端","slug":"前端","permalink":"https://me.obey.fun/categories/前端/"}]},{"title":"简单句","slug":"简单句","date":"2018-11-25T08:06:50.000Z","updated":"2019-05-04T13:39:17.502Z","comments":true,"path":"简单句.html","link":"","permalink":"https://me.obey.fun/简单句.html","excerpt":"","text":"第一章：简单句的核心一、简单句的核心构成简单句一个句子（一件事）世界是物质的，物质是运动的 n. + v.主语 + 谓语n. + 谓语 v.一主一谓，谓语动词的不同决定简单句的不同构成。例子I swim.I like English区分vt./vi.1)意思2)介词(prep.)I like English.The bride kissed the groom.Birds fly in the sky.We walked on the street yesterday.You look at me.介宾结构They offered me a vacant post.they offered a vacant post to me.I bought you a present.I bought a present for you.I find HongKong ???I find HongKong very beautiful.I find HongKong a place for shopping.我非常高兴。I very happy. ???I am very happy.主系表系动词be动词 （单独）“变得” get become turn go grow感官动词 look sound smell taste feel“看 / 听 / 闻 / 尝 / 感觉起来…..”keep remain/seem appearFor example:I ask you a question. 主谓双宾You answer. 主谓I love you. 主谓宾You make my life complete. 主谓宾补I am happy. 主系表主语 + 谓语 + ?","categories":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}],"tags":[{"name":"English-Syntax","slug":"English-Syntax","permalink":"https://me.obey.fun/tags/English-Syntax/"}],"keywords":[{"name":"英语","slug":"英语","permalink":"https://me.obey.fun/categories/英语/"}]}]}